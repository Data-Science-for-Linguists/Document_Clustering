{"articles": [{"url": "https://en.wikipedia.org/wiki?curid=894", "text": "Agnosticism\n\nAgnosticism is the view that the existence of God or the supernatural is unknown or unknowable.\n\nAccording to the philosopher William L. Rowe, \"agnosticism is the view that human reason is incapable of providing sufficient rational grounds to justify either the belief that God exists or the belief that God does not exist\". Agnosticism is a doctrine or set of tenets rather than a religion.\n\nEnglish biologist Thomas Henry Huxley coined the word \"agnostic\" in 1869.\nEarlier thinkers, however, had written works that promoted agnostic points of view, such as Sanjaya Belatthaputta, a 5th-century BCE Indian philosopher who expressed agnosticism about any afterlife; and Protagoras, a 5th-century BCE Greek philosopher who expressed agnosticism about the existence of \"the gods\". The Nasadiya Sukta in the Rigveda is agnostic about the origin of the universe.\n\nBeing a scientist, above all else, Huxley presented agnosticism as a form of demarcation. A hypothesis with no supporting objective, testable evidence is not an objective, scientific claim. As such, there would be no way to test said hypotheses, leaving the results inconclusive. His agnosticism was not compatible with forming a belief as to the truth, or falsehood, of the claim at hand. Karl Popper would also describe himself as an agnostic. According to philosopher William L. Rowe, in this strict sense, agnosticism is the view that human reason is incapable of providing sufficient rational grounds to justify either the belief that God exists or the belief that God does not exist.\n\nOthers have redefined this concept. George H. Smith, while admitting that the narrow definition of atheist was the common usage definition of that word, and admitting that the broad definition of agnostic was the common usage definition of that word, promoted broadening the definition of atheist and narrowing the definition of agnostic. Smith rejects agnosticism as a third alternative to theism and atheism and promotes terms such as agnostic atheism (the view of those who do not \"believe\" in the existence of any deity, but do not claim to \"know\" if a deity does or does not exist) and agnostic theism (the view of those who do not claim to \"know\" of the existence of any deity, but still \"believe\" in such an existence).\n\n\"Agnostic\" () was used by Thomas Henry Huxley in a speech at a meeting of the Metaphysical Society in 1869 to describe his philosophy, which rejects all claims of spiritual or mystical knowledge.\n\nEarly Christian church leaders used the Greek word \"gnosis\" (knowledge) to describe \"spiritual knowledge\". Agnosticism is not to be confused with religious views opposing the ancient religious movement of Gnosticism in particular; Huxley used the term in a broader, more abstract sense.\nHuxley identified agnosticism not as a creed but rather as a method of skeptical, evidence-based inquiry.\n\nIn recent years, scientific literature dealing with neuroscience and psychology has used the word to mean \"not knowable\".\nIn technical and marketing literature, \"agnostic\" can also mean independence from some parameters—for example, \"platform agnostic\"\nor \"hardware agnostic\".\n\nScottish Enlightenment philosopher David Hume contended that meaningful statements about the universe are always qualified by some degree of doubt. He asserted that the fallibility of human beings means that they cannot obtain absolute certainty except in trivial cases where a statement is true by definition (e.g. tautologies such as \"all bachelors are unmarried\" or \"all triangles have three corners\").\n\n\nAgnostic thought, in the form of skepticism, emerged as a formal philosophical position in ancient Greece. Its proponents included Protagoras, Pyrrho, Carneades, Sextus Empiricus\nand, to some degree, Socrates, who was a strong advocate for a skeptical approach to epistemology.\n\nPyrrho said that we should refrain from making judgment as we can never know the true reality. According to Pyrrho, having opinion was possible, but certainty and knowledge are impossible.\nCarneades was also a skeptic in relation to all knowledge claims. He proposed a probability theory, however. According to him, certainty could never be attained. Protagoras rejected the conventional accounts of the gods. He said:\n\nThroughout the history of Hinduism there has been a strong tradition of philosophic speculation and skepticism.\n\nThe Rig Veda takes an agnostic view on the fundamental question of how the universe and the gods were created. Nasadiya Sukta (\"Creation Hymn\") in the tenth chapter of the Rig Veda says:\nAristotle,\nAnselm,\nAquinas,\nand Descartes\npresented arguments attempting to rationally prove the existence of God. The skeptical empiricism of David Hume, the antinomies of Immanuel Kant, and the existential philosophy of Søren Kierkegaard convinced many later philosophers to abandon these attempts, regarding it impossible to construct any unassailable proof for the existence or non-existence of God.\n\nIn his 1844 book, \"Philosophical Fragments\", Kierkegaard writes:\nHume was Huxley's favourite philosopher, calling him \"the Prince of Agnostics\". Diderot wrote to his mistress, telling of a visit by Hume to the Baron D'Holbach, and describing how a word for the position that Huxley would later describe as agnosticism didn't seem to exist, or at least wasn't common knowledge, at the time.\n\nAgnostic views are as old as philosophical skepticism, but the terms agnostic and agnosticism were created by Huxley to sum up his thoughts on contemporary developments of metaphysics about the \"unconditioned\" (William Hamilton) and the \"unknowable\" (Herbert Spencer). Though Huxley began to use the term \"agnostic\" in 1869, his opinions had taken shape some time before that date. In a letter of September 23, 1860, to Charles Kingsley, Huxley discussed his views extensively:\nAnd again, to the same correspondent, May 6, 1863:\nOf the origin of the name agnostic to describe this attitude, Huxley gave the following account:\nIn 1889, Huxley wrote:Therefore, although it be, as I believe, demonstrable that we have no real knowledge of the authorship, or of the date of composition of the Gospels, as they have come down to us, and that nothing better than more or less probable guesses can be arrived at on that subject.\n\nWilliam Stewart Ross wrote under the name of Saladin. He championed agnosticism in opposition to the atheism of Charles Bradlaugh as an open-ended spiritual exploration.\nIn \"Why I am an Agnostic\" (c. 1889) he claims that agnosticism is \"the very reverse of atheism\".\n\nRobert G. Ingersoll, an Illinois lawyer and politician who evolved into a well-known and sought-after orator in 19th-century America, has been referred to as the \"Great Agnostic\".\n\nIn an 1896 lecture titled \"Why I Am An Agnostic\", Ingersoll related why he was an agnostic:\nIn the conclusion of the speech he simply sums up the agnostic position as:\n\nBertrand Russell's pamphlet, \"Why I Am Not a Christian\", based on a speech delivered in 1927 and later included in a book of the same title, is considered a classic statement of agnosticism.\nHe calls upon his readers to \"stand on their own two feet and look fair and square at the world with a fearless attitude and a free intelligence\".\n\nIn 1939, Russell gave a lecture on \"The existence and nature of God\", in which he characterized himself as an atheist. He said:\nHowever, later in the same lecture, discussing modern non-anthropomorphic concepts of God, Russell states:\nIn Russell's 1947 pamphlet, \"Am I An Atheist or an Agnostic?\" (subtitled \"A Plea For Tolerance in the Face of New Dogmas\"), he ruminates on the problem of what to call himself:\nIn his 1953 essay, \"What Is An Agnostic?\" Russell states:\nLater in the essay, Russell adds:\nIn 1965 Christian theologian Leslie Weatherhead published \"The Christian Agnostic\", in which he argues:\nAlthough radical and unpalatable to conventional theologians, Weatherhead's \"agnosticism\" falls far short of Huxley's, and short even of \"weak agnosticism\":\nRaised in a religious environment, Charles Darwin studied to be an Anglican clergyman. While eventually doubting parts of his faith, Darwin continued to help in church affairs, even while avoiding church attendance. Darwin stated that it would be \"absurd to doubt that a man might be an ardent theist and an evolutionist\". Although reticent about his religious views, in 1879 he wrote that \"I have never been an atheist in the sense of denying the existence of a God. – I think that generally ... an agnostic would be the most correct description of my state of mind.\"\n\nDemographic research services normally do not differentiate between various types of non-religious respondents, so agnostics are often classified in the same category as atheists or other non-religious people.\n\nA 2010 survey published in \"Encyclopædia Britannica\" found that the non-religious people or the agnostics made up about 9.6% of the world's population.\nA November–December 2006 poll published in the \"Financial Times\" gives rates for the United States and five European countries. The rates of agnosticism in the United States were at 14%, while the rates of agnosticism in the European countries surveyed were considerably higher: Italy (20%), Spain (30%), Great Britain (35%), Germany (25%), and France (32%).\n\nA study conducted by the Pew Research Center found that about 16% of the world's people, the third largest group after Christianity and Islam, have no religious affiliation.\nAccording to a 2012 report by the Pew Research Center, agnostics made up 3.3% of the US adult population.\nIn the \"U.S. Religious Landscape Survey\", conducted by the Pew Research Center, 55% of agnostic respondents expressed \"a belief in God or a universal spirit\",\nwhereas 41% stated that they thought that they felt a tension \"being non-religious in a society where most people are religious\".\nAccording to the 2011 Australian Bureau of Statistics, 22% of Australians have \"no religion\", a category that includes agnostics.\nBetween 64% and 65%\nof Japanese and up to 81%\nof Vietnamese are atheists, agnostics, or do not believe in a god. An official European Union survey reported that 3% of the EU population is unsure about their belief in a god or spirit.\n\nAgnosticism is criticized from a variety of standpoints. Some religious thinkers see agnosticism as limiting the mind's capacity to know reality to materialism. Some atheists criticize the use of the term agnosticism as functionally indistinguishable from atheism; this results in frequent criticisms of those who adopt the term as avoiding the atheist label.\n\nTheistic critics claim that agnosticism is impossible in practice, since a person can live only either as if God did not exist (\"etsi deus non-daretur\"), or as if God did exist (\"etsi deus daretur\").\n\nReligious scholars such as Laurence B. Brown criticize the misuse of the word agnosticism, claiming that it has become one of the most misapplied terms in metaphysics. Brown raises the question, \"You claim that nothing can be known with certainty ... how, then, can you be so sure?\"\n\nAccording to Pope Benedict XVI, strong agnosticism in particular contradicts itself in affirming the power of reason to know scientific truth. He blames the exclusion of reasoning from religion and ethics for dangerous pathologies such as crimes against humanity and ecological disasters.\n\"Agnosticism\", said Ratzinger, \"is always the fruit of a refusal of that knowledge which is in fact offered to man ... The knowledge of God has always existed\". He asserted that agnosticism is a choice of comfort, pride, dominion, and utility over truth, and is opposed by the following attitudes: the keenest self-criticism, humble listening to the whole of existence, the persistent patience and self-correction of the scientific method, a readiness to be purified by the truth.\n\nThe Catholic Church sees merit in examining what it calls \"partial agnosticism\", specifically those systems that \"do not aim at constructing a complete philosophy of the unknowable, but at excluding special kinds of truth, notably religious, from the domain of knowledge\". However, the Church is historically opposed to a full denial of the capacity of human reason to know God. The Council of the Vatican declares, \"God, the beginning and end of all, can, by the natural light of human reason, be known with certainty from the works of creation\".\n\nBlaise Pascal argued that even if there were truly no evidence for God, agnostics should consider what is now known as Pascal's Wager: the infinite expected value of acknowledging God is always greater than the finite expected value of not acknowledging his existence, and thus it is a safer \"bet\" to choose God.\n\nPeter Kreeft and Ronald Tacelli cited 20 arguments for God's existence, asserting that any demand for evidence testable in a laboratory is in effect asking God, the supreme being, to become man's servant.\n\nAccording to Richard Dawkins, a distinction between agnosticism and atheism is unwieldy and depends on how close to zero a person is willing to rate the probability of existence for any given god-like entity. About himself, Dawkins continues, \"I am agnostic only to the extent that I am agnostic about fairies at the bottom of the garden.\" Dawkins also identifies two categories of agnostics; \"Temporary Agnostics in Practice\" (TAPs), and \"Permanent Agnostics in Principle\" (PAPs). He states that \"agnosticism about the existence of God belongs firmly in the temporary or TAP category. Either he exists or he doesn't. It is a scientific question; one day we may know the answer, and meanwhile we can say something pretty strong about the probability.\", and considers PAP a \"deeply inescapable kind of fence-sitting\".\n\nIgnosticism is the view that a coherent definition of a deity must be put forward before the question of the existence of a deity can be meaningfully discussed. If the chosen definition is not coherent, the ignostic holds the noncognitivist view that the existence of a deity is meaningless or empirically untestable.\n\nA.J. Ayer, Theodore Drange, and other philosophers see both atheism and agnosticism as incompatible with ignosticism on the grounds that atheism and agnosticism accept \"a deity exists\" as a meaningful proposition that can be argued for or against.\n\nNotes\nBibliography\n\n", "id": "894", "title": "Agnosticism"},{"url": "https://en.wikipedia.org/wiki?curid=896", "text": "Argon\n\nArgon is a chemical element with symbol Ar and atomic number 18. It is in group 18 of the periodic table and is a noble gas. Argon is the third-most abundant gas in the Earth's atmosphere, at 0.934% (9340 ppmv). It is more than twice as abundant as water vapor (which averages about 4000 ppmv, but varies greatly), 23 times as abundant as carbon dioxide (400 ppmv), and more than 500 times as abundant as neon (18 ppmv). Argon is the most abundant noble gas in Earth's crust, comprising 0.00015% of the crust.\n\nNearly all of the argon in Earth's atmosphere is radiogenic argon-40, derived from the decay of potassium-40 in the Earth's crust. In the universe, argon-36 is by far the most common argon isotope, being the preferred argon isotope produced by stellar nucleosynthesis in supernovas.\n\nThe name \"argon\" is derived from the Greek word , neuter singular form of meaning \"lazy\" or \"inactive\", as a reference to the fact that the element undergoes almost no chemical reactions. The complete octet (eight electrons) in the outer atomic shell makes argon stable and resistant to bonding with other elements. Its triple point temperature of 83.8058 K is a defining fixed point in the International Temperature Scale of 1990.\n\nArgon is produced industrially by the fractional distillation of liquid air. Argon is mostly used as an inert shielding gas in welding and other high-temperature industrial processes where ordinarily unreactive substances become reactive; for example, an argon atmosphere is used in graphite electric furnaces to prevent the graphite from burning. Argon is also used in incandescent, fluorescent lighting, and other gas-discharge tubes. Argon makes a distinctive blue-green gas laser. Argon is also used in fluorescent glow starters.\n\nArgon has approximately the same solubility in water as oxygen and is 2.5 times more soluble in water than nitrogen. Argon is colorless, odorless, nonflammable and nontoxic as a solid, liquid or gas. Argon is chemically inert under most conditions and forms no confirmed stable compounds at room temperature.\n\nAlthough argon is a noble gas, it can form some compounds under extreme conditions. Argon fluorohydride (HArF), a compound of argon with fluorine and hydrogen that is stable below , has been demonstrated. Although the neutral ground-state chemical compounds of argon are presently limited to HArF, argon can form clathrates with water when atoms of argon are trapped in a lattice of water molecules. Ions, such as , and excited-state complexes, such as ArF, have been demonstrated. Theoretical calculation predicts several more argon compounds that should be stable but have not yet been synthesized.\n\n\"Argon\" (, neuter singular form of , meaning \"inactive\", in reference to its chemical inactivity) was suspected to be a component of air by Henry Cavendish in 1785. Argon was first isolated from air in 1894 by Lord Rayleigh and Sir William Ramsay at University College London by removing oxygen, carbon dioxide, water, and nitrogen from a sample of clean air. They had determined that nitrogen produced from chemical compounds was 0.5% lighter than nitrogen from the atmosphere. The difference was slight, but it was important enough to attract their attention for many months. They concluded that there was another gas in the air mixed in with the nitrogen. Argon was also encountered in 1882 through independent research of H. F. Newall and W. N. Hartley. Each observed new lines in the emission spectrum of air that did not match known elements. Argon was the first noble gas to be discovered. Until 1957, the symbol for argon was \"A\", but now is \"Ar\".\n\nArgon constitutes 0.934% by volume and 1.288% by mass of the Earth's atmosphere, and air is the primary industrial source of purified argon products. Argon is isolated from air by fractionation, most commonly by cryogenic fractional distillation, a process that also produces purified nitrogen, oxygen, neon, krypton and xenon. The Earth's crust and seawater contain 1.2 ppm and 0.45 ppm of argon, respectively.\n\nThe main isotopes of argon found on Earth are (99.6%), (0.34%), and (0.06%). Naturally occurring , with a half-life of 1.25 years, decays to stable (11.2%) by electron capture or positron emission, and also to stable (88.8%) by beta decay. These properties and ratios are used to determine the age of rocks by K–Ar dating.\n\nIn the Earth's atmosphere, is made by cosmic ray activity, primarily by neutron capture of followed by two-neutron emission. In the subsurface environment, it is also produced through neutron capture by , followed by proton emission. is created from the neutron capture by followed by an alpha particle emission as a result of subsurface nuclear explosions. It has a half-life of 35 days.\n\nBetween locations in the Solar System, the isotopic composition of argon varies greatly. Where the major source of argon is the decay of in rocks, will be the dominant isotope, as it is on Earth. Argon produced directly by stellar nucleosynthesis, is dominated by the alpha-process nuclide . Correspondingly, solar argon contains 84.6% (according to solar wind measurements), and the ratio of the three isotopes Ar : Ar : Ar in the atmospheres of the outer planets is 8400 : 1600 : 1. This contrasts with the low abundance of primordial in Earth's atmosphere, which is only 31.5 ppmv (= 9340 ppmv × 0.337%), comparable with that of neon (18.18 ppmv) on Earth and with interplanetary gasses, measured by probes.\n\nThe atmospheres of Mars, Mercury and Titan (the largest moon of Saturn) contain argon, predominantly as , and its content may be as high as 1.93% (Mars).\n\nThe predominance of radiogenic is the reason the standard atomic weight of terrestrial argon is greater than that of the next element, potassium, a fact that was puzzling when argon was discovered. Mendeleev positioned the elements on his periodic table in order of atomic weight, but the inertness of argon suggested a placement \"before\" the reactive alkali metal. Henry Moseley later solved this problem by showing that the periodic table is actually arranged in order of atomic number (see History of the periodic table).\n\nArgon's complete octet of electrons indicates full s and p subshells. This full valence shell makes argon very stable and extremely resistant to bonding with other elements. Before 1962, argon and the other noble gases were considered to be chemically inert and unable to form compounds; however, compounds of the heavier noble gases have since been synthesized. The first argon compound with tungsten pentacarbonyl, W(CO)Ar, was isolated in 1975. However it was not widely recognised at that time. In August 2000, another argon compound, argon fluorohydride (HArF), was formed by researchers at the University of Helsinki, by shining ultraviolet light onto frozen argon containing a small amount of hydrogen fluoride with caesium iodide. This discovery caused the recognition that argon could form weakly bound compounds, even though it was not the first. It is stable up to 17 kelvins (−256 °C). The metastable dication, which is valence-isoelectronic with carbonyl fluoride and phosgene, was observed in 2010. Argon-36, in the form of argon hydride (argonium) ions, has been detected in interstellar medium associated with the Crab Nebula supernova; this was the first noble-gas molecule detected in outer space.\n\nSolid argon hydride (Ar(H)) has the same crystal structure as the MgZn Laves phase. It forms at pressures between 4.3 and 220 GPa, though Raman measurements suggest that the H molecules in Ar(H) dissociate above 175 GPa.\n\nArgon is produced industrially by the fractional distillation of liquid air in a cryogenic air separation unit; a process that separates liquid nitrogen, which boils at 77.3 K, from argon, which boils at 87.3 K, and liquid oxygen, which boils at 90.2 K. About 700,000 tonnes of argon are produced worldwide every year.\n\nAr, the most abundant isotope of argon, is produced by the decay of K with a half-life of 1.25 years by electron capture or positron emission. Because of this, it is used in potassium–argon dating to determine the age of rocks.\n\nArgon has several desirable properties:\n\nOther noble gases would be equally suitable for most of these applications, but argon is by far the cheapest. Argon is inexpensive, since it occurs naturally in air and is readily obtained as a byproduct of cryogenic air separation in the production of liquid oxygen and liquid nitrogen: the primary constituents of air are used on a large industrial scale. The other noble gases (except helium) are produced this way as well, but argon is the most plentiful by far. The bulk of argon applications arise simply because it is inert and relatively cheap.\n\nArgon is used in some high-temperature industrial processes where ordinarily non-reactive substances become reactive. For example, an argon atmosphere is used in graphite electric furnaces to prevent the graphite from burning.\n\nFor some of these processes, the presence of nitrogen or oxygen gases might cause defects within the material. Argon is used in some types of arc welding such as gas metal arc welding and gas tungsten arc welding, as well as in the processing of titanium and other reactive elements. An argon atmosphere is also used for growing crystals of silicon and germanium.\nArgon is used in the poultry industry to asphyxiate birds, either for mass culling following disease outbreaks, or as a means of slaughter more humane than the electric bath. Argon is denser than air and displaces oxygen close to the ground during gassing. Its non-reactive nature makes it suitable in a food product, and since it replaces oxygen within the dead bird, argon also enhances shelf life.\n\nArgon is sometimes used for extinguishing fires where valuable equipment may be damaged by water or foam.\n\nLiquid argon is used as the target for neutrino experiments and direct dark matter searches. The interaction between the hypothetical WIMPs and an argon nucleus produces scintillation light that is detected by photomultiplier tubes. Two-phase detectors containing argon gas are used to detect the ionized electrons produced during the WIMP–nucleus scattering. As with most other liquefied noble gases, argon has a high scintillation light yield (about 51 photons/keV), is transparent to its own scintillation light, and is relatively easy to purify. Compared to xenon, argon is cheaper and has a distinct scintillation time profile, which allows the separation of electronic recoils from nuclear recoils. On the other hand, its intrinsic beta-ray background is larger due to contamination, unless one uses argon from underground sources, which has much less contamination. Most of the argon in the Earth’s atmosphere was produced by electron capture of long-lived ( + e → + ν) present in natural potassium within the Earth. The activity in the atmosphere is maintained by cosmogenic production through the knockout reaction (n,2n) and similar reactions. The half-life of is only 269 years. As a result, the underground Ar, shielded by rock and water, has much less contamination. Dark-matter detectors currently operating with liquid argon include DarkSide, WArP, ArDM, microCLEAN and DEAP. Neutrino experiments include ICARUS and MicroBooNE, both of which use high-purity liquid argon in a time projection chamber for fine grained three-dimensional imaging of neutrino interactions.\n\nArgon is used to displace oxygen- and moisture-containing air in packaging material to extend the shelf-lives of the contents (argon has the European food additive code E938). Aerial oxidation, hydrolysis, and other chemical reactions that degrade the products are retarded or prevented entirely. High-purity chemicals and pharmaceuticals are sometimes packed and sealed in argon.\n\nIn winemaking, argon is used in a variety of activities to provide a barrier against oxygen at the liquid surface, which can spoil wine by fueling both microbial metabolism (as with acetic acid bacteria) and standard redox chemistry.\n\nArgon is sometimes used as the propellant in aerosol cans for such products as varnish, polyurethane, and paint, and to displace air when preparing a container for storage after opening.\n\nSince 2002, the American National Archives stores important national documents such as the Declaration of Independence and the Constitution within argon-filled cases to inhibit their degradation. Argon is preferable to the helium that had been used in the preceding five decades, because helium gas escapes through the intermolecular pores in most containers and must be regularly replaced.\n\nArgon may be used as the inert gas within Schlenk lines and gloveboxes. Argon is preferred to less expensive nitrogen in cases where nitrogen may react with the reagents or apparatus.\n\nArgon may be used as the carrier gas in gas chromatography and in electrospray ionization mass spectrometry; it is the gas of choice for the plasma used in ICP spectroscopy. Argon is preferred for the sputter coating of specimens for scanning electron microscopy. Argon gas is also commonly used for sputter deposition of thin films as in microelectronics and for wafer cleaning in microfabrication.\n\nCryosurgery procedures such as cryoablation use liquid argon to destroy tissue such as cancer cells. It is used in a procedure called \"argon-enhanced coagulation\", a form of argon plasma beam electrosurgery. The procedure carries a risk of producing gas embolism and has resulted in the death of at least one patient.\n\nBlue argon lasers are used in surgery to weld arteries, destroy tumors, and correct eye defects.\n\nArgon has also been used experimentally to replace nitrogen in the breathing or decompression mix known as Argox, to speed the elimination of dissolved nitrogen from the blood.\n\nIncandescent lights are filled with argon, to preserve the filaments at high temperature from oxidation. It is used for the specific way it ionizes and emits light, such as in plasma globes and calorimetry in experimental particle physics. Gas-discharge lamps filled with pure argon provide lilac/violet light; with argon and some mercury, blue light. Argon is also used for blue and green argon-ion lasers.\n\nArgon is used for thermal insulation in energy-efficient windows. Argon is also used in technical scuba diving to inflate a dry suit because it is inert and has low thermal conductivity.\n\nArgon is used as a propellant in the development of the Variable Specific Impulse Magnetoplasma Rocket (VASIMR). Compressed argon gas is allowed to expand, to cool the seeker heads of some versions of the AIM-9 Sidewinder missile and other missiles that use cooled thermal seeker heads. The gas is stored at high pressure.\n\nArgon-39, with a half-life of 269 years, has been used for a number of applications, primarily ice core and ground water dating. Also, potassium–argon dating is used to date igneous rocks.\n\nArgon has been used by athletes as a doping agent to simulate hypoxic conditions. In 2014, the World Anti-Doping Agency (WADA) added argon and xenon to the list of prohibited substances and methods, although at this time there is no reliable test for abuse.\n\nAlthough argon is non-toxic, it is 38% denser than air and therefore considered a dangerous asphyxiant in closed areas. It is difficult to detect because it is colorless, odorless, and tasteless. A 1994 incident, in which a man was asphyxiated after entering an argon-filled section of oil pipe under construction in Alaska, highlights the dangers of argon tank leakage in confined spaces and emphasizes the need for proper use, storage and handling.\n\n\n", "id": "896", "title": "Argon"},{"url": "https://en.wikipedia.org/wiki?curid=897", "text": "Arsenic\n\nArsenic is a chemical element with symbol As and atomic number 33. Arsenic occurs in many minerals, usually in combination with sulfur and metals, but also as a pure elemental crystal. Arsenic is a metalloid. It has various allotropes, but only the gray form is important to industry.\n\nThe primary use of metallic arsenic is in alloys of lead (for example, in car batteries and ammunition). Arsenic is a common n-type dopant in semiconductor electronic devices, and the optoelectronic compound gallium arsenide is the second most commonly used semiconductor after doped silicon. Arsenic and its compounds, especially the trioxide, are used in the production of pesticides, treated wood products, herbicides, and insecticides. These applications are declining, however.\n\nA few species of bacteria are able to use arsenic compounds as respiratory metabolites. Trace quantities of arsenic are an essential dietary element in rats, hamsters, goats, chickens, and presumably many other species, including humans. However, arsenic poisoning occurs in multicellular life if quantities are larger than needed. Arsenic contamination of groundwater is a problem that affects millions of people across the world.\n\nThe three most common arsenic allotropes are metallic gray, yellow, and black arsenic, with gray being the most common. Gray arsenic (α-As, space group Rm No. 166) adopts a double-layered structure consisting of many interlocked, ruffled, six-membered rings. Because of weak bonding between the layers, gray arsenic is brittle and has a relatively low Mohs hardness of 3.5. Nearest and next-nearest neighbors form a distorted octahedral complex, with the three atoms in the same double-layer being slightly closer than the three atoms in the next. This relatively close packing leads to a high density of 5.73 g/cm. Gray arsenic is a semimetal, but becomes a semiconductor with a bandgap of 1.2–1.4 eV if amorphized. Gray arsenic is also the most stable form. Yellow arsenic is soft and waxy, and somewhat similar to tetraphosphorus (). Both have four atoms arranged in a tetrahedral structure in which each atom is bound to each of the other three atoms by a single bond. This unstable allotrope, being molecular, is the most volatile, least dense, and most toxic. Solid yellow arsenic is produced by rapid cooling of arsenic vapor, . It is rapidly transformed into gray arsenic by light. The yellow form has a density of 1.97 g/cm. Black arsenic is similar in structure to black phosphorus.\nBlack arsenic can also be formed by cooling vapor at around 100–220 °C. It is glassy and brittle. It is also a poor electrical conductor.\n\nArsenic occurs in nature as a monoisotopic element, composed of one stable isotope, As. As of 2003, at least 33 radioisotopes have also been synthesized, ranging in atomic mass from 60 to 92. The most stable of these is As with a half-life of 80.30 days. All other isotopes have half-lives of under one day, with the exception of As (\"t\"=65.30 hours), As (\"t\"=26.0 hours), As (\"t\"=17.77 days), As (\"t\"=1.0942 days), and As (\"t\"=38.83 hours). Isotopes that are lighter than the stable As tend to decay by β decay, and those that are heavier tend to decay by β decay, with some exceptions.\n\nAt least 10 nuclear isomers have been described, ranging in atomic mass from 66 to 84. The most stable of arsenic's isomers is As with a half-life of 111 seconds.\n\nArsenic has a similar electronegativity and ionization energies to its lighter congener phosphorus and as such readily forms covalent molecules with most of the nonmetals. Though stable in dry air, arsenic forms a golden-bronze tarnish upon exposure to humidity which eventually becomes a black surface layer. When heated in air, arsenic oxidizes to arsenic trioxide; the fumes from this reaction have an odor resembling garlic. This odor can be detected on striking arsenide minerals such as arsenopyrite with a hammer. It burns in oxygen to form arsenic trioxide and arsenic pentoxide, which have the same structure as the more well-known phosphorus compounds, and in fluorine to give arsenic pentafluoride. Arsenic (and some arsenic compounds) sublimes upon heating at atmospheric pressure, converting directly to a gaseous form without an intervening liquid state at . The triple point is 3.63 MPa and . Arsenic makes arsenic acid with concentrated nitric acid, arsenous acid with dilute nitric acid, and arsenic trioxide with concentrated sulfuric acid; however, it does not react with water, alkalis, or non-oxidising acids. Arsenic reacts with metals to form arsenides, though these are not ionic compounds containing the As ion as the formation of such an anion would be highly endothermic and even the group 1 arsenides have properties of intermetallic compounds. Like germanium, selenium, and bromine, which like arsenic succeed the 3d transition series, arsenic is much less stable in the group oxidation state of +5 than its vertical neighbors phosphorus and antimony, and hence arsenic pentoxide and arsenic acid are potent oxidizers.\n\nCompounds of arsenic resemble in some respects those of phosphorus which occupies the same group (column) of the periodic table. The most common oxidation states for arsenic are: −3 in the arsenides, which are alloy-like intermetallic compounds, +3 in the arsenites, and +5 in the arsenates and most organoarsenic compounds. Arsenic also bonds readily to itself as seen in the square As ions in the mineral skutterudite. In the +3 oxidation state, arsenic is typically pyramidal owing to the influence of the lone pair of electrons.\n\nOne of the simplest arsenic compound is the trihydride, the highly toxic, flammable, pyrophoric arsine (AsH). This compound is generally regarded as stable, since at room temperature it decomposes only slowly. At temperatures of 250–300 °C decomposition to arsenic and hydrogen is rapid. Several factors, such as humidity, presence of light and certain catalysts (namely aluminium) facilitate the rate of decomposition. It oxidises readily in air to form arsenic trioxide and water, and analogous reactions take place with sulfur and selenium instead of oxygen.\n\nArsenic forms colorless, odorless, crystalline oxides AsO (\"white arsenic\") and AsO which are hygroscopic and readily soluble in water to form acidic solutions. Arsenic(V) acid is a weak acid and the salts are called arsenates, the most common arsenic contamination of groundwater, and a problem that affects many people. Synthetic arsenates include Scheele's Green (cupric hydrogen arsenate, acidic copper arsenate), calcium arsenate, and lead hydrogen arsenate. These three have been used as agricultural insecticides and poisons.\n\nThe protonation steps between the arsenate and arsenic acid are similar to those between phosphate and phosphoric acid. Unlike phosphorous acid, arsenous acid is genuinely tribasic, with the formula As(OH).\n\nA broad variety of sulfur compounds of arsenic are known. Orpiment (AsS) and realgar (AsS) are somewhat abundant and were formerly used as painting pigments. In AsS, arsenic has a formal oxidation state of +2 in AsS which features As-As bonds so that the total covalency of As is still 3. Both orpiment and realgar, as well as AsS, have selenium analogs; although arsenic tellurides are not known, the anion AsTe is known as a ligand in cobalt complexes.\n\nAll trihalides of arsenic(III) are well known except the astatide, which is unknown. Arsenic pentafluoride (AsF) is the only important pentahalide, reflecting the lower stability of the +5 oxidation state; even so, it is a very strong fluorinating and oxidizing agent. (The pentachloride is stable only below −50 °C, at which temperature it decomposes to the trichloride, releasing chlorine gas.)\n\nArsenic is used as the group 5 element in the III-V semiconductors gallium arsenide, indium arsenide, and aluminium arsenide. The valence electron count of GaAs is the same as a pair of Si atoms, but the band structure is completely different which results distinct bulk properties. Other arsenic alloys include the II-V semiconductor cadmium arsenide.\n\nA large variety of organoarsenic compounds are known. Several were developed as chemical warfare agents during World War I, including vesicants such as lewisite and vomiting agents such as adamsite. Cacodylic acid, which is of historic and practical interest, arises from the methylation of arsenic trioxide, a reaction that has no analogy in phosphorus chemistry. Indeed, cacodyl was the first organometallic compound known, and was named from the Greek \"κακωδἰα\" \"stink\" for its offensive odor; like all arsenic compounds, it is very poisonous.\n\nArsenic comprises about 1.5 ppm (0.00015%) of the Earth's crust, and is the 53rd most abundant element.\n\nMinerals with the formula MAsS and MAs (M = Fe, Ni, Co) are the dominant commercial sources of arsenic, together with realgar (an arsenic sulfide mineral) and native arsenic. An illustrative mineral is arsenopyrite (FeAsS), which is structurally related to iron pyrite. Many minor As-containing minerals are known. Arsenic also occurs in various organic forms in the environment.\n\nIn 2014, China was the top producer of white arsenic with almost 70% world share, followed by Morocco, Russia, and Belgium, according to the British Geological Survey and the United States Geological Survey. Most arsenic refinement operations in the US and Europe have closed over environmental concerns. Arsenic is found of the smelter dust from copper, gold, and lead smelters, and is recovered primarily from copper refinement dust.\n\nOn roasting arsenopyrite in air, arsenic sublimes as arsenic(III) oxide leaving iron oxides, while roasting without air results in the production of metallic arsenic. Further purification from sulfur and other chalcogens is achieved by sublimation in vacuum, in a hydrogen atmosphere, or by distillation from molten lead-arsenic mixture.\n\nThe word \"arsenic\" has its origin in the Syriac word \"(al) zarniqa\", from the Persian word \"zarnikh\", meaning \"yellow\" (literally \"gold-colored\") and hence \"(yellow) orpiment\". It was adopted into Greek as \"arsenikon\" (), a form that is folk etymology, being the neuter form of the Greek word \"arsenikos\" (), meaning \"male\", \"virile\". The Greek word was adopted in Latin as \"arsenicum\", which in French became \"arsenic\", from which the English word arsenic is taken. Arsenic sulfides (orpiment, realgar) and oxides have been known and used since ancient times. Zosimos (circa 300 AD) describes roasting \"sandarach\" (realgar) to obtain \"cloud of arsenic\" (arsenic trioxide), which he then reduces to metallic arsenic. As the symptoms of arsenic poisoning were somewhat ill-defined, it was frequently used for murder until the advent of the Marsh test, a sensitive chemical test for its presence. (Another less sensitive but more general test is the Reinsch test.) Owing to its use by the ruling class to murder one another and its potency and discreetness, arsenic has been called the \"poison of kings\" and the \"king of poisons\".\n\nDuring the Bronze Age, arsenic was often included in bronze, which made the alloy harder (so-called \"arsenical bronze\").\nAlbertus Magnus (Albert the Great, 1193–1280) is believed to have been the first to isolate the element from a compound in 1250, by heating soap together with arsenic trisulfide. In 1649, Johann Schröder published two ways of preparing arsenic. Crystals of elemental (native) arsenic are found in nature, although rare.\n\nCadet's fuming liquid (impure cacodyl), often claimed as the first synthetic organometallic compound, was synthesized in 1760 by Louis Claude Cadet de Gassicourt by the reaction of potassium acetate with arsenic trioxide.\n\nIn the Victorian era, \"arsenic\" (\"white arsenic\" or arsenic trioxide) was mixed with vinegar and chalk and eaten by women to improve the complexion of their faces, making their skin paler to show they did not work in the fields. Arsenic was also rubbed into the faces and arms of women to \"improve their complexion\". The accidental use of arsenic in the adulteration of foodstuffs led to the Bradford sweet poisoning in 1858, which resulted in around 20 deaths.\n\nTwo arsenic pigments have been widely used since their discovery – Paris Green and Scheele's Green. After the toxicity of arsenic became widely known, these chemicals were used less often as pigments and more often as insecticides. In the 1860s, an arsenic byproduct of dye production, London Purple was widely used. This was a solid mixture of arsenic trioxide, aniline, lime, and ferrous oxide, insoluble in water and very toxic by inhalation or ingestion But it was later replaced with Paris Green, another arsenic-based dye. With better understanding of the toxicology mechanism, two other compounds were used starting in the 1890s. Arsenite of lime and arsenate of lead were used widely as insecticides until the discovery of DDT in 1942.\n\nThe toxicity of arsenic to insects, bacteria, and fungi led to its use as a wood preservative. In the 1950s, a process of treating wood with chromated copper arsenate (also known as CCA or Tanalith) was invented, and for decades, this treatment was the most extensive industrial use of arsenic. An increased appreciation of the toxicity of arsenic led to a ban of CCA in consumer products in 2004, initiated by the European Union and United States. However, CCA remains in heavy use in other countries (such as on Malaysian rubber plantations).\n\nArsenic was also used in various agricultural insecticides and poisons. For example, lead hydrogen arsenate was a common insecticide on fruit trees, but contact with the compound sometimes resulted in brain damage among those working the sprayers. In the second half of the 20th century, monosodium methyl arsenate (MSMA) and disodium methyl arsenate (DSMA) – less toxic organic forms of arsenic – replaced lead arsenate in agriculture. These organic arsenicals were in turn phased out by 2013 in all agricultural activities except cotton farming.\n\nThe biogeochemistry of arsenic is complex and includes various adsorption and desorption processes. The toxicity of arsenic is connected to its solubility and is affected by pH. Arsenite () is more soluble than arsenate () and is more toxic; however, at a lower pH, arsenate becomes more mobile and toxic. It was found that addition of sulfur, phosphorus, and iron oxides to high-arsenite soils greatly reduces arsenic phytotoxicity.\n\nArsenic is used as a feed additive in poultry and swine production, in particular in the U.S. to increase weight gain, improve feed efficiency, and to prevent disease. An example is roxarsone, which had been used as a broiler starter by about 70% of U.S. broiler growers. The Poison-Free Poultry Act of 2009 proposed to ban the use of roxarsone in industrial swine and poultry production. Alpharma, a subsidiary of Pfizer Inc., which produces roxarsone, voluntarily suspended sales of the drug in response to studies showing elevated levels of inorganic arsenic, a carcinogen, in treated chickens. A successor to Alpharma, Zoetis, continues to sell nitarsone, primarily for use in turkeys.\n\nArsenic is intentionally added to the feed of chickens raised for human consumption. Organic arsenic compounds are less toxic than pure arsenic, and promote the growth of chickens. Under some conditions, the arsenic in chicken feed is converted to the toxic inorganic form.\n\nA 2006 study of the remains of the Australian racehorse, Phar Lap, determined that the 1932 death of the famous champion was caused by a massive overdose of arsenic. Sydney veterinarian Percy Sykes stated, \"In those days, arsenic was quite a common tonic, usually given in the form of a solution (Fowler's Solution) ... It was so common that I'd reckon 90 per cent of the horses had arsenic in their system.\"\n\nDuring the 18th, 19th, and 20th centuries, a number of arsenic compounds were used as medicines, including arsphenamine (by Paul Ehrlich) and arsenic trioxide (by Thomas Fowler). Arsphenamine, as well as neosalvarsan, was indicated for syphilis and trypanosomiasis, but has been superseded by modern antibiotics.\n\nArsenic trioxide has been used in a variety of ways over the past 500 years, most commonly in the treatment of cancer, but in medications as diverse as Fowler's solution in psoriasis. The US Food and Drug Administration in the year 2000 approved this compound for the treatment of patients with acute promyelocytic leukemia that is resistant to all-trans retinoic acid.\n\nRecently, researchers have been locating tumors using arsenic-74 (a positron emitter). This isotope produces clearer PET scan images than the previous radioactive agent, iodine-124, because the body tends to transport iodine to the thyroid gland producing signal noise.\n\nIn subtoxic doses, soluble arsenic compounds act as stimulants, and were once popular in small doses as medicine by people in the mid-18th to 19th centuries.\n\nThe main use of metallic arsenic is in alloying with lead. Lead components in car batteries are strengthened by the presence of a very small percentage of arsenic. Dezincification of brass (a copper-zinc alloy) is greatly reduced by the addition of arsenic. \"Phosphorus Deoxidized Arsenical Copper\" with an arsenic content of 0.3% has an increased corrosion stability in certain environments. Gallium arsenide is an important semiconductor material, used in integrated circuits. Circuits made from GaAs are much faster (but also much more expensive) than those made from silicon. Unlike silicon, GaAs has a direct bandgap, and can be used in laser diodes and LEDs to convert electrical energy directly into light.\n\nAfter World War I, the United States built a stockpile of 20,000 tonnes of weaponized lewisite (ClCH=CHAsCl), a vesicant (blister agent) and lung irritant. The stockpile was neutralized with bleach and dumped into the Gulf of Mexico in the 1950s. During the Vietnam War, the United States used Agent Blue, a mixture of sodium cacodylate and its acid form, as one of the rainbow herbicides to deprive North Vietnamese soldiers of foliage cover and rice.\n\n\nSome species of bacteria obtain their energy by oxidizing various fuels while reducing arsenate to arsenite. Under oxidative environmental conditions some bacteria oxidize arsenite to arsenate as fuel for their metabolism. The enzymes involved are known as arsenate reductases (Arr).\n\nIn 2000, bacteria were discovered that employ a version of photosynthesis in the absence of oxygen with arsenites as electron donors, producing arsenates (just as ordinary photosynthesis uses water as electron donor, producing molecular oxygen). This may be classified as chemolithoautotrophic arsenite oxidation, for which oxygen is used as the terminal electron acceptor, arsenite is the electron donor, and carbon dioxide is the carbon source. Researchers conjecture that, over the course of history, these photosynthesizing organisms produced the arsenates that allowed the arsenate-reducing bacteria to thrive. One strain PHS-1 has been isolated and is related to the gammaproteobacterium \"Ectothiorhodospira shaposhnikovii\". The mechanism is unknown, but an encoded Arr enzyme may function in reverse to its known homologues.\n\nAlthough the arsenate and phosphate anions are similar structurally, no evidence exists for the replacement of phosphate in ATP or nucleic acids by arsenic.\n\nSome evidence indicates that arsenic is an essential trace mineral in birds (chickens), and in mammals (rats, hamsters, and goats). However, the biological function is not known.\n\nArsenic has been linked to epigenetic changes, heritable changes in gene expression that occur without changes in DNA sequence. These include DNA methylation, histone modification, and RNA interference. Toxic levels of arsenic cause significant DNA hypermethylation of tumor suppressor genes p16 and p53, thus increasing risk of carcinogenesis. These epigenetic events have been studied \"in vitro\" using human kidney cells and \"in vivo\" using rat liver cells and peripheral blood leukocytes in humans. Inductively coupled plasma mass spectrometry (ICP-MS) is used to detect precise levels of intracellular arsenic and other arsenic bases involved in epigenetic modification of DNA. Studies investigating arsenic as an epigenetic factor be used to develop precise biomarkers of exposure and susceptibility.\n\nThe Chinese brake fern (\"Pteris vittata\") hyperaccumulates arsenic from the soil into its leaves and has a proposed use in phytoremediation.\n\nInorganic arsenic and its compounds, upon entering the food chain, are progressively metabolized through a process of methylation. For example, the mold \"Scopulariopsis brevicaulis\" produces significant amounts of trimethylarsine if inorganic arsenic is present. The organic compound arsenobetaine is found in some marine foods such as fish and algae, and also in mushrooms in larger concentrations. The average person's intake is about 10–50 µg/day. Values about 1000 µg are not unusual following consumption of fish or mushrooms, but there is little danger in eating fish because this arsenic compound is nearly non-toxic.\n\nNaturally occurring sources of human exposure include volcanic ash, weathering of minerals and ores, and mineralized groundwater. Arsenic is also found in food, water, soil, and air. Arsenic is absorbed by all plants, but is more concentrated in leafy vegetables, rice, apple and grape juice, and seafood. An additional route of exposure is inhalation of atmospheric gases and dusts.\n\nExtensive arsenic contamination of groundwater has led to widespread arsenic poisoning in Bangladesh and neighboring countries. It is estimated that approximately 57 million people in the Bengal basin are drinking groundwater with arsenic concentrations elevated above the World Health Organization's standard of 10 parts per billion (ppb). However, a study of cancer rates in Taiwan suggested that significant increases in cancer mortality appear only at levels above 150 ppb. The arsenic in the groundwater is of natural origin, and is released from the sediment into the groundwater, caused by the anoxic conditions of the subsurface. This groundwater was used after local and western NGOs and the Bangladeshi government undertook a massive shallow tube well drinking-water program in the late twentieth century. This program was designed to prevent drinking of bacteria-contaminated surface waters, but failed to test for arsenic in the groundwater. Many other countries and districts in Southeast Asia, such as Vietnam and Cambodia, have geological environments that produce groundwater with a high arsenic content. was reported in Nakhon Si Thammarat, Thailand in 1987, and the Chao Phraya River probably contains high levels of naturally occurring dissolved arsenic without being a public health problem because much of the public uses bottled water.\n\nIn the United States, arsenic is most commonly found in the ground waters of the southwest. Parts of New England, Michigan, Wisconsin, Minnesota and the Dakotas are also known to have significant concentrations of arsenic in ground water. Increased levels of skin cancer have been associated with arsenic exposure in Wisconsin, even at levels below the 10 part per billion drinking water standard. According to a recent film funded by the US Superfund, millions of private wells have unknown arsenic levels, and in some areas of the US, more than 20% of the wells may contain levels that exceed established limits.\n\nLow-level exposure to arsenic at concentrations of 100 parts per billion (i.e., above the 10 parts per billion drinking water standard) compromises the initial immune response to H1N1 or swine flu infection according to NIEHS-supported scientists. The study, conducted in laboratory mice, suggests that people exposed to arsenic in their drinking water may be at increased risk for more serious illness or death from the virus.\n\nSome Canadians are drinking water that contains inorganic arsenic. Private-dug–well waters are most at risk for containing inorganic arsenic. Preliminary well water analysis typically does not test for arsenic. Researchers at the Geological Survey of Canada have modeled relative variation in natural arsenic hazard potential for the province of New Brunswick. This study has important implications for potable water and health concerns relating to inorganic arsenic.\n\nEpidemiological evidence from Chile shows a dose-dependent connection between chronic arsenic exposure and various forms of cancer, in particular when other risk factors, such as cigarette smoking, are present. These effects have been demonstrated at contaminations less than 50 ppb. Arsenic is itself a constituent of tobacco smoke.\n\nAnalyzing multiple epidemiological studies on inorganic arsenic exposure suggests a small but measurable increase in risk for bladder cancer at 10 ppb. According to Peter Ravenscroft of the Department of Geography at the University of Cambridge, roughly 80 million people worldwide consume between 10 and 50 ppb arsenic in their drinking water. If they all consumed exactly 10 ppb arsenic in their drinking water, the previously cited multiple epidemiological study analysis would predict an additional 2,000 cases of bladder cancer alone. This represents a clear underestimate of the overall impact, since it does not include lung or skin cancer, and explicitly underestimates the exposure. Those exposed to levels of arsenic above the current WHO standard should weigh the costs and benefits of arsenic remediation.\nEarly (1973) evaluations of the processes for removing dissolved arsenic from drinking water demonstrated the efficacy of co-precipitation with either iron or aluminum oxides. In particular, iron as a coagulant was found to remove arsenic with an efficacy exceeding 90%. Several adsorptive media systems have been approved for use at point-of-service in a study funded by the United States Environmental Protection Agency (US EPA) and the National Science Foundation (NSF). A team of European and Indian scientists and engineers have set up six arsenic treatment plants in West Bengal based on in-situ remediation method (SAR Technology). This technology does not use any chemicals and arsenic is left in an insoluble form (+5 state) in the subterranean zone by recharging aerated water into the aquifer and developing an oxidation zone that supports arsenic oxidizing micro-organisms. This process does not produce any waste stream or sludge and is relatively cheap.\n\nAnother effective and inexpensive method to avoid arsenic contamination is to sink wells 500 feet or deeper to reach purer waters. A recent 2011 study funded by the US National Institute of Environmental Health Sciences' Superfund Research Program shows that deep sediments can remove arsenic and take it out of circulation. In this process, called \"adsorption\", arsenic sticks to the surfaces of deep sediment particles and is naturally removed from the ground water.\n\nMagnetic separations of arsenic at very low magnetic field gradients with high-surface-area and monodisperse magnetite (FeO) nanocrystals have been demonstrated in point-of-use water purification. Using the high specific surface area of FeO nanocrystals, the mass of waste associated with arsenic removal from water has been dramatically reduced.\n\nEpidemiological studies have suggested a correlation between chronic consumption of drinking water contaminated with arsenic and the incidence of all leading causes of mortality. The literature indicates that arsenic exposure is causative in the pathogenesis of diabetes.\n\nChaff-based filters have recently been shown to reduce the arsenic content of water to 3 µg/L. This may find applications in areas where the potable water is extracted from underground aquifers.\n\nFor several centuries, the people of San Pedro de Atacama in Chile have been drinking water that is contaminated with arsenic, and some evidence suggests they have developed some immunity.\n\nAround one-third of the world’s population drinks water from groundwater resources. Of this, about 10 percent, approximately 300 million people, obtains water from groundwater resources that are contaminated with unhealthy levels of arsenic or fluoride. These trace elements derive mainly from minerals.\n\nArsenic is unique among the trace metalloids and oxyanion-forming trace metals (e.g. As, Se, Sb, Mo, V, Cr, U, Re). It is sensitive to mobilization at pH values typical of natural waters (pH 6.5–8.5) under both oxidizing and reducing conditions. Arsenic can occur in the environment in several oxidation states (−3, 0, +3 and +5), but in natural waters it is mostly found in inorganic forms as oxyanions of trivalent arsenite [As(III)] or pentavalent arsenate [As(V)]. Organic forms of arsenic are produced by biological activity, mostly in surface waters, but are rarely quantitatively important. Organic arsenic compounds may, however, occur where waters are signiﬁcantly impacted by industrial pollution.\n\nArsenic may be solubilized by various processes. When pH is high, arsenic may be released from surface binding sites that lose their positive charge. When water level drops and sulfide minerals are exposed to air, arsenic trapped in sulfide minerals can be released into water. When organic carbon is present in water, bacteria are fed by directly reducing As(V) to As(III) or by reducing the element at the binding site, releasing inorganic arsenic.\n\nThe aquatic transformations of arsenic are affected by pH, reduction-oxidation potential, organic matter concentration and the concentrations and forms of other elements, especially iron and manganese. The main factors are pH and the redox potential. Generally, the main forms of arsenic under oxic conditions are HAsO, HAsO, HAsO, and AsO at pH 2, 2–7, 7–11 and 11, respectively. Under reducing conditions, HAsO is predominant at pH 2–9.\n\nOxidation and reduction affects the migration of arsenic in subsurface environments. Arsenite is the most stable soluble form of arsenic in reducing environments and arsenate, which is less mobile than arsenite, is dominant in oxidizing environments at neutral pH. Therefore, arsenic may be more mobile under reducing conditions. The reducing environment is also rich in organic matter which may enhance the solubility of arsenic compounds. As a result, the adsorption of arsenic is reduced and dissolved arsenic accumulates in groundwater. That is why the arsenic content is higher in reducing environments than in oxidizing environments.\n\nThe presence of sulfur is another factor that affects the transformation of arsenic in natural water. Arsenic can precipitate when metal sulfides form. In this way, arsenic is removed from the water and its mobility decreases. When oxygen is present, bacteria oxidize reduced sulfur to generate energy, potentially releasing bound arsenic.\n\nRedox reactions involving Fe also appear to be essential factors in the fate of arsenic in aquatic systems. The reduction of iron oxyhydroxides plays a key role in the release of arsenic to water. So arsenic can be enriched in water with elevated Fe concentrations. Under oxidizing conditions, arsenic can be mobilized from pyrite or iron oxides especially at elevated pH. Under reducing conditions, arsenic can be mobilized by reductive desorption or dissolution when associated with iron oxides. The reductive desorption occurs under two circumstances. One is when arsenate is reduced to arsenite which adsorbs to iron oxides less strongly. The other results from a change in the charge on the mineral surface which leads to the desorption of bound arsenic.\n\nSome species of bacteria catalyze redox transformations of arsenic. Dissimilatory arsenate-respiring prokaryotes (DARP) speed up the reduction of As(V) to As(III). DARP use As(V) as the electron acceptor of anaerobic respiration and obtain energy to survive. Other organic and inorganic substances can be oxidized in this process. Chemoautotrophic arsenite oxidizers (CAO) and heterotrophic arsenite oxidizers (HAO) convert As(III) into As(V). CAO combine the oxidation of As(III) with the reduction of oxygen or nitrate. They use obtained energy to fix produce organic carbon from CO. HAO cannot obtain energy from As(III) oxidation. This process may be an arsenic detoxification mechanism for the bacteria.\n\nEquilibrium thermodynamic calculations predict that As(V) concentrations should be greater than As(III) concentrations in all but strongly reducing conditions, i.e. where SO reduction is occurring. However, abiotic redox reactions of arsenic are slow. Oxidation of As(III) by dissolved O is a particularly slow reaction. For example, Johnson and Pilson (1975) gave half-lives for the oxygenation of As(III) in seawater ranging from several months to a year. In other studies, As(V)/As(III) ratios were stable over periods of days or weeks during water sampling when no particular care was taken to prevent oxidation, again suggesting relatively slow oxidation rates. Cherry found from experimental studies that the As(V)/As(III) ratios were stable in anoxic solutions for up to 3 weeks but that gradual changes occurred over longer timescales. Sterile water samples have been observed to be less susceptible to speciation changes than non-sterile samples. Oremland found that the reduction of As(V) to As(III) in Mono Lake was rapidly catalyzed by bacteria with rate constants ranging from 0.02 to 0.3 day.\n\nAs of 2002, US-based industries consumed 19,600 metric tons of arsenic. Ninety percent of this was used for treatment of wood with chromated copper arsenate (CCA). In 2007, 50% of the 5,280 metric tons of consumption was still used for this purpose. In the United States, the voluntary phasing-out of arsenic in production of consumer products and residential and general consumer construction products began on 31 December 2003, and alternative chemicals are now used, such as Alkaline Copper Quaternary, borates, copper azole, cyproconazole, and propiconazole.\n\nAlthough discontinued, this application is also one of the most concern to the general public. The vast majority of older pressure-treated wood was treated with CCA. CCA lumber is still in widespread use in many countries, and was heavily used during the latter half of the 20th century as a structural and outdoor building material. Although the use of CCA lumber was banned in many areas after studies showed that arsenic could leach out of the wood into the surrounding soil (from playground equipment, for instance), a risk is also presented by the burning of older CCA timber. The direct or indirect ingestion of wood ash from burnt CCA lumber has caused fatalities in animals and serious poisonings in humans; the lethal human dose is approximately 20 grams of ash. Scrap CCA lumber from construction and demolition sites may be inadvertently used in commercial and domestic fires. Protocols for safe disposal of CCA lumber are not consistent throughout the world. Widespread landfill disposal of such timber raises some concern, but other studies have shown no arsenic contamination in the groundwater.\n\nOne tool that maps the location (and other information) of arsenic releases in the United State is TOXMAP. TOXMAP is a Geographic Information System (GIS) from the Division of Specialized Information Services of the United States National Library of Medicine (NLM) funded by the US Federal Government. With marked-up maps of the United States, TOXMAP enables users to visually explore data from the United States Environmental Protection Agency's (EPA) Toxics Release Inventory and Superfund Basic Research Programs. TOXMAP's chemical and environmental health information is taken from NLM's Toxicology Data Network (TOXNET), PubMed, and from other authoritative sources.\n\nPhysical, chemical, and biological methods have been used to remediate arsenic contaminated water. Bioremediation is said to be cost effective and environmentally friendly Bioremediation of ground water contaminated with arsenic aims to convert arsenite, the toxic form of arsenic to humans, to arsenate. Arsenate (+5 oxidation state) is the dominant form of arsenic in surface water, while arsenite (+3 oxidation state) is the dominant form in hypoxic to anoxic environments. Arsenite is more soluble and mobile than arsenate. Many species of bacteria can transform arsenite to arsenate in anoxic conditions by using arsenite as an electron donor. This is a useful method in ground water remediation. Another bioremediation strategy is to use plants that accumulate arsenic in their tissues via phytoremediation but the disposal of contaminated plant material needs to be considered.\n\nBioremediation requires careful evaluation and design in accordance with existing conditions. Some sites may require the addition of an electron acceptor while others require microbe supplementation (bioaugmentation). Regardless of the method used, only constant monitoring can prevent future contamination.\n\nArsenic and many of its compounds are especially potent poisons.\n\nElemental arsenic and arsenic compounds are classified as \"toxic\" and \"dangerous for the environment\" in the European Union under directive 67/548/EEC.\n\nThe International Agency for Research on Cancer (IARC) recognizes arsenic and arsenic compounds as group 1 carcinogens, and the EU lists arsenic trioxide, arsenic pentoxide, and arsenate salts as category 1 carcinogens.\n\nArsenic is known to cause when present in drinking water, \"the most common species being arsenate [; As(V)] and arsenite [HAsO; As(III)]\".\n\nIn the United States since 2006, the maximum concentration in drinking water allowed by the Environmental Protection Agency (EPA) is 10 ppb and the FDA set the same standard in 2005 for bottled water. The Department of Environmental Protection for New Jersey set a drinking water limit of 5 ppb in 2006. The IDLH (immediately dangerous to life and health) value for arsenic metal and inorganic arsenic compounds is 5 mg/m. The Occupational Safety and Health Administration has set the permissible exposure limit (PEL) to a time-weighted average (TWA) of 0.01 mg/m, and the National Institute for Occupational Safety and Health (NIOSH) has set the recommended exposure limit (REL) to a 15-minute constant exposure of 0.002 mg/m. The PEL for organic arsenic compounds is a TWA of 0.5 mg/m.\n\nIn 2008, based on its ongoing testing of a wide variety of American foods for toxic chemicals, the U.S. Food and Drug Administration set the \"level of concern\" for inorganic arsenic apple and pear juices at 23 ppb, based on non-carcinogenic effects, and began blocking importation of products in excess of this level; it also required recalls for non-conforming domestic products. In 2011, the national \"Dr. Oz\" television show broadcast a program highlighting tests performed by an independent lab hired by the producers. Though the methodology was disputed (it did not distinguish between organic and inorganic arsenic) the tests showed levels of arsenic up to 36 ppb. In response, FDA tested the worst brand from the \"Dr.\" \"Oz\" show and found much lower levels. Ongoing testing found 95% of the apple juice samples were below the level of concern. Later testing by Consumer Reports showed inorganic arsenic at levels slightly above 10 ppb, and the organization urged parents to reduce consumption. In July 2013, on consideration of consumption by children, chronic exposure, and carcinogenic effect, the FDA established an \"action level\" of 10 ppb for apple juice, the same as the drinking water standard.\n\nConcern about arsenic in rice in Bangladesh was raised in 2002, but at the time only Australia had a legal limit for food (one milligram per kilogram). Concern was raised about people who were eating U.S. rice exceeding WHO standards for personal arsenic intake in 2005. In 2011, the People's Republic of China set a food standard of 150 ppb for arsenic.\n\nIn the United States in 2012, testing by separate groups of researchers at the Children's Environmental Health and Disease Prevention Research Center at Dartmouth College (early in the year, focusing on urinary levels in children) and Consumer Reports (in November) found levels of arsenic in rice that resulted in calls for the FDA to set limits. The FDA released some testing results in September 2012, and as of July 2013, is still collecting data in support of a new potential regulation. It has not recommended any changes in consumer behavior.\n\nConsumer Reports recommended: \nA 2014 World Health Organization advisory conference was scheduled to consider limits of 200–300 ppb for rice.\n\nArsenic is bioaccumulative in many organisms, marine species in particular, but it does not appear to biomagnify significantly in food webs. In polluted areas, plant growth may be affected by root uptake of arsenate, which is a phosphate analog and therefore readily transported in plant tissues and cells. In polluted areas, uptake of the more toxic arsenite ion (found more particularly in reducing conditions) is likely in poorly-drained soils.\n\nArsenic's toxicity comes from the affinity of arsenic(III) oxides for thiols. Thiols, in the form of cysteine residues and cofactors such as lipoic acid and coenzyme A, are situated at the active sites of many important enzymes.\n\nArsenic disrupts ATP production through several mechanisms. At the level of the citric acid cycle, arsenic inhibits lipoic acid, which is a cofactor for pyruvate dehydrogenase. By competing with phosphate, arsenate uncouples oxidative phosphorylation, thus inhibiting energy-linked reduction of NAD+, mitochondrial respiration and ATP synthesis. Hydrogen peroxide production is also increased, which, it is speculated, has potential to form reactive oxygen species and oxidative stress. These metabolic interferences lead to death from multi-system organ failure. The organ failure is presumed to be from necrotic cell death, not apoptosis, since energy reserves have been too depleted for apoptosis to occur.\nAlthough arsenic causes toxicity it can also play a protective role.\n\nOccupational exposure and arsenic poisoning may occur in persons working in industries involving the use of inorganic arsenic and its compounds, such as wood preservation, glass production, nonferrous metal alloys, and electronic semiconductor manufacturing. Inorganic arsenic is also found in coke oven emissions associated with the smelter industry.\n\nThe conversion between As(III) and As(V) is a large factor in arsenic environmental contamination. According to Croal, Gralnick, Malasarn and Newman, \"[the] understanding [of] what stimulates As(III) oxidation and/or limits As(V) reduction is relevant for bioremediation of contaminated sites (Croal). The study of chemolithoautotrophic As(III) oxidizers and the heterotrophic As(V) reducers can help the understanding of the oxidation and/or reduction of arsenic.\n\nTreatment of chronic arsenic poisoning is possible. British anti-lewisite (dimercaprol) is prescribed in doses of 5 mg/kg up to 300 mg every 4 hours for the first day, then every 6 hours for the second day, and finally every 8 hours for 8 additional days. However the USA's Agency for Toxic Substances and Disease Registry (ATSDR) states that the long-term effects of arsenic exposure cannot be predicted. Blood, urine, hair, and nails may be tested for arsenic; however, these tests cannot foresee possible health outcomes from the exposure. Long-term exposure and consequent excretion through urine has been linked to bladder and kidney cancer in addition to cancer of the liver, prostate, skin, lungs, and nasal cavity.\n\n\n", "id": "897", "title": "Arsenic"},{"url": "https://en.wikipedia.org/wiki?curid=898", "text": "Antimony\n\nAntimony is a chemical element with symbol Sb (from ) and atomic number 51. A lustrous gray metalloid, it is found in nature mainly as the sulfide mineral stibnite (SbS). Antimony compounds have been known since ancient times and were powdered for use as medicine and cosmetics, often known by the Arabic name, kohl. Metallic antimony was also known, but it was erroneously identified as lead upon its discovery. In the West, it was first isolated by Vannoccio Biringuccio and described in 1540.\n\nFor some time, China has been the largest producer of antimony and its compounds, with most production coming from the Xikuangshan Mine in Hunan. The industrial methods for refining antimony are roasting and reduction with carbon or direct reduction of stibnite with iron.\n\nThe largest applications for metallic antimony is an alloy with lead and tin and the lead antimony plates in lead–acid batteries. Alloys of lead and tin with antimony have improved properties for solders, bullets, and plain bearings. Antimony compounds are prominent additives for chlorine and bromine-containing fire retardants found in many commercial and domestic products. An emerging application is the use of antimony in microelectronics.\n\nAntimony is in a pnictogen (a member of group 15) and has an electronegativity of 2.05. In accordance with periodic trends, it is more electronegative than tin or bismuth, and less electronegative than tellurium or arsenic. Antimony is stable in air at room temperature, but reacts with oxygen if heated to produce antimony trioxide, SbO.\n\nAntimony is a silvery, lustrous gray metalloid with a Mohs scale hardness of 3, which is too soft to make hard objects; coins of antimony were issued in China's Guizhou province in 1931 but the durability was poor and the minting was soon discontinued. Antimony is resistant to attack by acids.\n\nFour allotropes of antimony are known: a stable metallic form and three metastable forms (explosive, black and yellow). Elemental antimony is a brittle, silver-white shiny metalloid. When slowly cooled, molten antimony crystallizes in a trigonal cell, isomorphic with the gray allotrope of arsenic. A rare explosive form of antimony can be formed from the electrolysis of antimony trichloride. When scratched with a sharp implement, an exothermic reaction occurs and white fumes are given off as metallic antimony forms; when rubbed with a pestle in a mortar, a strong detonation occurs. Black antimony is formed upon rapid cooling of antimony vapor. It has the same crystal structure as red phosphorus and black arsenic, it oxidizes in air and may ignite spontaneously. At 100 °C, it gradually transforms into the stable form. The yellow allotrope of antimony is the most unstable. It has only been generated by oxidation of stibine (SbH) at −90 °C. Above this temperature and in ambient light, this metastable allotrope transforms into the more stable black allotrope.\n\nElemental antimony adopts a layered structure (space group Rm No. 166) in which layers consist of fused, ruffled, six-membered rings. The nearest and next-nearest neighbors form an irregular octahedral complex, with the three atoms in each double layer slightly closer than the three atoms in the next. This relatively close packing leads to a high density of 6.697 g/cm, but the weak bonding between the layers leads to the low hardness and brittleness of antimony.\n\nAntimony has two stable isotopes: Sb with a natural abundance of 57.36% and Sb with a natural abundance of 42.64%. It also has 35 radioisotopes, of which the longest-lived is Sb with a half-life of 2.75 years. In addition, 29 metastable states have been characterized. The most stable of these is Sb with a half-life of 5.76 days. Isotopes that are lighter than the stable Sb tend to decay by β decay, and those that are heavier tend to decay by β decay, with some exceptions.\n\nThe abundance of antimony in the Earth's crust is estimated to be 0.2 to 0.5 parts per million, comparable to thallium at 0.5 parts per million and silver at 0.07 ppm. Even though this element is not abundant, it is found in more than 100 mineral species. Antimony is sometimes found natively (e.g. on Antimony Peak), but more frequently it is found in the sulfide stibnite (SbS) which is the predominant ore mineral.\n\nAntimony compounds are often classified according to their oxidation state: Sb(III) and Sb(V). The +5 oxidation state is more stable.\n\nAntimony trioxide is formed when antimony is burnt in air. In the gas phase, the molecule of the compound is , but it polymerizes upon condensing. Antimony pentoxide () can be formed only by oxidation with concentrated nitric acid. Antimony also forms a mixed-valence oxide, antimony tetroxide (), which features both Sb(III) and Sb(V). Unlike oxides of phosphorus and arsenic, these oxides are amphoteric, do not form well-defined oxoacids, and react with acids to form antimony salts.\n\nAntimonous acid is unknown, but the conjugate base sodium antimonite () forms upon fusing sodium oxide and . Transition metal antimonites are also known. Antimonic acid exists only as the hydrate , forming salts as the antimonate anion . When a solution containing this anion is dehydrated, the precipitate contains mixed oxides.\n\nMany antimony ores are sulfides, including stibnite (), pyrargyrite (), zinkenite, jamesonite, and boulangerite. Antimony pentasulfide is non-stoichiometric and features antimony in the +3 oxidation state and S-S bonds. Several thioantimonides are known, such as and .\n\nAntimony forms two series of halides: and . The trihalides , , , and are all molecular compounds having trigonal pyramidal molecular geometry.\n\nThe trifluoride is prepared by the reaction of with HF:\n\nIt is Lewis acidic and readily accepts fluoride ions to form the complex anions and . Molten is a weak electrical conductor. The trichloride is prepared by dissolving in hydrochloric acid:\nThe pentahalides and have trigonal bipyramidal molecular geometry in the gas phase, but in the liquid phase, is polymeric, whereas is monomeric. is a powerful Lewis acid used to make the superacid fluoroantimonic acid (\"HSbF\").\n\nOxyhalides are more common for antimony than for arsenic and phosphorus. Antimony trioxide dissolves in concentrated acid to form oxoantimonyl compounds such as SbOCl and .\n\nCompounds in this class generally are described as derivatives of Sb. Antimony forms antimonides with metals, such as indium antimonide (InSb) and silver antimonide (). The alkali metal and zinc antimonides, such as NaSb and ZnSb, are more reactive. Treating these antimonides with acid produces the unstable gas stibine, :\nStibine can also be produced by treating salts with hydride reagents such as sodium borohydride. Stibine decomposes spontaneously at room temperature. Because stibine has a positive heat of formation, it is thermodynamically unstable and thus antimony does not react with hydrogen directly.\n\nOrganoantimony compounds are typically prepared by alkylation of antimony halides with Grignard reagents. A large variety of compounds are known with both Sb(III) and Sb(V) centers, including mixed chloro-organic derivatives, anions, and cations. Examples include Sb(CH) (triphenylstibine), Sb(CH) (with an Sb-Sb bond), and cyclic [Sb(CH)]. Pentacoordinated organoantimony compounds are common, examples being Sb(CH) and several related halides.\n\nAntimony(III) sulfide, SbS, was recognized in predynastic Egypt as an eye cosmetic (kohl) as early as about 3100 BC, when the cosmetic palette was invented.\n\nAn artifact, said to be part of a vase, made of antimony dating to about 3000 BC was found at Telloh, Chaldea (part of present-day Iraq), and a copper object plated with antimony dating between 2500 BC and 2200 BC has been found in Egypt. Austen, at a lecture by Herbert Gladstone in 1892 commented that \"we only know of antimony at the present day as a highly brittle and crystalline metal, which could hardly be fashioned into a useful vase, and therefore this remarkable 'find' (artifact mentioned above) must represent the lost art of rendering antimony malleable.\"\n\nMoorey was unconvinced the artifact was indeed a vase, mentioning that Selimkhanov, after his analysis of the Tello object (published in 1975), \"attempted to relate the metal to Transcaucasian natural antimony\" (i.e. native metal) and that \"the antimony objects from Transcaucasia are all small personal ornaments.\" This weakens the evidence for a lost art \"of rendering antimony malleable.\"\n\nThe Roman scholar Pliny the Elder described several ways of preparing antimony sulfide for medical purposes in his treatise \"Natural History\". Pliny the Elder also made a distinction between \"male\" and \"female\" forms of antimony; the male form is probably the sulfide, while the female form, which is superior, heavier, and less friable, has been suspected to be native metallic antimony.\n\nThe Roman naturalist Pedanius Dioscorides mentioned that antimony sulfide could be roasted by heating by a current of air. It is thought that this produced metallic antimony.\n\nThe first description of a procedure for isolating antimony is in the 1540 book \"De la pirotechnia\" by Vannoccio Biringuccio, predating the more famous 1556 book by Agricola, \"De re metallica\". In this context Agricola has been often incorrectly credited with the discovery of metallic antimony. The book \"Currus Triumphalis Antimonii\" (The Triumphal Chariot of Antimony), describing the preparation of metallic antimony, was published in Germany in 1604. It was purported to be written by a Benedictine monk, writing under the name Basilius Valentinus in the 15th century; if it were authentic, which it is not, it would predate Biringuccio.\n\nThe metal antimony was known to German chemist Andreas Libavius in 1615 who obtained it by adding iron to a molten mixture of antimony sulfide, salt and potassium tartrate. This procedure produced antimony with a crystalline or starred surface.\n\nWith the advent of challenges to phlogiston theory, it was recognized that antimony is an element forming sulfides, oxides, and other compounds, as do other metals.\n\nThe first natural occurrence of pure antimony in the Earth's crust was described by the Swedish scientist and local mine district engineer Anton von Swab in 1783; the type-sample was collected from the Sala Silver Mine in the Bergslagen mining district of Sala, Västmanland, Sweden.\n\nThe medieval Latin form, from which the modern languages and late Byzantine Greek take their names for antimony, is \"antimonium\". The origin of this is uncertain; all suggestions have some difficulty either of form or interpretation. The popular etymology, from ἀντίμοναχός \"anti-monachos\" or French \"antimoine\", still has adherents; this would mean \"monk-killer\", and is explained by many early alchemists being monks, and antimony being poisonous.\n\nAnother popular etymology is the hypothetical Greek word ἀντίμόνος \"antimonos\", \"against aloneness\", explained as \"not found as metal\", or \"not found unalloyed\". Lippmann conjectured a hypothetical Greek word ανθήμόνιον \"anthemonion\", which would mean \"floret\", and cites several examples of related Greek words (but not that one) which describe chemical or biological efflorescence.\n\nThe early uses of \"antimonium\" include the translations, in 1050–1100, by Constantine the African of Arabic medical treatises. Several authorities believe \"antimonium\" is a scribal corruption of some Arabic form; Meyerhof derives it from \"ithmid\"; other possibilities include \"athimar\", the Arabic name of the metalloid, and a hypothetical \"as-stimmi\", derived from or parallel to the Greek.\n\nThe standard chemical symbol for antimony (Sb) is credited to Jöns Jakob Berzelius, who derived the abbreviation from \"stibium\".\n\nThe ancient words for antimony mostly have, as their chief meaning, kohl, the sulfide of antimony.\nThe Egyptians called antimony \"mśdmt\"; in hieroglyphs, the vowels are uncertain, but an Arabic tradition holds that the word is ميسديميت \"mesdemet\". The Greek word, στίμμι \"stimmi\", is probably a loan word from Arabic or from Egyptian \"stm\" O34:D46-G17-F21:D4 and is used by Attic tragic poets of the 5th century BC. Later Greeks also used στἰβι \"stibi\", as did Celsus and Pliny, writing in Latin, in the first century AD. Pliny also gives the names \"stimi\" , \"larbaris\", alabaster, and the \"very common\" \"platyophthalmos\", \"wide-eye\" (from the effect of the cosmetic). Later Latin authors adapted the word to Latin as \"stibium\". The Arabic word for the substance, as opposed to the cosmetic, can appear as إثمد \"ithmid, athmoud, othmod\", or \"uthmod\". Littré suggests the first form, which is the earliest, derives from \"stimmida\", an accusative for \"stimmi\".\n\nThe British Geological Survey (BGS) reported that in 2005, China was the top producer of antimony with approximately 84% of the world share, followed at a distance by South Africa, Bolivia and Tajikistan. Xikuangshan Mine in Hunan province has the largest deposits in China with an estimated deposit of 2.1 million metric tons.\n\nIn 2016, according to the US Geological Survey, China accounted for 76.9% of total antimony production, followed in second place by Russia with 6.9% and Tajikistan with 6.2%.\n\nChinese production of antimony is expected to decline in the future as mines and smelters are closed down by the government as part of pollution control. Especially due to a new environmental protection law having gone into effect on January 2015 and revised “Emission Standards of Pollutants for Stanum, Antimony, and Mercury”having gone into effect, hurdles for economic production are higher. According to the National Bureau of Statistics in China, by September 2015 50% of antimony production capacity in the Hunan province (the province with biggest antimony reserves in China) had not been used.\n\nReported production of antimony in China has fallen and is unlikely to increase in the coming years, according to the Roskill report. No significant antimony deposits in China have been developed for about ten years, and the remaining economic reserves are being rapidly depleted.\n\nThe world's largest antimony producers, according to Roskill, are listed below:\n\nAccording to statistics from the USGS, current global reserves of antimony will be depleted in 13 years. However, the USGS expects more resources will be found.\n\nThe extraction of antimony from ores depends on the quality and composition of the ore. Most antimony is mined as the sulfide; lower-grade ores are concentrated by froth flotation, while higher-grade ores are heated to 500–600 °C, the temperature at which stibnite melts and separates from the gangue minerals. Antimony can be isolated from the crude antimony sulfide by reduction with scrap iron:\n\nThe sulfide is converted to an oxide; the product is then roasted, sometimes for the purpose of vaporizing the volatile antimony(III) oxide, which is recovered. This material is often used directly for the main applications, impurities being arsenic and sulfide. Antimony is isolated from the oxide by a carbothermal reduction:\n\nThe lower-grade ores are reduced in blast furnaces while the higher-grade ores are reduced in reverberatory furnaces.\n\nAntimony has consistently been ranked high in European and US Risk Lists concerning criticality of the element indicating the relative risk to the supply of chemical elements or element groups required to maintain the current economy and lifestyle.\n\nWith most of the antimony imported into Europe and the US coming from China, Chinese production is critical to supply. As China is revising and increasing environmental control standards, antimony production is becoming increasingly restricted. Additionally Chinese export quotas for antimony have been decreasing in the past years. These two factors increase supply risk for both Europe and US.\n\nAccording to the BGS Risk List 2015, antimony is ranked second highest (after rare earth elements) on the relative supply risk index. This indicates that it has currently the second highest supply risk for chemical elements or element groups which are of economic value to the British economy and lifestyle.\nFurthermore, antimony was identified as one of 20 critical raw materials for the EU in a report published in 2014 (which revised the initial report published in 2011). As seen in Figure xxx antimony maintains high supply risk relative to its economic importance. 92% of the antimony is imported from China, which is a significantly high concentration of production.\n\nMuch analysis has been conducted in the U.S. toward defining which metals should be called strategic or critical to the nation's security. Exact definitions do not exist, and views as to what constitutes a strategic or critical mineral to U.S. security diverge.\n\nIn 2015, no antimony was mined in the U.S. The metal is imported from foreign countries. From 2011-2014 68% of America's antimony came from China, 14% from India, 4% from Mexico, and 14% from other sources. There are no government stockpiles in place currently.\n\nThe U.S. “Subcommittee on Critical and Strategic Mineral Supply Chains” has screened 78 mineral resources from 1996-2008. It found that a small subset of minerals including antimony has fallen into the category of potentially critical minerals consistently. In the future, a second assessment will be made of the found subset of minerals to identify which should be defined of significant risk and critical to U.S. interests.\n\nAbout 60% of antimony is consumed in flame retardants, and 20% is used in alloys for batteries, plain bearings, and solders.\n\nAntimony is mainly used in the trioxide for flame-proofing compounds, always in combination with halogenated flame retardants except in halogen-containing polymers. The flame retarding effect of antimony trioxide is produced by the formation of halogenated antimony compounds, which react with hydrogen atoms, and probably also with oxygen atoms and OH radicals, thus inhibiting fire. Markets for these flame-retardants include children's clothing, toys, aircraft, and automobile seat covers. They are also added to polyester resins in fiberglass composites for such items as light aircraft engine covers. The resin will burn in the presence of an externally generated flame, but will extinguish when the external flame is removed.\n\nAntimony forms a highly useful alloy with lead, increasing its hardness and mechanical strength. For most applications involving lead, varying amounts of antimony are used as alloying metal. In lead–acid batteries, this addition improves the charging characteristics and reduces generation of unwanted hydrogen during charging. It is used in antifriction alloys (such as Babbitt metal), in bullets and lead shot, electrical cable sheathing, type metal (for example, for linotype printing machines), solder (some \"lead-free\" solders contain 5% Sb), in pewter, and in hardening alloys with low tin content in the manufacturing of organ pipes.\n\nThree other applications consume nearly all the rest of the world's supply. One application is a stabilizer and a catalyst for the production of polyethyleneterephthalate. Another is a fining agent to remove microscopic bubbles in glass, mostly for TV screens; antimony ions interact with oxygen, suppressing the tendency of the latter to form bubbles. The third application is pigments.\n\nAntimony is increasingly being used in semiconductors as a dopant in n-type silicon wafers for diodes, infrared detectors, and Hall-effect devices. In the 1950s, the emitters and collectors of n-p-n alloy junction transistors were doped with tiny beads of a lead-antimony alloy. Indium antimonide is used as a material for mid-infrared detectors.\n\nBiology and medicine have few uses for antimony. Treatments containing antimony, known as antimonials, are used as emetics. Antimony compounds are used as antiprotozoan drugs. Potassium antimonyl tartrate, or tartar emetic, was once used as an anti-schistosomal drug from 1919 on. It was subsequently replaced by praziquantel. Antimony and its compounds are used in several veterinary preparations, such as anthiomaline and lithium antimony thiomalate, as a skin conditioner in ruminants. Antimony has a nourishing or conditioning effect on keratinized tissues in animals.\n\nAntimony-based drugs, such as meglumine antimoniate, are also considered the drugs of choice for treatment of leishmaniasis in domestic animals. Unfortunately, besides having low therapeutic indices, the drugs have minimal penetration of the bone marrow, where some of the \"Leishmania\" amastigotes reside, and curing the disease – especially the visceral form – is very difficult. Elemental antimony as an antimony pill was once used as a medicine. It could be reused by others after ingestion and elimination.\n\nAntimony(III) sulfide is used in the heads of some safety matches.\n\nAntimony sulfides help to stabilize the friction coefficient in automotive brake pad materials.\n\nAntimony is used in bullets, bullet tracers, paint, glass art, and as an opacifier in enamel.\n\nAntimony-124 is used together with beryllium in neutron sources; the gamma rays emitted by antimony-124 initiate the photodisintegration of beryllium. The emitted neutrons have an average energy of 24 keV. Natural antimony is used in startup neutron sources.\n\nThe effects of antimony and its compounds on human and environmental health differ widely. The elemental antimony metal does not affect human and environmental health. Inhalation of antimony trioxide (and similar poorly soluble Sb(III) dust particles such as antimony dust) is considered harmful and suspected of causing cancer. However, these effects are only observed with female rats and after long-term exposure to high dust concentrations. The effects are hypothesized to be attributed to inhalation of poorly soluble Sb particles leading to impaired lung clearance, lung overload, inflammation and ultimately tumour formation, not to exposure to antimony ions (OECD, 2008). Antimony chlorides are corrosive to skin. The effects of antimony are not comparable to arsenic; this might be caused by the significant differences of uptake, metabolism and excretion between arsenic and antimony.\n\nFor oral absorption, ICRP (1994) recommended values of 10% for tartar emetic and 1% for all other antimony compounds. Dermal absorption for metals is estimated at most 1% (HERAG, 2007). Inhalation absorption of antimony trioxide and other poorly soluble Sb(III) substances (such as antimony dust) is estimated at 6.8% (OECD, 2008), whereas a value <1% is derived for Sb(V) substances. Antimony(V) is not quantitatively reduced to antimony(III) in the cell, and both species exist simultaneously.\n\nAntimony is mainly excreted from the human body via urine. Antimony and its compounds do not cause acute human health effects, with the exception of antimony potassium tartrate (\"tartar emetic\"), a prodrug that is intentionally used to treat leishmaniasis patients.\n\nProlonged skin contact with antimony dust may cause dermatitis. However, it was agreed at the European Union level that the skin rashes observed are not substance-specific, but most probably due to a physical blocking of sweat ducts (ECHA/PR/09/09, Helsinki, 6 July 2009). Antimony dust may also be explosive when dispersed in the air; when in a bulk solid it is not combustible.\n\nAntimony is incompatible with strong acids, halogenated acids, and oxidizers; when exposed to newly formed hydrogen it may form stibine (SbH).\n\nThe 8-hour time-weighted average (TWA) is set at 0.5 mg/m by the American Conference of Governmental Industrial Hygienists and by the Occupational Safety and Health Administration (OSHA) as a legal permissible exposure limit (PEL) in the workplace. The National Institute for Occupational Safety and Health (NIOSH) has set a recommended exposure limit (REL) of 0.5 mg/m as an 8 hour TWA. Antimony compounds are used as catalysts for polyethylene terephthalate (PET) production. Some studies report minor antimony leaching from PET bottles into liquids, but levels are below drinking water guidelines. Antimony concentrations in fruit juice concentrates were somewhat higher (up to 44.7 µg/L of antimony), but juices do not fall under the drinking water regulations. The drinking water guidelines are:\n\n\nThe TDI proposed by WHO is 6 µg antimony per kilogram of body weight. The IDLH (immediately dangerous to life and health) value for antimony is 50 mg/m.\n\n\n\n", "id": "898", "title": "Antimony"},{"url": "https://en.wikipedia.org/wiki?curid=899", "text": "Actinium\n\nActinium is a chemical element with symbol Ac and atomic number 89. Actinium gave the name to the actinide series, a group of 15 similar elements between actinium and lawrencium in the periodic table. It is also sometimes considered the first of the 7th-period transition metals, although lawrencium is less commonly given that position. Discovered in 1899, it was the first non-primordial radioactive element to be isolated. Polonium, radium and radon were observed before actinium, but they were not isolated until 1902.\n\nA soft, silvery-white radioactive metal, actinium reacts rapidly with oxygen and moisture in air forming a white coating of actinium oxide that prevents further oxidation. As with most lanthanides and many actinides, actinium assumes oxidation state +3 in nearly all its chemical compounds. Actinium is found only in traces in uranium and thorium ores as the isotope Ac, which decays with a half-life of 21.772 years, predominantly emitting beta and sometimes alpha particles, and Ac, which is beta active with a half-life of 6.15 hours. One tonne of natural uranium in ore contains about 0.2 milligrams of actinium-227, and one tonne of natural thorium contains about 5 nanograms of actinium-228. The close similarity of physical and chemical properties of actinium and lanthanum makes separation of actinium from the ore impractical. Instead, the element is prepared, in milligram amounts, by the neutron irradiation of in a nuclear reactor. Owing to its scarcity, high price and radioactivity, actinium has no significant industrial use. Its current applications include a neutron source and an agent for radiation therapy targeting cancer cells in the body.\n\nAndré-Louis Debierne, a French chemist, announced the discovery of a new element in 1899. He separated it from pitchblende residues left by Marie and Pierre Curie after they had extracted radium. In 1899, Debierne described the substance as similar to titanium and (in 1900) as similar to thorium. Friedrich Oskar Giesel independently discovered actinium in 1902 as a substance being similar to lanthanum and called it \"emanium\" in 1904. After a comparison of the substances half-lives determined by Debierne, Harriet Brooks in 1904, and Otto Hahn and Otto Sackur in 1905, Debierne's chosen name for the new element was retained because it had seniority, despite the contradicting chemical properties he claimed for the element at different times.\n\nArticles published in the 1970s and later suggest that Debierne's results published in 1904 conflict with those reported in 1899 and 1900. Furthermore, the now-known chemistry of actinium precludes its presence as anything other than a minor constituent of Debierne's 1899 and 1900 results; in fact, the chemical properties he reported make it likely that he had, instead, accidentally identified protactinium, which would not be discovered for another fourteen years, only to have it disappear due to its hydrolysis and adsorption onto his laboratory equipment. This has led some authors to advocate that Giesel alone should be credited with the discovery. A less confrontational vision of scientific discovery is proposed by Adloff. He suggests that hindsight criticism of the early publications should be mitigated by the then nascent state of radiochemistry: highlighting the prudence of Debierne's claims in the original papers, he notes that nobody can contend that Debierne's substance did not contain actinium. Debierne, who is now considered by the vast majority of historians as the discoverer, lost interest in the element and left the topic. Giesel, on the other hand, can rightfully be credited with the first preparation of radiochemically pure actinium and with the identification of its atomic number 89.\n\nThe name actinium originates from the Ancient Greek \"aktis, aktinos\" (ακτίς, ακτίνος), meaning beam or ray. Its symbol Ac is also used in abbreviations of other compounds that have nothing to do with actinium, such as acetyl, acetate and sometimes acetaldehyde.\n\nActinium is a soft, silvery-white, radioactive, metallic element. Its estimated shear modulus is similar to that of lead. Owing to its strong radioactivity, actinium glows in the dark with a pale blue light, which originates from the surrounding air ionized by the emitted energetic particles. Actinium has similar chemical properties to lanthanum and other lanthanides, and therefore these elements are difficult to separate when extracting from uranium ores. Solvent extraction and ion chromatography are commonly used for the separation.\n\nThe first element of the actinides, actinium gave the group its name, much as lanthanum had done for the lanthanides. The group of elements is more diverse than the lanthanides and therefore it was not until 1928 that Charles Janet proposed the most significant change to Dmitri Mendeleev's periodic table since the recognition of the lanthanides, by introducing the actinides, a move suggested again in 1945 by Glenn T. Seaborg.\n\nActinium reacts rapidly with oxygen and moisture in air forming a white coating of actinium oxide that impedes further oxidation. As with most lanthanides and actinides, actinium exists in the oxidation state +3, and the Ac ions are colorless in solutions. The oxidation state +3 originates from the [Rn]6d7s electronic configuration of actinium, with three valence electrons that are easily donated to give the stable closed-shell structure of the noble gas radon. The rare oxidation state +2 is only known for actinium dihydride (AcH); even this may in reality be an electride compound like its lighter congener LaH.\n\nOnly a limited number of actinium compounds are known including AcF, AcCl, AcBr, AcOF, AcOCl, AcOBr, AcS, AcO and AcPO. Except for AcPO, they are all similar to the corresponding lanthanum compounds. They all contain actinium in the oxidation state +3. In particular, the lattice constants of the analogous lanthanum and actinium compounds differ by only a few percent.\n\nHere \"a\", \"b\" and \"c\" are lattice constants, No is space group number and \"Z\" is the number of formula units per unit cell. Density was not measured directly but calculated from the lattice parameters.\n\nActinium oxide (AcO) can be obtained by heating the hydroxide at 500 °C or the oxalate at 1100 °C, in vacuum. Its crystal lattice is isotypic with the oxides of most trivalent rare-earth metals.\n\nActinium trifluoride can be produced either in solution or in solid reaction. The former reaction is carried out at room temperature, by adding hydrofluoric acid to a solution containing actinium ions. In the latter method, actinium metal is treated with hydrogen fluoride vapors at 700 °C in an all-platinum setup. Treating actinium trifluoride with ammonium hydroxide at 900–1000 °C yields oxyfluoride AcOF. Whereas lanthanum oxyfluoride can be easily obtained by burning lanthanum trifluoride in air at 800 °C for an hour, similar treatment of actinium trifluoride yields no AcOF and only results in melting of the initial product.\n\nActinium trichloride is obtained by reacting actinium hydroxide or oxalate with carbon tetrachloride vapors at temperatures above 960 °C. Similar to oxyfluoride, actinium oxychloride can be prepared by hydrolyzing actinium trichloride with ammonium hydroxide at 1000 °C. However, in contrast to the oxyfluoride, the oxychloride could well be synthesized by igniting a solution of actinium trichloride in hydrochloric acid with ammonia.\n\nReaction of aluminium bromide and actinium oxide yields actinium tribromide:\n\nand treating it with ammonium hydroxide at 500 °C results in the oxybromide AcOBr.\n\nActinium hydride was obtained by reduction of actinium trichloride with potassium at 300 °C, and its structure was deduced by analogy with the corresponding LaH hydride. The source of hydrogen in the reaction was uncertain.\n\nMixing monosodium phosphate (NaHPO) with a solution of actinium in hydrochloric acid yields white-colored actinium phosphate hemihydrate (AcPO·0.5HO), and heating actinium oxalate with hydrogen sulfide vapors at 1400 °C for a few minutes results in a black actinium sulfide AcS. It may possibly be produced by acting with a mixture of hydrogen sulfide and carbon disulfide on actinium oxide at 1000 °C.\n\nNaturally occurring actinium is composed of two radioactive isotopes; (from the radioactive family of ) and (a granddaughter of ). decays mainly as a beta emitter with a very small energy, but in 1.38% of cases it emits an alpha particle, so it can readily be identified through alpha spectrometry. Thirty-six radioisotopes have been identified, the most stable being with a half-life of 21.772 years, with a half-life of 10.0 days and with a half-life of 29.37 hours. All remaining radioactive isotopes have half-lives that are less than 10 hours and the majority of them have half-lives shorter than one minute. The shortest-lived known isotope of actinium is (half-life of 69 nanoseconds) which decays through alpha decay and electron capture. Actinium also has two known meta states. The most significant isotopes for chemistry are Ac, Ac, and Ac.\n\nPurified comes into equilibrium with its decay products after about a half of year. It decays according to its 21.772-year half-life emitting mostly beta (98.62%) and some alpha particles (1.38%); the successive decay products are part of the actinium series. Owing to the low available amounts, low energy of its beta particles (maximum 44.8 keV) and low intensity of alpha radiation, is difficult to detect directly by its emission and it is therefore traced via its decay products. The isotopes of actinium range in atomic weight from 206 u () to 236 u ().\n\nActinium is found only in traces in uranium ores – one tonne of uranium in ore contains about 0.2 milligrams of Ac – and in thorium ores, which contain about 5 nanograms of Ac per one tonne of thorium. The actinium isotope Ac is a transient member of the uranium-actinium series decay chain, which begins with the parent isotope U (or Pu) and ends with the stable lead isotope Pb. The isotope Ac is a transient member of the thorium series decay chain, which begins with the parent isotope Th and ends with the stable lead isotope Pb. Another actinium isotope (Ac) was transiently present in the neptunium series decay chain, beginning with Np (or U) and ending with thallium (Tl) and near-stable bismuth (Bi), but this chain existed only in the early Solar System, due to the short half-life of neptunium-237.\n\nThe low natural concentration, and the close similarity of physical and chemical properties to those of lanthanum and other lanthanides, which are always abundant in actinium-bearing ores, render separation of actinium from the ore impractical, and complete separation was never achieved. Instead, actinium is prepared, in milligram amounts, by the neutron irradiation of in a nuclear reactor.\n\n\\ce\n", "id": "899", "title": "Actinium"},{"url": "https://en.wikipedia.org/wiki?curid=900", "text": "Americium\n\nAmericium is a radioactive chemical element with symbol Am and atomic number 95. It is a transuranic member of the actinide series, in the periodic table located under the lanthanide element europium, and thus by analogy was named after the Americas.\n\nAmericium was first produced in 1944 by the group of Glenn T. Seaborg from Berkeley, California, at the Metallurgical Laboratory of the University of Chicago, a part of the Manhattan Project. Although it is the third element in the transuranic series, it was discovered fourth, after the heavier curium. The discovery was kept secret and only released to the public in November 1945. Most americium is produced by uranium or plutonium being bombarded with neutrons in nuclear reactors – one tonne of spent nuclear fuel contains about 100 grams of americium. It is widely used in commercial ionization chamber smoke detectors, as well as in neutron sources and industrial gauges. Several unusual applications, such as nuclear batteries or fuel for space ships with nuclear propulsion, have been proposed for the isotope Am, but they are as yet hindered by the scarcity and high price of this nuclear isomer.\n\nAmericium is a relatively soft radioactive metal with silvery appearance. Its common isotopes are Am and Am. In chemical compounds, americium usually assumes the oxidation state +3, especially in solutions. Several other oxidation states are known, which range from +2 to +8 and can be identified by their characteristic optical absorption spectra. The crystal lattice of solid americium and its compounds contain small instrinsic radiogenic defects, due to metamicitization induced by self-irradiation with alpha particles, which accumulates with time; this can cause a drift of some material properties over time, more noticeable in older samples.\n\nAlthough americium was likely produced in previous nuclear experiments, it was first intentionally synthesized, isolated and identified in late autumn 1944, at the University of California, Berkeley, by Glenn T. Seaborg, Leon O. Morgan, Ralph A. James, and Albert Ghiorso. They used a 60-inch cyclotron at the University of California, Berkeley. The element was chemically identified at the Metallurgical Laboratory (now Argonne National Laboratory) of the University of Chicago. Following the lighter neptunium, plutonium, and heavier curium, americium was the fourth transuranium element to be discovered. At the time, the periodic table had been restructured by Seaborg to its present layout, containing the actinide row below the lanthanide one. This led to americium being located right below its twin lanthanide element europium; it was thus by analogy named after the Americas: \"The name americium (after the Americas) and the symbol Am are suggested for the element on the basis of its position as the sixth member of the actinide rare-earth series, analogous to europium, Eu, of the lanthanide series.\"\n\nThe new element was isolated from its oxides in a complex, multi-step process. First plutonium-239 nitrate (PuNO) solution was coated on a platinum foil of about 0.5 cm area, the solution was evaporated and the residue was converted into plutonium dioxide (PuO) by annealing. After cyclotron irradiation, the coating was dissolved with nitric acid, and then precipitated as the hydroxide using concentrated aqueous ammonia solution. The residue was dissolved in perchloric acid. Further separation was carried out by ion exchange, yielding a certain isotope of curium. The separation of curium and americium was so painstaking that those elements were initially called by the Berkeley group as \"pandemonium\" (from Greek for \"all demons\" or \"hell\") and \"delirium\" (from Latin for \"madness\").\n\nInitial experiments yielded four americium isotopes: Am, Am, Am and Am. Americium-241 was directly obtained from plutonium upon absorption of one neutron. It decays by emission of a α-particle to Np; the half-life of this decay was first determined as 510 ± 20 years but then corrected to 432.2 years.\n\nThe second isotope Am was produced upon neutron bombardment of the already-created Am. Upon rapid β-decay, Am converts into the isotope of curium Cm (which had been discovered previously). The half-life of this decay was initially determined at 17 hours, which was close to the presently accepted value of 16.02 h.\n\nThe discovery of americium and curium in 1944 was closely related to the Manhattan Project; the results were confidential and declassified only in 1945. Seaborg leaked the synthesis of the elements 95 and 96 on the U.S. radio show for children \"Quiz Kids\" five days before the official presentation at an American Chemical Society meeting on 11 November 1945, when one of the listeners asked whether any new transuranium element beside plutonium and neptunium had been discovered during the war. After the discovery of americium isotopes Am and Am, their production and compounds were patented listing only Seaborg as the inventor. The initial americium samples weighed a few micrograms; they were barely visible and were identified by their radioactivity. The first substantial amounts of metallic americium weighing 40–200 micrograms were not prepared until 1951 by reduction of americium(III) fluoride with barium metal in high vacuum at 1100 °C.\n\nThe longest-lived and most common isotopes of americium, Am and Am, have half-lives of 432.2 and 7,370 years, respectively. Therefore, any primordial americium (americium that was present on Earth during its formation) should have decayed by now.\n\nExisting americium is concentrated in the areas used for the atmospheric nuclear weapons tests conducted between 1945 and 1980, as well as at the sites of nuclear incidents, such as the Chernobyl disaster. For example, the analysis of the debris at the testing site of the first U.S. hydrogen bomb, Ivy Mike, (1 November 1952, Enewetak Atoll), revealed high concentrations of various actinides including americium; but due to military secrecy, this result was not published until later, in 1956. Trinitite, the glassy residue left on the desert floor near Alamogordo, New Mexico, after the plutonium-based Trinity nuclear bomb test on 16 July 1945, contains traces of americium-241. Elevated levels of americium were also detected at the crash site of a US Boeing B-52 bomber aircraft, which carried four hydrogen bombs, in 1968 in Greenland.\n\nIn other regions, the average radioactivity of surface soil due to residual americium is only about 0.01 picocuries/g (0.37 mBq/g). Atmospheric americium compounds are poorly soluble in common solvents and mostly adhere to soil particles. Soil analysis revealed about 1,900 times higher concentration of americium inside sandy soil particles than in the water present in the soil pores; an even higher ratio was measured in loam soils.\n\nAmericium is produced mostly artificially in small quantities, for research purposes. A tonne of spent nuclear fuel contains about 100 grams of various americium isotopes, mostly Am and Am. Their prolonged radioactivity is undesirable for the disposal, and therefore americium, together with other long-lived actinides, must be neutralized. The associated procedure may involve several steps, where americium is first separated and then converted by neutron bombardment in special reactors to short-lived nuclides. This procedure is well known as nuclear transmutation, but it is still being developed for americium. The transuranic elements from americium to fermium occurred naturally in the natural nuclear fission reactor at Oklo, but no longer do so.\n\nAmericium has been produced in small quantities in nuclear reactors for decades, and kilograms of its Am and Am isotopes have been accumulated by now. Nevertheless, since it was first offered for sale in 1962, its price, about 1,500 USD per gram of Am, remains almost unchanged owing to the very complex separation procedure. The heavier isotope Am is produced in much smaller amounts; it is thus more difficult to separate, resulting in a higher cost of the order 100,000–160,000 USD/g.\n\nAmericium is not synthesized directly from uranium – the most common reactor material – but from the plutonium isotope Pu. The latter needs to be produced first, according to the following nuclear process:\n\nThe capture of two neutrons by Pu (a so-called (n,γ) reaction), followed by a β-decay, results in Am:\n\nThe plutonium present in spent nuclear fuel contains about 12% of Pu. Because it spontaneously converts to Am, Pu can be extracted and may be used to generate further Am. However, this process is rather slow: half of the original amount of Pu decays to Am after about 15 years, and the Am amount reaches a maximum after 70 years.\n\nThe obtained Am can be used for generating heavier americium isotopes by further neutron capture inside a nuclear reactor. In a light water reactor (LWR), 79% of Am converts to Am and 10% to its nuclear isomer Am:\n\nAmericium-242 has a half-life of only 16 hours, which makes its further up-conversion to Am, extremely inefficient. The latter isotope is produced instead in a process where Pu captures four neutrons under high neutron flux:\n\nMost synthesis routines yield a mixture of different actinide isotopes in oxide forms, from which isotopes of americium can be separated. In a typical procedure, the spent reactor fuel (e.g. MOX fuel) is dissolved in nitric acid, and the bulk of uranium and plutonium is removed using a PUREX-type extraction (Plutonium–URanium EXtraction) with tributyl phosphate in a hydrocarbon. The lanthanides and remaining actinides are then separated from the aqueous residue (raffinate) by a diamide-based extraction, to give, after stripping, a mixture of trivalent actinides and lanthanides. Americium compounds are then selectively extracted using multi-step chromatographic and centrifugation techniques with an appropriate reagent. A large amount of work has been done on the solvent extraction of americium. For example, a 2003 EU-funded project codenamed \"EUROPART\" studied triazines and other compounds as potential extraction agents. A \"bis\"-triazinyl bipyridine complex was proposed in 2009 as such a reagent is highly selective to americium (and curium). Separation of americium from the highly similar curium can be achieved by treating a slurry of their hydroxides in aqueous sodium bicarbonate with ozone, at elevated temperatures. Both Am and Cm are mostly present in solutions in the +3 valence state; whereas curium remains unchanged, americium oxidizes to soluble Am(IV) complexes which can be washed away.\n\nMetallic americium is obtained by reduction from its compounds. Americium(III) fluoride was first used for this purpose. The reaction was conducted using elemental barium as reducing agent in a water- and oxygen-free environment inside an apparatus made of tantalum and tungsten.\n\nAn alternative is the reduction of americium dioxide by metallic lanthanum or thorium:\n\nIn the periodic table, americium is located to the right of plutonium, to the left of curium, and below the lanthanide europium, with which it shares many similarities in physical and chemical properties. Americium is a highly radioactive element. When freshly prepared, it has a silvery-white metallic lustre, but then slowly tarnishes in air. With a density of 12 g/cm, americium is less dense than both curium (13.52 g/cm) and plutonium (19.8 g/cm); but has a higher density than europium (5.264 g/cm)—mostly because of its higher atomic mass. Americium is relatively soft and easily deformable and has a significantly lower bulk modulus than the actinides before it: Th, Pa, U, Np and Pu. Its melting point of 1173 °C is significantly higher than that of plutonium (639 °C) and europium (826 °C), but lower than for curium (1340 °C).\n\nAt ambient conditions, americium is present in its most stable α form which has a hexagonal crystal symmetry, and a space group P6/mmc with lattice parameters \"a\" = 346.8 pm and \"c\" = 1124 pm, and four atoms per unit cell. The crystal consists of a double-hexagonal close packing with the layer sequence ABAC and so is isotypic with α-lanthanum and several actinides such as α-curium. The crystal structure of americium changes with pressure and temperature. When compressed at room temperature to 5 GPa, α-Am transforms to the β modification, which has a face-centered cubic (\"fcc\") symmetry, space group Fmm and lattice constant \"a\" = 489 pm. This \"fcc\" structure is equivalent to the closest packing with the sequence ABC. Upon further compression to 23 GPa, americium transforms to an orthorhombic γ-Am structure similar to that of α-uranium. There are no further transitions observed up to 52 GPa, except for an appearance of a monoclinic phase at pressures between 10 and 15 GPa. There is no consistency on the status of this phase in the literature, which also sometimes lists the α, β and γ phases as I, II and III. The β-γ transition is accompanied by a 6% decrease in the crystal volume; although theory also predicts a significant volume change for the α-β transition, it is not observed experimentally. The pressure of the α-β transition decreases with increasing temperature, and when α-americium is heated at ambient pressure, at 770 °C it changes into an \"fcc\" phase which is different from β-Am, and at 1075 °C it converts to a body-centered cubic structure. The pressure-temperature phase diagram of americium is thus rather similar to those of lanthanum, praseodymium and neodymium.\n\nAs with many other actinides, self-damage of the crystal lattice due to alpha-particle irradiation is intrinsic to americium. It is especially noticeable at low temperatures, where the mobility of the produced lattice defects is relatively low, by broadening of X-ray diffraction peaks. This effect makes somewhat uncertain the temperature of americium and some of its properties, such as electrical resistivity. So for americium-241, the resistivity at 4.2 K increases with time from about 2 µOhm·cm to 10 µOhm·cm after 40 hours, and saturates at about 16 µOhm·cm after 140 hours. This effect is less pronounced at room temperature, due to annihilation of radiation defects; also heating to room temperature the sample which was kept for hours at low temperatures restores its resistivity. In fresh samples, the resistivity gradually increases with temperature from about 2 µOhm·cm at liquid helium to 69 µOhm·cm at room temperature; this behavior is similar to that of neptunium, uranium, thorium and protactinium, but is different from plutonium and curium which show a rapid rise up to 60 K followed by saturation. The room temperature value for americium is lower than that of neptunium, plutonium and curium, but higher than for uranium, thorium and protactinium.\n\nAmericium is paramagnetic in a wide temperature range, from that of liquid helium, to room temperature and above. This behavior is markedly different from that of its neighbor curium which exhibits antiferromagnetic transition at 52 K. The thermal expansion coefficient of americium is slightly anisotropic and amounts to (7.5 ± 0.2)/°C along the shorter \"a\" axis and (6.2 ± 0.4)/°C for the longer \"c\" hexagonal axis. The enthalpy of dissolution of americium metal in hydrochloric acid at standard conditions is −620.6 ± 1.3 kJ/mol, from which the standard enthalpy change of formation (Δ\"H\"°) of aqueous Am ion is −621.2 ± 2.0 kJ/mol. The standard potential Am/Am is −2.08 ± 0.01 V.\n\nAmericium readily reacts with oxygen and dissolves well in acids. The most common oxidation state for americium is +3, in which americium compounds are rather stable against oxidation and reduction. In this sense, americium is chemically similar to most lanthanides. The trivalent americium forms insoluble fluoride, oxalate, iodate, hydroxide, phosphate and other salts. Other oxidation states have been observed between +2 and +7, which is the widest range among the actinide elements. Their color in aqueous solutions varies as follows: Am (colorless to yellow-reddish), Am (yellow-reddish), Am; (yellow), Am (brown) and Am (dark green). All oxidation states have their characteristic optical absorption spectra, with a few sharp peaks in the visible and mid-infrared regions, and the position and intensity of these peaks can be converted into the concentrations of the corresponding oxidation states. For example, Am(III) has two sharp peaks at 504 and 811 nm, Am(V) at 514 and 715 nm, and Am(VI) at 666 and 992 nm.\n\nAmericium compounds with oxidation state +4 and higher are strong oxidizing agents, comparable in strength to the permanganate ion () in acidic solutions. Whereas the Am ions are unstable in solutions and readily convert to Am, the +4 oxidation state occurs well in solids, such as americium dioxide (AmO) and americium(IV) fluoride (AmF).\n\nAll pentavalent and hexavalent americium compounds are complex salts such as KAmOF, LiAmO and LiAmO, BaAmO, AmOF. These high oxidation states Am(IV), Am(V) and Am(VI) can be prepared from Am(III) by oxidation with ammonium persulfate in dilute nitric acid, with silver(I) oxide in perchloric acid, or with ozone or sodium persulfate in sodium carbonate solutions. The pentavalent oxidation state of americium was first observed in 1951. It is present in aqueous solution in the form of ions (acidic) or ions (alkaline) which are however unstable and subject to several rapid disproportionation reactions:\n\nThree americium oxides are known, with the oxidation states +2 (AmO), +3 (AmO) and +4 (AmO). Americium(II) oxide was prepared in minute amounts and has not been characterized in details. Americium(III) oxide is a red-brown solid with a melting point of 2205 °C. Americium(IV) oxide is the main form of solid americium which is used in nearly all its applications. As most other actinide dioxides, it is a black solid with a cubic (fluorite) crystal structure.\n\nThe oxalate of americium(III), vacuum dried at room temperature, has the chemical formula Am(CO)·7HO. Upon heating in vacuum, it loses water at 240 °C and starts decomposing into AmO at 300 °C, the decomposition completes at about 470 °C. The initial oxalate dissolves in nitric acid with the maximum solubility of 0.25 g/L.\n\nHalides of americium are known for the oxidation states +2, +3 and +4, where the +3 is most stable, especially in solutions.\n\nReduction of Am(III) compounds with sodium amalgam yields Am(II) salts – the black halides AmCl, AmBr and AmI. They are very sensitive to oxygen and oxidize in water, releasing hydrogen and converting back to the Am(III) state. Specific lattice constants are:\n\nAmericium(III) fluoride (AmF) is poorly soluble and precipitates upon reaction of Am and fluoride ions in weak acidic solutions:\n\nThe tetravalent americium(IV) fluoride (AmF) is obtained by reacting solid americium(III) fluoride with molecular fluorine:\n\nAnother known form of solid tetravalent americium chloride is KAmF. Tetravalent americium has also been observed in the aqueous phase. For this purpose, black Am(OH) was dissolved in 15-M NHF with the americium concentration of 0.01 M. The resulting reddish solution had a characteristic optical absorption spectrum which is similar to that of AmF but differed from other oxidation states of americium. Heating the Am(IV) solution to 90 °C did not result in its disproportionation or reduction, however a slow reduction was observed to Am(III) and assigned to self-irradiation of americium by alpha particles.\n\nMost americium(III) halides form hexagonal crystals with slight variation of the color and exact structure between the halogens. So, chloride (AmCl) is reddish and has a structure isotypic to uranium(III) chloride (space group P6/m) and the melting point of 715 °C. The fluoride is isotypic to LaF (space group P6/mmc) and the iodide to BiI (space group R). The bromide is an exception with the orthorhombic PuBr-type structure and space group Cmcm. Crystals of americium hexahydrate (AmCl·6HO) can be prepared by dissolving americium dioxide in hydrochloric acid and evaporating the liquid. Those crystals are hygroscopic and have yellow-reddish color and a monoclinic crystal structure.\n\nOxyhalides of americium in the form AmOX, AmOX, AmOX and AmOX can be obtained by reacting the corresponding americium halide with oxygen or SbO, and AmOCl can also be produced by vapor phase hydrolysis:\n\nThe known chalcogenides of americium include the sulfide AmS, selenides AmSe and AmSe, and tellurides AmTe and AmTe. The pnictides of americium (Am) of the AmX type are known for the elements phosphorus, arsenic, antimony and bismuth. They crystallize in the rock-salt lattice.\n\nAmericium monosilicide (AmSi) and \"disilicide\" (nominally AmSi with: 1.87 < x < 2.0) were obtained by reduction of americium(III) fluoride with elementary silicon in vacuum at 1050 °C (AmSi) and 1150−1200 °C (AmSi). AmSi is a black solid isomorphic with LaSi, it has an orthorhombic crystal symmetry. AmSi has a bright silvery lustre and a tetragonal crystal lattice (space group \"I\"4/amd), it is isomorphic with PuSi and ThSi. Borides of americium include AmB and AmB. The tetraboride can be obtained by heating an oxide or halide of americium with magnesium diboride in vacuum or inert atmosphere.\n\nAnalogous to uranocene, americium forms the organometallic compound amerocene with two cyclooctatetraene ligands, with the chemical formula (η-CH)Am. It also makes the trigonal tricyclopentadienylamericium [(η-CH)Am)] complex with three cyclopentadienyl rings surrounding one atom of americium.\n\nFormation of the complexes of the type Am(n-CH-BTP), where BTP stands for 2,6-di(1,2,4-triazin-3-yl)pyridine, in solutions containing n-CH-BTP and Am ions has been confirmed by EXAFS. Some of these BTP-type complexes selectively interact with americium and therefore are useful in its selective separation from lanthanides and another actinides.\n\nAmericium is an artificial element of recent origin, and thus does not have a biological requirement. It is harmful to life. It has been proposed to use bacteria for removal of americium and other heavy metals from rivers and streams. Thus, Enterobacteriaceae of the genus \"Citrobacter\" precipitate americium ions from aqueous solutions, binding them into a metal-phosphate complex at their cell walls. Several studies have been reported on the biosorption and bioaccumulation of americium by bacteria and fungi.\n\nThe isotope Am (half-life 141 years) has the largest cross sections for absorption of thermal neutrons (5,700 barns), that results in a small critical mass for a sustained nuclear chain reaction. The critical mass for a bare Am sphere is about 9–14 kg (the uncertainty results from insufficient knowledge of its material properties). It can be lowered to 3–5 kg with a metal reflector and should become even smaller with a water reflector. Such small critical mass is favorable for portable nuclear weapons, but those based on Am are not known yet, probably because of its scarcity and high price. The critical masses of two other readily available isotopes, Am and Am, are relatively high – 57.6 to 75.6 kg for Am and 209 kg for Am. Scarcity and high price yet hinder application of americium as a nuclear fuel in nuclear reactors.\n\nThere are proposals of very compact 10-kW high-flux reactors using as little as 20 grams of Am. Such low-power reactors would be relatively safe to use as neutron sources for radiation therapy in hospitals.\n\nAbout 19 isotopes and 8 nuclear isomers are known for americium. There are two long-lived alpha-emitters, Am and Am with half-lives of 432.2 and 7,370 years, respectively, and the nuclear isomer Am has a long half-life of 141 years. The half-lives of other isotopes and isomers range from 0.64 microseconds for Am to 50.8 hours for Am. As with most other actinides, the isotopes of americium with odd number of neutrons have relatively high rate of nuclear fission and low critical mass.\n\nAmericium-241 decays to Np emitting alpha particles of 5 different energies, mostly at 5.486 MeV (85.2%) and 5.443 MeV (12.8%). Because many of the resulting states are metastable, they also emit gamma rays with the discrete energies between 26.3 and 158.5 keV.\n\nAmericium-242 is a short-lived isotope with a half-life of 16.02 h. It mostly (82.7%) converts by β-decay to Cm, but also by electron capture to Pu (17.3%). Both Cm and Pu transform via nearly the same decay chain through Pu down to U.\n\nNearly all (99.541%) of Am decays by internal conversion to Am and the remaining 0.459% by α-decay to Np. The latter subsequently decays to Pu and then to U.\n\nAmericium-243 transforms by α-emission into Np, which converts by β-decay to Pu, and the Pu changes into U by emitting an α-particle.\n\nAmericium is the only synthetic element to have found its way into the household, where the most common type of smoke detector uses Am in the form of americium dioxide as its source of ionizing radiation. This isotope is preferred over Ra because it emits 5 times more alpha particles and relatively little harmful gamma radiation. Element collector Theodore Gray mentions in his book \"The Elements: A Visual Exploration of Every Known Atom in the Universe\":\n\nThe amount of americium in a typical new smoke detector is 1 microcurie (37 kBq) or 0.29 microgram. This amount declines slowly as the americium decays into neptunium-237, a different transuranic element with a much longer half-life (about 2.14 million years). With its half-life of 432.2 years, the americium in a smoke detector includes about 3% neptunium after 19 years, and about 5% after 32 years. The radiation passes through an ionization chamber, an air-filled space between two electrodes, and permits a small, constant current between the electrodes. Any smoke that enters the chamber absorbs the alpha particles, which reduces the ionization and affects this current, triggering the alarm. Compared to the alternative optical smoke detector, the ionization smoke detector is cheaper and can detect particles which are too small to produce significant light scattering; however, it is more prone to false alarms.\n\nAs Am has a roughly similar half-life to Pu (432.2 years vs. 87 years), it has been proposed as an active element of radioisotope thermoelectric generators, for example in spacecraft. Although americium produces less heat and electricity – the power yield is 114.7 mW/g for Am and 6.31 mW/g for Am (cf. 390 mW/g for Pu) – and its radiation poses more threat to humans owing to neutron emission, the European Space Agency is considering using americium for its space probes.\n\nAnother proposed space-related application of americium is a fuel for space ships with nuclear propulsion. It relies on the very high rate of nuclear fission of Am, which can be maintained even in a micrometer-thick foil. Small thickness avoids the problem of self-absorption of emitted radiation. This problem is pertinent to uranium or plutonium rods, in which only surface layers provide alpha-particles. The fission products of Am can either directly propel the spaceship or they can heat up a thrusting gas; they can also transfer their energy to a fluid and generate electricity through a magnetohydrodynamic generator.\n\nOne more proposal which utilizes the high nuclear fission rate of Am is a nuclear battery. Its design relies not on the energy of the emitted by americium alpha particles, but on their charge, that is the americium acts as the self-sustaining \"cathode\". A single 3.2 kg Am charge of such battery could provide about 140 kW of power over a period of 80 days. Even with all the potential benefits, the current applications of Am are as yet hindered by the scarcity and high price of this particular nuclear isomer.\n\nThe oxide of Am pressed with beryllium is an efficient neutron source. Here americium acts as the alpha source, and beryllium produces neutrons owing to its large cross-section for the (α,n) nuclear reaction:\n\nThe most widespread use of AmBe neutron sources is a neutron probe – a device used to measure the quantity of water present in soil, as well as moisture/density for quality control in highway construction. Am neutron sources are also used in well logging applications, as well as in neutron radiography, tomography and other radiochemical investigations.\n\nAmericium is a starting material for the production of other transuranic elements and transactinides – for example, 82.7% of Am decays to Cm and 17.3% to Pu. In the nuclear reactor, Am is also up-converted by neutron capture to Am and Am, which transforms by β-decay to Cm:\n\nIrradiation of Am by C or Ne ions yields the isotopes Es (einsteinium) or Db (dubnium), respectively. Furthermore, the element berkelium (Bk isotope) had been first intentionally produced and identified by bombarding Am with alpha particles, in 1949, by the same Berkeley group, using the same 60-inch cyclotron. Similarly, nobelium was produced at the Joint Institute for Nuclear Research, Dubna, Russia, in 1965 in several reactions, one of which included irradiation of Am with N ions. Besides, one of the synthesis reactions for lawrencium, discovered by scientists at Berkeley and Dubna, included bombardment of Am with O.\n\nAmericium-241 has been used as a portable source of both gamma rays and alpha particles for a number of medical and industrial uses. The 59.5409 keV gamma ray emissions from Am in such sources can be used for indirect analysis of materials in radiography and X-ray fluorescence spectroscopy, as well as for quality control in fixed nuclear density gauges and nuclear densometers. For example, the element has been employed to gauge glass thickness to help create flat glass. Americium-241 is also suitable for calibration of gamma-ray spectrometers in the low-energy range, since its spectrum consists of nearly a single peak and negligible Compton continuum (at least three orders of magnitude lower intensity). Americium-241 gamma rays were also used to provide passive diagnosis of thyroid function. This medical application is however obsolete.\n\nAs a highly radioactive element, americium and its compounds must be handled only in an appropriate laboratory under special arrangements. Although most americium isotopes predominantly emit alpha particles which can be blocked by thin layers of common materials, many of the daughter products emit gamma-rays and neutrons which have a long penetration depth.\n\nIf consumed, most of the americium is excreted within a few days, with only 0.05% absorbed in the blood, of which roughly 45% goes to the liver and 45% to the bones, and the remaining 10% is excreted. The uptake to the liver depends on the individual and increases with age. In the bones, americium is first deposited over cortical and trabecular surfaces and slowly redistributes over the bone with time. The biological half-life of Am is 50 years in the bones and 20 years in the liver, whereas in the gonads (testicles and ovaries) it remains permanently; in all these organs, americium promotes formation of cancer cells as a result of its radioactivity.\n\nAmericium often enters landfills from discarded smoke detectors. The rules associated with the disposal of smoke detectors are relaxed in most jurisdictions. In 1994, 17-year-old David Hahn extracted the americium from about 100 smoke detectors in an attempt to build a breeder nuclear reactor. There have been a few cases of exposure to americium, the worst case being that of chemical operations technician Harold McCluskey, who at the age of 64 was exposed to 500 times the occupational standard for americium-241 as a result of an explosion in his lab. McCluskey died at the age of 75 of unrelated pre-existing disease.\n\n\n\n\n", "id": "900", "title": "Americium"},{"url": "https://en.wikipedia.org/wiki?curid=901", "text": "Astatine\n\nAstatine is a radioactive chemical element with symbol At and atomic number 85. It is the rarest naturally occurring element on the Earth's crust. It occurs on Earth as the decay product of various heavier elements. All its isotopes are short-lived; the most stable is astatine-210, with a half-life of 8.1 hours. Elemental astatine has never been viewed because any macroscopic sample would be immediately vaporized by its radioactive heating. It has yet to be determined if this obstacle could be overcome with sufficient cooling.\n\nThe bulk properties of astatine are not known with any certainty. Many of these have been estimated based on its periodic table position as a heavier analog of iodine, and a member of the halogens – the group of elements including fluorine, chlorine, bromine, and iodine. It is likely to have a dark or lustrous appearance and may be a semiconductor or possibly a metal; it probably has a higher melting point than that of iodine. Chemically, several anionic species of astatine are known and most of its compounds resemble those of iodine. It also shows some metallic behavior, including being able to form a stable monatomic cation in aqueous solution (unlike the lighter halogens).\n\nDale R. Corson, Kenneth Ross MacKenzie, and Emilio G. Segrè synthesized the element at the University of California, Berkeley in 1940, naming it after the Greek \"astatos\" (ἄστατος), \"unstable\". Four isotopes of astatine were subsequently found in nature, although it is the least abundant of all the naturally occurring elements, with much less than one gram being present at any given time in the Earth's crust. Neither the most stable isotope astatine-210 nor the medically useful astatine-211 occurs naturally. They can only be produced synthetically, usually by bombarding bismuth-209 with alpha particles.\n\nAstatine is an extremely radioactive element; all its isotopes have short half-lives of 8.1 hours or less, decaying into other astatine isotopes, bismuth, polonium or radon. Most of its isotopes are very unstable with half-lives of one second or less. Of the first 101 elements in the periodic table, only francium is less stable, and all the astatine isotopes more stable than francium are in any case synthetic and do not occur in nature.\n\nThe bulk properties of astatine are not known with any certainty. Research is limited by its short half-life, which prevents the creation of weighable quantities. A visible piece of astatine would immediately vaporize itself because of the heat generated by its intense radioactivity. It remains to be seen if, with sufficient cooling, a macroscopic quantity of astatine could be deposited as a thin film. Astatine is usually classified as either a nonmetal or a metalloid; metal formation has also been predicted.\n\nMost of the physical properties of astatine have been estimated (by interpolation or extrapolation), using theoretically or empirically derived methods. For example, halogens get darker with increasing atomic weight – fluorine is nearly colorless, chlorine is yellow-green, bromine is red-brown, and iodine is dark gray/violet. Astatine is sometimes described as probably being a black solid (assuming it follows this trend), or as having a metallic appearance (if it is a metalloid or a metal). The melting and boiling points of astatine are also expected to follow the trend seen in the halogen series, increasing with atomic number. On this basis they are estimated to be , respectively. Some experimental evidence suggests astatine may have lower melting and boiling points than those implied by the halogen trend. Astatine sublimes less readily than does iodine, having a lower vapor pressure. Even so, half of a given quantity of astatine will vaporize in approximately an hour if put on a clean glass surface at room temperature. The absorption spectrum of astatine in the middle ultraviolet region has lines at 224.401 and 216.225 nm, suggestive of 6p to 7s transitions.\n\nThe structure of solid astatine is unknown. As an analogue of iodine it may have an orthorhombic crystalline structure composed of diatomic astatine molecules, and be a semiconductor (with a band gap of 0.7 eV). Alternatively, if condensed astatine forms a metallic phase, as has been predicted, it may have a monatomic face-centered cubic structure. Evidence for (or against) the existence of diatomic astatine (At) is sparse and inconclusive. Some sources state that it does not exist, or at least has never been observed, while other sources assert or imply its existence. Despite this controversy, many properties of diatomic astatine have been predicted; for example, its bond length would be 300 ±10 pm, dissociation energy 83.7 ±12.5 kJ·mol, and heat of vaporization (∆H) 54.39 kJ·mol. The latter figure means that astatine may (at least) be metallic in the liquid state on the basis that elements with a heat of vaporization greater than ~42 kJ·mol are metallic when liquid; diatomic iodine, with a value of 41.71 kJ·mol, falls just short of the threshold figure.\n\nThe chemistry of astatine is \"clouded by the extremely low concentrations at which astatine experiments have been conducted, and the possibility of reactions with impurities, walls and filters, or radioactivity by-products, and other unwanted nano-scale interactions.\" Many of its apparent chemical properties have been observed using tracer studies on extremely dilute astatine solutions, typically less than 10 mol·L. Some properties – such as anion formation – align with other halogens. Astatine has some metallic characteristics as well, such as plating onto a cathode, coprecipitating with metal sulfides in hydrochloric acid, and forming a stable monatomic cation in aqueous solution. It forms complexes with EDTA, a metal chelating agent, and is capable of acting as a metal in antibody radiolabeling; in some respects astatine in the +1 state is akin to silver in the same state. Most of the organic chemistry of astatine is, however, analogous to that of iodine.\n\nAstatine has an electronegativity of 2.2 on the revised Pauling scale – lower than that of iodine (2.66) and the same as hydrogen. In hydrogen astatide (HAt) the negative charge is predicted to be on the hydrogen atom, implying that this compound should instead be referred to as astatine hydride. That would be consistent with the electronegativity of astatine on the Allred–Rochow scale (1.9) being less than that of hydrogen (2.2). The electron affinity of astatine is predicted to be reduced by one-third because of spin-orbit interactions.\n\nLess reactive than iodine, astatine is the least reactive of the halogens, although its compounds have been synthesized in microscopic amounts and studied as intensively as possible before their radioactive disintegration. The reactions involved have been typically tested with dilute solutions of astatine mixed with larger amounts of iodine. Acting as a carrier, the iodine ensures there is sufficient material for laboratory techniques (such as filtration and precipitation) to work. Like iodine, astatine has been shown to adopt odd-numbered oxidation states ranging from −1 to +7.\n\nOnly a few compounds with metals have been reported, in the form of astatides of sodium, palladium, silver, thallium, and lead. Some characteristic properties of silver and sodium astatide, and the other hypothetical alkali and alkaline earth astatides, have been estimated by extrapolation from other metal halides.\n\nThe formation of an astatine compound with hydrogen – usually referred to as hydrogen astatide – was noted by the pioneers of astatine chemistry. As mentioned, there are grounds for instead referring to this compound as astatine hydride. It is easily oxidized; acidification by dilute nitric acid gives the At or At forms, and the subsequent addition of silver(I) may only partially, at best, precipitate astatine as silver(I) astatide (AgAt). Iodine, in contrast, is not oxidized, and precipitates readily as silver(I) iodide.\n\nAstatine is known to bind to boron, carbon, and nitrogen. Various boron cage compounds have been prepared with At–B bonds, these being more stable than At–C bonds. Carbon tetraastatide (CAt) has been synthesized. Astatine can replace a hydrogen atom in benzene to form astatobenzene CHAt; this may be oxidized to CHAtCl by chlorine. By treating this compound with an alkaline solution of hypochlorite, CHAtO can be produced. In the molecules dipyridine-astatine(I) perchlorate [At(CHN)][ClO] and the analogous nitrate, the astatine atom is bonded to each nitrogen atom in the two pyridine rings.\n\nWith oxygen, there is evidence of the species AtO, , and AtO in aqueous solution, formed by the reaction of astatine with an oxidant such as elemental bromine or (in the last case) by sodium persulfate in a solution of perchloric acid. The well characterized anion can be obtained by, for example, the oxidation of astatine with potassium hypochlorite in a solution of potassium hydroxide. Preparation of lanthanum triastatinate La(AtO), following the oxidation of astatine by a hot NaSO solution, has been reported. Further oxidation of , such as by xenon difluoride (in a hot alkaline solution) or periodate (in a neutral or alkaline solution), yields the perastatate ion ; this is only stable in neutral or alkaline solutions. Astatine is also thought to be capable of forming cations in salts with oxyanions such as iodate or dichromate; this is based on the observation that, in acidic solutions, monovalent or intermediate positive states of astatine coprecipitate with the insoluble salts of metal cations such as silver(I) iodate or thallium(I) dichromate.\n\nAstatine may form bonds to the other chalcogens; these include SAt and with sulfur, a coordination selenourea compound with selenium, and an astatine–tellurium colloid with tellurium.\n\nAstatine is known to react with its lighter homologs iodine, bromine, and chlorine in the vapor state; these reactions produce diatomic interhalogen compounds with formulas AtI, AtBr, and AtCl. The first two compounds may also be produced in water – astatine reacts with iodine/iodide solution to form AtI, whereas AtBr requires (aside from astatine) an iodine/iodine monobromide/bromide solution. The excess of iodides or bromides may lead to and ions, or in a chloride solution, they may produce species like or via equilibrium reactions with the chlorides. Oxidation of the element with dichromate (in nitric acid solution) showed that adding chloride turned the astatine into a molecule likely to be either AtCl or AtOCl. Similarly, or may be produced. Polyhalides PdAtI, CsAtI, TlAtI, and PbAtI are known or presumed to have been precipitated. In a plasma ion source mass spectrometer, the ions [AtI], [AtBr], and [AtCl] have been formed by introducing lighter halogen vapors into a helium-filled cell containing astatine, supporting the existence of stable neutral molecules in the plasma ion state. No astatine fluorides have been discovered yet. Their absence has been speculatively attributed to the extreme reactivity of such compounds, including the reaction of an initially formed fluoride with the walls of the glass container to form a non-volatile product. Thus, although the synthesis of an astatine fluoride is thought to be possible, it may require a liquid halogen fluoride solvent, as has already been used for the characterization of radon fluoride.\n\nIn 1869, when Dmitri Mendeleev published his periodic table, the space under iodine was empty; after Niels Bohr established the physical basis of the classification of chemical elements, it was suggested that the fifth halogen belonged there. Before its officially recognized discovery, it was called \"eka-iodine\" (from Sanskrit \"eka\" – \"one\") to imply it was one space under iodine (in the same manner as eka-silicon, eka-boron, and others). Scientists tried to find it in nature; given its extreme rarity, these attempts resulted in several false discoveries.\n\nThe first claimed discovery of eka-iodine was made by Fred Allison and his associates at the Alabama Polytechnic Institute (now Auburn University) in 1931. The discoverers named element 85 \"alabamine\", and assigned it the symbol Ab, designations that were used for a few years. In 1934, H. G. MacPherson of University of California, Berkeley disproved Allison's method and the validity of his discovery. There was another claim in 1937, by the chemist Rajendralal De. Working in Dacca in British India (now Dhaka in Bangladesh), he chose the name \"dakin\" for element 85, which he claimed to have isolated as the thorium series equivalent of radium F (polonium-210) in the radium series. The properties he reported for dakin do not correspond to those of astatine; moreover, astatine is not found in the thorium series, and the true identity of dakin is not known.\n\nIn 1936, a team of Romanian physicist Horia Hulubei and French physicist Yvette Cauchois claimed to have discovered element 85 via X-ray analysis. In 1939 they published another paper which supported and extended previous data. In 1944, Hulubei published a summary of data he had obtained up to that time, claiming it was supported by the work of other researchers. He chose the name \"dor\", presumably from the Romanian for \"longing\" [for peace], as World War II had started five years earlier. As Hulubei was writing in French, a language which does not accommodate the \"ine\" suffix, dor would likely have been rendered in English as \"dorine\", had it been adopted. In 1947, Hulubei's claim was effectively rejected by the Austrian chemist Friedrich Paneth, who would later chair the IUPAC committee responsible for recognition of new elements. Even though Hulubei's samples did contain astatine, his means to detect it were too weak, by current standards, to enable correct identification. He had also been involved in an earlier false claim as to the discovery of element 87 (francium) and this is thought to have caused other researchers to downplay his work.\nIn 1940, the Swiss chemist Walter Minder announced the discovery of element 85 as the beta decay product of radium A (polonium-218), choosing the name \"helvetium\" (from , \"Switzerland\"). Karlik and Bernert were unsuccessful in reproducing his experiments, and subsequently attributed Minder's results to contamination of his radon stream (radon-222 is the parent isotope of polonium-218). In 1942, Minder, in collaboration with the English scientist Alice Leigh-Smith, announced the discovery of another isotope of element 85, presumed to be the product of thorium A (polonium-216) beta decay. They named this substance \"anglo-helvetium\", but Karlik and Bernert were again unable to reproduce these results.\n\nLater in 1940, Dale R. Corson, Kenneth Ross MacKenzie, and Emilio Segrè isolated the element at the University of California, Berkeley. Instead of searching for the element in nature, the scientists created it by bombarding bismuth-209 with alpha particles in a cyclotron (particle accelerator) to produce, after emission of two neutrons, astatine-211. The discoverers, however, did not immediately suggest a name for the element; this was because an element created synthetically at the moment was not seen as a completely valid one, created in \"invisible quantities\" and not yet discovered in nature; in addition, chemists were reluctant to recognize radioactive isotopes as legitimately as stable ones. In 1943, astatine was found as a product of two naturally occurring decay chains by Berta Karlik and Traude Bernert, first in the so-called uranium series, and then in the actinium series. (Since then, astatine has been determined in a third decay chain, the neptunium series.) Friedrich Paneth in 1946 called to finally recognize synthetic elements, quoting, among other reasons, recent confirmation of their natural occurrence, and proposed the discoverers of the newly discovered unnamed elements name these elements. In early 1947, \"Nature\" published discoverers' suggestions; a letter from Corson, MacKenzie, and Segrè suggested the name \"astatine\" coming from the Greek \"astatos\" (αστατος) meaning \"unstable\", because of its propensity for radioactive decay, with the ending \"-ine\", found in the names of the four previously discovered halogens. The name was also chosen to continue the tradition of the four stable halogens, where the name referred to a property of the element.\n\nCorson and his colleagues classified astatine as a metal on the basis of its analytical chemistry. Subsequent investigators reported iodine-like, cationic, or amphoteric behavior. In a 2003 retrospective, Corson wrote that \"some of the properties [of astatine] are similar to iodine … it also exhibits metallic properties, more like its metallic neighbors Po and Bi.\"\n\nThere are 39 known isotopes of astatine, with atomic masses (mass numbers) of 191–229. Theoretical modeling suggests that 37 more isotopes could exist. No stable or long-lived astatine isotope has been observed nor is one expected to exist.\n\nAstatine's alpha decay energies follow the same trend as for other heavy elements. Lighter astatine isotopes have quite high energies of alpha decay, which become lower as the nuclei become heavier. Astatine-211 has a significantly higher energy than the previous isotope, because it has a nucleus with 126 neutrons, and 126 is a magic number corresponding to a filled neutron shell. Despite having a similar half-life to the previous isotope (8.1 hours for astatine-210 and 7.2 hours for astatine-211), the alpha decay probability is much higher for the latter: 41.81% against only 0.18%. The two following isotopes release even more energy, with astatine-213 releasing the most energy. For this reason, it is the shortest-lived astatine isotope. Even though heavier astatine isotopes release less energy, no long-lived astatine isotope exists, because of the increasing role of beta decay (electron emission). This decay mode is especially important for astatine; as early as 1950 it was postulated that all isotopes of the element undergo beta decay. Beta decay modes have been found for all astatine isotopes except astatine-213, -214, -215, and -216m. Astatine-210 and lighter isotopes exhibit beta plus decay (positron emission), astatine-216 and heavier isotopes exhibit beta (minus) decay, and astatine-212 decays via both modes, while astatine-211 undergoes electron capture.\n\nThe most stable isotope is astatine-210, which has a half-life of 8.1 hours. The primary decay mode is beta plus, to the relatively long-lived (in comparison to astatine isotopes) alpha emitter polonium-210. In total, only five isotopes have half-lives exceeding one hour (astatine-207 to -211). The least stable ground state isotope is astatine-213, with a half-life of 125 nanoseconds. It undergoes alpha decay to the extremely long-lived bismuth-209.\n\nAstatine has 24 known nuclear isomers, which are nuclei with one or more nucleons (protons or neutrons) in an excited state. A nuclear isomer may also be called a \"meta-state\", meaning the system has more internal energy than the \"ground state\" (the state with the lowest possible internal energy), making the former likely to decay into the latter. There may be more than one isomer for each isotope. The most stable of these nuclear isomers is astatine-202m1, which has a half-life of about 3 minutes, longer than those of all the ground states bar those of isotopes 203–211 and 220. The least stable is astatine-214m1; its half-life of 265 nanoseconds is shorter than those of all ground states except that of astatine-213.\n\nAstatine is the rarest naturally occurring element. The total amount of astatine in the Earth's crust (quoted mass 2.36 × 10 grams) is estimated to be less than one gram at any given time.\n\nAny astatine present at the formation of the Earth has long since disappeared; the four naturally occurring isotopes (astatine-215, -217, -218 and -219) are instead continuously produced as a result of the decay of radioactive thorium and uranium ores, and trace quantities of neptunium-237. The landmass of North and South America combined, to a depth of 16 kilometers (10 miles), contains only about one trillion astatine-215 atoms at any given time (around 3.5 × 10 grams). Astatine-217 is produced via the radioactive decay of neptunium-237. Primordial remnants of the latter isotope—due to its relatively short half-life of 2.14 million years—are no longer present on Earth. However trace amounts occur naturally as a product of transmutation reactions in uranium ores. Astatine-218 was the first astatine isotope discovered in nature. Astatine-219, with a half-life of 56 seconds, is the longest lived of the naturally occurring isotopes.\n\nIsotopes of astatine are sometimes not listed as naturally occurring because of misconceptions that there are no such isotopes, or discrepancies in the literature. Astatine-216 has been counted as a naturally occurring isotope but reports of its observation (which were described as doubtful) have not been confirmed.\n\nAstatine was first produced by bombarding bismuth-209 with energetic alpha particles, and this is still the major route used to create the relatively long-lived isotopes astatine-209 through astatine-211. Astatine is only produced in minuscule quantities, with modern techniques allowing production runs of up to 6.6 gigabecquerels (about 86 nanograms or 2.47 × 10 atoms). Synthesis of greater quantities of astatine using this method is constrained by the limited availability of suitable cyclotrons and the prospect of melting the target. Solvent radiolysis due to the cumulative effect of astatine decay is a related problem. With cryogenic technology, microgram quantities of astatine might be able to be generated via proton irradiation of thorium or uranium to yield radon-211, in turn decaying to astatine-211. Contamination with astatine-210 is expected to be a drawback of this method.\n\nThe most important isotope is astatine-211, the only one in commercial use. To produce the bismuth target, the metal is sputtered onto a gold, copper, or aluminium surface at 50 to 100 milligrams per square centimeter. Bismuth oxide can be used instead; this is forcibly fused with a copper plate. The target is kept under a chemically neutral nitrogen atmosphere, and is cooled with water to prevent premature astatine vaporization. In a particle accelerator, such as a cyclotron, alpha particles are collided with the bismuth. Even though only one bismuth isotope is used (bismuth-209), the reaction may occur in three possible ways, producing astatine-209, astatine-210, or astatine-211. In order to eliminate undesired nuclides, the maximum energy of the particle accelerator is set to a value (optimally 29.17 MeV) above that for the reaction producing astatine-211 (to produce the desired isotope) and below the one producing astatine-210 (to avoid producing other astatine isotopes).\n\nSince astatine is the main product of the synthesis, after its formation it must only be separated from the target and any significant contaminants. Several methods are available, \"but they generally follow one of two approaches—dry distillation or [wet] acid treatment of the target followed by solvent extraction.\" The methods summarized below are modern adaptations of older procedures, as reviewed by Kugler and Keller. Pre-1985 techniques more often addressed the elimination of co-produced toxic polonium; this requirement is now mitigated by capping the energy of the cyclotron irradiation beam.\n\nThe astatine-containing cyclotron target is heated to a temperature of around 650 °C. The astatine volatilizes and is condensed in (typically) a cold trap. Higher temperatures of up to around 850 °C may increase the yield, at the risk of bismuth contamination from concurrent volatilization. Redistilling the condensate may be required to minimize the presence of bismuth (as bismuth can interfere with astatine labeling reactions). The astatine is recovered from the trap using one or more low concentration solvents such as sodium hydroxide, methanol or chloroform. Astatine yields of up to around 80% may be achieved. Dry separation is the method most commonly used to produce a chemically useful form of astatine.\n\nThe bismuth (or sometimes bismuth trioxide) target is dissolved in, for example, concentrated nitric or perchloric acid. Astatine is extracted using an organic solvent such as butyl or isopropyl ether, or thiosemicarbazide. A separation yield of 93% using nitric acid has been reported, falling to 72% by the time purification procedures were completed (distillation of nitric acid, purging residual nitrogen oxides, and redissolving bismuth nitrate to enable liquid-liquid extraction). Wet methods involve \"multiple radioactivity handling steps\" and are not well suited for isolating larger quantities of astatine. They can enable the production of astatine in a specific oxidation state and may have greater applicability in experimental radiochemistry.\n\nNewly formed astatine-211 is the subject of ongoing research in nuclear medicine. It must be used quickly as it decays with a half-life of 7.2 hours; this is long enough to permit multistep labeling strategies. Astatine-211 has potential for targeted alpha particle radiotherapy, since it decays either via emission of an alpha particle (to bismuth-207), or via electron capture (to an extremely short-lived nuclide, polonium-211, which undergoes further alpha decay). Polonium X-rays emitted as a result of the electron capture branch, in the range of 77–92 keV, enable the tracking of astatine in animals and patients. Although astatine-210 has a slightly longer half-life, it is wholly unsuitable because it usually undergoes beta plus decay to the extremely toxic polonium-210.\n\nThe principal medicinal difference between astatine-211 and iodine-131 (a radioactive iodine isotope also used in medicine) is that iodine-131 emits high-energy beta particles, and astatine does not. Beta particles have much greater penetrating power through tissues than do the much heavier alpha particles. An average alpha particle released by astatine-211 can travel up to 70 µm through surrounding tissues; an average-energy beta particle emitted by iodine-131 can travel nearly 30 times as far, to about 2 mm. The short half-life and limited penetrating power of alpha radiation through tissues offers advantages in situations where the \"tumor burden is low and/or malignant cell populations are located in close proximity to essential normal tissues.\" Significant morbidity in cell culture models of human cancers has been achieved with from one to ten astatine-211 atoms bound per cell.\nSeveral obstacles have been encountered in the development of astatine-based radiopharmaceuticals for cancer treatment. World War II delayed research for close to a decade. Results of early experiments indicated that a cancer-selective carrier would need to be developed and it was not until the 1970s that monoclonal antibodies became available for this purpose. Unlike iodine, astatine shows a tendency to dehalogenate from molecular carriers such as these, particularly at sp carbon sites (less so from sp sites). Given the toxicity of astatine accumulated and retained in the body, this emphasized the need to ensure it remained attached to its host molecule. While astatine carriers that are slowly metabolized can be assessed for their efficacy, more rapidly metabolized carriers remain a significant obstacle to the evaluation of astatine in nuclear medicine. Mitigating the effects of astatine-induced radiolysis of labeling chemistry and carrier molecules is another area requiring further development. A practical application for astatine as a cancer treatment would potentially be suitable for a \"staggering\" number of patients; production of astatine in the quantities that would be required remains an issue.\n\nAnimal studies show that astatine, similarly to iodine, although to a lesser extent, is preferentially concentrated in the thyroid gland. Unlike iodine, astatine also shows a tendency to be taken up by the lungs and spleen, possibly because of in-body oxidation of At to At. If administered in the form of a radiocolloid it tends to concentrate in the liver. Experiments in rats and monkeys suggest that astatine-211 causes much greater damage to the thyroid gland than does iodine-131, with repetitive injection of the nuclide resulting in necrosis and cell dysplasia within the gland. Early research suggested that injection of astatine into female rodents caused morphological changes in breast tissue; this conclusion remained controversial for many years. General agreement was later reached that this was likely caused by the effect of breast tissue irradiation combined with hormonal changes due to irradiation of the ovaries. Trace amounts of astatine can be handled safely in fume hoods if they are well-aerated; biological uptake of the element must be avoided.\n\n\n", "id": "901", "title": "Astatine"},{"url": "https://en.wikipedia.org/wiki?curid=902", "text": "Atom\n\nAtom, from the Greek word atomos, which means indivisible, was first conceived around 2,400 years ago by a Greek man named Democritus. An atom is the smallest constituent unit of ordinary matter that has the properties of a chemical element. Every solid, liquid, gas, and plasma is composed of neutral or ionized atoms. Atoms are very small; typical sizes are around 100 picometers (a ten-billionth of a meter, in the short scale).\n\nAtoms are small enough that attempting to predict their behavior using classical physics – as if they were billiard balls, for example – gives noticeably incorrect predictions due to quantum effects. Through the development of physics, atomic models have incorporated quantum principles to better explain and predict the behavior.\n\nEvery atom is composed of a nucleus and one or more electrons bound to the nucleus. The nucleus is made of one or more protons and typically a similar number of neutrons. Protons and neutrons are called nucleons. More than 99.94% of an atom's mass is in the nucleus. The protons have a positive electric charge, the electrons have a negative electric charge, and the neutrons have no electric charge. If the number of protons and electrons are equal, that atom is electrically neutral. If an atom has more or fewer electrons than protons, then it has an overall negative or positive charge, respectively, and it is called an ion.\n\nThe electrons of an atom are attracted to the protons in an atomic nucleus by this electromagnetic force. The protons and neutrons in the nucleus are attracted to each other by a different force, the nuclear force, which is usually stronger than the electromagnetic force repelling the positively charged protons from one another. Under certain circumstances, the repelling electromagnetic force becomes stronger than the nuclear force, and nucleons can be ejected from the nucleus, leaving behind a different element: nuclear decay resulting in nuclear transmutation.\n\nThe number of protons in the nucleus defines to what chemical element the atom belongs: for example, all copper atoms contain 29 protons. The number of neutrons defines the isotope of the element. The number of electrons influences the magnetic properties of an atom. Atoms can attach to one or more other atoms by chemical bonds to form chemical compounds such as molecules. The ability of atoms to associate and dissociate is responsible for most of the physical changes observed in nature and is the subject of the discipline of chemistry.\n\nThe idea that matter is made up of discrete units is a very old idea, appearing in many ancient cultures such as Greece and India. The word \"atom\" was coined by ancient Greek philosophers. However, these ideas were founded in philosophical and theological reasoning rather than evidence and experimentation. As a result, their views on what atoms look like and how they behave were incorrect. They also could not convince everybody, so atomism was but one of a number of competing theories on the nature of matter. It was not until the 19th century that the idea was embraced and refined by scientists, when the blossoming science of chemistry produced discoveries that only the concept of atoms could explain.\n\nIn the early 1800s, John Dalton used the concept of atoms to explain why elements always react in ratios of small whole numbers (the law of multiple proportions). For instance, there are two types of tin oxide: one is 88.1% tin and 11.9% oxygen and the other is 78.7% tin and 21.3% oxygen (tin(II) oxide and tin dioxide respectively). This means that 100g of tin will combine either with 13.5g or 27g of oxygen. 13.5 and 27 form a ratio of 1:2, a ratio of small whole numbers. This common pattern in chemistry suggested to Dalton that elements react in whole number multiples of discrete units—in other words, atoms. In the case of tin oxides, one tin atom will combine with either one or two oxygen atoms.\n\nDalton also believed atomic theory could explain why water absorbs different gases in different proportions. For example, he found that water absorbs carbon dioxide far better than it absorbs nitrogen. Dalton hypothesized this was due to the differences between the masses and configurations of the gases' respective particles, and carbon dioxide molecules (CO) are heavier and larger than nitrogen molecules (N).\n\nIn 1827, botanist Robert Brown used a microscope to look at dust grains floating in water and discovered that they moved about erratically, a phenomenon that became known as \"Brownian motion\". This was thought to be caused by water molecules knocking the grains about. In 1905, Albert Einstein proved the reality of these molecules and their motions by producing the first Statistical physics analysis of Brownian motion. French physicist Jean Perrin used Einstein's work to experimentally determine the mass and dimensions of atoms, thereby conclusively verifying Dalton's atomic theory.\n\nThe physicist J. J. Thomson measured the mass of cathode rays, showing they were made of particles, but were around 1800 times lighter than the lightest atom, hydrogen. Therefore, they were not atoms, but a new particle, the first \"subatomic\" particle to be discovered, which he originally called \"\"corpuscle\"\" but was later named \"electron\", after particles postulated by George Johnstone Stoney in 1874. He also showed they were identical to particles given off by photoelectric and radioactive materials. It was quickly recognized that they are the particles that carry electric currents in metal wires, and carry the negative electric charge within atoms. Thomson was given the 1906 Nobel Prize in Physics for this work. Thus he overturned the belief that atoms are the indivisible, ultimate particles of matter. Thomson also incorrectly postulated that the low mass, negatively charged electrons were distributed throughout the atom in a uniform sea of positive charge. This became known as the plum pudding model.\n\nIn 1909, Hans Geiger and Ernest Marsden, under the direction of Ernest Rutherford, bombarded a metal foil with alpha particles to observe how they scattered. They expected all the alpha particles to pass straight through with little deflection, because Thomson's model said that the charges in the atom are so diffuse that their electric fields could not affect the alpha particles much. However, Geiger and Marsden spotted alpha particles being deflected by angles greater than 90°, which was supposed to be impossible according to Thomson's model. To explain this, Rutherford proposed that the positive charge of the atom is concentrated in a tiny nucleus at the center of the atom. Rutherford compared his findings to one firing a 15-inch shell and it coming back to hit the person who fired it.\n\nWhile experimenting with the products of radioactive decay, in 1913 radiochemist Frederick Soddy discovered that there appeared to be more than one type of atom at each position on the periodic table. The term isotope was coined by Margaret Todd as a suitable name for different atoms that belong to the same element. J.J. Thomson created a technique for separating atom types through his work on ionized gases, which subsequently led to the discovery of stable isotopes.\n\nIn 1913 the physicist Niels Bohr proposed a model in which the electrons of an atom were assumed to orbit the nucleus but could only do so in a finite set of orbits, and could jump between these orbits only in discrete changes of energy corresponding to absorption or radiation of a photon. This quantization was used to explain why the electrons orbits are stable (given that normally, charges in acceleration, including circular motion, lose kinetic energy which is emitted as electromagnetic radiation, see \"synchrotron radiation\") and why elements absorb and emit electromagnetic radiation in discrete spectra.\n\nLater in the same year Henry Moseley provided additional experimental evidence in favor of Niels Bohr's theory. These results refined Ernest Rutherford's and Antonius Van den Broek's model, which proposed that the atom contains in its nucleus a number of positive nuclear charges that is equal to its (atomic) number in the periodic table. Until these experiments, atomic number was not known to be a physical and experimental quantity. That it is equal to the atomic nuclear charge remains the accepted atomic model today.\n\nChemical bonds between atoms were now explained, by Gilbert Newton Lewis in 1916, as the interactions between their constituent electrons. As the chemical properties of the elements were known to largely repeat themselves according to the periodic law, in 1919 the American chemist Irving Langmuir suggested that this could be explained if the electrons in an atom were connected or clustered in some manner. Groups of electrons were thought to occupy a set of electron shells about the nucleus.\n\nThe Stern–Gerlach experiment of 1922 provided further evidence of the quantum nature of the atom. When a beam of silver atoms was passed through a specially shaped magnetic field, the beam was split based on the direction of an atom's angular momentum, or spin. As this direction is random, the beam could be expected to spread into a line. Instead, the beam was split into two parts, depending on whether the atomic spin was oriented up or down.\n\nIn 1924, Louis de Broglie proposed that all particles behave to an extent like waves. In 1926, Erwin Schrödinger used this idea to develop a mathematical model of the atom that described the electrons as three-dimensional waveforms rather than point particles. A consequence of using waveforms to describe particles is that it is mathematically impossible to obtain precise values for both the position and momentum of a particle at a given point in time; this became known as the uncertainty principle, formulated by Werner Heisenberg in 1926. In this concept, for a given accuracy in measuring a position one could only obtain a range of probable values for momentum, and vice versa.\nThis model was able to explain observations of atomic behavior that previous models could not, such as certain structural and spectral patterns of atoms larger than hydrogen. Thus, the planetary model of the atom was discarded in favor of one that described atomic orbital zones around the nucleus where a given electron is most likely to be observed.\n\nThe development of the mass spectrometer allowed the mass of atoms to be measured with increased accuracy. The device uses a magnet to bend the trajectory of a beam of ions, and the amount of deflection is determined by the ratio of an atom's mass to its charge. The chemist Francis William Aston used this instrument to show that isotopes had different masses. The atomic mass of these isotopes varied by integer amounts, called the whole number rule. The explanation for these different isotopes awaited the discovery of the neutron, an uncharged particle with a mass similar to the proton, by the physicist James Chadwick in 1932. Isotopes were then explained as elements with the same number of protons, but different numbers of neutrons within the nucleus.\n\nIn 1938, the German chemist Otto Hahn, a student of Rutherford, directed neutrons onto uranium atoms expecting to get transuranium elements. Instead, his chemical experiments showed barium as a product. A year later, Lise Meitner and her nephew Otto Frisch verified that Hahn's result were the first experimental \"nuclear fission\". In 1944, Hahn received the Nobel prize in chemistry. Despite Hahn's efforts, the contributions of Meitner and Frisch were not recognized.\n\nIn the 1950s, the development of improved particle accelerators and particle detectors allowed scientists to study the impacts of atoms moving at high energies. Neutrons and protons were found to be hadrons, or composites of smaller particles called quarks. The standard model of particle physics was developed that so far has successfully explained the properties of the nucleus in terms of these sub-atomic particles and the forces that govern their interactions.\n\nThough the word \"atom\" originally denoted a particle that cannot be cut into smaller particles, in modern scientific usage the atom is composed of various subatomic particles. The constituent particles of an atom are the electron, the proton and the neutron; all three are fermions. However, the hydrogen-1 atom has no neutrons and the hydron ion has no electrons.\n\nThe electron is by far the least massive of these particles at , with a negative electrical charge and a size that is too small to be measured using available techniques. It is the lightest particle with a positive rest mass measured. Under ordinary conditions, electrons are bound to the positively charged nucleus by the attraction created from opposite electric charges. If an atom has more or fewer electrons than its atomic number, then it becomes respectively negatively or positively charged as a whole; a charged atom is called an ion. Electrons have been known since the late 19th century, mostly thanks to J.J. Thomson; see history of subatomic physics for details.\n\nProtons have a positive charge and a mass 1,836 times that of the electron, at . The number of protons in an atom is called its atomic number. Ernest Rutherford (1919) observed that nitrogen under alpha-particle bombardment ejects what appeared to be hydrogen nuclei. By 1920 he had accepted that the hydrogen nucleus is a distinct particle within the atom and named it proton.\n\nNeutrons have no electrical charge and have a free mass of 1,839 times the mass of the electron, or , the heaviest of the three constituent particles, but it can be reduced by the nuclear binding energy. Neutrons and protons (collectively known as nucleons) have comparable dimensions—on the order of —although the 'surface' of these particles is not sharply defined. The neutron was discovered in 1932 by the English physicist James Chadwick.\n\nIn the Standard Model of physics, electrons are truly elementary particles with no internal structure. However, both protons and neutrons are composite particles composed of elementary particles called quarks. There are two types of quarks in atoms, each having a fractional electric charge. Protons are composed of two up quarks (each with charge +) and one down quark (with a charge of −). Neutrons consist of one up quark and two down quarks. This distinction accounts for the difference in mass and charge between the two particles.\n\nThe quarks are held together by the strong interaction (or strong force), which is mediated by gluons. The protons and neutrons, in turn, are held to each other in the nucleus by the nuclear force, which is a residuum of the strong force that has somewhat different range-properties (see the article on the nuclear force for more). The gluon is a member of the family of gauge bosons, which are elementary particles that mediate physical forces.\n\nAll the bound protons and neutrons in an atom make up a tiny atomic nucleus, and are collectively called nucleons. The radius of a nucleus is approximately equal to 1.07  fm, where \"A\" is the total number of nucleons. This is much smaller than the radius of the atom, which is on the order of 10 fm. The nucleons are bound together by a short-ranged attractive potential called the residual strong force. At distances smaller than 2.5 fm this force is much more powerful than the electrostatic force that causes positively charged protons to repel each other.\n\nAtoms of the same element have the same number of protons, called the atomic number. Within a single element, the number of neutrons may vary, determining the isotope of that element. The total number of protons and neutrons determine the nuclide. The number of neutrons relative to the protons determines the stability of the nucleus, with certain isotopes undergoing radioactive decay.\n\nThe proton, the electron, and the neutron are classified as fermions. Fermions obey the Pauli exclusion principle which prohibits \"identical\" fermions, such as multiple protons, from occupying the same quantum state at the same time. Thus, every proton in the nucleus must occupy a quantum state different from all other protons, and the same applies to all neutrons of the nucleus and to all electrons of the electron cloud. However, a proton and a neutron are allowed to occupy the same quantum state.\n\nFor atoms with low atomic numbers, a nucleus that has more neutrons than protons tends to drop to a lower energy state through radioactive decay so that the neutron–proton ratio is closer to one. However, as the atomic number increases, a higher proportion of neutrons is required to offset the mutual repulsion of the protons. Thus, there are no stable nuclei with equal proton and neutron numbers above atomic number \"Z\" = 20 (calcium) and as \"Z\" increases, the neutron–proton ratio of stable isotopes increases. The stable isotope with the highest proton–neutron ratio is lead-208 (about 1.5).\n\nThe number of protons and neutrons in the atomic nucleus can be modified, although this can require very high energies because of the strong force. Nuclear fusion occurs when multiple atomic particles join to form a heavier nucleus, such as through the energetic collision of two nuclei. For example, at the core of the Sun protons require energies of 3–10 keV to overcome their mutual repulsion—the coulomb barrier—and fuse together into a single nucleus. Nuclear fission is the opposite process, causing a nucleus to split into two smaller nuclei—usually through radioactive decay. The nucleus can also be modified through bombardment by high energy subatomic particles or photons. If this modifies the number of protons in a nucleus, the atom changes to a different chemical element.\n\nIf the mass of the nucleus following a fusion reaction is less than the sum of the masses of the separate particles, then the difference between these two values can be emitted as a type of usable energy (such as a gamma ray, or the kinetic energy of a beta particle), as described by Albert Einstein's mass–energy equivalence formula, \"E\" = \"mc\", where \"m\" is the mass loss and \"c\" is the speed of light. This deficit is part of the binding energy of the new nucleus, and it is the non-recoverable loss of the energy that causes the fused particles to remain together in a state that requires this energy to separate.\n\nThe fusion of two nuclei that create larger nuclei with lower atomic numbers than iron and nickel—a total nucleon number of about 60—is usually an exothermic process that releases more energy than is required to bring them together. It is this energy-releasing process that makes nuclear fusion in stars a self-sustaining reaction. For heavier nuclei, the binding energy per nucleon in the nucleus begins to decrease. That means fusion processes producing nuclei that have atomic numbers higher than about 26, and atomic masses higher than about 60, is an endothermic process. These more massive nuclei can not undergo an energy-producing fusion reaction that can sustain the hydrostatic equilibrium of a star.\n\nThe electrons in an atom are attracted to the protons in the nucleus by the electromagnetic force. This force binds the electrons inside an electrostatic potential well surrounding the smaller nucleus, which means that an external source of energy is needed for the electron to escape. The closer an electron is to the nucleus, the greater the attractive force. Hence electrons bound near the center of the potential well require more energy to escape than those at greater separations.\n\nElectrons, like other particles, have properties of both a particle and a wave. The electron cloud is a region inside the potential well where each electron forms a type of three-dimensional standing wave—a wave form that does not move relative to the nucleus. This behavior is defined by an atomic orbital, a mathematical function that characterises the probability that an electron appears to be at a particular location when its position is measured. Only a discrete (or quantized) set of these orbitals exist around the nucleus, as other possible wave patterns rapidly decay into a more stable form. Orbitals can have one or more ring or node structures, and differ from each other in size, shape and orientation.\n\nEach atomic orbital corresponds to a particular energy level of the electron. The electron can change its state to a higher energy level by absorbing a photon with sufficient energy to boost it into the new quantum state. Likewise, through spontaneous emission, an electron in a higher energy state can drop to a lower energy state while radiating the excess energy as a photon. These characteristic energy values, defined by the differences in the energies of the quantum states, are responsible for atomic spectral lines.\n\nThe amount of energy needed to remove or add an electron—the electron binding energy—is far less than the binding energy of nucleons. For example, it requires only 13.6 eV to strip a ground-state electron from a hydrogen atom, compared to 2.23 \"million\" eV for splitting a deuterium nucleus. Atoms are electrically neutral if they have an equal number of protons and electrons. Atoms that have either a deficit or a surplus of electrons are called ions. Electrons that are farthest from the nucleus may be transferred to other nearby atoms or shared between atoms. By this mechanism, atoms are able to bond into molecules and other types of chemical compounds like ionic and covalent network crystals.\n\nBy definition, any two atoms with an identical number of \"protons\" in their nuclei belong to the same chemical element. Atoms with equal numbers of protons but a different number of \"neutrons\" are different isotopes of the same element. For example, all hydrogen atoms admit exactly one proton, but isotopes exist with no neutrons (hydrogen-1, by far the most common form, also called protium), one neutron (deuterium), two neutrons (tritium) and more than two neutrons. The known elements form a set of atomic numbers, from the single proton element hydrogen up to the 118-proton element oganesson. All known isotopes of elements with atomic numbers greater than 82 are radioactive, although the radioactivity of element 83 (bismuth) is so slight as to be practically negligible.\n\nAbout 339 nuclides occur naturally on Earth, of which 254 (about 75%) have not been observed to decay, and are referred to as \"stable isotopes\". However, only 90 of these nuclides are stable to all decay, even in theory. Another 164 (bringing the total to 254) have not been observed to decay, even though in theory it is energetically possible. These are also formally classified as \"stable\". An additional 34 radioactive nuclides have half-lives longer than 80 million years, and are long-lived enough to be present from the birth of the solar system. This collection of 288 nuclides are known as primordial nuclides. Finally, an additional 51 short-lived nuclides are known to occur naturally, as daughter products of primordial nuclide decay (such as radium from uranium), or else as products of natural energetic processes on Earth, such as cosmic ray bombardment (for example, carbon-14).\n\nFor 80 of the chemical elements, at least one stable isotope exists. As a rule, there is only a handful of stable isotopes for each of these elements, the average being 3.2 stable isotopes per element. Twenty-six elements have only a single stable isotope, while the largest number of stable isotopes observed for any element is ten, for the element tin. Elements 43, 61, and all elements numbered 83 or higher have no stable isotopes.\n\nStability of isotopes is affected by the ratio of protons to neutrons, and also by the presence of certain \"magic numbers\" of neutrons or protons that represent closed and filled quantum shells. These quantum shells correspond to a set of energy levels within the shell model of the nucleus; filled shells, such as the filled shell of 50 protons for tin, confers unusual stability on the nuclide. Of the 254 known stable nuclides, only four have both an odd number of protons \"and\" odd number of neutrons: hydrogen-2 (deuterium), lithium-6, boron-10 and nitrogen-14. Also, only four naturally occurring, radioactive odd–odd nuclides have a half-life over a billion years: potassium-40, vanadium-50, lanthanum-138 and tantalum-180m. Most odd–odd nuclei are highly unstable with respect to beta decay, because the decay products are even–even, and are therefore more strongly bound, due to nuclear pairing effects.\n\nThe large majority of an atom's mass comes from the protons and neutrons that make it up. The total number of these particles (called \"nucleons\") in a given atom is called the mass number. It is a positive integer and dimensionless (instead of having dimension of mass), because it expresses a count. An example of use of a mass number is \"carbon-12,\" which has 12 nucleons (six protons and six neutrons).\n\nThe actual mass of an atom at rest is often expressed using the unified atomic mass unit (u), also called dalton (Da). This unit is defined as a twelfth of the mass of a free neutral atom of carbon-12, which is approximately . Hydrogen-1 (the lightest isotope of hydrogen which is also the nuclide with the lowest mass) has an atomic weight of 1.007825 u. The value of this number is called the atomic mass. A given atom has an atomic mass approximately equal (within 1%) to its mass number times the atomic mass unit (for example the mass of a nitrogen-14 is roughly 14 u). However, this number will not be exactly an integer except in the case of carbon-12 (see below). The heaviest stable atom is lead-208, with a mass of .\n\nAs even the most massive atoms are far too light to work with directly, chemists instead use the unit of moles. One mole of atoms of any element always has the same number of atoms (about ). This number was chosen so that if an element has an atomic mass of 1 u, a mole of atoms of that element has a mass close to one gram. Because of the definition of the unified atomic mass unit, each carbon-12 atom has an atomic mass of exactly 12 u, and so a mole of carbon-12 atoms weighs exactly 0.012 kg.\n\nAtoms lack a well-defined outer boundary, so their dimensions are usually described in terms of an atomic radius. This is a measure of the distance out to which the electron cloud extends from the nucleus. However, this assumes the atom to exhibit a spherical shape, which is only obeyed for atoms in vacuum or free space. Atomic radii may be derived from the distances between two nuclei when the two atoms are joined in a chemical bond. The radius varies with the location of an atom on the atomic chart, the type of chemical bond, the number of neighboring atoms (coordination number) and a quantum mechanical property known as spin. On the periodic table of the elements, atom size tends to increase when moving down columns, but decrease when moving across rows (left to right). Consequently, the smallest atom is helium with a radius of 32 pm, while one of the largest is caesium at 225 pm.\n\nWhen subjected to external forces, like electrical fields, the shape of an atom may deviate from spherical symmetry. The deformation depends on the field magnitude and the orbital type of outer shell electrons, as shown by group-theoretical considerations. Aspherical deviations might be elicited for instance in crystals, where large crystal-electrical fields may occur at low-symmetry lattice sites. Significant ellipsoidal deformations have been shown to occur for sulfur ions and chalcogen ions in pyrite-type compounds.\n\nAtomic dimensions are thousands of times smaller than the wavelengths of light (400–700 nm) so they cannot be viewed using an optical microscope. However, individual atoms can be observed using a scanning tunneling microscope. To visualize the minuteness of the atom, consider that a typical human hair is about 1 million carbon atoms in width. A single drop of water contains about 2 sextillion () atoms of oxygen, and twice the number of hydrogen atoms. A single carat diamond with a mass of contains about 10 sextillion (10) atoms of carbon. If an apple were magnified to the size of the Earth, then the atoms in the apple would be approximately the size of the original apple.\n\nEvery element has one or more isotopes that have unstable nuclei that are subject to radioactive decay, causing the nucleus to emit particles or electromagnetic radiation. Radioactivity can occur when the radius of a nucleus is large compared with the radius of the strong force, which only acts over distances on the order of 1 fm.\n\nThe most common forms of radioactive decay are:\n\nOther more rare types of radioactive decay include ejection of neutrons or protons or clusters of nucleons from a nucleus, or more than one beta particle. An analog of gamma emission which allows excited nuclei to lose energy in a different way, is internal conversion— a process that produces high-speed electrons that are not beta rays, followed by production of high-energy photons that are not gamma rays. A few large nuclei explode into two or more charged fragments of varying masses plus several neutrons, in a decay called spontaneous nuclear fission.\n\nEach radioactive isotope has a characteristic decay time period—the half-life—that is determined by the amount of time needed for half of a sample to decay. This is an exponential decay process that steadily decreases the proportion of the remaining isotope by 50% every half-life. Hence after two half-lives have passed only 25% of the isotope is present, and so forth.\n\nElementary particles possess an intrinsic quantum mechanical property known as spin. This is analogous to the angular momentum of an object that is spinning around its center of mass, although strictly speaking these particles are believed to be point-like and cannot be said to be rotating. Spin is measured in units of the reduced Planck constant (ħ), with electrons, protons and neutrons all having spin ½ ħ, or \"spin-½\". In an atom, electrons in motion around the nucleus possess orbital angular momentum in addition to their spin, while the nucleus itself possesses angular momentum due to its nuclear spin.\n\nThe magnetic field produced by an atom—its magnetic moment—is determined by these various forms of angular momentum, just as a rotating charged object classically produces a magnetic field. However, the most dominant contribution comes from electron spin. Due to the nature of electrons to obey the Pauli exclusion principle, in which no two electrons may be found in the same quantum state, bound electrons pair up with each other, with one member of each pair in a spin up state and the other in the opposite, spin down state. Thus these spins cancel each other out, reducing the total magnetic dipole moment to zero in some atoms with even number of electrons.\n\nIn ferromagnetic elements such as iron, cobalt and nickel, an odd number of electrons leads to an unpaired electron and a net overall magnetic moment. The orbitals of neighboring atoms overlap and a lower energy state is achieved when the spins of unpaired electrons are aligned with each other, a spontaneous process known as an exchange interaction. When the magnetic moments of ferromagnetic atoms are lined up, the material can produce a measurable macroscopic field. Paramagnetic materials have atoms with magnetic moments that line up in random directions when no magnetic field is present, but the magnetic moments of the individual atoms line up in the presence of a field.\n\nThe nucleus of an atom will have no spin when it has even numbers of both neutrons and protons, but for other cases of odd numbers, the nucleus may have a spin. Normally nuclei with spin are aligned in random directions because of thermal equilibrium. However, for certain elements (such as xenon-129) it is possible to polarize a significant proportion of the nuclear spin states so that they are aligned in the same direction—a condition called hyperpolarization. This has important applications in magnetic resonance imaging.\n\nThe potential energy of an electron in an atom is negative, its dependence of its position reaches the minimum (the most absolute value) inside the nucleus, and vanishes when the distance from the nucleus goes to infinity, roughly in an inverse proportion to the distance. In the quantum-mechanical model, a bound electron can only occupy a set of states centered on the nucleus, and each state corresponds to a specific energy level; see time-independent Schrödinger equation for theoretical explanation. An energy level can be measured by the amount of energy needed to unbind the electron from the atom, and is usually given in units of electronvolts (eV). The lowest energy state of a bound electron is called the ground state, i.e. stationary state, while an electron transition to a higher level results in an excited state. The electron's energy raises when \"n\" increases because the (average) distance to the nucleus increases. Dependence of the energy on is caused not by electrostatic potential of the nucleus, but by interaction between electrons.\n\nFor an electron to transition between two different states, e.g. grounded state to first excited level (ionization), it must absorb or emit a photon at an energy matching the difference in the potential energy of those levels, according to Niels Bohr model, what can be precisely calculated by the Schrödinger equation.\nElectrons jump between orbitals in a particle-like fashion. For example, if a single photon strikes the electrons, only a single electron changes states in response to the photon; see Electron properties.\n\nThe energy of an emitted photon is proportional to its frequency, so these specific energy levels appear as distinct bands in the electromagnetic spectrum. Each element has a characteristic spectrum that can depend on the nuclear charge, subshells filled by electrons, the electromagnetic interactions between the electrons and other factors.\n\nWhen a continuous spectrum of energy is passed through a gas or plasma, some of the photons are absorbed by atoms, causing electrons to change their energy level. Those excited electrons that remain bound to their atom spontaneously emit this energy as a photon, traveling in a random direction, and so drop back to lower energy levels. Thus the atoms behave like a filter that forms a series of dark absorption bands in the energy output. (An observer viewing the atoms from a view that does not include the continuous spectrum in the background, instead sees a series of emission lines from the photons emitted by the atoms.) Spectroscopic measurements of the strength and width of atomic spectral lines allow the composition and physical properties of a substance to be determined.\n\nClose examination of the spectral lines reveals that some display a fine structure splitting. This occurs because of spin–orbit coupling, which is an interaction between the spin and motion of the outermost electron. When an atom is in an external magnetic field, spectral lines become split into three or more components; a phenomenon called the Zeeman effect. This is caused by the interaction of the magnetic field with the magnetic moment of the atom and its electrons. Some atoms can have multiple electron configurations with the same energy level, which thus appear as a single spectral line. The interaction of the magnetic field with the atom shifts these electron configurations to slightly different energy levels, resulting in multiple spectral lines. The presence of an external electric field can cause a comparable splitting and shifting of spectral lines by modifying the electron energy levels, a phenomenon called the Stark effect.\n\nIf a bound electron is in an excited state, an interacting photon with the proper energy can cause stimulated emission of a photon with a matching energy level. For this to occur, the electron must drop to a lower energy state that has an energy difference matching the energy of the interacting photon. The emitted photon and the interacting photon then move off in parallel and with matching phases. That is, the wave patterns of the two photons are synchronized. This physical property is used to make lasers, which can emit a coherent beam of light energy in a narrow frequency band.\n\nValency is the combining power of an element. It is equal to number of hydrogen atoms that atom can combine or displace in forming compounds. The outermost electron shell of an atom in its uncombined state is known as the valence shell, and the electrons in\nthat shell are called valence electrons. The number of valence electrons determines the bonding\nbehavior with other atoms. Atoms tend to chemically react with each other in a manner that fills (or empties) their outer valence shells. For example, a transfer of a single electron between atoms is a useful approximation for bonds that form between atoms with one-electron more than a filled shell, and others that are one-electron short of a full shell, such as occurs in the compound sodium chloride and other chemical ionic salts. However, many elements display multiple valences, or tendencies to share differing numbers of electrons in different compounds. Thus, chemical bonding between these elements takes many forms of electron-sharing that are more than simple electron transfers. Examples include the element carbon and the organic compounds.\n\nThe chemical elements are often displayed in a periodic table that is laid out to display recurring chemical properties, and elements with the same number of valence electrons form a group that is aligned in the same column of the table. (The horizontal rows correspond to the filling of a quantum shell of electrons.) The elements at the far right of the table have their outer shell completely filled with electrons, which results in chemically inert elements known as the noble gases.\n\nQuantities of atoms are found in different states of matter that depend on the physical conditions, such as temperature and pressure. By varying the conditions, materials can transition between solids, liquids, gases and plasmas. Within a state, a material can also exist in different allotropes. An example of this is solid carbon, which can exist as graphite or diamond. Gaseous allotropes exist as well, such as dioxygen and ozone.\n\nAt temperatures close to absolute zero, atoms can form a Bose–Einstein condensate, at which point quantum mechanical effects, which are normally only observed at the atomic scale, become apparent on a macroscopic scale. This super-cooled collection of atoms\nthen behaves as a single super atom, which may allow fundamental checks of quantum mechanical behavior.\n\nThe scanning tunneling microscope is a device for viewing surfaces at the atomic level. It uses the quantum tunneling phenomenon, which allows particles to pass through a barrier that would normally be insurmountable. Electrons tunnel through the vacuum between two planar metal electrodes, on each of which is an adsorbed atom, providing a tunneling-current density that can be measured. Scanning one atom (taken as the tip) as it moves past the other (the sample) permits plotting of tip displacement versus lateral separation for a constant current. The calculation shows the extent to which scanning-tunneling-microscope images of an individual atom are visible. It confirms that for low bias, the microscope images the space-averaged dimensions of the electron orbitals across closely packed energy levels—the Fermi level local density of states.\n\nAn atom can be ionized by removing one of its electrons. The electric charge causes the trajectory of an atom to bend when it passes through a magnetic field. The radius by which the trajectory of a moving ion is turned by the magnetic field is determined by the mass of the atom. The mass spectrometer uses this principle to measure the mass-to-charge ratio of ions. If a sample contains multiple isotopes, the mass spectrometer can determine the proportion of each isotope in the sample by measuring the intensity of the different beams of ions. Techniques to vaporize atoms include inductively coupled plasma atomic emission spectroscopy and inductively coupled plasma mass spectrometry, both of which use a plasma to vaporize samples for analysis.\n\nA more area-selective method is electron energy loss spectroscopy, which measures the energy loss of an electron beam within a transmission electron microscope when it interacts with a portion of a sample. The atom-probe tomograph has sub-nanometer resolution in 3-D and can chemically identify individual atoms using time-of-flight mass spectrometry.\n\nSpectra of excited states can be used to analyze the atomic composition of distant stars. Specific light wavelengths contained in the observed light from stars can be separated out and related to the quantized transitions in free gas atoms. These colors can be replicated using a gas-discharge lamp containing the same element. Helium was discovered in this way in the spectrum of the Sun 23 years before it was found on Earth.\n\nAtoms form about 4% of the total energy density of the observable Universe, with an average density of about 0.25 atoms/m. Within a galaxy such as the Milky Way, atoms have a much higher concentration, with the density of matter in the interstellar medium (ISM) ranging from 10 to 10 atoms/m. The Sun is believed to be inside the Local Bubble, a region of highly ionized gas, so the density in the solar neighborhood is only about 10 atoms/m. Stars form from dense clouds in the ISM, and the evolutionary processes of stars result in the steady enrichment of the ISM with elements more massive than hydrogen and helium. Up to 95% of the Milky Way's atoms are concentrated inside stars and the total mass of atoms forms about 10% of the mass of the galaxy. (The remainder of the mass is an unknown dark matter.)\n\nElectrons are thought to exist in the Universe since early stages of the Big Bang. Atomic nuclei forms in nucleosynthesis reactions. In about three minutes Big Bang nucleosynthesis produced most of the helium, lithium, and deuterium in the Universe, and perhaps some of the beryllium and boron.\n\nUbiquitousness and stability of atoms relies on their binding energy, which means that an atom has a lower energy than an unbound system of the nucleus and electrons. Where the temperature is much higher than ionization potential, the matter exists in the form of plasma—a gas of positively charged ions (possibly, bare nuclei) and electrons. When the temperature drops below the ionization potential, atoms become statistically favorable. Atoms (complete with bound electrons) became to dominate over charged particles 380,000 years after the Big Bang—an epoch called recombination, when the expanding Universe cooled enough to allow electrons to become attached to nuclei.\n\nSince the Big Bang, which produced no carbon or heavier elements, atomic nuclei have been combined in stars through the process of nuclear fusion to produce more of the element helium, and (via the triple alpha process) the sequence of elements from carbon up to iron; see stellar nucleosynthesis for details.\n\nIsotopes such as lithium-6, as well as some beryllium and boron are generated in space through cosmic ray spallation. This occurs when a high-energy proton strikes an atomic nucleus, causing large numbers of nucleons to be ejected.\n\nElements heavier than iron were produced in supernovae through the r-process and in AGB stars through the s-process, both of which involve the capture of neutrons by atomic nuclei. Elements such as lead formed largely through the radioactive decay of heavier elements.\n\nMost of the atoms that make up the Earth and its inhabitants were present in their current form in the nebula that collapsed out of a molecular cloud to form the Solar System. The rest are the result of radioactive decay, and their relative proportion can be used to determine the age of the Earth through radiometric dating. Most of the helium in the crust of the Earth (about 99% of the helium from gas wells, as shown by its lower abundance of helium-3) is a product of alpha decay.\n\nThere are a few trace atoms on Earth that were not present at the beginning (i.e., not \"primordial\"), nor are results of radioactive decay. Carbon-14 is continuously generated by cosmic rays in the atmosphere. Some atoms on Earth have been artificially generated either deliberately or as by-products of nuclear reactors or explosions. Of the transuranic elements—those with atomic numbers greater than 92—only plutonium and neptunium occur naturally on Earth. Transuranic elements have radioactive lifetimes shorter than the current age of the Earth and thus identifiable quantities of these elements have long since decayed, with the exception of traces of plutonium-244 possibly deposited by cosmic dust. Natural deposits of plutonium and neptunium are produced by neutron capture in uranium ore.\n\nThe Earth contains approximately atoms. Although small numbers of independent atoms of noble gases exist, such as argon, neon, and helium, 99% of the atmosphere is bound in the form of molecules, including carbon dioxide and diatomic oxygen and nitrogen. At the surface of the Earth, an overwhelming majority of atoms combine to form various compounds, including water, salt, silicates and oxides. Atoms can also combine to create materials that do not consist of discrete molecules, including crystals and liquid or solid metals. This atomic matter forms networked arrangements that lack the particular type of small-scale interrupted order associated with molecular matter.\n\nWhile isotopes with atomic numbers higher than lead (82) are known to be radioactive, an \"island of stability\" has been proposed for some elements with atomic numbers above 103. These superheavy elements may have a nucleus that is relatively stable against radioactive decay. The most likely candidate for a stable superheavy atom, unbihexium, has 126 protons and 184 neutrons.\n\nEach particle of matter has a corresponding antimatter particle with the opposite electrical charge. Thus, the positron is a positively charged antielectron and the antiproton is a negatively charged equivalent of a proton. When a matter and corresponding antimatter particle meet, they annihilate each other. Because of this, along with an imbalance between the number of matter and antimatter particles, the latter are rare in the universe. The first causes of this imbalance are not yet fully understood, although theories of baryogenesis may offer an explanation. As a result, no antimatter atoms have been discovered in nature. However, in 1996 the antimatter counterpart of the hydrogen atom (antihydrogen) was synthesized at the CERN laboratory in Geneva.\n\nOther exotic atoms have been created by replacing one of the protons, neutrons or electrons with other particles that have the same charge. For example, an electron can be replaced by a more massive muon, forming a muonic atom. These types of atoms can be used to test the fundamental predictions of physics.\n\n", "id": "902", "title": "Atom"},{"url": "https://en.wikipedia.org/wiki?curid=903", "text": "Arable land\n\nArable land (from Latin \"arabilis\", \"able to be plowed\") is, according to one definition, land capable of being ploughed and used to grow crops. In Britain, it was traditionally contrasted with pasturable lands such as heaths which could be used for sheep-rearing but not farmland.\n\nA quite different kind of definition is used by various agencies concerned with agriculture. In providing statistics on arable land, the FAO and the World Bank use the definition offered in the glossary accompanying FAOSTAT: \"Arable land is the land under temporary agricultural crops (multiple-cropped areas are counted only once), temporary meadows for mowing or pasture, land under market and kitchen gardens and land temporarily fallow (less than five years). The abandoned land resulting from shifting cultivation is not included in this category. Data for ‘Arable land’ are not meant to indicate the amount of land that is potentially cultivable.\" A briefer definition appearing in the Eurostat glossary similarly refers to actual, rather than potential use: \"land worked (ploughed or tilled) regularly, generally under a system of crop rotation.\"\n\nAccording to Food and Agriculture Organization of the United Nations the world's Arable land amounted to 1,407 M ha, out of a total 4,924 M ha land used for agriculture, as for year 2013.\n\nAgricultural land that is not arable according to the FAO definition above includes:\nOther non-arable land includes land that is not suitable for any agricultural use.\n\nLand that is not arable, in the sense of lacking capability or suitability for cultivation for crop production, has one or more limitations e.g. lack of sufficient fresh water for irrigation, stoniness, steepness, adverse climate, excessive wetness with impracticality of drainage, excessive salts, among others. Although such limitations may preclude cultivation, and some will in some cases preclude any agricultural use, large areas unsuitable for cultivation are agriculturally productive. For example, US NRCS statistics indicate that about 59 percent of US non-federal pasture and unforested rangeland is unsuitable for cultivation, yet such land has value for grazing of livestock. In British Columbia, Canada, 41 percent of the provincial Agricultural Land Reserve area is unsuitable for production of cultivated crops, but is suitable for uncultivated production of forage usable by grazing livestock. Similar examples can be found in many rangeland areas elsewhere.\n\nLand incapable of being cultivated for production of crops can sometimes be converted to arable land. New arable land makes more food, and can reduce starvation. This outcome also makes a country more self-sufficient and politically independent, because food importation is reduced. Making non-arable land arable often involves digging new irrigation canals and new wells, aqueducts, desalination plants, planting trees for shade in the desert, hydroponics, fertilizer, nitrogen fertilizer, pesticides, reverse osmosis water processors, PET film insulation or other insulation against heat and cold, digging ditches and hills for protection against the wind, and greenhouses with internal light and heat for protection against the cold outside and to provide light in cloudy areas. This process is often extremely expensive. An alternative is the Seawater Greenhouse which desalinates water through evaporation and condensation using solar energy as the only energy input. This technology is optimized to grow crops on desert land close to the sea.\n\nSome examples of infertile non-arable land being turned into fertile arable land are:\n\nSome examples of fertile arable land being turned into infertile land are:\n\n\n", "id": "903", "title": "Arable land"},{"url": "https://en.wikipedia.org/wiki?curid=904", "text": "Aluminium\n\nAluminium or aluminum is a chemical element with symbol Al and atomic number 13. It is a silvery-white, soft, nonmagnetic, ductile metal in the boron group. By mass, aluminium makes up about 8% of the Earth's crust; it is the third most abundant element after oxygen and silicon and the most abundant metal in the crust, though it is less common in the mantle below. Aluminium metal is so chemically reactive that native specimens are rare and limited to extreme reducing environments. Instead, it is found combined in over 270 different minerals. The chief ore of aluminium is bauxite.\n\nAluminium is remarkable for the metal's low density and its ability to resist corrosion through the phenomenon of passivation. Aluminium and its alloys are vital to the aerospace industry and important in transportation and building industries, such as building facades and window frames. The oxides and sulfates are the most useful compounds of aluminium.\n\nDespite its prevalence in the environment, no known form of life uses aluminium salts metabolically, but aluminium is well tolerated by plants and animals. Because of these salts' abundance, the potential for a biological role for them is of continuing interest, and studies continue.\n\nAluminium is a relatively soft, durable, lightweight, ductile, and malleable metal with appearance ranging from silvery to dull gray, depending on the surface roughness. It is nonmagnetic and does not easily ignite. A fresh film of aluminium serves as a good reflector (approximately 92%) of visible light and an excellent reflector (as much as 98%) of medium and far infrared radiation. The yield strength of pure aluminium is 7–11 MPa, while aluminium alloys have yield strengths ranging from 200 MPa to 600 MPa. Aluminium has about one-third the density and stiffness of steel. It is easily machined, cast, drawn and extruded.\n\nAluminium atoms are arranged in a face-centered cubic (fcc) structure. Aluminium has a stacking-fault energy of approximately 200 mJ/m.\n\nAluminium is a good thermal and electrical conductor, having 59% the conductivity of copper, both thermal and electrical, while having only 30% of copper's density. Aluminium is capable of superconductivity, with a superconducting critical temperature of 1.2 kelvin and a critical magnetic field of about 100 gauss (10 milliteslas).\nAluminium is the most common material for the fabrication of superconducting qubits.\n\nCorrosion resistance can be excellent because a thin surface layer of aluminium oxide forms when the bare metal is exposed to air, effectively preventing further oxidation, in a process termed passivation. The strongest aluminium alloys are less corrosion resistant due to galvanic reactions with alloyed copper. This corrosion resistance is greatly reduced by aqueous salts, particularly in the presence of dissimilar metals.\n\nIn highly acidic solutions, aluminium reacts with water to form hydrogen, and in highly alkaline ones to form aluminates— protective passivation under these conditions is negligible. Primarily because it is corroded by dissolved chlorides, such as common sodium chloride, household plumbing is never made from aluminium.\n\nHowever, because of its general resistance to corrosion, aluminium is one of the few metals that retains silvery reflectance in finely powdered form, making it an important component of silver-colored paints. Aluminium mirror finish has the highest reflectance of any metal in the 200–400 nm (UV) and the 3,000–10,000 nm (far IR) regions; in the 400–700 nm visible range it is slightly outperformed by tin and silver and in the 700–3000 nm (near IR) by silver, gold, and copper.\n\nAluminium is oxidized by water at temperatures below 280 °C to produce hydrogen, aluminium hydroxide and heat:\nThis conversion is of interest for the production of hydrogen. However, commercial application of this fact has challenges in circumventing the passivating oxide layer, which inhibits the reaction, and in storing the energy required to regenerate the aluminium metal.\n\nAluminium has many known isotopes, with mass numbers range from 21 to 42; however, only Al (stable) and Al (radioactive, t = 7.2×10 years) occur naturally. Al has a natural abundance above 99.9%. Al is produced from argon in the atmosphere by spallation caused by cosmic-ray protons. Aluminium isotopes are useful in dating marine sediments, manganese nodules, glacial ice, quartz in rock exposures, and meteorites. The ratio of Al to Be has been used to study transport, deposition, sediment storage, burial times, and erosion on 10 to 10 year time scales. Cosmogenic Al was first applied in studies of the Moon and meteorites. Meteoroid fragments, after departure from their parent bodies, are exposed to intense cosmic-ray bombardment during their travel through space, causing substantial Al production. After falling to Earth, atmospheric shielding drastically reduces Al production, and its decay can then be used to determine the meteorite's terrestrial age. Meteorite research has also shown that Al was relatively abundant at the time of formation of our planetary system. Most meteorite scientists believe that the energy released by the decay of Al was responsible for the melting and differentiation of some asteroids after their formation 4.55 billion years ago.\n\nStable aluminium is created when hydrogen fuses with magnesium, either in large stars or in supernovae. It is estimated to be the 14th most common element in the Universe, by mass-fraction. However, among the elements that have odd atomic numbers, aluminium is the third most abundant by mass fraction, after hydrogen and nitrogen.\n\nIn the Earth's crust, aluminium is the most abundant (8.3% by mass) metallic element and the third most abundant of all elements (after oxygen and silicon). The Earth's crust has a greater abundance of aluminium than the rest of the planet, primarily in aluminium silicates. In the Earth's mantle, which is only 2% aluminium by mass, these aluminium silicate minerals are largely replaced by silica and magnesium oxides. Overall, the Earth is about 1.4% aluminium by mass (eighth in abundance by mass). Aluminium occurs in greater proportion in the Earth than in the Solar system and Universe because the more common elements (hydrogen, helium, neon, nitrogen, carbon as hydrocarbon) are volatile at Earth's proximity to the Sun and large quantities of those were lost.\n\nBecause of its strong affinity for oxygen, aluminium is almost never found in the elemental state; instead it is found in oxides or silicates. Feldspars, the most common group of minerals in the Earth's crust, are aluminosilicates. Native aluminium metal can only be found as a minor phase in low oxygen fugacity environments, such as the interiors of certain volcanoes. Native aluminium has been reported in cold seeps in the northeastern continental slope of the South China Sea. Chen \"et al.\" (2011) propose the theory that these deposits resulted from bacterial reduction of tetrahydroxoaluminate Al(OH).\n\nAluminium also occurs in the minerals beryl, cryolite, garnet, spinel, and turquoise. Impurities in AlO, such as chromium and iron, yield the gemstones ruby and sapphire, respectively.\n\nAlthough aluminium is a common and widespread element, not all aluminium minerals are economically viable sources of the metal. Almost all metallic aluminium is produced from the ore bauxite (AlO(OH)). Bauxite occurs as a weathering product of low iron and silica bedrock in tropical climatic conditions. Bauxite is mined from large deposits in Australia, Brazil, Guinea, and Jamaica; it is also mined from lesser deposits in China, India, Indonesia, Russia, and Suriname.\n\nBauxite is converted to aluminium oxide (AlO) by the Bayer process. Relevant chemical equations are:\nThe intermediate, sodium aluminate, with the simplified formula NaAlO, is soluble in strongly alkaline water, and the other components of the ore are not. Depending on the quality of the bauxite ore, twice as much waste (\"Bauxite tailings\") as alumina is generated.\n\nThe conversion of alumina to aluminium metal is achieved by the Hall–Héroult process. In this energy-intensive process, a solution of alumina in a molten () mixture of cryolite (NaAlF) with calcium fluoride is electrolyzed to produce metallic aluminium:\nThe liquid aluminium metal sinks to the bottom of the solution and is tapped off, and usually cast into large blocks called aluminium billets for further processing. Carbon dioxide is produced at the carbon anode:\nThe carbon anode is consumed by reaction with oxygen to form carbon dioxide gas, with a small quantity of fluoride gases. In modern smelters, the gas is filtered through alumina to remove fluorine compounds and return aluminium fluoride to the electrolytic cells. The anode (i.e. the reduction cell) must be replaced regularly, since it is consumed in the process. The cathode is also eroded, mainly by electrochemical processes and liquid metal movement induced by intense electrolytic currents. After five to ten years, depending on the current used in the electrolysis, a cell must be rebuilt because of cathode wear.\n\nAluminium electrolysis with the Hall–Héroult process consumes a lot of energy. The worldwide average specific energy consumption is approximately 15±0.5 kilowatt-hours per kilogram of aluminium produced (52 to 56 MJ/kg). Some smelters achieve approximately 12.8 kW·h/kg (46.1 MJ/kg). (Compare this to the heat of reaction, 31 MJ/kg, and the Gibbs free energy of reaction, 29 MJ/kg.) Minimizing line currents for older technologies are typically 100 to 200 kiloamperes; state-of-the-art smelters operate at about 350 kA.\n\nThe Hall–Heroult process produces aluminium with a purity of above 99%. Further purification can be done by the Hoopes process. This process involves the electrolysis of molten aluminium with a sodium, barium and aluminium fluoride electrolyte. The resulting aluminium has a purity of 99.99%.\n\nElectric power represents about 20% to 40% of the cost of producing aluminium, depending on the location of the smelter. Aluminium production consumes roughly 5% of electricity generated in the US. Aluminium producers tend to locate smelters in places where electric power is both plentiful and inexpensive—such as the United Arab Emirates with its large natural gas supplies, and Iceland and Norway with energy generated from renewable sources. The world's largest smelters of alumina are located in the People's Republic of China, Russia and the provinces of Quebec and British Columbia in Canada.\nIn 2005, the People's Republic of China was the top producer of aluminium with almost a one-fifth world share, followed by Russia, Canada, and the US, reports the British Geological Survey.\n\nOver the last 50 years, Australia has become the world's top producer of bauxite ore and a major producer and exporter of alumina (before being overtaken by China in 2007). Australia produced 77 million tonnes of bauxite in 2013. The Australian deposits have some refining problems, some being high in silica, but have the advantage of being shallow and relatively easy to mine.\n\nThe high energy consumption of Hall–Héroult process motivated the development of the electrolytic process based on aluminium chloride. The pilot plant with 6500 tons/year output was started in 1976 by Alcoa. The plant offered two advantages: (i) energy requirements were 40% less than plants using the Hall–Héroult process, and (ii) the more accessible kaolinite (instead of bauxite and cryolite) was used for feedstock. Nonetheless, the pilot plant was shut down. The reasons for failure were the cost of aluminium chloride, general technology maturity problems, and leakage of the trace amounts of toxic polychlorinated biphenyl compounds.\n\nAluminium chloride process can also be used for the co-production of titanium, depending on titanium contents in kaolinite.\n\nThe non-electrolytic \"aluminium carbothermic\" process of aluminium production would theoretically be cheaper and consume less energy. However, it has been in the experimental phase for decades because the high operating temperature creates difficulties in material technology that have not yet been solved.\n\nAluminium is theoretically 100% recyclable without any loss of its natural qualities. According to the International Resource Panel's Metal Stocks in Society report, the global per capita stock of aluminium in use in society (i.e. in cars, buildings, electronics etc.) is . Much of this is in more-developed countries ( per capita) rather than less-developed countries ( per capita). Knowing the per capita stocks and their approximate lifespans is important for planning recycling.\n\nRecovery of the metal through recycling has become an important task of the aluminium industry. Recycling was a low-profile activity until the late 1960s, when the growing use of aluminium beverage cans brought it to public awareness.\n\nRecycling involves melting the scrap, a process that requires only 5% of the energy used to produce aluminium from ore, though a significant part (up to 15% of the input material) is lost as dross (ash-like oxide). An aluminium stack melter produces significantly less dross, with values reported below 1%. The dross can undergo a further process to extract aluminium.\n\nEurope has achieved high rates of aluminium recycling ranging from 42% of beverage cans, 85% of construction materials, and 95% of transport vehicles.\n\nRecycled aluminium is known as secondary aluminium, but maintains the same physical properties as primary aluminium. Secondary aluminium is produced in a wide range of formats and is employed in 80% of alloy injections. Another important use is extrusion.\n\nWhite dross from primary aluminium production and from secondary recycling operations still contains useful quantities of aluminium that can be extracted industrially. The process produces aluminium billets, together with a highly complex waste material. This waste is difficult to manage. It reacts with water, releasing a mixture of gases (including, among others, hydrogen, acetylene, and ammonia), which spontaneously ignites on contact with air; contact with damp air results in the release of copious quantities of ammonia gas. Despite these difficulties, the waste is used as a filler in asphalt and concrete.\n\nThe vast majority of compounds, including all Al-containing minerals and all commercially significant aluminium compounds, feature aluminium in the oxidation state 3+. The coordination number of such compounds varies, but generally Al is six-coordinate or tetracoordinate. Almost all compounds of aluminium(III) are colorless.\n\nAll four trihalides are well known. Unlike the structures of the three heavier trihalides, aluminium fluoride (AlF) features six-coordinate Al. The octahedral coordination environment for AlF is related to the compactness of the fluoride ion, six of which can fit around the small Al center. AlF sublimes (with cracking) at . With heavier halides, the coordination numbers are lower. The other trihalides are dimeric or polymeric with tetrahedral Al centers. These materials are prepared by treating aluminium metal with the halogen, although other methods exist. Acidification of the oxides or hydroxides affords hydrates. In aqueous solution, the halides often form mixtures, generally containing six-coordinate Al centers that feature both halide and aquo ligands. When aluminium and fluoride are together in aqueous solution, they readily form complex ions such as , , and . In the case of chloride, polyaluminium clusters are formed such as [AlO(OH)(HO)].\n\nAluminium forms one stable oxide with the chemical formula AlO It can be found in nature in the mineral corundum. Aluminium oxide is also commonly called alumina. Sapphire and ruby are impure corundum contaminated with trace amounts of other metals. The two oxide-hydroxides, AlO(OH), are boehmite and diaspore. There are three trihydroxides: bayerite, gibbsite, and nordstrandite, which differ in their crystalline structure (polymorphs). Most are produced from ores by a variety of wet processes using acid and base. Heating the hydroxides leads to formation of corundum. These materials are of central importance to the production of aluminium and are themselves extremely useful.\n\nAluminium carbide (AlC) is made by heating a mixture of the elements above . The pale yellow crystals consist of tetrahedral aluminium centers. It reacts with water or dilute acids to give methane. The acetylide, Al(C), is made by passing acetylene over heated aluminium.\n\nAluminium nitride (AlN) is the only nitride known for aluminium. Unlike the oxides, it features tetrahedral Al centers. It can be made from the elements at . It is air-stable material with a usefully high thermal conductivity. Aluminium phosphide (AlP) is made similarly; it hydrolyses to give phosphine:\n\nA variety of compounds of empirical formula AlR and AlRCl exist. These species usually feature tetrahedral Al centers formed by dimerization with some R or Cl bridging between both Al atoms, e.g. \"trimethylaluminium\" has the formula Al(CH) (see figure). With large organic groups, triorganoaluminium compounds exist as three-coordinate monomers, such as triisobutylaluminium. Such compounds are widely used in industrial chemistry, despite the fact that they are often highly pyrophoric. Few analogues exist between organoaluminium and organoboron compounds other than large organic groups.\n\nThe important aluminium hydride is lithium aluminium hydride (LiAlH), which is used in as a reducing agent in organic chemistry. It can be produced from lithium hydride and aluminium trichloride:\n\nSeveral useful derivatives of LiAlH are known, e.g. sodium bis(2-methoxyethoxy)dihydridoaluminate. The simplest hydride, aluminium hydride or alane, remains a laboratory curiosity. It is a polymer with the formula (AlH), in contrast to the corresponding boron hydride that is a dimer with the formula (BH).\n\nAlthough the great majority of aluminium compounds feature Al centers, compounds with lower oxidation states are known and sometime of significance as precursors to the Al species.\n\nAlF, AlCl and AlBr exist in the gaseous phase when the trihalide is heated with aluminium. The composition is unstable at room temperature, converting to triiodide:\n\nA stable derivative of aluminium monoiodide is the cyclic adduct formed with triethylamine, . Also of theoretical interest but only of fleeting existence are AlO and AlS. AlO is made by heating the normal oxide, AlO, with silicon at in a vacuum. Such materials quickly disproportionate to the starting materials.\n\nVery simple Al(II) compounds are invoked or observed in the reactions of Al metal with oxidants. For example, aluminium monoxide, AlO, has been detected in the gas phase after explosion and in stellar absorption spectra. More thoroughly investigated are compounds of the formula RAl which contain an Al-Al bond and where R is a large organic ligand.\n\nThe presence of aluminium can be detected in qualitative analysis using aluminon.\n\nAluminium is the most widely used non-ferrous metal. The global production of aluminium in 2005 was 31.9 million tonnes. It exceeded that of any other metal except iron (837.5 million tonnes).\n\nAluminium is almost always alloyed, which markedly improves its mechanical properties, especially when tempered. For example, the common aluminium foils and beverage cans are alloys of 92% to 99% aluminium. The main alloying agents are copper, zinc, magnesium, manganese, and silicon (e.g., duralumin) with the levels of other metals in a few percent by weight.\n\nSome of the many uses for aluminium metal are in:\n\nAluminium is usually alloyed – it is used as pure metal only when corrosion resistance and/or workability is more important than strength or hardness. The strength of aluminium alloys is abruptly increased with small additions of scandium, zirconium, or hafnium. A thin layer of aluminium can be deposited onto a flat surface by physical vapor deposition or (very infrequently) chemical vapor deposition or other chemical means to form optical coatings and mirrors.\n\nBecause aluminium is abundant and most of its derivatives exhibit low toxicity, the compounds of aluminium enjoy wide and sometimes large-scale applications.\n\nAluminium oxide (AlO) and the associated oxy-hydroxides and trihydroxides are produced or extracted from minerals on a large scale. The great majority of this material is converted to metallic aluminium. In 2013, about 10% of the domestic shipments in the United States were used for other applications. One major use is to absorb water where it is viewed as a contaminant or impurity. Alumina is used to remove water from hydrocarbons in preparation for subsequent processes that would be poisoned by moisture.\n\nAluminium oxides are common catalysts for industrial processes; e.g. the Claus process to convert hydrogen sulfide to sulfur in refineries and to alkylate amines. Many industrial catalysts are \"supported\" by alumina, meaning that the expensive catalyst material (e.g., platinum) is dispersed over a surface of the inert alumina.\n\nBeing a very hard material (Mohs hardness 9), alumina is widely used as an abrasive; being extraordinarily chemically inert, it is useful in highly reactive environments such as high pressure sodium lamps.\n\nSeveral sulfates of aluminium have industrial and commercial application. Aluminium sulfate (Al(SO)·(HO)) is produced on the annual scale of several billions of kilograms. About half of the production is consumed in water treatment. The next major application is in the manufacture of paper. It is also used as a mordant, in fire extinguishers, in fireproofing, as a food additive (E number E173), and in leather tanning. Aluminium ammonium sulfate, which is also called ammonium alum, (NH)Al(SO)·12HO, is used as a mordant and in leather tanning, as is aluminium potassium sulfate ([Al(K)](SO))·(HO). The consumption of both alums is declining.\n\nAluminium chloride (AlCl) is used in petroleum refining and in the production of synthetic rubber and polymers. Although it has a similar name, aluminium chlorohydrate has fewer and very different applications, particularly as a colloidal agent in water purification and an antiperspirant. It is an intermediate in the production of aluminium metal.\n\nMany aluminium compounds have niche applications:\n\nAluminium alloys with a wide range of properties are used in engineering structures. Alloy systems are classified by a number system (ANSI) or by names indicating their main alloying constituents (DIN and ISO).\n\nThe strength and durability of aluminium alloys vary widely, not only as a result of the components of the specific alloy, but also as a result of heat treatments and manufacturing processes. A lack of knowledge of these aspects has from time to time led to improperly designed structures and gained aluminium a bad reputation.\n\nOne important structural limitation of aluminium alloys is their fatigue strength. Unlike steels, aluminium alloys have no well-defined fatigue limit, meaning that fatigue failure eventually occurs, under even very small cyclic loadings. Engineers must assess applications and design for a fixed and finite life of the structure, rather than infinite life.\n\nAnother important property of aluminium alloys is sensitivity to heat. Workshop procedures are complicated by the fact that aluminium, unlike steel, melts without first glowing red. Manual blow torch operations require additional skill and experience. Aluminium alloys, like all structural alloys, are subject to internal stresses after heat operations such as welding and casting. The lower melting points of aluminium alloys make them more susceptible to distortions from thermally induced stress relief. Stress can be relieved and controlled during manufacturing by heat-treating the parts in an oven, followed by gradual cooling—in effect annealing the stresses.\n\nThe low melting point of aluminium alloys has not precluded use in rocketry, even in combustion chambers where gases can reach 3500 K. The Agena upper stage engine used regeneratively cooled aluminium in some parts of the nozzle, including the thermally critical throat region.\n\nAnother alloy of some value is aluminium bronze (Cu-Al alloy).\n\nAlthough ancient Greeks and Romans used aluminium salts as dyeing mordants and as astringents for dressing wounds, metallic aluminium was not refined until the modern era. Alum, a salt of aluminium and potassium, is still used as a styptic.\n\nIn 1782, Guyton de Morveau suggested calling the \"base\" of (i.e., the metallic element in) alum \"alumine\". In 1808, Humphry Davy identified the existence of a metal base of alum, which he at first termed \"alumium\" and later \"aluminum\" (see etymology section, below).\n\nThe metal was first produced in 1825 in an impure form by Danish physicist and chemist Hans Christian Ørsted. He reacted anhydrous aluminium chloride with potassium amalgam, yielding a lump of metal looking similar to tin. Friedrich Wöhler was aware of these experiments and cited them, but after repeating Ørsted's experiments, he concluded that this metal was pure potassium. He conducted a similar experiment in 1827 by mixing anhydrous aluminium chloride with potassium and produced aluminium. Wöhler is therefore generally credited with isolating aluminium (Latin \"alumen\", alum). Further, Pierre Berthier discovered aluminium in bauxite ore. Henri Etienne Sainte-Claire Deville improved Wöhler's method in 1846. As described in his 1859 book, aluminium trichloride could be reduced by sodium, which was more convenient and less expensive than potassium, which Wöhler had used. \nIn the mid-1880s, aluminium metal was exceedingly difficult to produce, which made pure aluminium more valuable than gold. So celebrated was the metal that bars of aluminium were exhibited at the Exposition Universelle of 1855. Napoleon III of France is reputed to have held a banquet where the most honored guests were given aluminium utensils, while the others made do with gold.\n\nAluminium was selected as the material for the capstone of the Washington Monument in 1884, a time when one ounce (30 grams) cost the daily wage of a common worker on the project (in 1884 about $1 for 10 hours of labor. The capstone, which was set in place on 6 December 1884 in an elaborate dedication ceremony, was the largest single piece of aluminium cast at the time. It suffered some damage from lightning strikes, and was reengineered, redesigned and replaced in the 1934 renovation of the monument.\n\nThe Cowles companies supplied aluminium alloy in quantity in the United States and England using smelters like the furnace of Carl Wilhelm Siemens by 1886.\n\nCharles Martin Hall of Ohio in the US and Paul Héroult of France independently developed the Hall-Héroult electrolytic process that facilitated large-scale production of metallic aluminium. This process remains in use today. In 1888, with the financial backing of Alfred E. Hunt, the Pittsburgh Reduction Company started; today it is known as Alcoa. Héroult's process was in production by 1889 in Switzerland at Aluminium Industrie, now Alcan, and at British Aluminium, now Luxfer Group and Alcoa, by 1896 in Scotland.\n\nBy 1895, the metal was being used as a building material as far away as Sydney, Australia, in the dome of the Chief Secretary's Building.\n\nWith the explosive expansion of the airplane industry during World War I (1914–1917), major governments demanded large shipments of aluminium for light, strong airframes. They often subsidized factories and the necessary electrical supply systems.\n\nMany navies have used an aluminium superstructure for their vessels; the 1975 fire aboard USS \"Belknap\" that gutted her aluminium superstructure, as well as observation of battle damage to British ships during the Falklands War, led to many navies switching to all steel superstructures.\n\nAluminium wire was once widely used for domestic electrical wiring in the United States, and a number of fires resulted from creep and corrosion-induced failures at junctions and terminations; additional and preventable factors in the failures have been identified. Aluminium is still used in electrical services with specially designed wire termination hardware.\n\nThe various names all derive from its elemental presence in alum. The word comes into English from Old French, from \"alumen\", a Latin word meaning \"bitter salt\".\n\nTwo variants of the name are in current use: \"aluminium\" () and \"aluminum\" (). There is also an obsolete variant \"alumium\". The International Union of Pure and Applied Chemistry (IUPAC) adopted \"aluminium\" as the standard international name for the element in 1990 but, three years later, recognized \"aluminum\" as an acceptable variant. The IUPAC periodic table uses the \"aluminium\" spelling only. IUPAC internal publications use the two spelling with nearly equal frequency.\n\nMost countries use the ending \"-ium\" for \"aluminium\". In the United States and Canada, the ending \"-um\" predominates. The Canadian Oxford Dictionary prefers \"aluminum\", whereas the Australian Macquarie Dictionary prefers \"aluminium\". In 1926, the American Chemical Society officially decided to use \"aluminum\" in its publications; American dictionaries typically label the spelling \"aluminium\" as \"chiefly British\". The earliest citation given in the Oxford English Dictionary for any word used as a name for this element is \"alumium\", which British chemist and inventor Humphry Davy employed in 1808 for the metal he was trying to isolate electrolytically from the mineral \"alumina\". The citation is from the journal \"Philosophical Transactions of the Royal Society of London\": \"Had I been so fortunate as to have obtained more certain evidences on this subject, and to have procured the metallic substances I was in search of, I should have proposed for them the names of silicium, alumium, zirconium, and glucium.\"\n\nDavy settled on \"aluminum\" by the time he published his book \"Elements of Chemical Philosophy\" in June 1812: \"This substance appears to contain a peculiar metal, but as yet Aluminum has not been obtained in a perfectly free state, though alloys of it with other metalline substances have been procured sufficiently distinct to indicate the probable nature of alumina.\" In September 1812, fellow British scientist Thomas Young wrote a review of Davy's book, which was published anonymously in the \"Quarterly Review,\" a British literary and political periodical, in which he objected to \"aluminum\" and proposed the name \"aluminium\": \"for so we shall take the liberty of writing the word, in preference to aluminum, which has a less classical sound.\"\n\nThe \"-ium\" suffix followed the precedent set in other newly discovered elements of the time: potassium, sodium, magnesium, calcium, and strontium (all of which Davy isolated himself). Nevertheless, element names ending in \"-um\" were not unknown at the time; for example, platinum (known to Europeans since the 16th century), molybdenum (discovered in 1778), and tantalum (discovered in 1802). The \"-um\" suffix is consistent with the universal spelling alumina for the oxide (as opposed to aluminia), as lanthana is the oxide of lanthanum, and magnesia, ceria, and thoria are the oxides of magnesium, cerium, and thorium respectively.\n\nThe \"aluminum\" spelling is used in the Webster's Dictionary of 1828. In his advertising handbill for his new electrolytic method of producing the metal in 1892, Charles Martin Hall used the \"-um\" spelling, despite his constant use of the \"-ium\" spelling in all the patents he filed between 1886 and 1903. Hall's domination of production of the metal ensured that \"aluminum\" became the standard English spelling in North America.\n\nDespite its widespread occurrence in the Earth crust, aluminium has no known function in biology. Aluminium salts are remarkably nontoxic, aluminium sulfate having an LD of 6207 mg/kg (oral, mouse), which corresponds to 500 grams for an person. The extremely low acute toxicity notwithstanding, the health effects of aluminium are of interest in view of the widespread occurrence of the element in the environment and in commerce.\n\nIn very high doses, aluminium is associated with altered function of the blood–brain barrier. A small percentage of people are allergic to aluminium and experience contact dermatitis, digestive disorders, vomiting or other symptoms upon contact or ingestion of products containing aluminium, such as antiperspirants and antacids. In those without allergies, aluminium is not as toxic as heavy metals, but there is evidence of some toxicity if it is consumed in amounts greater than 40 mg/day per kg of body mass. The use of aluminium cookware has not been shown to lead to aluminium toxicity in general, however excessive consumption of antacids containing aluminium compounds and excessive use of aluminium-containing antiperspirants provide more significant exposure levels. Consumption of acidic foods or liquids with aluminium enhances aluminium absorption, and maltol has been shown to increase the accumulation of aluminium in nerve and bone tissues. Aluminium increases estrogen-related gene expression in human breast cancer cells cultured in the laboratory. The estrogen-like effects of these salts have led to their classification as metalloestrogens.\n\nThere is little evidence that aluminium in antiperspirants causes skin irritation. Nonetheless, its occurrence in antiperspirants, dyes (such as aluminium lake), and food additives has caused concern. Although there is little evidence that normal exposure to aluminium presents a risk to healthy adults, some studies point to risks associated with increased exposure to the metal. Aluminium in food may be absorbed more than aluminium from water. It is classified as a non-carcinogen by the US Department of Health and Human Services.\n\nIn case of suspected sudden intake of a large amount of aluminium, deferoxamine mesylate may be given to help eliminate it from the body by chelation.\n\nExposure to powdered aluminium or aluminium welding fumes can cause pulmonary fibrosis. The United States Occupational Safety and Health Administration (OSHA) has set a permissible exposure limit of 15 mg/m time weighted average (TWA) for total exposure and 5 mg/m TWA for respiratory exposure. The US National Institute for Occupational Safety and Health (NIOSH) recommended exposure limit is the same for respiratory exposure but is 10 mg/m for total exposure, and 5 mg/m for fumes and powder.\n\nFine aluminium powder can ignite or explode, posing another workplace hazard.\n\nAluminium has controversially been implicated as a factor in Alzheimer's disease. According to the Alzheimer's Society, the medical and scientific opinion is that studies have not convincingly demonstrated a causal relationship between aluminium and Alzheimer's disease. Nevertheless, some studies, such as those on the PAQUID cohort, cite aluminium exposure as a risk factor for Alzheimer's disease. Some brain plaques have been found to contain increased levels of the metal. Research in this area has been inconclusive; aluminium accumulation may be a consequence of the disease rather than a causal agent.\n\nAluminium is primary among the factors that reduce plant growth on acid soils. Although it is generally harmless to plant growth in pH-neutral soils, the concentration in acid soils of toxic Al cations increases and disturbs root growth and function.\n\nMost acid soils are saturated with aluminium rather than hydrogen ions. The acidity of the soil is therefore, a result of hydrolysis of aluminium compounds. The concept of \"corrected lime potential\" is now used to define the degree of base saturation in soil testing to determine the \"lime requirement\".\n\nWheat has developed a tolerance to aluminium, releasing organic compounds that bind to harmful aluminium cations. Sorghum is believed to have the same tolerance mechanism. The first gene for aluminium tolerance has been identified in wheat. It was shown that sorghum's aluminium tolerance is controlled by a single gene, as for wheat. This adaptation is not found in all plants.\n\nA Spanish scientific report from 2001 claimed that the fungus \"Geotrichum candidum\" consumes the aluminium in compact discs. Other reports all refer back to the 2001 Spanish report and there is no supporting original research. Better documented, the bacterium \"Pseudomonas aeruginosa\" and the fungus \"Cladosporium resinae\" are commonly detected in aircraft fuel tanks that use kerosene-based fuels (not AV gas), and laboratory cultures can degrade aluminium. However, these life forms do not directly attack or consume the aluminium; rather, the metal is corroded by microbe waste products.\n\n\n\n", "id": "904", "title": "Aluminium"},{"url": "https://en.wikipedia.org/wiki?curid=905", "text": "Advanced Chemistry\n\nAdvanced Chemistry is a German hip hop group from Heidelberg, a scenic city in Baden-Württemberg, South Germany. Advanced Chemistry was founded in 1987 by Toni L, Linguist, Gee-One, DJ Mike MD (Mike Dippon) and MC Torch. Each member of the group holds German citizenship, and Toni L, Linguist, and Torch are of Italian, Ghanaian, and Haitian backgrounds, respectively.\n\nInfluenced by North American socially conscious rap and the Native tongues movement, Advanced Chemistry is regarded as one of the main pioneers in German hip hop. They were one of the first groups to rap in German (although their name is in English). Furthermore, their songs tackled controversial social and political issues, distinguishing them from early German hip hop group \"Die Fantastischen Vier\" (The Fantastic Four), which had a more light-hearted, playful, party image.\n\nThe rivalry between Advanced Chemistry and Die Fantastischen Vier has served to highlight a dichotomy in the routes that hip hop has taken in becoming a part of the German soundscape. While Die Fantastischen Vier may be said to view hip hop primarily as an aesthetic art form, Advanced Chemistry understand hip hop as being inextricably linked to the social and political circumstances under which it is created. For Advanced Chemistry, hip hop is a “vehicle of general human emancipation,”. In their undertaking of social and political issues, the band introduced the term \"Afro-German\" into the context of German hip hop, and the theme of race is highlighted in much of their music.\n\nWith the release of the single “Fremd im eigenen Land”, Advanced Chemistry separated itself from the rest of the rap being produced in Germany. This single was the first of its kind to go beyond simply imitating US rap and addressed the current issues of the time. Fremd im eigenen Land which translates to “foreign in my own country” dealt with the widespread racism that non-white German citizens faced. This change from simple imitation to political commentary was the start of German identification with rap. The sound of “Fremd im eigenen Land” was influenced by the 'wall of noise' created by Public Enemy's producers, The Bomb Squad.\n\nAfter the reunification of Germany, an abundance of anti-immigrant sentiment emerged, as well as attacks on the homes of refugees in the early 90's. Advanced Chemistry came to prominence in the wake of these actions because of their pro-multicultural society stance in their music. Advanced Chemistry's attitudes revolve around their attempts to create a distinct \"Germanness\" in hip hop, as opposed to imitating American hip hop as other groups had done. Torch has said, \"What the Americans do is exotic for us because we don't live like they do. What they do seems to be more interesting and newer. But not for me. For me it's more exciting to experience my fellow Germans in new contexts...For me, it's interesting to see what the kids try to do that's different from what I know.\" Advanced Chemistry were the first to use the term \"Afro-German\" in a hip hop context. This was part of the pro-immigrant political message they sent via their music.\n\nWhile Advanced Chemistry's use of the German language in their rap allows them to make claims to authenticity and true German heritage, bolstering pro-immigration sentiment, their style can also be problematic for immigrant notions of any real ethnic roots. Indeed, part of the Turkish ethnic minority of Frankfurt views Advanced Chemistry's appeal to the German image as a \"symbolic betrayal of the right of ethnic minorities to 'roots' or to any expression of cultural heritage.\" In this sense, their rap represents a complex social discourse internal to the German soundscape in which they attempt to negotiate immigrant assimilation into a xenophobic German culture with the maintenance of their own separate cultural traditions. It is quite possibly the feelings of alienation from the pure-blooded German demographic that drive Advanced Chemistry to attack nationalistic ideologies by asserting their \"Germanness\" as a group composed primarily of ethnic others. The response to this pseudo-German authenticity can be seen in what Andy Bennett refers to as \"alternative forms of local hip hop culture which actively seek to rediscover and, in many cases, reconstruct notions of identity tied to cultural roots.\" These alternative local hip hop cultures include Oriental hip hop, the members of which cling to their Turkish heritage and are confused by Advanced Chemistry's elicitation of a German identity politics to which they technically do not belong. This cultural binary illustrates that rap has taken different routes in Germany and that, even among an already isolated immigrant population, there is still disunity and, especially, disagreement on the relative importance of assimilation versus cultural defiance. According to German hip hop enthusiast 9@home, Advanced Chemistry is part of a \"hip-hop movement [which] took a clear stance for the minorities and against the [marginalization] of immigrants who...might be German on paper, but not in real life,\" which speaks to the group's hope of actually being recognized as German citizens and not foreigners, despite their various other ethnic and cultural ties.\n\nOne of the first issues that confronts us when we move outside the English-speaking market for recorded music is to establish whether or not the discrete musical genres we know from that market are fully congruent with similar divisions in other pop worlds. This is important in two ways. First, although no single country comes close to matching the amounts spent on recorded music in the United States, these markets are nonetheless economically significant. Germany, for instance, is the largest single market in western Europe, with estimated annual sales of U.S. $3.74 billion in 1996. This represents around 30 percent of reported U.S. sales and makes Germany the third biggest music market in the world.\n\nAdvanced Chemistry frequently rapped about their lives and experiences as children of immigrants, exposing the marginalization experienced by most ethnic minorities in Germany, and the feelings of frustration and resentment that being denied a German identity can cause. The song \"Fremd im eigenem Land\" (Foreign in your own nation) was released by Advanced Chemistry in November 1992. The single became a staple in the German hip hop scene. It made a strong statement about the status of immigrants throughout Germany, as the group was composed of multi-national and multi-racial members. The video shows several members brandishing their German passports as a demonstration of their German citizenship to skeptical and unaccepting 'ethnic' Germans.\n\nThis idea of national identity is important, as many rap artists in Germany have been of foreign origin. These so-called \"Gastarbeiter\" (guest workers) children saw breakdance, graffiti, rap music, and hip hop culture as a means of expressing themselves. Since the release of \"Fremd im eigenen Land\", many other German-language rappers have also tried to confront anti-immigrant ideas and develop themes of citizenship. However, though many ethnic minority youth in Germany find these German identity themes appealing, others view the desire of immigrants to be seen as German negatively, and they have actively sought to revive and recreate concepts of identity in connection to traditional ethnic origins.\n\nAdvanced Chemistry helped to found the German chapter of the Zulu nation.\n\nAdvanced Chemistry's work was rooted in German history and the country's specific political realities. However, they also drew inspiration from African-American hip-hop acts like A Tribe Called Quest and Public Enemy, who had helped bring a soulful sound and political consciousness to American hip-hop. One member, Torch, later explicitly listed his references on his solo song \"Als (When I Was in School):\" \"My favorite subject, which was quickly discovered poetry in load Poets, awakens the intellect or policy at Chuck D I'll never forget the lyrics by Public Enemy.\" Torch goes on to list other American rappers like Biz Markie, Big Daddy Kane and Dr. Dre as influences.\n\n\n\nEl-Tayeb, Fatima “‘If You Cannot Pronounce My Name, You Can Just Call Me \nPride.’ Afro-German Activism, Gender, and Hip Hop,” \"Gender & History\"15/3(2003):459-485.\n\nFelbert, Oliver von. “Die Unbestechlichen.” \"Spex\" (March 1993): 50-53.\n\nWeheliye, Alexander G. \"Phonographies:Grooves in Sonic Afro-Modernity\", Duke University Press, 2005.\n", "id": "905", "title": "Advanced Chemistry"},{"url": "https://en.wikipedia.org/wiki?curid=909", "text": "Anglican Communion\n\nThe Anglican Communion is an international association of autonomous churches consisting of the Church of England and national and regional Anglican churches (\"provinces\") in full communion with it. Full participation in the sacramental life of each church is available to all communicant Anglicans.\n\nThe Archbishop of Canterbury, Primate of All England, has a place of honour among the bishops of the Anglican churches. He is recognised as \"primus inter pares\" (\"first among equals\"). The archbishop does not exercise authority in the provinces outside England, but instead acts as a focus of unity.\n\nThe churches of the Anglican Communion considers themselves to be part of the one, holy, catholic and apostolic church and to be both Catholic and Reformed. For some adherents, Anglicanism represents a non-papal Catholicism, for others a form of Protestantism though without a dominant guiding figure such as Luther, Knox, Calvin, Zwingli or Wesley. For others, their self-identity represents some combination of the two. The communion encompasses a wide spectrum of belief and practice including evangelical, liberal and Anglo-Catholic.\n\nWith a membership estimated at around 85 million members, the Anglican Communion is the third largest Christian communion in the world, after the Catholic Church and the Eastern Orthodox Church. Some of these churches are known as Anglican, such as the Anglican Church of Canada, due to their historical link to England (\"Ecclesia Anglicana\" means \"English Church\"). Some, for example the Church of Ireland, the Scottish and American Episcopal churches, and some other associated churches have a separate name. Each independent church has its own doctrine and liturgy, aligned in most cases with that of the Church of England; and each church has its own legislative process and overall episcopal polity, under the leadership of a local primate.\n\nThe Anglican Communion has no official legal existence nor any governing structure which might exercise authority over the member churches. There is an Anglican Communion Office in London, under the aegis of the Archbishop of Canterbury, but it only serves in a supporting and organisational role. The Communion is held together by a shared history, expressed in its ecclesiology, polity and ethos and also by participation in international consultative bodies.\n\nThree elements have been important in holding the Communion together: first, the shared ecclesial structure of the component churches, manifested in an episcopal polity maintained through the apostolic succession of bishops and synodical government; second, the principle of belief expressed in worship, investing importance in approved prayer books and their rubrics; and third, the historical documents and the writings of early Anglican divines that have influenced the ethos of the Communion.\n\nOriginally, the Church of England was self-contained and relied for its unity and identity on its own history, its traditional legal and episcopal structure and its status as an established church of the state. As such Anglicanism was, from the outset, a movement with an explicitly episcopal polity, a characteristic which has been vital in maintaining the unity of the Communion by conveying the episcopate's role in manifesting visible catholicity and ecumenism.\n\nEarly in its development, Anglicanism developed a vernacular prayer book, called the Book of Common Prayer. Unlike other traditions, Anglicanism has never been governed by a magisterium nor by appeal to one founding theologian, nor by an extra-credal summary of doctrine (such as the Westminster Confession of the Presbyterian Church). Instead, Anglicans have typically appealed to the Book of Common Prayer (1662) and its offshoots as a guide to Anglican theology and practice. This had the effect of inculcating the principle of \"Lex orandi, lex credendi\" (Latin loosely translated as \"the law of praying [is] the law of believing\") as the foundation of Anglican identity and confession.\n\nProtracted conflict through the seventeenth century with more radical Protestants on the one hand and Catholics who recognised the primacy of the Pope on the other, resulted in an association of churches that were both deliberately vague about doctrinal principles, yet bold in developing parameters of acceptable deviation. These parameters were most clearly articulated in the various rubrics of the successive prayer books, as well as the Thirty-Nine Articles of Religion. These Articles have historically shaped and continue to direct the ethos of the Communion, an ethos reinforced by their interpretation and expansion by such influential early theologians as Richard Hooker, Lancelot Andrewes, John Cosin, and others.\n\nWith the expansion of the British Empire, and hence the growth of Anglicanism outside Great Britain and Ireland, the Communion sought to establish new vehicles of unity. The first major expression of this were the Lambeth Conferences of the communion's bishops, first convened by Archbishop of Canterbury Charles Longley in 1869. From the beginning, these were not intended to displace the autonomy of the emerging provinces of the Communion, but to \"discuss matters of practical interest, and pronounce what we deem expedient in resolutions which may serve as safe guides to future action.\"\n\nOne of the enduringly influential early resolutions of the conference was the so-called Chicago-Lambeth Quadrilateral of 1888. Its intent was to provide the basis for discussions of reunion with the Roman Catholic and Orthodox Churches, but it had the ancillary effect of establishing parameters of Anglican identity. It establishes four principles with these words:\n\nAs mentioned above, the Anglican Communion has no international juridical organisation. The Archbishop of Canterbury's role is strictly symbolic and unifying and the communion's three international bodies are consultative and collaborative, their resolutions having no legal effect on the autonomous provinces of the communion. Taken together, however, the four do function as \"instruments of communion\", since all churches of the communion participate in them. In order of antiquity, they are:\n\n\nSince there is no binding authority in the Anglican Communion, these international bodies are a vehicle for consultation and persuasion. In recent years, persuasion has tipped over into debates over conformity in certain areas of doctrine, discipline, worship and ethics. The most notable example has been the objection of many provinces of the communion (particularly in Africa and Asia) to the changing role of homosexuals in the North American churches (e.g., by blessing same-sex unions and ordaining and consecrating gays and lesbians in same-sex relationships) and to the process by which changes were undertaken. (See Anglican realignment.)\n\nThose who objected condemned these actions as unscriptural, unilateral, and without the agreement of the Communion prior to these steps being taken. In response, the American Episcopal Church and the Anglican Church of Canada answered that the actions had been undertaken after lengthy scriptural and theological reflection, legally in accordance with their own canons and constitutions and after extensive consultation with the provinces of the communion. \n\nThe Primates' Meeting voted to request the two churches to withdraw their delegates from the 2005 meeting of the Anglican Consultative Council. Canada and the United States decided to attend the meeting but without exercising their right to vote. They have not been expelled or suspended, since there is no mechanism in this voluntary association to suspend or expel an independent province of the communion. Since membership is based on a province's communion with Canterbury, expulsion would require the Archbishop of Canterbury's refusal to be in communion with the affected jurisdiction(s). In line with the suggestion of the Windsor Report, Rowan Williams (the previous Archbishop of Canterbury) established a working group to examine the feasibility of an Anglican covenant which would articulate the conditions for communion in some fashion.\n\nAll 38 provinces of the Anglican Communion are autonomous, each with its own primate and governing structure. These provinces may take the form of national churches (such as in Canada, Uganda, or Japan) or a collection of nations (such as the West Indies, Central Africa, or Southeast Asia).\n\nIn addition, there are six extraprovincial churches, five of which are under the metropolitical authority of the Archbishop of Canterbury.\n\nIn addition to other member churches, the churches of the Anglican Communion are in full communion with the Old Catholic churches of the Union of Utrecht and the Scandinavian Lutheran churches of the Porvoo Communion in Europe, the India-based Malankara Mar Thoma Syrian and Malabar Independent Syrian churches and the Philippine Independent Church, also known as the Aglipayan Church.\n\nThe Anglican Communion traces much of its growth to the older mission organisations of the Church of England such as the Society for Promoting Christian Knowledge (founded 1698), the Society for the Propagation of the Gospel in Foreign Parts (founded 1701) and the Church Missionary Society (founded 1799). The Church of England (which until the 20th century included the Church in Wales) initially separated from the Roman Catholic Church in 1538 in the reign of King Henry VIII, reunited in 1555 under Queen Mary I and then separated again in 1570 under Queen Elizabeth I (the Roman Catholic Church excommunicated Elizabeth I in 1570 in response to the Act of Supremacy 1559).\n\nThe Church of England has always thought of itself not as a new foundation but rather as a reformed continuation of the ancient \"English Church\" (\"Ecclesia Anglicana\") and a reassertion of that church's rights. As such it was a distinctly national phenomenon. The Church of Scotland was formed as a separate church from the Roman Catholic Church as a result of the Scottish Reformation in 1560 and the later formation of the Scottish Episcopal Church began in 1582 in the reign of James VI of Scotland over disagreements about the role of bishops.\n\nThe oldest-surviving Anglican church building outside of the British Isles (Britain and Ireland) is St Peter's Church in St. George's, Bermuda, established in 1612 (though the actual building had to be rebuilt several times over the following century). This is also the oldest surviving non-Roman Catholic church in the New World. It remained part of the Church of England until 1978 when the Anglican Church of Bermuda separated. The Church of England was the established church not only in England, but in its trans-Oceanic colonies.\n\nThus the only member churches of the present Anglican Communion existing by the mid-18th century were the Church of England, its closely linked sister church the Church of Ireland (which also separated from Roman Catholicism under Henry VIII) and the Scottish Episcopal Church which for parts of the 17th and 18th centuries was partially underground (it was suspected of Jacobite sympathies).\n\nThe enormous expansion in the 18th and 19th centuries of the British Empire brought Anglicanism along with it. At first all these colonial churches were under the jurisdiction of the Bishop of London. After the American Revolution, the parishes in the newly independent country found it necessary to break formally from a church whose supreme governor was (and remains) the British monarch. Thus they formed their own dioceses and national church, the Episcopal Church in the United States of America, in a mostly amicable separation.\n\nAt about the same time, in the colonies which remained linked to the crown, the Church of England began to appoint colonial bishops. In 1787 a bishop of Nova Scotia was appointed with a jurisdiction over all of British North America; in time several more colleagues were appointed to other cities in present-day Canada. In 1814 a bishop of Calcutta was made; in 1824 the first bishop was sent to the West Indies and in 1836 to Australia. By 1840 there were still only ten colonial bishops for the Church of England; but even this small beginning greatly facilitated the growth of Anglicanism around the world. In 1841 a \"Colonial Bishoprics Council\" was set up and soon many more dioceses were created.\n\nIn time, it became natural to group these into provinces and a metropolitan was appointed for each province. Although it had at first been somewhat established in many colonies, in 1861 it was ruled that, except where specifically established, the Church of England had just the same legal position as any other church. Thus a colonial bishop and colonial diocese was by nature quite a different thing from their counterparts back home. In time bishops came to be appointed locally rather than from England and eventually national synods began to pass ecclesiastical legislation independent of England.\n\nA crucial step in the development of the modern communion was the idea of the Lambeth Conferences (discussed above). These conferences demonstrated that the bishops of disparate churches could manifest the unity of the church in their episcopal collegiality despite the absence of universal legal ties. Some bishops were initially reluctant to attend, fearing that the meeting would declare itself a council with power to legislate for the church; but it agreed to pass only advisory resolutions. These Lambeth Conferences have been held roughly every 10 years since 1878 (the second such conference) and remain the most visible coming-together of the whole Communion.\n\nThe Lambeth Conference of 1998 included what has been seen by Philip Jenkins and others as a \"watershed in global Christianity\". The 1998 Lambeth Conference considered the issue of the theology of same-sex attraction in relation to human sexuality. At this 1998 conference for the first time in centuries the Christians of developing regions, especially, Africa, Asia, and Latin America, prevailed over the bishops of more prosperous countries (many from the USA, Canada, and the UK) who supported a redefinition of Anglican doctrine. Seen in this light 1998 is a date that marked the shift from a West-dominated Christianity to one wherein the growing churches of the two-thirds world are predominant, but the gay bishop controversy in subsequent years led to the reassertion of Western dominance, this time of the liberal variety.\n\nThe churches of the Anglican Communion have traditionally held that ordination in the historic episcopate is a core element in the validity of clerical ordinations. The Roman Catholic Church does not recognise most Anglican orders (see \"Apostolicae curae\"). Some Eastern Orthodox Churches have issued statements to the effect that Anglican orders could be accepted, yet have still reordained former Anglican clergy; other Orthodox churches have rejected Anglican orders altogether. Orthodox bishop Kallistos Ware explains this apparent discrepancy as follows:\n\n\"Anglican clergy who join the Orthodox Church are reordained; but [some Orthodox Churches hold that] if Anglicanism and Orthodoxy were to reach full unity in the faith, perhaps such reordination might not be found necessary. It should be added, however, that a number of individual Orthodox theologians hold that under no circumstances would it be possible to recognise the validity of Anglican Orders.\"\n\nOne effect of the Communion's dispersed authority has been that conflict and controversy can arise over the effect divergent practices and doctrines in one part of the Communion have on others. Disputes that had been confined to the Church of England could be dealt with legislatively in that realm, but as the Communion spread out into new nations and disparate cultures, such controversies multiplied and intensified. These controversies have generally been of two types: liturgical and social.\n\n\nThe first such controversy of note concerned that of the growing influence of the Catholic Revival manifested in the tractarian and so-called ritualism controversies of the late nineteenth and early twentieth centuries. This controversy produced the Free Church of England and, in the United States and Canada, the Reformed Episcopal Church.\n\n\nLater, rapid social change and the dissipation of British cultural hegemony over its former colonies contributed to disputes over the role of women, the parameters of marriage and divorce, and the practices of contraception and abortion. In the late 1970s, the Continuing Anglican movement produced a number of new church bodies in opposition to women's ordination, prayer book changes, and the new understandings concerning marriage.\n\nMore recently, disagreements over homosexuality have strained the unity of the Communion as well as its relationships with other Christian denominations, leading to another round of withdrawals from the Anglican Communion. Some churches were founded outside the Anglican Communion in the late 20th and early 21st centuries, largely in opposition to the ordination of openly homosexual bishops and other clergy and are usually referred to as belonging to the Anglican realignment movement, or else as \"orthodox\" Anglicans. These disagreements were especially noted when the Episcopal Church (US) consecrated an openly gay bishop in a same-sex relationship, Gene Robinson, in 2003; then, the debate re-ignited when the Church of England agreed to allow clergy to enter into same-sex civil partnerships in 2005. The Church of Nigeria opposed the Episcopal Church's decision as well as the Church of England's approval for civil partnerships.\n\n\"The more liberal provinces that are open to changing Church doctrine on marriage in order to allow for same-sex unions include Brazil, Canada, New Zealand, Scotland, South India, South Africa, the US and Wales\". The Church of England does not allow same-gender marriages or blessing rites, but does permit special prayer services for same-sex couples following a civil marriage or partnership. The Church of England also permits clergy to enter into same-sex civil partnerships. The Church of Ireland has no official position on civil unions, and one senior cleric has entered into a same-sex civil partnership. The Church of Ireland recognised that it will \"treat civil partners the same as spouses.\" The Anglican Church of Australia does not have an official position on homosexuality.\n\nThe conservative Anglican churches, encouraging the realignment movement, are more concentrated in the Global South. For example, the Anglican Church of Kenya, the Church of Nigeria, and Church of Uganda have opposed homosexuality. GAFCON, or a fellowship of conservative Anglican churches, has appointed 'missionary bishops' in response to the disagreements with the perceived liberalisation in the Anglican churches in North America and Europe.\n\nSuch debates about social theology and ethics, have occurred at the same time as debates on prayer book revision and the acceptable grounds for achieving full communion with non-Anglican churches.\n\n\n", "id": "909", "title": "Anglican Communion"},{"url": "https://en.wikipedia.org/wiki?curid=910", "text": "Arne Kaijser\n\nArne Kaijser (born 1950) is a professor of History of Technology at the Royal Institute of Technology in Stockholm, and the head of the university's department of History of science and technology.\n\nKaijser has published two books in Swedish: \"Stadens ljus. Etableringen av de första svenska gasverken\" and \"I fädrens spår. Den svenska infrastrukturens historiska utveckling och framtida utmaningar\", and has co-edited several anthologies. Kaijser is a member of the Royal Swedish Academy of Engineering Sciences since 2007 and also a member of the editorial board of two scientific journals: \"Journal of Urban Technology\" and \"Centaurus\". Lately, he has been occupied with the history of Large Technical Systems.\n\n", "id": "910", "title": "Arne Kaijser"},{"url": "https://en.wikipedia.org/wiki?curid=911", "text": "Archipelago\n\nAn archipelago ( ), sometimes called an island group or island chain, is a chain, cluster or collection of islands, or sometimes a sea containing a small number of scattered islands.\n\nThe word \"archipelago\" is derived from the Greek \"ἄρχι- – arkhi-\" (\"chief\") and \"πέλαγος – pélagos\" (\"sea\") through the Italian \"arcipelago\". In Italian, possibly following a tradition of antiquity, the Archipelago (from medieval Greek \"*ἀρχιπέλαγος\" and Latin \"archipelagus\") was the proper name for the Aegean Sea and, later, usage shifted to refer to the Aegean Islands (since the sea is remarkable for its large number of islands).\n\nArchipelagos may be found isolated in large amounts of water or neighbouring a large land mass. For example, Scotland has more than 700 islands surrounding its mainland which form an archipelago. Archipelagos are often volcanic, forming along island arcs generated by subduction zones or hotspots, but may also be the result of erosion, deposition, and land elevation. Depending on their geological origin, islands forming archipelagos can be referred to as 'oceanic islands', 'continental fragments', and 'continental islands'. Oceanic islands are mainly of volcanic origin. Continental fragments correspond to land masses that have separated from a continental mass due to tectonic displacement. Finally, sets of islands formed close to the coast of a continent are considered continental archipelagos when they form part of the same continental shelf so islands are just exposed continental shelf.\n\nIndonesia, Japan, Taiwan, the Philippines, New Zealand, Maldives, the Bahamas, Greece, Hawaii, the Polynesian islands and the Azores are examples of well-known archipelagos. The largest archipelagic state in the world by area and population is Indonesia. The archipelago with the most islands is the Swedish East Coast Archipelago, which contains the Stockholm archipelago, which, in turn, connects to the world's second largest archipelago, the Archipelago Sea in Finland.\n\n\n", "id": "911", "title": "Archipelago"},{"url": "https://en.wikipedia.org/wiki?curid=914", "text": "Author\n\nAn author is narrowly defined as the originator of any written work and can thus also be described as a writer (with any distinction primarily being an implication that an is a writer of one or more major works, such as books or plays). More broadly defined, an author is \"the person who originated or gave existence to anything\" and whose authorship determines responsibility for what was created. The more specific phrase published author refers to an author (especially but not necessarily of books) whose work has been independently accepted for publication by a reputable publisher , versus a self-publishing author or an unpublished one.\n\nTypically, the first owner of a copyright is the person who created the work i.e. the author. But, what if more than one person created the work? Then, a case of joint authorship can be made provided some criteria are met. In the copyright laws of various jurisdictions, there is a necessity for little flexibility regarding what constitutes authorship. The United States Copyright Office, for example, defines copyright as \"a form of protection provided by the laws of the United States (title 17, U.S. Code) to authors of \"original works of authorship\". Holding the title of \"author\" over any \"literary, dramatic, musical, artistic, [or] certain other intellectual works\" gives rights to this person, the owner of the copyright, especially the exclusive right to engage in or authorize any production or distribution of their work. Any person or entity wishing to use intellectual property held under copyright must receive permission from the copyright holder to use this work, and often will be asked to pay for the use of copyrighted material. After a fixed amount of time, the copyright expires on intellectual work and it enters the public domain, where it can be used without limit. Copyright laws in many jurisdictions – mostly following the lead of the United States, in which the entertainment and publishing industries have very strong lobbying power – have been amended repeatedly since their inception, to extend the length of this fixed period where the work is exclusively controlled by the copyright holder. However, copyright is merely the legal reassurance that one owns his/her work. Technically, someone owns their work from the time it's created. An interesting aspect of authorship emerges with copyright in that, in many jurisdictions, it can be passed down to another upon one's death. The person who inherits the copyright is not the author, but enjoys the same legal benefits.\n\nQuestions arise as to the application of copyright law. How does it, for example, apply to the complex issue of fan fiction? If the media agency responsible for the authorized production allows material from fans, what is the limit before legal constraints from actors, music, and other considerations, come into play? Additionally, how does copyright apply to fan-generated stories for books? What powers do the original authors, as well as the publishers, have in regulating or even stopping the fan fiction? This particular sort of case also illustrates how complex intellectual property law can be, since such fiction may also involved trademark law (e.g. for names of characters in media franchises), likeness rights (such as for actors, or even entirely fictional entities), fair use rights held by the public (including the right to parody or satirize), and many other interacting complications. Authors may portion out different rights they hold to different parties, at different times, and for different purposes or uses, such as the right to adapt a plot into a film, but only with different character names, because the characters have already been optioned by another company for a television series or a video game. An author may also not have rights when working under contract that they would otherwise have, such as when creating a work for hire (e.g., hired to write a city tour guide by a municipal government that totally owns the copyright to the finished work), or when writing material using intellectual property owned by others (such as when writing a novel or screenplay that is a new installment in an already established media franchise).\n\nIn literary theory, critics find complications in the term \"author\" beyond what constitutes authorship in a legal setting. In the wake of postmodern literature, critics such as Roland Barthes and Michel Foucault have examined the role and relevance of authorship to the meaning or interpretation of a text.\n\nBarthes challenges the idea that a text can be attributed to any single author. He writes, in his essay \"Death of the Author\" (1968), that \"it is language which speaks, not the author\". The words and language of a text itself determine and expose meaning for Barthes, and not someone possessing legal responsibility for the process of its production. Every line of written text is a mere reflection of references from any of a multitude of traditions, or, as Barthes puts it, \"the text is a tissue of quotations drawn from the innumerable centres of culture\"; it is never original. With this, the perspective of the author is removed from the text, and the limits formerly imposed by the idea of one authorial voice, one ultimate and universal meaning, are destroyed. The explanation and meaning of a work does not have to be sought in the one who produced it, \"as if it were always in the end, through the more or less transparent allegory of the fiction, the voice of a single person, the author 'confiding' in us\". The psyche, culture, fanaticism of an author can be disregarded when interpreting a text, because the words are rich enough themselves with all of the traditions of language. To expose meanings in a written work without appealing to the celebrity of an author, their tastes, passions, vices, is, to Barthes, to allow language to speak, rather than author.\n\nMichel Foucault argues in his essay \"What is an author?\" (1969) that all authors are writers, but not all writers are authors. He states that \"a private letter may have a signatory—it does not have an author\". For a reader to assign the title of author upon any written work is to attribute certain standards upon the text which, for Foucault, are working in conjunction with the idea of \"the author function\". Foucault's author function is the idea that an author exists only as a function of a written work, a part of its structure, but not necessarily part of the interpretive process. The author's name \"indicates the status of the discourse within a society and culture\", and at one time was used as an anchor for interpreting a text, a practice which Barthes would argue is not a particularly relevant or valid endeavor.\n\nExpanding upon Foucault's position, Alexander Nehamas writes that Foucault suggests \"an author [...] is whoever can be understood to have produced a particular text as we interpret it\", not necessarily who penned the text. It is this distinction between producing a written work and producing the interpretation or meaning in a written work that both Barthes and Foucault are interested in. Foucault warns of the risks of keeping the author's name in mind during interpretation, because it could affect the value and meaning with which one handles an interpretation.\n\nLiterary critics Barthes and Foucault suggest that readers should not rely on or look for the notion of one overarching voice when interpreting a written work, because of the complications inherent with a writer's title of \"author\". They warn of the dangers interpretations could suffer from when associating the subject of inherently meaningful words and language with the personality of one authorial voice. Instead, readers should allow a text to be interpreted in terms of the language as \"author\".\n\nThe author of a work may receive a percentage calculated on a wholesale or a specific price or a fixed amount on each book sold. Publishers, at times, reduced the risk of this type of arrangement, by agreeing only to pay this after a certain amount of copies had sold. In Canada, this practice occurred during the 1890s, but was not commonplace until the 1920s. Established and successful authors may receive advance payments, set against future royalties, but this is no longer common practice. Most independent publishers pay royalties as a percentage of net receipts - how net receipts are calculated varies from publisher to publisher. Under this arrangement, the author does not pay anything towards the expense of publication. The costs and financial risk are all carried by the publisher, who will then take the greatest percentage of the receipts. See Compensation for more.\n\nWith commissioned publishing, the publisher makes all the publication arrangements and the author covers all expenses (today, the practice of authors self-publishing or paying for their publications is sometimes called vanity publishing, and is looked down upon by many mainstream publishers, even though it may have been a common and accepted practice in the past). This type of publisher normally charges a flat fee for arranging publication, offers a platform for selling, and then takes a percentage of the sale of every copy of a book. The author receives the rest of the money made. An alternative self-publishing method commonly adopted is to use a third-party print on demand publishing platform, but this type of platform creates books that are only available through limited outlets and not through mainstream distributors and bookshops (CreateSpace, for example, is exclusive to its owner Amazon).\n\nThe relationship between the author and the editor, often the author's only liaison to the publishing company, is often characterized as the site of tension. For the author to reach his or her audience, the work usually must attract the attention of the editor. The idea of the author as the sole meaning-maker of necessity changes to include the influences of the editor and the publisher in order to engage the audience in writing as a social act. There are three principal areas covered by editors - Proofing (checking the Grammar and spelling, looking for typing errors), Story (potentially an area of deep angst for both author and publisher), and Layout (the setting of the final proof ready for publishing often requires minor text changes so a layout editor is required to ensure that these do not alter the sense of the text).\n\nPierre Bourdieu's essay \"The Field of Cultural Production\" depicts the publishing industry as a \"space of literary or artistic position-takings\", also called the \"field of struggles\", which is defined by the tension and movement inherent among the various positions in the field. Bourdieu claims that the \"field of position-takings [...] is not the product of coherence-seeking intention or objective consensus\", meaning that an industry characterized by position-takings is not one of harmony and neutrality. In particular for the writer, their authorship in their work makes their work part of their identity, and there is much at stake personally over the negotiation of authority over that identity. However, it is the editor who has \"the power to impose the dominant definition of the writer and therefore to delimit the population of those entitled to take part in the struggle to define the writer\". As \"cultural investors,\" publishers rely on the editor position to identify a good investment in \"cultural capital\" which may grow to yield economic capital across all positions.\n\nAccording to the studies of James Curran, the system of shared values among editors in Britain has generated a pressure among authors to write to fit the editors' expectations, removing the focus from the reader-audience and putting a strain on the relationship between authors and editors and on writing as a social act. Even the book review by the editors has more significance than the readership's reception.\n\nA standard contract for an author will usually include provision for payment in the form of an advance and royalties. An advance is a lump sum paid in advance of publication. An advance must be earned out before royalties are payable. An advance may be paid in two lump sums: the first payment on contract signing, and the second on delivery of the completed manuscript or on publication.\n\nAn author's contract may specify, for example, that they will earn 10% of the retail price of each book sold. Some contracts specify a scale of royalties payable (for example, where royalties start at 10% for the first 10,000 sales, but then increase to a higher percentage rate at higher sale thresholds).\n\nAn author's book must earn the advance before any further royalties are paid. For example, if an author is paid a modest advance of $2000, and their royalty rate is 10% of a book priced at $20 - that is, $2 per book - the book will need to sell 1000 copies before any further payment will be made. Publishers typically withhold payment of a percentage of royalties earned against returns.\n\nIn some countries, authors also earn income from a government scheme such as the ELR (educational lending right) and PLR (public lending right) schemes in Australia. Under these schemes, authors are paid a fee for the number of copies of their books in educational and/or public libraries.\n\nThese days, many authors supplement their income from book sales with public speaking engagements, school visits, residencies, grants, and teaching positions.\n\nGhostwriters, technical writers, and textbooks writers are typically paid in a different way: usually a set fee or a per word rate rather than on a percentage of sales.\n\n", "id": "914", "title": "Author"},{"url": "https://en.wikipedia.org/wiki?curid=915", "text": "Andrey Markov\n\nAndrey (Andrei) Andreyevich Markov (, in older works also spelled Markoff) (14 June 1856 N.S. – 20 July 1922) was a Russian mathematician. He is best known for his work on stochastic processes. A primary subject of his research later became known as Markov chains and Markov processes.\n\nMarkov and his younger brother Vladimir Andreevich Markov (1871–1897) proved Markov brothers' inequality.\nHis son, another Andrei Andreevich Markov (1903–1979), was also a notable mathematician, making contributions to constructive mathematics and recursive function theory.\n\nAndrey Markov was born on 14 June 1856 in Russia. He attended Petersburg Grammar, where he was seen as a rebellious student by a select few teachers. In his academics he performed poorly in most subjects other than mathematics (which later became his profession). Later in life he attended Petersburg University and was lectured by Pafnuty Chebyshev. Among his teachers were Yulian Sokhotski (differential calculus, higher algebra), Konstantin Posse (analytic geometry), Yegor Zolotarev (integral calculus), Pafnuty Chebyshev (number theory and probability theory), Aleksandr Korkin (ordinary and partial differential equations), Mikhail Okatov (mechanism theory), Osip Somov (mechanics), and Nikolai Budaev (descriptive and higher geometry). He completed his studies at the University and was later asked if he would like to stay and have a career as a Mathematician. He later taught at high schools and continued his own mathematical studies. In this time he found a practical use for his mathematical skills. He figured out that he could use chains to model the alliteration of vowels and consonants in Russian literature. He also contributed to many other mathematical aspects in his time. He died at age 66 on 20 July 1922.\n\nIn 1877, Markov was awarded a gold medal for his outstanding solution of the problem\n\n\"About Integration of Differential Equations by Continuous Fractions with an Application to the Equation\" formula_1.\n\nDuring the following year, he passed the candidate's examinations, and he remained at the university to prepare for a lecturer's position.\n\nIn April 1880, Markov defended his master's thesis \"About Binary Quadratic Forms with Positive Determinant\", which was encouraged by Aleksandr Korkin and Yegor Zolotarev.\n\nFive years later, in January 1885, there followed his doctoral thesis \"About Some Applications of Algebraic Continuous Fractions\".\n\nHis pedagogical work began after the defense of his master's thesis in autumn 1880. As a privatdozent he lectured on differential and integral calculus. Later he lectured alternately on \"introduction to analysis\", probability theory (succeeding Chebyshev, who had left the university in 1882) and the calculus of differences. From 1895 through 1905 he also lectured in differential calculus.\nOne year after the defense of his doctoral thesis, Markov was appointed extraordinary professor (1886) and in the same year he was elected adjunct to the Academy of Sciences. In 1890, after the death of Viktor Bunyakovsky, Markov became an extraordinary member of the academy. His promotion to an ordinary professor of St. Petersburg University followed in the fall of 1894.\n\nIn 1896, Markov was elected an ordinary member of the academy as the successor of Chebyshev. In 1905, he was appointed merited professor and was granted the right to retire, which he did immediately. Until 1910, however, he continued to lecture in the calculus of differences.\n\nIn connection with student riots in 1908, professors and lecturers of St. Petersburg University were ordered to monitor their students. Markov refused to accept this decree, and he wrote an explanation in which he declined to be an \"agent of the governance\". Markov was removed from further teaching duties at St. Petersburg University, and hence he decided to retire from the university.\n\nMarkov was an atheist. In 1912 he protested Leo Tolstoy's excommunication from the Russian Orthodox Church by requesting his own excommunication. The Church complied with his request.\nIn 1913, the council of St. Petersburg elected nine scientists honorary members of the university. Markov was among them, but his election was not affirmed by the minister of education. The affirmation only occurred four years later, after the February Revolution in 1917. Markov then resumed his teaching activities and lectured on probability theory and the calculus of differences until his death in 1922.\n\nhttp://blog.wolfram.com/2013/02/04/centennial-of-markov-chains/\nAndrey Markov Jnr\n\n▪ Markov Biography - Extracted from a number of sources \"written by Joseph Brooks\" 2016 Markov early life: Russia, Petersburg.\n\n", "id": "915", "title": "Andrey Markov"},{"url": "https://en.wikipedia.org/wiki?curid=921", "text": "Angst\n\nAngst means fear or anxiety (\"anguish\" is its Latinate equivalent, and \"anxious,\" \"anxiety\" are of similar origin). The word \"angst\" was introduced into English from the Danish, Norwegian and Dutch word \"angst\" and the German word \"Angst\". It is attested since the 19th century in English translations of the works of Kierkegaard and Freud. It is used in English to describe an intense feeling of apprehension, anxiety, or inner turmoil.\n\nIn German, the technical terminology of psychology and philosophy distinguishes between \"Angst\" and \"Furcht\" in that \"Furcht\" is a negative anticipation regarding a concrete threat, while \"Angst\" is a non-directional and unmotivated emotion. In common language, however, \"Angst\" is the normal word for \"fear\", while \"Furcht\" is an elevated synonym.\n\nIn other languages having the meaning of the Latin word \"pavor\" for \"fear\", the derived words differ in meaning, e.g. as in the French \"anxiété\" and \"peur\". The word \"Angst\" has existed since the 8th century, from the Proto-Indo-European root \"*anghu-\", \"restraint\" from which Old High German \"angust\" developed. It is pre-cognate with the Latin \"angustia\", \"tensity, tightness\" and \"angor\", \"choking, clogging\"; compare to the Ancient Greek ἄγχω (\"ankho\") \"strangle\".\n\nIn Existentialist philosophy the term \"angst\" carries a specific conceptual meaning. The use of the term was first attributed to Danish philosopher Søren Kierkegaard (1813–1855). In \"The Concept of Anxiety\" (also known as \"The Concept of Dread\", depending on the translation), Kierkegaard used the word \"Angest\" (in common Danish, \"angst\", meaning \"dread\" or \"anxiety\") to describe a profound and deep-seated condition. Where animals are guided solely by instinct, said Kierkegaard, human beings enjoy a freedom of choice that we find both appealing and terrifying. It is the anxiety of understanding of being free when considering undefined possibilities of one's life and one's power of choice over them. Kierkegaard's concept of angst reappeared in the works of existentialist philosophers who followed, such as Friedrich Nietzsche, Jean-Paul Sartre and Martin Heidegger, each of whom developed the idea further in individual ways. While Kierkegaard's angst referred mainly to ambiguous feelings about moral freedom within a religious personal belief system, later existentialists discussed conflicts of personal principles, cultural norms, and existential despair.\nExistential angst makes its appearance in classical musical composition in the early twentieth century as a result of both philosophical developments and as a reflection of the war-torn times. Notable composers whose works are often linked with the concept include Gustav Mahler, Richard Strauss (operas \"Elektra\" and \"Salome\", Claude-Achille Debussy (opera \"Pelleas et Melisande\", ballet \"Jeux\", other works), Jean Sibelius (especially the Fourth Symphony), Arnold Schoenberg \"(A Survivor from Warsaw\", other works), Alban Berg, Francis Poulenc (opera \"Dialogues of the Carmelites\"), Dmitri Shostakovich (opera \"Lady Macbeth of the Mtsensk District\", symphonies and chamber music), Béla Bartók (opera \"Bluebeard's Castle\", other works), and Krzysztof Penderecki (especially \"Threnody to the Victims of Hiroshima\").\nAngst began to be discussed in reference to popular music in the mid- to late 1950s amid widespread concerns over international tensions and nuclear proliferation. Jeff Nuttall's book \"Bomb Culture\" (1968) traced angst in popular culture to Hiroshima. Dread was expressed in works of folk rock such as Bob Dylan's \"Masters of War\" (1963) and \"A Hard Rain's a-Gonna Fall\". The term often makes an appearance in reference to punk rock, grunge, nu metal, and works of emo where expressions of melancholy, existential despair or nihilism predominate.\n", "id": "921", "title": "Angst"},{"url": "https://en.wikipedia.org/wiki?curid=922", "text": "Anxiety\n\nAnxiety is an emotion characterized by an unpleasant state of inner turmoil, often accompanied by nervous behavior, such as pacing back and forth, somatic complaints, and rumination. It is the subjectively unpleasant feelings of dread over anticipated events, such as the feeling of imminent death. Anxiety is not the same as fear, which is a response to a real or perceived immediate threat, whereas anxiety is the expectation of future threat. Anxiety is a feeling of uneasiness and worry, usually generalized and unfocused as an overreaction to a situation that is only subjectively seen as menacing. It is often accompanied by muscular tension, restlessness, fatigue and problems in concentration. Anxiety can be appropriate, but when experienced regularly the individual may suffer from an anxiety disorder.\n\nPeople facing anxiety may withdraw from situations which have provoked anxiety in the past. There are various types of anxiety. Existential anxiety can occur when a person faces angst, an existential crisis, or nihilistic feelings. People can also face mathematical anxiety, somatic anxiety, stage fright, or test anxiety. Social anxiety and stranger anxiety are caused when people are apprehensive around strangers or other people in general. Furthermore, anxiety has been linked with physical symptoms such as IBS and can heighten other mental health illnesses such as OCD and panic disorder. The first step in the management of a person with anxiety symptoms is to evaluate the possible presence of an underlying medical cause, whose recognition is essential in order to decide its correct treatment. Anxiety symptoms may be masking an organic disease, or appear associated or as a result of a medical disorder.\n\nAnxiety can be either a short term \"state\" or a long term \"trait\". Whereas trait anxiety represents worrying about future events, anxiety disorders are a group of mental disorders characterized by feelings of anxiety and fear. Anxiety disorders are partly genetic but may also be due to drug use, including alcohol, caffeine, and benzodiazepines (which are often prescribed to treat anxiety), as well as withdrawal from drugs of abuse. They often occur with other mental disorders, particularly bipolar disorder, eating disorders, major depressive disorder, or certain personality disorders. Common treatment options include lifestyle changes, medication, and therapy.\n\nAnxiety is distinguished from fear, which is an appropriate cognitive and emotional response to a perceived threat. Anxiety is related to the specific behaviors of fight-or-flight responses, defensive behavior or escape. It occurs in situations only perceived as uncontrollable or unavoidable, but not realistically so. David Barlow defines anxiety as \"a future-oriented mood state in which one is not ready or prepared to attempt to cope with upcoming negative events,\" and that it is a distinction between future and present dangers which divides anxiety and fear. Another description of anxiety is agony, dread, terror, or even apprehension. In positive psychology, anxiety is described as the mental state that results from a difficult challenge for which the subject has insufficient coping skills.\n\nFear and anxiety can be differentiated in four domains: (1) duration of emotional experience, (2) temporal focus, (3) specificity of the threat, and (4) motivated direction. Fear is defined as short lived, present focused, geared towards a specific threat, and facilitating escape from threat; anxiety, on the other hand, is defined as long-acting, future focused, broadly focused towards a diffuse threat, and promoting excessive caution while approaching a potential threat and interferes with constructive coping.\n\nAnxiety can be experienced with long, drawn out daily symptoms that reduce quality of life, known as chronic (or generalized) anxiety, or it can be experienced in short spurts with sporadic, stressful panic attacks, known as acute anxiety. Symptoms of anxiety can range in number, intensity, and frequency, depending on the person. While almost everyone has experienced anxiety at some point in their lives, most do not develop long-term problems with anxiety.\n\nAnxiety may cause psychiatric and physiological symptoms.\n\nThe behavioral effects of anxiety may include withdrawal from situations which have provoked anxiety or negative feelings in the past. Other effects may include changes in sleeping patterns, changes in habits, increase or decrease in food intake, and increased motor tension (such as foot tapping).\n\nThe emotional effects of anxiety may include \"feelings of apprehension or dread, trouble concentrating, feeling tense or jumpy, anticipating the worst, irritability, restlessness, watching (and waiting) for signs (and occurrences) of danger, and, feeling like your mind's gone blank\" as well as \"nightmares/bad dreams, obsessions about sensations, déjà vu, a trapped in your mind feeling, and feeling like everything is scary.\"\n\nThe cognitive effects of anxiety may include thoughts about suspected dangers, such as fear of dying. \"You may ... fear that the chest pains are a deadly heart attack or that the shooting pains in your head are the result of a tumor or an aneurysm. You feel an intense fear when you think of dying, or you may think of it more often than normal, or can't get it out of your mind.\"\n\nThe physiological symptoms of anxiety may include:\n\nThe philosopher Søren Kierkegaard, in \"The Concept of Anxiety\" (1844), described anxiety or dread associated with the \"dizziness of freedom\" and suggested the possibility for positive resolution of anxiety through the self-conscious exercise of responsibility and choosing. In \"Art and Artist\" (1932), the psychologist Otto Rank wrote that the psychological trauma of birth was the pre-eminent human symbol of existential anxiety and encompasses the creative person's simultaneous fear of – and desire for – separation, individuation, and differentiation.\n\nThe theologian Paul Tillich characterized existential anxiety as \"the state in which a being is aware of its possible nonbeing\" and he listed three categories for the nonbeing and resulting anxiety: ontic (fate and death), moral (guilt and condemnation), and spiritual (emptiness and meaninglessness). According to Tillich, the last of these three types of existential anxiety, i.e. spiritual anxiety, is predominant in modern times while the others were predominant in earlier periods. Tillich argues that this anxiety can be accepted as part of the human condition or it can be resisted but with negative consequences. In its pathological form, spiritual anxiety may tend to \"drive the person toward the creation of certitude in systems of meaning which are supported by tradition and authority\" even though such \"undoubted certitude is not built on the rock of reality\".\n\nAccording to Viktor Frankl, the author of \"Man's Search for Meaning\", when a person is faced with extreme mortal dangers, the most basic of all human wishes is to find a meaning of life to combat the \"trauma of nonbeing\" as death is near.\n\nAccording to Yerkes-Dodson law, an optimal level of arousal is necessary to best complete a task such as an exam, performance, or competitive event. However, when the anxiety or level of arousal exceeds that optimum, the result is a decline in performance.\n\nTest anxiety is the uneasiness, apprehension, or nervousness felt by students who have a fear of failing an exam. Students who have test anxiety may experience any of the following: the association of grades with personal worth; fear of embarrassment by a teacher; fear of alienation from parents or friends; time pressures; or feeling a loss of control. Sweating, dizziness, headaches, racing heartbeats, nausea, fidgeting, uncontrollable crying or laughing and drumming on a desk are all common. Because test anxiety hinges on fear of negative evaluation, debate exists as to whether test anxiety is itself a unique anxiety disorder or whether it is a specific type of social phobia. The DSM-IV classifies test anxiety as a type of social phobia.\n\nWhile the term \"test anxiety\" refers specifically to students, many workers share the same experience with regard to their career or profession. The fear of failing at a task and being negatively evaluated for failure can have a similarly negative effect on the adult. Management of test anxiety focuses on achieving relaxation and developing mechanisms to manage anxiety.\n\nHumans generally require social acceptance and thus sometimes dread the disapproval of others. Apprehension of being judged by others may cause anxiety in social environments.\nAnxiety during social interactions, particularly between strangers, is common among young people. It may persist into adulthood and become social anxiety or social phobia. \"Stranger anxiety\" in small children is not considered a phobia. In adults, an excessive fear of other people is not a developmentally common stage; it is called social anxiety. According to Cutting, social phobics do not fear the crowd but the fact that they may be judged negatively.\n\nSocial anxiety varies in degree and severity. For some people, it is characterized by experiencing discomfort or awkwardness during physical social contact (e.g. embracing, shaking hands, etc.), while in other cases it can lead to a fear of interacting with unfamiliar people altogether. Those suffering from this condition may restrict their lifestyles to accommodate the anxiety, minimizing social interaction whenever possible. Social anxiety also forms a core aspect of certain personality disorders, including avoidant personality disorder.\n\nTo the extent that a person is fearful of social encounters with unfamiliar others, some people may experience anxiety particularly during interactions with outgroup members, or people who share different group memberships (i.e., by race, ethnicity, class, gender, etc.). Depending on the nature of the antecedent relations, cognitions, and situational factors, intergroup contact may be stressful and lead to feelings of anxiety. This apprehension or fear of contact with outgroup members is often called interracial or intergroup anxiety.\n\nAs is the case the more generalized forms of social anxiety, intergroup anxiety has behavioral, cognitive, and affective effects. For instance, increases in schematic processing and simplified information processing can occur when anxiety is high. Indeed, such is consistent with related work on attentional bias in implicit memory. Additionally recent research has found that implicit racial evaluations (i.e. automatic prejudiced attitudes) can be amplified during intergroup interaction. Negative experiences have been illustrated in producing not only negative expectations, but also avoidant, or antagonistic, behavior such as hostility. Furthermore, when compared to anxiety levels and cognitive effort (e.g., impression management and self-presentation) in intragroup contexts, levels and depletion of resources may be exacerbated in the intergroup situation.\n\nAnxiety can be either a short term 'state' or a long term \"trait\". Trait anxiety reflects a stable tendency to respond with state anxiety in the anticipation of threatening situations. A meta-analysis showed that a high level of neuroticism is a risk factor for development of anxiety symptoms and disorders. Such anxiety may be conscious or unconscious.\n\nAnxiety induced by the need to choose between similar options is increasingly being recognized as a problem for individuals and for organizations. In 2004, Capgemini wrote: \"Today we're all faced with greater choice, more competition and less time to consider our options or seek out the right advice.\"\n\nIn a decision context, unpredictability or uncertainty may trigger emotional responses in anxious individuals that systematically alter decision-making. There are primarily two forms of this anxiety type. The first form refers to a choice in which there are multiple potential outcomes with known or calculable probabilities. The second form refers to the uncertainty and ambiguity related to a decision context in which there are multiple possible outcomes with unknown probabilities.\n\nAnxiety disorders are a group of mental disorders characterized by feelings of anxiety and fear. Anxiety is a worry about future events and fear is a reaction to current events. These feelings may cause physical symptoms, such as a fast heart rate and shakiness. There are a number of anxiety disorders: including generalized anxiety disorder, specific phobia, social anxiety disorder, separation anxiety disorder, agoraphobia, panic disorder, and selective mutism. The disorder differs by what results in the symptoms. People often have more than one anxiety disorder.\nThe cause of anxiety disorders is a combination of genetic and environmental factors. Risk factors include a history of child abuse, family history of mental disorders, and poverty. Anxiety disorders often occur with other mental disorders, particularly major depressive disorder, personality disorder, and substance use disorder. To be diagnosed symptoms typically need to be present at least six months, be more than would be expected for the situation, and decrease functioning. Other problems that may result in similar symptoms including hyperthyroidism, heart disease, caffeine, alcohol, or cannabis use, and withdrawal from certain drugs, among others.\nWithout treatment, anxiety disorders tend to remain. Treatment may include lifestyle changes, counselling, and medications. Counselling is typically with a type of cognitive behavioural therapy. Medications, such as antidepressants or beta blockers, may improve symptoms.\nAbout 12% of people are affected by an anxiety disorder in a given year and between 5-30% are affected at some point in their life. They occur about twice as often in females as males, and generally begin before the age of 25. The most common are specific phobia which affects nearly 12% and social anxiety disorder which affects 10% at some point in their life. They affect those between the ages of 15 and 35 the most and become less common after the age of 55. Rates appear to be higher in the United States and Europe.\n\nNeural circuitry involving the amygdala (which regulates emotions like anxiety and fear, stimulating the HPA Axis and sympathetic nervous system) and hippocampus (which is implicated in emotional memory along with the amygdala) is thought to underlie anxiety. People who have anxiety tend to show high activity in response to emotional stimuli in the amygdala. Some writers believe that excessive anxiety can lead to an overpotentiation of the limbic system (which includes the amygdala and nucleus accumbens), giving increased future anxiety, but this does not appear to have been proven.\n\nResearch upon adolescents who as infants had been highly apprehensive, vigilant, and fearful finds that their nucleus accumbens is more sensitive than that in other people when deciding to make an action that determined whether they received a reward. This suggests a link between circuits responsible for fear and also reward in anxious people. As researchers note, \"a sense of 'responsibility', or self-agency, in a context of uncertainty (probabilistic outcomes) drives the neural system underlying appetitive motivation (i.e., nucleus accumbens) more strongly in temperamentally inhibited than noninhibited adolescents\".\n\nGenetics and family history (e.g., parental anxiety) may predispose an individual for an increased risk of an anxiety disorder, but generally external stimuli will trigger its onset or exacerbation. Genetic differences account for about 43% of variance in panic disorder and 28% in generalized anxiety disorder. Although single genes are neither necessary nor sufficient for anxiety by themselves, several gene polymorphisms have been found to correlate with anxiety: PLXNA2, SERT, CRH, COMT and BDNF. Several of these genes influence neurotransmitters (such as serotonin and norepinephrine) and hormones (such as cortisol) which are implicated in anxiety. The epigenetic signature of at least one of these genes BDNF has also been associated with anxiety and specific patterns of neural activity.\n\nMany medical conditions can cause anxiety. This includes conditions that affect the ability to breathe, like COPD and asthma, and the difficulty in breathing that often occurs near death. Conditions that cause abdominal pain or chest pain can cause anxiety and may in some cases be a somatization of anxiety; the same is true for some sexual dysfunctions. Conditions that affect the face or the skin can cause social anxiety especially among adolescents, and developmental disabilities often lead to social anxiety for children as well. Life-threatening conditions like cancer also cause anxiety.\n\nFurthermore, certain organic diseases may present with anxiety or symptoms that mimic anxiety. These disorders include certain endocrine diseases (hypo- and hyperthyroidism, hyperprolactinemia), metabolic disorders (diabetes), deficiency states (low levels of vitamin D, B2, B12, folic acid), gastrointestinal diseases (celiac disease, non-celiac gluten sensitivity, inflammatory bowel disease), heart diseases, blood diseases (anemia), cerebral vascular accidents (transient ischemic attack, stroke), and brain degenerative diseases (Parkinson's disease, dementia, multiple sclerosis, Huntington's disease), among others.\n\nSeveral drugs can cause or worsen anxiety, whether in intoxication, withdrawal or from chronic use. These include alcohol, tobacco, cannabis, sedatives (including prescription benzodiazepines), opioids (including prescription pain killers and illicit drugs like heroin), stimulants (such as caffeine, cocaine and amphetamines), hallucinogens, and inhalants. While many often report self-medicating anxiety with these substances, improvements in anxiety from drugs are usually short-lived (with worsening of anxiety in the long-term, sometimes with acute anxiety as soon as the drug effects wear off) and tend to be exaggerated. Acute exposure to toxic levels of benzene may cause euphoria, anxiety, and irritability lasting up to 2 weeks after the exposure.\n\nPoor coping skills (e.g., rigidity/inflexible problem solving, denial, avoidance, impulsivity, extreme self-expectation, affective instability, and inability to focus on problems) are associated with anxiety. Anxiety is also linked and perpetuated by the person's own pessimistic outcome expectancy and how they cope with feedback negativity. Temperament (e.g., neuroticism) and attitudes (e.g. pessimism) have been found to be risk factors for anxiety.\n\nCognitive distortions such as overgeneralizing, catastrophizing, mind reading, emotional reasoning, binocular trick, and mental filter can result in anxiety. For example, an overgeneralized belief that something bad \"always\" happens may lead someone to have excessive fears of even minimally risky situations and to avoid benign social situations due to anticipatory anxiety of embarrassment. Such unhealthy thoughts can be targets for successful treatment with cognitive therapy.\n\nPsychodynamic theory posits that anxiety is often the result of opposing unconscious wishes or fears that manifest via maladaptive defense mechanisms (such as suppression, repression, anticipation, regression, somatization, passive aggression, dissociation) that develop to adapt to problems with early objects (e.g., caregivers) and empathic failures in childhood. For example, persistent parental discouragement of anger may result in repression/suppression of angry feelings which manifests as gastrointestinal distress (somatization) when provoked by another while the anger remains unconscious and outside the individual's awareness. Such conflicts can be targets for successful treatment with psychodynamic therapy.\n\nAn evolutionary psychology explanation is that increased anxiety serves the purpose of increased vigilance regarding potential threats in the environment as well as increased tendency to take proactive actions regarding such possible threats. This may cause false positive reactions but an individual suffering from anxiety may also avoid real threats. This may explain why anxious people are less likely to die due to accidents.\n\nWhen people are confronted with unpleasant and potentially harmful stimuli such as foul odors or tastes, PET-scans show increased bloodflow in the amygdala. In these studies, the participants also reported moderate anxiety. This might indicate that anxiety is a protective mechanism designed to prevent the organism from engaging in potentially harmful behaviors.\n\nSocial risk factors for anxiety include a history of trauma (e.g., physical, sexual or emotional abuse or assault), early life experiences and parenting factors (e.g., rejection, lack of warmth, high hostility, harsh discipline, high maternal negative affect, anxious childrearing, modelling of dysfunctional and drug-abusing behaviour, discouragement of emotions, poor socialization, poor attachment, and child abuse and neglect), cultural factors (e.g., stoic families/cultures, persecuted minorities including the disabled), and socioeconomics (e.g., uneducated, unemployed, impoverished (although developed countries have higher rates of anxiety disorders than developing countries)).\n\nContextual factors that are thought to contribute to anxiety include gender socialization and learning experiences. In particular, learning mastery (the degree to which people perceive their lives to be under their own control) and instrumentality, which includes such traits as self-confidence, independence, and competitiveness fully mediate the relation between gender and anxiety. That is, though gender differences in anxiety exist, with higher levels of anxiety in women compared to men, gender socialization and learning mastery explain these gender differences. Research has demonstrated the ways in which facial prominence in photographic images differs between men and women. More specifically, in official online photographs of politicians around the world, women's faces are less prominent than men's. Interestingly enough, the difference in these images actually tended to be greater in cultures with greater institutional gender equality.\n\n", "id": "922", "title": "Anxiety"},{"url": "https://en.wikipedia.org/wiki?curid=924", "text": "A. A. Milne\n\nAlan Alexander Milne (; 18 January 1882 – 31 January 1956) was an English author, best known for his books about the teddy bear Winnie-the-Pooh and for various poems. Milne was a noted writer, primarily as a playwright, before the huge success of Pooh overshadowed all his previous work. Milne served in both World Wars, joining the British Army in World War I, and was a captain of the British Home Guard in World War II.\n\nAlan Alexander Milne was born in Kilburn, London to parents John Vine Milne, who was born in Jamaica, and Sarah Marie Milne (née Heginbotham) and grew up at Henley House School, 6/7 Mortimer Road (now Crescent), Kilburn, a small public school run by his father. One of his teachers was H. G. Wells, who taught there in 1889–90. Milne attended Westminster School and Trinity College, Cambridge where he studied on a mathematics scholarship, graduating with a B.A. in Mathematics in 1903. He edited and wrote for \"Granta\", a student magazine. He collaborated with his brother Kenneth and their articles appeared over the initials AKM. Milne's work came to the attention of the leading British humour magazine \"Punch\", where Milne was to become a contributor and later an assistant editor. Milne played for the amateur English cricket team the Allahakbarries alongside authors J. M. Barrie and Arthur Conan Doyle.\n\nMilne joined the British Army in World War I and served as an officer in the Royal Warwickshire Regiment and later, after a debilitating illness, the Royal Corps of Signals. He was commissioned into the 4th Battalion, Royal Warwickshire Regiment on 17 February 1915 as a second lieutenant (on probation). His commission was confirmed on 20 December 1915. On 7 July 1916, he was injured while serving in the Battle of the Somme and invalided back to England. Having recuperated, he was recruited into Military Intelligence to write propaganda articles for MI 7b between 1916 and 1918. He was discharged on 14 February 1919, and settled in Mallord Street, Chelsea. He relinquished his commission on 19 February 1920, retaining the rank of lieutenant.\n\nAfter the war, he wrote a denunciation of war titled \"Peace with Honour\" (1934), which he retracted somewhat with 1940's \"War with Honour\". During World War II, Milne was one of the most prominent critics of fellow English writer P. G. Wodehouse, who was captured at his country home in France by the Nazis and imprisoned for a year. Wodehouse made radio broadcasts about his internment, which were broadcast from Berlin. Although the light-hearted broadcasts made fun of the Germans, Milne accused Wodehouse of committing an act of near treason by cooperating with his country's enemy. Wodehouse got some revenge on his former friend (e.g., in \"The Mating Season\") by creating fatuous parodies of the Christopher Robin poems in some of his later stories, and claiming that Milne \"was probably jealous of all other writers... But I loved his stuff.\"\n\nMilne married Dorothy \"Daphne\" de Sélincourt in 1913 and their son Christopher Robin Milne was born in 1920. In 1925, Milne bought a country home, Cotchford Farm, in Hartfield, East Sussex.\n\nDuring World War II, Milne was Captain of the British Home Guard in Hartfield & Forest Row, insisting on being plain \"Mr. Milne\" to the members of his platoon. He retired to the farm after a stroke and brain surgery in 1952 left him an invalid, and by August 1953 \"he seemed very old and disenchanted\". Milne died in January 1956, aged 74.\n\nAfter graduating from Cambridge in 1903, A. A. Milne contributed humorous verse and whimsical essays to \"Punch\", joining the staff in 1906 and becoming an assistant editor.\n\nDuring this period he published 18 plays and three novels, including the murder mystery \"The Red House Mystery\" (1922). His son was born in August 1920 and in 1924 Milne produced a collection of children's poems \"When We Were Very Young\", which were illustrated by \"Punch\" staff cartoonist E. H. Shepard. A collection of short stories for children \"Gallery of Children\", and other stories that became part of the Winnie-the-Pooh books, were first published in 1925.\n\nMilne was an early screenwriter for the nascent British film industry, writing four stories filmed in 1920 for the company Minerva Films (founded in 1920 by the actor Leslie Howard and his friend and story editor Adrian Brunel). These were \"The Bump\", starring Aubrey Smith; \"Twice Two\"; \"Five Pound Reward\"; and \"Bookworms\". Some of these films survive in the archives of the British Film Institute. Milne had met Howard when the actor starred in Milne’s play \"Mr Pim Passes By\" in London.\n\nLooking back on this period (in 1926), Milne observed that when he told his agent that he was going to write a detective story, he was told that what the country wanted from a \"\"Punch\" humorist\" was a humorous story; when two years later he said he was writing nursery rhymes, his agent and publisher were convinced he should write another detective story; and after another two years, he was being told that writing a detective story would be in the worst of taste given the demand for children's books. He concluded that \"the only excuse which I have yet discovered for writing anything is that I want to write it; and I should be as proud to be delivered of a Telephone Directory \"con amore\" as I should be ashamed to create a Blank Verse Tragedy at the bidding of others.\"\n\nMilne is most famous for his two \"Pooh\" books about a boy named Christopher Robin after his son, Christopher Robin Milne, and various characters inspired by his son's stuffed animals, most notably the bear named Winnie-the-Pooh. Christopher Robin Milne's stuffed bear, originally named \"Edward\", was renamed \"Winnie-the-Pooh\" after a Canadian black bear named Winnie (after Winnipeg), which was used as a military mascot in World War I, and left to London Zoo during the war. \"The pooh\" comes from a swan called \"Pooh\". E. H. Shepard illustrated the original Pooh books, using his own son's teddy, Growler (\"a magnificent bear\"), as the model. The rest of Christopher Robin Milne's toys, Piglet, Eeyore, Kanga, Roo and Tigger, were incorporated into A. A. Milne's stories, and two more characters – Rabbit and Owl – were created by Milne's imagination. Christopher Robin Milne's own toys are now under glass in New York where 750,000 people visit them every year.\n\nThe fictional Hundred Acre Wood of the Pooh stories derives from Five Hundred Acre Wood in Ashdown Forest in East Sussex, South East England, where the Pooh stories were set. Milne lived on the northern edge of the forest at Cotchford Farm, , and took his son walking there. E. H. Shepard drew on the landscapes of Ashdown Forest as inspiration for many of the illustrations he provided for the Pooh books. The adult Christopher Robin commented: \"Pooh's Forest and Ashdown Forest are identical\". Popular tourist locations at Ashdown Forest include: \"Galleon's Lap\", \"The Enchanted Place\", the \"Heffalump Trap\" and \"Lone Pine\", \"Eeyore’s Sad and Gloomy Place\", and the wooden \"Pooh Bridge\" where Pooh and Piglet invented Poohsticks.\n\nNot yet known as Pooh, he made his first appearance in a poem, \"Teddy Bear\", published in \"Punch\" magazine in February 1924. Pooh first appeared in the \"London Evening News\" on Christmas Eve, 1925, in a story called \"The Wrong Sort Of Bees\". \"Winnie-the-Pooh\" was published in 1926, followed by \"The House at Pooh Corner\" in 1928. A second collection of nursery rhymes, \"Now We Are Six\", was published in 1927. All three books were illustrated by E. H. Shepard. Milne also published four plays in this period. He also \"gallantly stepped forward\" to contribute a quarter of the costs of dramatising P. G. Wodehouse's \"A Damsel in Distress\". \"The World of Pooh\" won the Lewis Carroll Shelf Award in 1958.\n\nThe success of his children's books was to become a source of considerable annoyance to Milne, whose self-avowed aim was to write whatever he pleased and who had, until then, found a ready audience for each change of direction: he had freed pre-war \"Punch\" from its ponderous facetiousness; he had made a considerable reputation as a playwright (like his idol J. M. Barrie) on both sides of the Atlantic; he had produced a witty piece of detective writing in \"The Red House Mystery\" (although this was severely criticised by Raymond Chandler for the implausibility of its plot). But once Milne had, in his own words, \"said goodbye to all that in 70,000 words\" (the approximate length of his four principal children's books), he had no intention of producing any reworkings lacking in originality, given that one of the sources of inspiration, his son, was growing older.\n\nIn his literary home, \"Punch\", where the \"When We Were Very Young\" verses had first appeared, Methuen continued to publish whatever Milne wrote, including the long poem \"The Norman Church\" and an assembly of articles entitled \"Year In, Year Out\" (which Milne likened to a benefit night for the author).\n\nIn 1930, Milne adapted Kenneth Grahame's novel \"The Wind in the Willows\" for the stage as \"Toad of Toad Hall\". The title was an implicit admission that such chapters as Chapter 7, \"The Piper at the Gates of Dawn\", could not survive translation to the theatre. A special introduction written by Milne is included in some editions of Grahame's novel.\n\nMilne and his wife became estranged from their son, who came to resent what he saw as his father's exploitation of his childhood and came to hate the books that had thrust him into the public eye. Marrying his first cousin, Lesley de Sélincourt, distanced Christopher still further from his parents - Lesley's father and Christopher's mother hadn't spoken to each other for 30 years.\n\nThe rights to A. A. Milne's Pooh books were left to four beneficiaries: his family, the Royal Literary Fund, Westminster School and the Garrick Club. After Milne's death in 1956, one week and six days after his 74th birthday, his widow sold her rights to the Pooh characters to Stephen Slesinger, whose widow sold the rights after Slesinger's death to the Walt Disney Company, which has made many Pooh cartoon movies, a Disney Channel television show, as well as Pooh-related merchandise. In 2001, the other beneficiaries sold their interest in the estate to the Disney Corporation for $350m. Previously Disney had been paying twice-yearly royalties to these beneficiaries. The estate of E. H. Shepard also received a sum in the deal. The U.K. copyright on the text of the original Winnie the Pooh books expires on 1 January 2027; at the beginning of the year after the 70th anniversary of the author's death (PMA-70), and has already expired in those countries with a PMA-50 rule. This applies to all of Milne's works except those first published posthumously. The illustrations in the Pooh books will remain under copyright until the same amount of time has passed, after the illustrator's death. In the United States, copyright will not expire until 95 years after publication for each of Milne's books first published before 1978, but this includes the illustrations.\n\nIn 2008, a collection of original illustrations featuring Winnie-the-Pooh and his animal friends sold for more than £1.2 million at auction in Sotheby's, London. \"Forbes\" magazine ranked Winnie the Pooh the most valuable fictional character in 2002; Winnie the Pooh merchandising products alone had annual sales of more than $5.9 billion. In 2005, Winnie the Pooh generated $6 billion, a figure surpassed by only Mickey Mouse.\n\nA memorial plaque in Ashdown Forest, unveiled by Christopher Robin in 1979, commemorates the work of A. A. Milne and Shepard in creating the world of Pooh. Milne once wrote of Ashdown Forest: \"In that enchanted place on the top of the forest a little boy and his bear will always be playing\".\n\nIn 2003, \"Winnie the Pooh\" was listed at number 7 on the BBC's poll The Big Read which determined the UK's \"best-loved novels\" of all time. In 2006, Winnie the Pooh received a star on the Hollywood Walk of Fame, marking the 80th birthday of Milne's creation. That same year a UK poll saw Winnie the Pooh voted onto the list of icons of England.\n\nMarking the 90th anniversary of Milne's creation of the character, and the 90th birthday of Elizabeth II, in 2016 a new story sees Winnie the Pooh meet the Queen at Buckingham Palace. The illustrated and audio adventure is titled \"Winnie-the-Pooh Meets the Queen\", and has been narrated by actor Jim Broadbent. Also in 2016, a new character, a Penguin, has been unveiled in \"The Best Bear in All the World\", which was inspired by a long-lost photograph of Milne and his son Christopher with a toy penguin.\n\nSeveral of Milne's children's poems were set to music by the composer Harold Fraser-Simson. His poems have been parodied many times, including with the books \"When We Were Rather Older\" and \"Now We Are Sixty\". The 1963 film \"The King's Breakfast\" was based on Milne's poem of the same name.\n\nMilne did not speak out much on the subject of religion, although he used religious terms to explain his decision, while remaining a pacifist, to join the British Home Guard: \"In fighting Hitler\", he wrote, \"we are truly fighting the Devil, the Anti-Christ ... Hitler was a crusader against God.\"\n\nHis best known comment on the subject was recalled on his death:\nHe wrote in the poem \"Explained\":\n<poem>Elizabeth Ann\nSaid to her Nan:\n\"Please will you tell me how God began?\n\"Somebody\" must have made Him. So\nWho could it be, 'cos I want to know?\"\n</poem>\n\nHe also wrote in the poem \"Vespers\":\n<poem>\"Oh! Thank you, God, for a lovely day.\nAnd what was the other I had to say?\nI said \"Bless Daddy,\" so what can it be?\nOh! Now I remember it. God bless Me.\"\n</poem>\n\n\n\n\n\n\n\n\n\n\n\n", "id": "924", "title": "A. A. Milne"},{"url": "https://en.wikipedia.org/wiki?curid=925", "text": "Asociación Alumni\n\nAsociación Alumni, usually just Alumni, is a rugby union club located in Tortuguitas, Greater Buenos Aires, Argentina. The senior squad currently competes at Grupo I, the first division of Unión de Rugby de Buenos Aires league system.\n\nThe club has ties with former association football club Alumni because both were established by Buenos Aires English High School students.\n\nThe first club with the name \"Alumni\" played association football, having been found in 1898 by students of Buenos Aires English High School (BAEHS) along with director Alexander Watson Hutton. Originally under the name \"English High School A.C.\", the team would be later obliged by the Association to change its name, therefore \"Alumni\" was chosen, following a proposal by Carlos Bowers, a former student of the school.\n\nAlumni was the most successful team during the first years of Argentine football, winning 10 of 14 league championships contested. Alumni is still considered the first great football team in the country. Alumni was reorganised in 1908, \"in order to encourage people to practise all kind of sports, specially football\". This was the last try to develop itself as a sports club rather than just a football team, such as Lomas, Belgrano and Quilmes had successfully done in the past, but the efforts were not enough. Alumni played its last game in 1911 and was definitely dissolved on April 24, 1913.\n\nIn 1951 a group of BAEHS students asked school's alumni for permission to re-establish the name \"Alumni\" for a rugby union team. This request was immediately approved in a meeting presided by Carlos Bowers, who had proposed the name \"Alumni\" to the original football team 50 years before.\n\nThe team achieved good results and in 1960 the club presented a team that won the third division of the Buenos Aires league, reaching the second division. Since then, Alumni has played at the highest level of Argentine rugby and its rivalry with Belgrano Athletic Club is one of the fiercest local derbies in Buenos Aires. Alumni would later climb up to first division winning 5 titles: 4 consecutive between 1989 and 1992, and the other in 2001.\n\nIn 2002, Alumni won its first Nacional de Clubes title, defeating Jockey Club de Rosario 23-21 in the final.\n\n\n\n", "id": "925", "title": "Asociación Alumni"},{"url": "https://en.wikipedia.org/wiki?curid=928", "text": "Axiom\n\nAn axiom or postulate is a statement that is taken to be true, to serve as a premise or starting point for further reasoning and arguments. The word comes from the Greek \"axíōma\" () 'that which is thought worthy or fit' or 'that which commends itself as evident.' \n\nThe term has subtle differences in definition when used in the context of different fields of study. As defined in classic philosophy, an axiom is a statement that is so evident or well-established, that it is accepted without controversy or question. As used in modern logic, an axiom is simply a premise or starting point for reasoning. \nAs used in mathematics, the term \"axiom\" is used in two related but distinguishable senses: \"logical axioms\" and \"non-logical axioms\". Logical axioms are usually statements that are taken to be true within the system of logic they define (e.g., (\"A\" and \"B\") implies \"A\"), often shown in symbolic form, while non-logical axioms (e.g., ) are actually substantive assertions about the elements of the domain of a specific mathematical theory (such as arithmetic). When used in the latter sense, \"axiom\", \"postulate\", and \"assumption\" may be used interchangeably. In general, a non-logical axiom is not a self-evident truth, but rather a formal logical expression used in deduction to build a mathematical theory. To axiomatize a system of knowledge is to show that its claims can be derived from a small, well-understood set of sentences (the axioms). There are typically multiple ways to axiomatize a given mathematical domain.\n\nIn both senses, an axiom is any mathematical statement that serves as a starting point from which other statements are logically derived. Whether it is meaningful (and, if so, what it means) for an axiom, or any mathematical statement, to be \"true\" is an open question in the philosophy of mathematics.\n\nThe word \"axiom\" comes from the Greek word (\"axíōma\"), a verbal noun from the verb (\"axioein\"), meaning \"to deem worthy\", but also \"to require\", which in turn comes from (\"áxios\"), meaning \"being in balance\", and hence \"having (the same) value (as)\", \"worthy\", \"proper\". Among the ancient Greek philosophers an axiom was a claim which could be seen to be true without any need for proof.\n\nThe root meaning of the word \"postulate\" is to \"demand\"; for instance, Euclid demands that one agree that some things can be done, e.g. any two points can be joined by a straight line, etc.\n\nAncient geometers maintained some distinction between axioms and postulates. While commenting on Euclid's books, Proclus remarks that, \"Geminus held that this [4th] Postulate should not be classed as a postulate but as an axiom, since it does not, like the first three Postulates, assert the possibility of some construction but expresses an essential property.\" Boethius translated 'postulate' as \"petitio\" and called the axioms \"notiones communes\" but in later manuscripts this usage was not always strictly kept.\n\nThe logico-deductive method whereby conclusions (new knowledge) follow from premises (old knowledge) through the application of sound arguments (syllogisms, rules of inference), was developed by the ancient Greeks, and has become the core principle of modern mathematics. Tautologies excluded, nothing can be deduced if nothing is assumed. Axioms and postulates are the basic assumptions underlying a given body of deductive knowledge. They are accepted without demonstration. All other assertions (theorems, if we are talking about mathematics) must be proven with the aid of these basic assumptions. However, the interpretation of mathematical knowledge has changed from ancient times to the modern, and consequently the terms \"axiom\" and \"postulate\" hold a slightly different meaning for the present day mathematician, than they did for Aristotle and Euclid.\n\nThe ancient Greeks considered geometry as just one of several sciences, and held the theorems of geometry on par with scientific facts. As such, they developed and used the logico-deductive method as a means of avoiding error, and for structuring and communicating knowledge. Aristotle's posterior analytics is a definitive exposition of the classical view.\n\nAn \"axiom\", in classical terminology, referred to a self-evident assumption common to many branches of science. A good example would be the assertion that \"When an equal amount is taken from equals, an equal amount results.\"\n\nAt the foundation of the various sciences lay certain additional hypotheses which were accepted without proof. Such a hypothesis was termed a \"postulate\". While the axioms were common to many sciences, the postulates of each particular science were different. Their validity had to be established by means of real-world experience. Indeed, Aristotle warns that the content of a science cannot be successfully communicated, if the learner is in doubt about the truth of the postulates.\n\nThe classical approach is well-illustrated by Euclid's Elements, where a list of postulates is given (common-sensical geometric facts drawn from our experience), followed by a list of \"common notions\" (very basic, self-evident assertions).\n\nA lesson learned by mathematics in the last 150 years is that it is useful to strip the meaning away from the mathematical assertions (axioms, postulates, propositions, theorems) and definitions. One must concede the need for primitive notions, or undefined terms or concepts, in any study. Such abstraction or formalization makes mathematical knowledge more general, capable of multiple different meanings, and therefore useful in multiple contexts. Alessandro Padoa, Mario Pieri, and Giuseppe Peano were pioneers in this movement.\n\nStructuralist mathematics goes further, and develops theories and axioms (e.g. field theory, group theory, topology, vector spaces) without \"any\" particular application in mind. The distinction between an \"axiom\" and a \"postulate\" disappears. The postulates of Euclid are profitably motivated by saying that they lead to a great wealth of geometric facts. The truth of these complicated facts rests on the acceptance of the basic hypotheses. However, by throwing out Euclid's fifth postulate we get theories that have meaning in wider contexts, hyperbolic geometry for example. We must simply be prepared to use labels like \"line\" and \"parallel\" with greater flexibility. The development of hyperbolic geometry taught mathematicians that postulates should be regarded as purely formal statements, and not as facts based on experience.\n\nWhen mathematicians employ the field axioms, the intentions are even more abstract. The propositions of field theory do not concern any one particular application; the mathematician now works in complete abstraction. There are many examples of fields; field theory gives correct knowledge about them all.\n\nIt is not correct to say that the axioms of field theory are \"propositions that are regarded as true without proof.\" Rather, the field axioms are a set of constraints. If any given system of addition and multiplication satisfies these constraints, then one is in a position to instantly know a great deal of extra information about this system.\n\nModern mathematics formalizes its foundations to such an extent that mathematical theories can be regarded as mathematical objects, and mathematics itself can be regarded as a branch of logic. Frege, Russell, Poincaré, Hilbert, and Gödel are some of the key figures in this development.\n\nIn the modern understanding, a set of axioms is any collection of formally stated assertions from which other formally stated assertions follow by the application of certain well-defined rules. In this view, logic becomes just another formal system. A set of axioms should be consistent; it should be impossible to derive a contradiction from the axiom. A set of axioms should also be non-redundant; an assertion that can be deduced from other axioms need not be regarded as an axiom.\n\nIt was the early hope of modern logicians that various branches of mathematics, perhaps all of mathematics, could be derived from a consistent collection of basic axioms. An early success of the formalist program was Hilbert's formalization of Euclidean geometry, and the related demonstration of the consistency of those axioms.\n\nIn a wider context, there was an attempt to base all of mathematics on Cantor's set theory. Here the emergence of Russell's paradox, and similar antinomies of naïve set theory raised the possibility that any such system could turn out to be inconsistent.\n\nThe formalist project suffered a decisive setback, when in 1931 Gödel showed that it is possible, for any sufficiently large set of axioms (Peano's axioms, for example) to construct a statement whose truth is independent of that set of axioms. As a corollary, Gödel proved that the consistency of a theory like Peano arithmetic is an unprovable assertion within the scope of that theory.\n\nIt is reasonable to believe in the consistency of Peano arithmetic because it is satisfied by the system of natural numbers, an infinite but intuitively accessible formal system. However, at present, there is no known way of demonstrating the consistency of the modern Zermelo–Fraenkel axioms for set theory. Furthermore, using techniques of forcing (Cohen) one can show that the continuum hypothesis (Cantor) is independent of the Zermelo–Fraenkel axioms. Thus, even this very general set of axioms cannot be regarded as the definitive foundation for mathematics.\n\nAxioms play a key role not only in mathematics, but also in other sciences, notably in theoretical physics. In particular, the monumental work of Isaac Newton is essentially based on Euclid's axioms, augmented by a postulate on the non-relation of spacetime and the physics taking place in it at any moment.\n\nIn 1905, Newton's axioms were replaced by those of Albert Einstein's special relativity, and later on by those of general relativity.\n\nAnother paper of Albert Einstein and coworkers (see EPR paradox), almost immediately contradicted by Niels Bohr, concerned the interpretation of quantum mechanics. This was in 1935. According to Bohr, this new theory should be probabilistic, whereas according to Einstein it should be deterministic. Notably, the underlying quantum mechanical theory, i.e. the set of \"theorems\" derived by it, seemed to be identical. Einstein even assumed that it would be sufficient to add to quantum mechanics \"hidden variables\" to enforce determinism. However, thirty years later, in 1964, John Bell found a theorem, involving complicated optical correlations (see Bell inequalities), which yielded measurably different results using Einstein's axioms compared to using Bohr's axioms. And it took roughly another twenty years until an experiment of Alain Aspect got results in favour of Bohr's axioms, not Einstein's. (Bohr's axioms are simply: The theory should be probabilistic in the sense of the Copenhagen interpretation.)\n\nAs a consequence, it is not necessary to explicitly cite Einstein's axioms, the more so since they concern subtle points on the \"reality\" and \"locality\" of experiments.\n\nRegardless, the role of axioms in mathematics and in the above-mentioned sciences is different. In mathematics one neither \"proves\" nor \"disproves\" an axiom for a set of theorems; the point is simply that in the conceptual realm identified by the axioms, the theorems logically follow. In contrast, in physics a comparison with experiments always makes sense, since a falsified physical theory needs modification.\n\nIn the field of mathematical logic, a clear distinction is made between two notions of axioms: \"logical\" and \"non-logical\" (somewhat similar to the ancient distinction between \"axioms\" and \"postulates\" respectively).\n\nThese are certain formulas in a formal language that are universally valid, that is, formulas that are satisfied by every assignment of values. Usually one takes as logical axioms \"at least\" some minimal set of tautologies that is sufficient for proving all tautologies in the language; in the case of predicate logic more logical axioms than that are required, in order to prove logical truths that are not tautologies in the strict sense.\n\nIn propositional logic it is common to take as logical axioms all formulae of the following forms, where formula_1, formula_2, and formula_3 can be any formulae of the language and where the included primitive connectives are only \"formula_4\" for negation of the immediately following proposition and \"formula_5\" for implication from antecedent to consequent propositions:\n\n\nEach of these patterns is an \"axiom schema\", a rule for generating an infinite number of axioms. For example, if formula_9, formula_10, and formula_11 are propositional variables, then formula_12 and formula_13 are both instances of axiom schema 1, and hence are axioms. It can be shown that with only these three axiom schemata and \"modus ponens\", one can prove all tautologies of the propositional calculus. It can also be shown that no pair of these schemata is sufficient for proving all tautologies with \"modus ponens\".\n\nOther axiom schemas involving the same or different sets of primitive connectives can be alternatively constructed.\n\nThese axiom schemata are also used in the predicate calculus, but additional logical axioms are needed to include a quantifier in the calculus.\n\nThis means that, for any variable symbol formula_14 the formula formula_15 can be regarded as an axiom. Also, in this example, for this not to fall into vagueness and a never-ending series of \"primitive notions\", either a precise notion of what we mean by formula_15 (or, for that matter, \"to be equal\") has to be well established first, or a purely formal and syntactical usage of the symbol formula_17 has to be enforced, only regarding it as a string and only a string of symbols, and mathematical logic does indeed do that.\n\nAnother, more interesting example axiom scheme, is that which provides us with what is known as Universal Instantiation:\n\nWhere the symbol formula_18 stands for the formula formula_1 with the term formula_20 substituted for formula_21. (See Substitution of variables.) In informal terms, this example allows us to state that, if we know that a certain property formula_22 holds for every formula_21 and that formula_20 stands for a particular object in our structure, then we should be able to claim formula_25. Again, \"we are claiming that the formula\" formula_26 \"is valid\", that is, we must be able to give a \"proof\" of this fact, or more properly speaking, a \"metaproof\". Actually, these examples are \"metatheorems\" of our theory of mathematical logic since we are dealing with the very concept of \"proof\" itself. Aside from this, we can also have Existential Generalization:\n\nNon-logical axioms are formulas that play the role of theory-specific assumptions. Reasoning about two different structures, for example the natural numbers and the integers, may involve the same logical axioms; the non-logical axioms aim to capture what is special about a particular structure (or set of structures, such as groups). Thus non-logical axioms, unlike logical axioms, are not \"tautologies\". Another name for a non-logical axiom is \"postulate\".\n\nAlmost every modern mathematical theory starts from a given set of non-logical axioms, and it was thought that in principle every theory could be axiomatized in this way and formalized down to the bare language of logical formulas.\n\nNon-logical axioms are often simply referred to as \"axioms\" in mathematical discourse. This does not mean that it is claimed that they are true in some absolute sense. For example, in some groups, the group operation is commutative, and this can be asserted with the introduction of an additional axiom, but without this axiom we can do quite well developing (the more general) group theory, and we can even take its negation as an axiom for the study of non-commutative groups.\n\nThus, an \"axiom\" is an elementary basis for a formal logic system that together with the rules of inference define a deductive system.\n\nThis section gives examples of mathematical theories that are developed entirely from a set of non-logical axioms (axioms, henceforth). A rigorous treatment of any of these topics begins with a specification of these axioms.\n\nBasic theories, such as arithmetic, real analysis and complex analysis are often introduced non-axiomatically, but implicitly or explicitly there is generally an assumption that the axioms being used are the axioms of Zermelo–Fraenkel set theory with choice, abbreviated ZFC, or some very similar system of axiomatic set theory like Von Neumann–Bernays–Gödel set theory, a conservative extension of ZFC. Sometimes slightly stronger theories such as Morse-Kelley set theory or set theory with a strongly inaccessible cardinal allowing the use of a Grothendieck universe are used, but in fact most mathematicians can actually prove all they need in systems weaker than ZFC, such as second-order arithmetic.\n\nThe study of topology in mathematics extends all over through point set topology, algebraic topology, differential topology, and all the related paraphernalia, such as homology theory, homotopy theory. The development of \"abstract algebra\" brought with itself group theory, rings, fields, and Galois theory.\n\nThis list could be expanded to include most fields of mathematics, including measure theory, ergodic theory, probability, representation theory, and differential geometry.\n\nCombinatorics is an example of a field of mathematics which does not, in general, follow the axiomatic method.\n\nThe Peano axioms are the most widely used \"axiomatization\" of first-order arithmetic. They are a set of axioms strong enough to prove many important facts about number theory and they allowed Gödel to establish his famous second incompleteness theorem.\n\nWe have a language formula_27 where formula_28 is a constant symbol and formula_29 is a unary function and the following axioms:\n\n\nThe standard structure is formula_35 where formula_36 is the set of natural numbers, formula_29 is the successor function and formula_28 is naturally interpreted as the number 0.\n\nProbably the oldest, and most famous, list of axioms are the 4 + 1 Euclid's postulates of plane geometry. The axioms are referred to as \"4 + 1\" because for nearly two millennia the fifth (parallel) postulate (\"through a point outside a line there is exactly one parallel\") was suspected of being derivable from the first four. Ultimately, the fifth postulate was found to be independent of the first four. Indeed, one can assume that exactly one parallel through a point outside a line exists, or that infinitely many exist. This choice gives us two alternative forms of geometry in which the interior angles of a triangle add up to exactly 180 degrees or less, respectively, and are known as Euclidean and hyperbolic geometries. If one also removes the second postulate (\"a line can be extended indefinitely\") then elliptic geometry arises, where there is no parallel through a point outside a line, and in which the interior angles of a triangle add up to more than 180 degrees.\n\nThe objectives of study are within the domain of real numbers. The real numbers are uniquely picked out (up to isomorphism) by the properties of a \"Dedekind complete ordered field\", meaning that any nonempty set of real numbers with an upper bound has a least upper bound. However, expressing these properties as axioms requires use of second-order logic. The Löwenheim-Skolem theorems tell us that if we restrict ourselves to first-order logic, any axiom system for the reals admits other models, including both models that are smaller than the reals and models that are larger. Some of the latter are studied in non-standard analysis.\n\nA deductive system consists of a set formula_39 of logical axioms, a set formula_40 of non-logical axioms, and a set formula_41 of \"rules of inference\". A desirable property of a deductive system is that it be complete. A system is said to be complete if, for all formulas formula_1,\n\nformula_43\nthat is, for any statement that is a \"logical consequence\" of formula_40 there actually exists a \"deduction\" of the statement from formula_40. This is sometimes expressed as \"everything that is true is provable\", but it must be understood that \"true\" here means \"made true by the set of axioms\", and not, for example, \"true in the intended interpretation\". Gödel's completeness theorem establishes the completeness of a certain commonly used type of deductive system.\n\nNote that \"completeness\" has a different meaning here than it does in the context of Gödel's first incompleteness theorem, which states that no \"recursive\", \"consistent\" set of non-logical axioms formula_40 of the Theory of Arithmetic is \"complete\", in the sense that there will always exist an arithmetic statement formula_1 such that neither formula_1 nor formula_49 can be proved from the given set of axioms.\n\nThere is thus, on the one hand, the notion of \"completeness of a deductive system\" and on the other hand that of \"completeness of a set of non-logical axioms\". The completeness theorem and the incompleteness theorem, despite their names, do not contradict one another.\n\nEarly mathematicians regarded axiomatic geometry as a model of physical space, and obviously there could only be one such model. The idea that alternative mathematical systems might exist was very troubling to mathematicians of the 19th century and the developers of systems such as Boolean algebra made elaborate efforts to derive them from traditional arithmetic. Galois showed just before his untimely death that these efforts were largely wasted. Ultimately, the abstract parallels between algebraic systems were seen to be more important than the details and modern algebra was born. In the modern view axioms may be any set of formulas, as long as they are not known to be inconsistent.\n\n\n\n", "id": "928", "title": "Axiom"},{"url": "https://en.wikipedia.org/wiki?curid=929", "text": "Alpha\n\nAlpha (uppercase , lowercase ; , \"álpha\", \"álfa\") is the first letter of the Greek alphabet. In the system of Greek numerals it has a value of 1. \n\nIt was derived from the Phoenician and Hebrew letter aleph - an ox or leader.\n\nLetters that arose from alpha include the Latin A and the Cyrillic letter А.\n\nIn English, the noun \"alpha\" is used as a synonym for \"beginning\", or \"first\" (in a series), reflecting its Greek roots.\n\nIn Ancient Greek, alpha was pronounced and could be either phonemically long ([a:]) or short ([a]). Where there is ambiguity, long and short alpha are sometimes written with a macron and breve today: Ᾱᾱ, Ᾰᾰ.\n\nIn Modern Greek, vowel length has been lost, and all instances of alpha simply represent .\n\nIn the polytonic orthography of Greek, alpha, like other vowel letters, can occur with several diacritic marks: any of three accent symbols (), and either of two breathing marks (), as well as combinations of these. It can also combine with the iota subscript ().\n\nIn the Attic-Ionic dialect of Ancient Greek, long alpha fronted to (eta). In Ionic, the shift took place in all positions. In Attic, the shift did not take place after epsilon, iota, and rho (ε, ι, ρ; \"e\", \"i\", \"r\"). In Doric and Aeolic, long alpha is preserved in all positions.\n\nPrivative a is the Ancient Greek prefix ἀ- or ἀν- \"a-\", \"an-\", added to words to negate them. It originates from the Proto-Indo-European *\"\" (syllabic nasal) and is cognate with English \"un-\".\n\nCopulative a is the Greek prefix ἁ- or ἀ- \"ha-\", \"a-\". It comes from Proto-Indo-European *\"\".\n\nThe letter alpha represents various concepts in physics and chemistry, including alpha radiation, angular acceleration, alpha particles, alpha carbon and strength of electromagnetic interaction (as Fine-structure constant). Alpha also stands for thermal expansion coefficient of a compound in physical chemistry. It is also commonly used in mathematics in algebraic solutions representing quantities such as angles. Furthermore, in mathematics, the letter alpha is used to denote the area underneath a normal curve in statistics to denote significance level when proving null and alternative hypotheses. In zoology, it is used to name the dominant individual in a wolf or dog pack.\n\nThe proportionality operator \"∝\" (in Unicode: U+221D) is sometimes mistaken for alpha.\n\nThe uppercase letter alpha is not generally used as a symbol because it tends to be rendered identically to the uppercase Latin A.\n\nIn the International Phonetic Alphabet, the letter ɑ, which looks similar to the lower-case alpha, represents the open back unrounded vowel.\n\nAlpha was derived from \"aleph\", which in Phoenician means \"ox\".\n\nPlutarch, in \"Moralia\", presents a discussion on why the letter alpha stands first in the alphabet. Ammonius asks Plutarch what he, being a Boeotian, has to say for Cadmus, the Phoenician who reputedly settled in Thebes and introduced the alphabet to Greece, placing \"alpha\" first because it is the Phoenician name for ox—which, unlike Hesiod, the Phoenicians considered not the second or third, but the first of all necessities. \"Nothing at all,\" Plutarch replied. He then added that he would rather be assisted by Lamprias, his own grandfather, than by Dionysus' grandfather, i.e. Cadmus. For Lamprias had said that the first articulate sound made is \"alpha\", because it is very plain and simple—the air coming off the mouth does not require any motion of the tongue—and therefore this is the first sound that children make.\n\nAccording to Plutarch's natural order of attribution of the vowels to the planets, alpha was connected with the Moon.\n\nAlpha, both as a symbol and term, is used to refer to or describe a variety of things, including the first or most significant occurrence of something. The New Testament has God declaring himself to be the \"Alpha and Omega, the beginning and the end, the first and the last.\" (Revelation 22:13, KJV, and see also 1:8).\n\nThe term \"alpha\" has been used to denote position in social hierarchy, examples being \"alpha males\" or pack leaders.\n\n\nFor accented Greek characters, see Greek diacritics: Computer encoding.\n\n\n", "id": "929", "title": "Alpha"},{"url": "https://en.wikipedia.org/wiki?curid=930", "text": "Alvin Toffler\n\nAlvin Toffler (October 4, 1928 – June 27, 2016) was an American writer and futurist, known for his works discussing modern technologies, including the digital revolution and the communication revolution, with emphasis on their effects on cultures worldwide.\n\nToffler was an associate editor of \"Fortune\" magazine. In his early works he focused on technology and its impact, which he termed \"information overload.\" In 1970 his first major book about the future, \"Future Shock\", became a worldwide best-seller and has sold over 6 million copies.\n\nHe and his wife Heidi Toffler, who collaborated with him for most of his writings, moved on to examining the reaction to changes in society with another best-selling book, \"The Third Wave\" in 1980. In it, he foresaw such technological advances as cloning, personal computers, the Internet, cable television and mobile communication. His later focus, via their other best-seller, \"Powershift\", (1990), was on the increasing power of 21st-century military hardware and the proliferation of new technologies.\n\nHe founded Toffler Associates, a management consulting company, and was a visiting scholar at the Russell Sage Foundation, visiting professor at Cornell University, faculty member of the New School for Social Research, a White House correspondent, and a business consultant. Toffler's ideas and writings were a significant influence on the thinking of business and government leaders worldwide, including Newt Gingrich, China's Zhao Ziyang, and AOL founder Steve Case.\n\nAlvin Toffler was born on October 4, 1928, in New York City, and raised in Brooklyn. He was the son of Rose (Albaum) and Sam Toffler, a furrier, both Jewish immigrants from Poland. He had one younger sister. He was inspired to become a writer at the age of 7 by his aunt and uncle, who lived with the Tofflers. \"They were Depression-era literary intellectuals,\" Toffler said, \"and they always talked about exciting ideas.\"\n\nToffler graduated from New York University in 1950 as an English major, though by his own account he was more focused on political activism than grades. He met his future wife, Adelaide Elizabeth Farrell (nicknamed \"Heidi\"), when she was starting a graduate course in linguistics. Being radical students, they decided against further graduate work and moved to the Midwest, where they married on April 29, 1950.\n\nSeeking experiences to write about, Alvin and Heidi Toffler spent the next five years as blue collar workers on assembly lines while studying industrial mass production in their daily work. He compared his own desire for experience to other writers, such as Jack London, who in his quest for subjects to write about sailed the seas, and John Steinbeck, who went to pick grapes with migrant workers. In their first factory jobs, Heidi became a union shop steward in the aluminum foundry where she worked. Alvin became a millwright and welder. In the evenings Alvin would write poetry and fiction, but discovered he was proficient at neither.\n\nHis hands-on practical labor experience helped Alvin Toffler land a position at a union-backed newspaper, a transfer to its Washington bureau in 1957, then three years as a White House correspondent, covering Congress and the White House for a Pennsylvania daily newspaper.\n\nThey returned to New York City in 1959 when \"Fortune\" magazine invited Alvin to become its labor columnist, later having him write about business and management. After leaving \"Fortune\" magazine in 1962, Toffler began a freelance career, writing long form articles for scholarly journals and magazines. His 1964 \"Playboy interviews\" with Russian novelist Vladimir Nabokov and Ayn Rand were considered among the magazine's best. His interview with Rand was the first time the magazine had given such a platform to a female intellectual, which as one commentator said, \"the real bird of paradise Toffler captured for Playboy in 1964 was Ayn Rand.\"\n\nToffler was hired by IBM to conduct research and write a paper on the social and organizational impact of computers, leading to his contact with the earliest computer \"gurus\" and artificial intelligence researchers and proponents. Xerox invited him to write about its research laboratory and AT&T consulted him for strategic advice. This AT&T work led to a study of telecommunications, which advised the company's top management to break up the company more than a decade before the government forced AT&T to break up.\n\nIn the mid-1960s, the Tofflers began five years of research on what would become \"Future Shock\", published in 1970. It has sold over 6 million copies worldwide, according to the \"New York Times,\" or over 15 million copies according to the Tofflers' Web site. Toffler coined the term \"future shock\" to refer to what happens to a society when change happens too fast, which results in social confusion and normal decision-making processes breaking down. The book has never been out of print and has been translated into dozens of languages.\n\nHe continued the theme in \"The Third Wave\" in 1980. While he describes the first and second waves as the agricultural and industrial revolutions, the \"third wave,\" a phrase he coined, represents the current information, computer-based revolution. He forecast the spread of the Internet and email, interactive media, cable television, cloning, and other digital advancements. He claimed that one of the side effects of the digital age has been \"information overload,\" another term he coined. In 1990 he wrote \"Powershift\", also with the help of his wife, Heidi.\n\nIn 1996, with American business consultant Tom Johnson, they co-founded Toffler Associates, an advisory firm designed to implement many of the ideas the Tofflers had written on. The firm worked with businesses, NGOs, and governments in the United States, South Korea, Mexico, Brazil, Singapore, Australia, and other countries. During this period in his career, Toffler lectured worldwide, taught at several schools and met world leaders, such as Mikhail Gorbachev, along with key executives and military officials.\n\nToffler stated many of his ideas during an interview with the Australian Broadcasting Corporation in 1998. Among a few of his opinions, he said that \"Society needs people who take care of the elderly and who know how to be compassionate and honest. Society needs people who work in hospitals. Society needs all kinds of skills that are not just cognitive; they're emotional, they're affectional. You can't run the society on data and computers alone.\"\n\nHis opinions about the future of education, many of which were in \"Future Shock\", have often been quoted. An often misattributed quote, however, is that of psychologist Herbert Gerjuoy: \"Tomorrow's illiterate will not be the man who can't read; he will be the man who has not learned how to learn.\"\n\nEarly in his career, after traveling to other countries, he became aware of the new and myriad inputs that visitors received from these other cultures. He explained during an interview that some visitors would become \"truly disoriented and upset\" by the strange environment, which he described as a reaction to culture shock. From that issue, he foresaw another problem for the future, when a culturally \"new environment comes to you ... and comes to you rapidly.\" That kind of sudden cultural change within one's own country, which he felt many would not understand, would lead to a similar reaction, one of \"future shock\", which he wrote about in his book by that title. Toffler writes:\nIn his book \"The Third Wave\", Toffler describes three types of societies, based on the concept of \"waves\" — each wave pushes the older societies and cultures aside. He describes the \"First Wave\" as the society after agrarian revolution and replaced the first hunter-gatherer cultures. The \"Second Wave,\" he labels society during the Industrial Revolution (ca. late 17th century through the mid-20th century). That period saw the increase of urban industrial populations which had undermined the traditional nuclear family, and initiated a factory-like education system, and the growth of the corporation. Toffler said:\n\nThe \"Third Wave\" was a term he coined to describe the post-industrial society, which began in the late 1950s. His description of this period dovetails with other futurist writers, who also wrote about the Information Age, Space Age, Electronic Era, Global Village, terms which highlighted a scientific-technological revolution. The Tofflers claimed to have predicted a number of geopolitical events, such as the collapse of the Soviet Union, the fall of the Berlin Wall and the future economic growth in the Asia-Pacific region.\n\nToffler often visited with dignitaries in Asia, including China's Zhao Ziyang, Singapore's Lee Kuan Yew and South Korea's Kim Dae Jung, all of whom were influenced by his views as Asia's emerging markets increased in global significance during the 1980s and 1990s. Although they had originally censored some of his books and ideas, China's government cited him along with Franklin Roosevelt and Bill Gates as being among the Westerners who had most influenced their country. \"The Third Wave\" along with a video documentary based on it became best-sellers in China and were widely distributed to schools. Toffler's influence on Asian thinkers was summed up in an article in \"Daedulus\", published by the American Academy of Arts & Sciences:\nU.S. House Speaker Newt Gingrich publicly lauded his ideas about the future, and urged members of Congress to read Toffler's book, \"Creating a New Civilization\" (1995). Others, such as AOL founder Steve Case, cited Toffler's \"The Third Wave\" as a formative influence on his thinking, which inspired him to write \"The Third Wave: An Entrepreneur's Vision of the Future\" in 2016. Case said that Toffler was a \"real pioneer in helping people, companies and even countries lean into the future.\"\n\nIn 1980 Ted Turner founded CNN, which he said was inspired by Toffler's forecasting the end of the dominance of the three main television networks. Turner's company, Turner Broadcasting, published Toffler's \"Creating a New Civilization\" in 1995. Shortly after the book was released, Russian president Mikhail Gorbachev hosted the Global Governance Conference in San Francisco with the theme, \"Toward a New Civilization\", which was attended by dozens of world figures, including the Tofflers, George H. W. Bush, Margaret Thatcher, Carl Sagan, Abba Eban and Turner with his wife, actress Jane Fonda.\n\nMexican billionaire Carlos Slim, was influenced by his works, and became a friend of the writer. And global marketer J.D. Power also said he was inspired by Toffler's works.\n\nSince the 1960s, people had tried to make sense out of the effect of new technologies and social change, a problem which made Toffler's writings widely influential beyond the confines of scientific, economic, and public policy. His works and ideas have been subject to various criticisms, usually with the same argumentation used against futurology: that foreseeing the future is nigh impossible.\n\nTechno music pioneer Juan Atkins cites Toffler's phrase \"techno rebels\" in \"The Third Wave\" as inspiring him to use the word \"techno\" to describe the musical style he helped to create\n\nMusicians Curtis Mayfield and Herbie Hancock both wrote songs called \"Future Shock.\" Science fiction author John Brunner wrote \"The Shockwave Rider,\" from the concept of \"future shock.\"\n\nAccenture, the management consultancy firm, identified Toffler in 2002 as being among the most influential voices in business leaders, along with Bill Gates and Peter Drucker. Toffler has also been described in a \"Financial Times\" interview as the \"world's most famous futurologist\". In 2006 the \"People's Daily\" classed him among the 50 foreigners who shaped modern China, which one U.S. newspaper notes made him a \"guru of sorts to world statesmen.\" Prime Minister Zhao Ziyang of China convened conferences to discuss \"The Third Wave\" in the early 1980s, and in 1985 the book was the No. 2 best seller in China.\n\nAuthor Mark Satin characterizes Toffler as an important early influence on radical centrist political thought.\n\nNewt Gingrich became close to the Tofflers in the 1970s and said \"The Third Wave\" had immensely influenced his own thinking and was \"one of the great seminal works of our time.\"\n\nToffler has received several prestigious prizes awards, including the McKinsey Foundation Book Award for Contributions to Management Literature, Officier de L'Ordre des Arts et Lettres, and appointments, including Fellow of the American Association for the Advancement of Science and the International Institute for Strategic Studies.\n\nIn 2006, the Alvin and Heidi Toffler were recipients of Brown University's Independent Award.\n\nToffler was married to Heidi Toffler, also a writer and futurist. They lived in the Bel Air section of Los Angeles, California, and previously lived in Redding, Connecticut.\n\nThe couple's only child, Karen Toffler (1954–2000), died at age 46 after more than a decade suffering from Guillain–Barré syndrome.\n\nAlvin Toffler died in his sleep on June 27, 2016, at his home in Los Angeles. No cause of death was given.\n\nAlvin Toffler co-wrote his books with his wife Heidi.\n\n\n", "id": "930", "title": "Alvin Toffler"},{"url": "https://en.wikipedia.org/wiki?curid=931", "text": "The Amazing Spider-Man\n\nThe Amazing Spider-Man is an American comic book series published by Marvel Comics, featuring the adventures of the fictional superhero Spider-Man. Being the mainstream continuity of the franchise, it began publication in 1963 as a monthly periodical and was published continuously, with a brief interruption in 1995, until its relaunch with a new numbering order in 1999. In 2003 the series reverted to the numbering order of the first volume. The title has occasionally been published biweekly, and was published three times a month from 2008 to 2010. A film named after the comic was released July 3, 2012.\n\nAfter DC Comics' relaunch of \"Action Comics\" and \"Detective Comics\" with new #1 issues in 2011, it had been the highest-numbered American comic still in circulation until it was cancelled. The title ended its 50-year run as a continuously published comic with issue #700 in December 2012. It was replaced by \"The Superior Spider-Man\" as part of the Marvel NOW! relaunch of Marvel's comic lines.\n\nThe title was relaunched in April 2014, starting fresh from issue #1, after the \"Goblin Nation\" story arc published in \"The Superior Spider-Man\" and \"Superior Spider-Man Team-Up\". In late 2015, \"The Amazing Spider-Man\" was relaunched again with a new volume with issue #1 following the 2015 \"Secret Wars\" event.\n\nThe character was created by writer-editor Stan Lee and artist and co-plotter Steve Ditko, and the pair produced 38 issues from March 1963 to July 1966. Ditko left after the 38th issue, while Lee remained as writer until issue 100. Since then, many writers and artists have taken over the monthly comic through the years, chronicling the adventures of Marvel's most identifiable hero.\n\n\"The Amazing Spider-Man\" has been the character's flagship series for his first fifty years in publication, and was the only monthly series to star Spider-Man until \"Peter Parker, The Spectacular Spider-Man\" in 1976, although 1972 saw the debut of \"Marvel Team-Up\", with the vast majority of issues featuring Spider-Man along with a rotating cast of other Marvel characters. Most of the major characters and villains of the Spider-Man saga have been introduced in \"Amazing\", and with few exceptions, it is where most key events in the character's history have occurred. The title was published continuously until #441 (Nov. 1998) when Marvel Comics relaunched it as vol. 2 #1 (Jan. 1999), but on Spider-Man's 40th anniversary, this new title reverted to using the numbering of the original series, beginning again with issue #500 (Dec. 2003) and lasting until the final issue, #700 (Feb. 2013).\nDue to strong sales on the character's first appearance in \"Amazing Fantasy\" #15, Spider-Man was given his own ongoing series in March 1963. The initial years of the series, under Lee and Ditko, chronicled Spider-Man's nascent career with his civilian life as hard-luck yet perpetually good-humored teenager Peter Parker. Peter balanced his career as Spider-Man with his job as a freelance photographer for \"The Daily Bugle\" under the bombastic editor-publisher J. Jonah Jameson to support himself and his frail Aunt May. At the same time, Peter dealt with public hostility towards Spider-Man and the antagonism of his classmates Flash Thompson and Liz Allan at Midtown High School, while embarking on a tentative, ill-fated romance with Jameson's secretary, Betty Brant.\n\nBy focusing on Parker's everyday problems, Lee and Ditko created a groundbreakingly flawed, self-doubting superhero, and the first major teenaged superhero to be a protagonist and not a sidekick. Ditko's quirky art provided a stark contrast to the more cleanly dynamic stylings of Marvel's most prominent artist, Jack Kirby, and combined with the humor and pathos of Lee's writing to lay the foundation for what became an enduring mythos.\n\nMost of Spider-Man's key villains and supporting characters were introduced during this time. Issue #1 (March 1963) featured the first appearances of J. Jonah Jameson and his astronaut son John Jameson, and the supervillain the Chameleon. It included the hero's first encounter with the superhero team the Fantastic Four. Issue #2 (May 1963) featured the first appearance of the Vulture and the beginning of Parker's freelance photography career at the newspaper \"The Daily Bugle\".\n\nThe Lee-Ditko era continued to usher in a significant number of villains and supporting characters, including Doctor Octopus in #3 (July 1963); the Sandman and Betty Brant in #4 (Sept. 1963); the Lizard in #6 (Nov. 1963); Living Brain in (#8, January, 1964); Electro in #9 (March 1964); Mysterio in #13 (June 1964); the Green Goblin in #14 (July 1964); Kraven The Hunter in #15 (Aug. 1964); reporter Ned Leeds in #18 (Nov. 1964); and the Scorpion in #20 (Jan. 1965). The Molten Man was introduced in #28 (Sept. 1965) which also featured Parker's graduation from high school. Peter began attending Empire State University in #31 (Dec. 1965), the issue which featured the first appearances of friends and classmates Gwen Stacy and Harry Osborn. Harry's father, Norman Osborn first appeared in #23 (April 1965) as a member of Jameson's country club but is not named nor revealed as Harry's father until #37 (June 1966). One of the most celebrated issues of the Lee-Ditko run is #33 (Feb. 1966), the third part of the story arc \"If This Be My Destiny...!\", which features the dramatic scene of Spider-Man, through force of will and thoughts of family, escaping from being pinned by heavy machinery. Comics historian Les Daniels noted that \"Steve Ditko squeezes every ounce of anguish out of Spider-Man's predicament, complete with visions of the uncle he failed and the aunt he has sworn to save.\" Peter David observed that \"After his origin, this two-page sequence from \"Amazing Spider-Man\" #33 is perhaps the best-loved sequence from the Stan Lee/Steve Ditko era.\" Steve Saffel stated the \"full page Ditko image from \"The Amazing Spider-Man\" #33 is one of the most powerful ever to appear in the series and influenced writers and artists for many years to come.\" and Matthew K. Manning wrote that \"Ditko's illustrations for the first few pages of this Lee story included what would become one of the most iconic scenes in Spider-Man's history.\" The story was chosen as #15 in the 100 Greatest Marvels of All Time poll of Marvel's readers in 2001. Editor Robert Greenberger wrote in his introduction to the story that \"These first five pages are a modern-day equivalent to Shakespeare as Parker's soliloquy sets the stage for his next action. And with dramatic pacing and storytelling, Ditko delivers one of the great sequences in all comics.\"\nAlthough credited only as artist for most of his run, Ditko would eventually plot the stories as well as draw them, leaving Lee to script the dialogue. A rift between Ditko and Lee developed, and the two men were not on speaking terms long before Ditko completed his last issue, \"The Amazing Spider-Man\" #38 (July 1966). The exact reasons for the Ditko-Lee split have never been fully explained. Spider-Man successor artist John Romita Sr., in a 2010 deposition, recalled that Lee and Ditko \"ended up not being able to work together because they disagreed on almost everything, cultural, social, historically, everything, they disagreed on characters...\"\n\nIn successor penciler Romita Sr.'s first issue, #39 (Aug. 1966), nemesis the Green Goblin discovers Spider-Man's secret identity and reveals his own to the captive hero. Romita's Spider-Man – more polished and heroic-looking than Ditko's – became the model for two decades. The Lee-Romita era saw the introduction of such characters as \"Daily Bugle\" managing editor Robbie Robertson in #52 (Sept. 1967) and NYPD Captain George Stacy, father of Parker's girlfriend Gwen Stacy, in #56 (Jan. 1968). The most important supporting character to be introduced during the Romita era was Mary Jane Watson, who made her first full appearance in #42, (Nov. 1966), although she first appeared in #25 (June 1965) with her face obscured and had been mentioned since #15 (Aug. 1964). Peter David wrote in 2010 that Romita \"made the definitive statement of his arrival by pulling Mary Jane out from behind the oversized potted plant [that blocked the readers' view of her face in issue #25] and placing her on panel in what would instantly become an iconic moment.\" Romita has stated that in designing Mary Jane, he \"used Ann-Margret from the movie \"Bye Bye Birdie\" as a guide, using her coloring, the shape of her face, her red hair and her form-fitting short skirts.\"\n\nLee and Romita toned down the prevalent sense of antagonism in Parker's world by improving Parker's relationship with the supporting characters and having stories focused as much on the social and college lives of the characters as they did on Spider-Man's adventures. The stories became more topical, addressing issues such as civil rights, racism, prisoners' rights, the Vietnam War, and political elections.\n\nIssue #50 (June 1967) introduced the highly enduring criminal mastermind the Kingpin, who would become a major force as well in the superhero series \"Daredevil\". Other notable first appearances in the Lee-Romita era include the Rhino in #41 (Oct. 1966), the Shocker in #46 (March 1967), the Prowler in #78 (Nov. 1969), and the Kingpin's son, Richard Fisk, in #83 (April 1970).\n\nSeveral spin-off series debuted in the 1970s: \"Marvel Team-Up\" in 1972, and \"The Spectacular Spider-Man\" in 1976. A short-lived series titled \"Giant-Size Spider-Man\" began in July 1974 and ran six issues through 1975. \"Spidey Super Stories\", a series aimed at children ages 6–10, ran for 57 issues from October 1974 through 1982. \nThe flagship title's second decade took a grim turn with a story in #89-90 (Oct.-Nov. 1970) featuring the death of Captain George Stacy. This was the first Spider-Man story to be penciled by Gil Kane, who would alternate drawing duties with Romita for the next year-and-a-half and would draw several landmark issues.\n\nOne such story took place in the controversial issues #96-98 (May–July 1971). Writer-editor Lee defied the Comics Code Authority with this story, in which Parker's friend Harry Osborn, was hospitalized after over-dosing on pills. Lee wrote this story upon a request from the U. S. Department of Health, Education, and Welfare for a story about the dangers of drugs. Citing its dictum against depicting drug use, even in an anti-drug context, the CCA refused to put its seal on these issues. With the approval of Marvel publisher Martin Goodman, Lee had the comics published without the seal. The comics sold well and Marvel won praise for its socially conscious efforts. The CCA subsequently loosened the Code to permit negative depictions of drugs, among other new freedoms.\n\n\"The Six Arms Saga\" of #100-102 (Sept.–Nov. 1971) introduced Morbius, the Living Vampire. The second installment was the first \"Amazing Spider-Man\" story not written by co-creator Lee, with Roy Thomas taking over writing the book for several months before Lee returned to write #105-110 (Feb.-July 1972). Lee, who was going on to become Marvel Comics' publisher, with Thomas becoming editor-in-chief, then turned writing duties over to 19-year-old Gerry Conway, who scripted the series through 1975. Romita penciled Conway's first half-dozen issues, which introduced the gangster Hammerhead in #113 (Oct. 1972). Kane then succeeded Romita as penciler, although Romita would continue inking Kane for a time.\n\nIssues 121-122 (June–July 1973, by Conway-Kane-Romita), which featured the death of Gwen Stacy at the hands of the Green Goblin in \"The Night Gwen Stacy Died\" in issue #121. Her demise and the Goblin's apparent death one issue later formed a story arc widely considered as the most defining in the history of Spider-Man. The aftermath of the story deepened both the characterization of Mary Jane Watson and her relationship with Parker.\n\nIn 1973, Gil Kane was succeeded by Ross Andru, whose run lasted from issue #125 (October 1973) to #185 (October 1978). Issue #129 (Feb. 1974) introduced the Punisher, who would become one of Marvel Comics' most popular characters. The Conway-Andru era featured the first appearances of the Man-Wolf in #124-125 (Sept.-Oct. 1973); the near-marriage of Doctor Octopus and Aunt May in #131 (April 1974); Harry Osborn stepping into his father's role as the Green Goblin in #135-137 (Aug.-Oct.1974); and the original \"Clone Saga\", containing the introduction of Spider-Man's clone, in #147-149 (Aug.-Oct. 1975).\nArchie Goodwin and Gil Kane produced the title's 150th issue (Nov. 1975) before Len Wein became writer with issue #151. During Wein's tenure, Harry Osborn and Liz Allen dated and became engaged, J. Jonah Jameson was introduced to his eventual second wife, Marla Madison, and Aunt May suffered a heart attack. Wein's last story on \"Amazing\" was a five-issue arc in #176-180 (Jan.-May 1978) featuring a third Green Goblin (Harry Osborn’s psychiatrist, Bart Hamilton). Marv Wolfman, Marvel's editor-in-chief from 1975 to 1976, succeeded Wein as writer, and in his first issue, #182 (July 1978), had Parker propose marriage to Watson who refused, in the following issue. Keith Pollard succeeded Ross Andru as artist shortly afterward, and with Wolfman introduced the likable rogue the Black Cat (Felicia Hardy) in #194 (July 1979). As a love interest for Spider-Man, the Black Cat would go on to be an important supporting character for the better part of the next decade, and remain a friend and occasional lover into the 2010s.\n\n\"The Amazing Spider-Man\" #200 (Jan. 1980) featured the return and death of the burglar who killed Spider-Man's Uncle Ben. Writer Marv Wolfman and penciler Keith Pollard both left the title by mid-year, succeeded by Dennis O'Neil, a writer known for groundbreaking 1970s work at rival DC Comics, and penciler John Romita Jr.. O'Neil wrote two issues of \"The Amazing Spider-Man Annual\" which were both drawn by Frank Miller. The 1980 Annual featured a team-up with Doctor Strange while the 1981 Annual showcased a meeting with the Punisher. Roger Stern, who had written nearly 20 issues of sister title \"The Spectacular Spider-Man\", took over \"Amazing\" with issue #224 (January 1982). During his two years on the title, Stern augmented the backgrounds of long-established Spider-Man villains, and with Romita Jr. created the mysterious supervillain the Hobgoblin in #238-239 (March–April 1983). Fans engaged with the mystery of the Hobgoblin's secret identity, which continued throughout #244-245 and 249-251 (Sept.-Oct. 1983 and Feb.-April 1984). One lasting change was the reintroduction of Mary Jane Watson as a more serious, mature woman who becomes Peter's confidante after she reveals that she knows his secret identity. Stern wrote \"The Kid Who Collects Spider-Man\" in \"The Amazing Spider-Man\" #248 (January 1984), a story which ranks among his most popular.\n\nBy mid-1984, Tom DeFalco and Ron Frenz took over scripting and penciling. DeFalco helped establish Parker and Watson's mature relationship, laying the foundation for the characters' wedding in 1987. Notably, in #257 (Oct. 1984), Watson tells Parker that she knows he is Spider-Man, and in #259 (Dec. 1984), she reveals to Parker the extent of her troubled childhood. Other notable issues of the DeFalco-Frenz era include #252 (May 1984), with the first appearance of Spider-Man's black costume, which the hero would wear almost exclusively for the next four years' worth of comics; the debut of criminal mastermind the Rose, in #253 (June 1984); the revelation in #258 (Nov. 1984) that the black costume is a living being, a symbiote; and the introduction of the female mercenary Silver Sable in #265 (June 1985).\n\nTom DeFalco and Ron Frenz were both removed from \"The Amazing Spider-Man\" in 1986 by editor Owsley under acrimonious circumstances. A succession of artists including Alan Kupperberg, John Romita Jr., and Alex Saviuk penciled the series from 1987 to 1988; Owsley wrote the book for the first half of 1987, scripting the five-part \"Gang War\" story (#284-288) that DeFalco plotted. Former \"Spectacular Spider-Man\" writer Peter David scripted #289 (June 1987), which revealed Ned Leeds as being the Hobgoblin although this was retconned in 1996 by Roger Stern into Leeds not being the original Hobgoblin after all.\n\nDavid Michelinie took over as writer in the next issue, for a story arc in #290-292 (July-Sept. 1987) that led to the marriage of Peter Parker and Mary Jane Watson in \"Amazing Spider-Man Annual\" #21. The \"Kraven's Last Hunt\" storyline by writer J.M. DeMatteis and artists Mike Zeck and Bob McLeod crossed over into \"The Amazing Spider-Man\" #293 and 294. Issue #298 (March 1988) was the first Spider-Man comic to be drawn by future industry star Todd McFarlane, the first regular artist on \"The Amazing Spider-Man\" since Frenz's departure. McFarlane revolutionized Spider-Man's look. His depiction – large-eyed, with wiry, contorted limbs, and messy, knotted, convoluted webbing – influenced the way virtually all subsequent artists would draw the character. McFarlane's other significant contribution to the Spider-Man canon was the design for what would become one of Spider-Man's most wildly popular antagonists, the supervillain Venom. Issue #299 (April 1988) featured Venom's first appearance (a last-page cameo) before his first full appearance in #300 (May 1988). The latter issue featured Spider-Man reverting to his original red-and-blue costume.\n\nOther notable issues of the Michelinie-McFarlane era include #312 (Feb. 1989), featuring the Green Goblin vs. the Hobgoblin; and #315-317 (May–July 1989), with the return of Venom. In July 2012, Todd McFarlane's original cover art for \"The Amazing Spider-Man\" #328 sold for a bid of $657,250, making it the most expensive American comic book art ever sold at auction.\n\nWith a civilian life as a married man, the Spider-Man of the 1990s was different from the superhero of the previous three decades. McFarlane left the title in 1990 to write and draw a new series titled simply \"\". His successor, Erik Larsen, penciled the book from early 1990 to mid-1991. After issue #350, Larsen was succeeded by Mark Bagley, who had won the 1986 Marvel Tryout Contest and was assigned a number of low-profile penciling jobs followed by a run on \"New Warriors\" in 1990. Bagley penciled the flagship Spider-Man title from 1991 to 1996.\n\nIssues #361-363 (April–June 1992) introduced Carnage, a second symbiote nemesis for Spider-Man. The series' 30th-anniversary issue, #365 (Aug. 1992), was a double-sized, hologram-cover issue with the cliffhanger ending of Peter Parker's parents, long thought dead, reappearing alive. It would be close to two years before they were revealed to be impostors, who are killed in #388 (April 1994), scripter Michelinie's last issue. His 1987–1994 stint gave him the second-longest run as writer on the title, behind Stan Lee.\n\nIssue #375 was released with a gold foil cover. There was an error affecting some issues and which are missing the majority of the foil.\n\nWith #389, writer J. M. DeMatteis, whose Spider-Man credits included the 1987 \"Kraven's Last Hunt\" story arc and a 1991–1993 run on \"The Spectacular Spider-Man\", took over the title. From October 1994 to June 1996, \"Amazing\" stopped running stories exclusive to it, and ran installments of multi-part stories that crossed over into all the Spider-Man books. One of the few self-contained stories during this period was in #400 (April 1995), which featured the death of Aunt May — later revealed to have been faked (although the death still stands in the MC2 continuity). The \"Clone Saga\" culminated with the revelation that the Spider-Man who had appeared in the previous 20 years of comics was a clone of the real Spider-Man. This plot twist was massively unpopular with many readers, and was later reversed in the \"Revelations\" story arc that crossed over the Spider-Man books in late 1996.\n\nThe Clone Saga tied into a publishing gap after #406 (Oct. 1995), when the title was temporarily replaced by \"The Amazing Scarlet Spider\" #1-2 (Nov.-Dec. 1995), featuring Ben Reilly. The series picked up again with #407 (Jan. 1996), with Tom DeFalco returning as writer. Bagley completed his 5½-year run by September 1996. A succession of artists, including Ron Garney, Steve Skroce, Joe Bennett, and Rafael Kayanan, penciled the book until the final issue, #441 (Nov. 1998), after which Marvel rebooted the title with vol. 2, #1 (Jan. 1999).\n\nMarvel began \"The Amazing Spider-Man\" anew with vol. 2, #1 (Jan. 1999). Howard Mackie wrote the first 29 issues. The relaunch included the Sandman being regressed to his criminal ways and the \"death\" of Mary Jane, which was ultimately reversed. Other elements included the introduction of a new Spider-Woman (who was spun off into her own short-lived series) and references to John Byrne's \"\", which launched at the same time as the reboot. Mackie's run ended with \"The Amazing Spider-Man Annual 2001\", which saw the return of Mary Jane, who then left Parker upon reuniting with him.\n\nWith #30 (June 2001), J. Michael Straczynski took over as writer and oversaw additional storylines — most notably his lengthy \"Spider-Totem\" arc, which raised the issue of whether Spider-Man's powers were magic-based, rather than as the result of a radioactive spider's bite. Additionally, Straczynski resurrected the plot point of Aunt May discovering her nephew was Spider-Man, and returned Mary Jane, with the couple reuniting in \"The Amazing Spider-Man\" #50. Straczynski gave Spider-Man a new profession, having Parker teach at his former high school.\n\nIssue #30 began a dual numbering system, with the original series numbering (#471) returned and placed alongside the volume-two number on the cover. Other longtime, rebooted Marvel Comics titles, including \"Fantastic Four\", likewise were given the dual numbering around this time. In October 2000, John Romita Jr. succeeded John Byrne as artist. After vol. 2, #58 (Nov. 2003), the title reverted completely to its original numbering for #500 (Dec. 2003). Mike Deodato, Jr. penciled the series from mid-2004 until 2006.\n\nThat year Peter Parker revealed his Spider-Man identity on live television in the company-crossover storyline \"Civil War\", in which the superhero community is split over whether to conform to the federal government's new Superhuman Registration Act. This knowledge was erased from the world with the event of the four-part, crossover story arc, \"\", written partially by J. Michael Straczynski and illustrated by Joe Quesada, running through \"The Amazing Spider-Man\" #544-545 (Nov.-Dec. 2007), \"Friendly Neighborhood Spider-Man\" #24 (Nov. 2007) and \"The Sensational Spider-Man\" #41 (Dec. 2007), the final issues of those two titles. Here, the demon Mephisto makes a Faustian bargain with Parker and Mary Jane, offering to save Parker's dying Aunt May if the couple will allow their marriage to have never existed, rewriting that portion of their pasts. This story arc marked the end of Straczynski's tenure as writer.\n\nFollowing this, Marvel made \"The Amazing Spider-Man\" the company's sole Spider-Man title, increasing its frequency of publication to three issues monthly, and inaugurating the series with a sequence of \"back to basics\" story arcs under the banner of \"\". Parker now exists in a changed world where he and Mary Jane had never married, and Parker has no memory of being married to her, with domino effect differences in their immediate world. The most notable of these revisions to Spider-Man continuity are the return of Harry Osborn, whose death in \"The Spectacular Spider-Man\" #200 (May 1993) is erased; and the reestablishment of Spider-Man's secret identity, with no one except Mary Jane able to recall that Parker is Spider-Man (although he soon reveals his secret identity to the New Avengers and the Fantastic Four). The alternating regular writers were initially Dan Slott, Bob Gale, Marc Guggenheim, Fred Van Lente, and Zeb Wells, joined by a rotation of artists that included Chris Bachalo, Phil Jimenez, Mike McKone, John Romita Jr. and Marcos Martín. Joe Kelly, Mark Waid and Roger Stern later joined the writing team and Barry Kitson the artist roster. Waid's work on the series included a meeting between Spider-Man and Stephen Colbert in \"The Amazing Spider-Man\" #573 (Dec. 2008).\nIssue #583 (March 2009) included a back-up story in which Spider-Man meets President Barack Obama.\n\nMark Waid scripted the opening of \"The Gauntlet\" storyline in issue #612 (Jan. 2010). With issue #648 (Jan. 2011), the series became a twice-monthly title with Dan Slott as sole writer. Eight additional pages were added per issue. This publishing format lasted until issue #700, which concluded the \"Dying Wish\" storyline, in which Parker and Doctor Octopus swapped bodies, and the latter taking on the mantle of Spider-Man when Parker apparently died in Doctor Octopus' body. \"The Amazing Spider-Man\" ended with this issue, with the story continuing in the new series \"The Superior Spider-Man\". In December 2013, the series returned for five issues, numbered 700.1 through 700.5, with the first two written by David Morrell and drawn by Klaus Janson.\n\nIn January 2014, Marvel confirmed that \"The Amazing Spider-Man\" would be relaunched on April 30, 2014, starting from issue #1, with Peter Parker as Spider-Man once again. Issues #1-6 were a story arc called \"Lucky to be Alive\", taking place immediately after \"Goblin Nation\", with issues #4 and #5 being a cross-over with the \"Original Sin\" storyline. Issue #4 introduced Silk, a new heroine, that was bitten by the same spider as Peter Parker. Issues #7-8 featured a team-up between Ms. Marvel and Spider-Man, and had backup stories that tied into Edge of Spider-Verse. The next major plot arc, titled \"Spider-Verse\", began in Issue #9 and ended in #15, features every Spider-Man from across the dimensions being hunted by Morlun, and a team-up to stop him, with Peter Parker of Earth-616 in command of the Spider-Men's Alliance. \"The Amazing Spider-Man Annual\" #1 of the relaunched series, was released in December 2014, featuring stories unrelated to \"Spider-Verse\".\n\nFollowing the 2015 \"Secret Wars\" event, a number of Spider-Man-related titles were either relaunched or created as part of the \"All-New, All-Different Marvel\" event. Among them, \"The Amazing Spider-Man\" was relaunched as well and primarily focuses on Peter Parker continuing to run Parker Industries, and becoming a successful businessman who is operating worldwide. It also tied with \"Civil War II\" (involving an Inhuman who can predict possible future named Ulysses Cain), \"Dead No More\" (where Ben Reilly (the original Scarlet Spider) revealed to be revived and as one of the antagonists instead), and \"Secret Empire\" (during Hydra's reign led by a Hydra influenced Captain America/Steve Rogers, and the dismissal of Parker Industries by Peter Parker/Spider-Man himself).\n\n", "id": "931", "title": "The Amazing Spider-Man"},{"url": "https://en.wikipedia.org/wiki?curid=933", "text": "AM\n\nAM may refer to:\n\n\n\n\n\n\n\n\n\n\n\n", "id": "933", "title": "AM"},{"url": "https://en.wikipedia.org/wiki?curid=951", "text": "Antigua and Barbuda\n\nAntigua and Barbuda (; ;) is a sovereign state in the Americas, lying between the Caribbean Sea and the Atlantic Ocean. It consists of two major inhabited islands, Antigua and Barbuda, and a number of smaller islands (including Great Bird, Green, Guinea, Long, Maiden and York Islands and further south, the island of Redonda). The permanent population numbers about 81,800 (at the 2011 Census) and the capital and largest port and city is St. John's, on Antigua.\n\nSeparated by a few nautical miles, Antigua and Barbuda are in the middle of the Leeward Islands, part of the Lesser Antilles, roughly at 17°N of the equator. The country's name was given by Christopher Columbus in 1493 after discovering the island, in honor of the Virgin of La Antigua in the Seville Cathedral. The country is nicknamed \"Land of 365 Beaches\" due to the many beaches surrounding the islands. Its governance, language, and culture have all been strongly influenced by the British Empire, of which the country was formerly a part.\n\nAntigua is Spanish for \"ancient\" and Barbuda is Spanish for \"bearded\". The island of Antigua, originally called \"Wa'ladli\" by Arawaks, is today called \"Wadadli\" by locals. Caribs possibly called it \"Wa'omoni\". Christopher Columbus, while sailing by in 1493 may have named it Santa Maria la Antigua, after an icon in the Spanish Seville Cathedral.\n\nAntigua was first settled by archaic age hunter-gatherer Amerindians called the Siboney or Ciboney. Carbon dating has established the earliest settlements started around 3100 BC. They were succeeded by the ceramic age pre-Columbian Arawak-speaking Saladoid people who migrated from the lower Orinoco River.\n\nThe Arawaks introduced agriculture, raising, among other crops, the famous Antigua black pineapple (Moris cultivar of \"Ananas comosus\"), corn, sweet potatoes (white with firmer flesh than the bright orange \"sweet potato\" most often used in the United States), chiles, guava, tobacco, and cotton.\n\nThe indigenous West Indians made excellent seagoing vessels which they used to sail around on the Atlantic and the Caribbean. As a result, Caribs and Arawaks were able to colonise much of South America and the Caribbean Islands. Their descendants still live there, notably in Brazil, Venezuela, and Colombia.\n\nMost Arawaks left Antigua around 1100 AD; those who remained were later raided by the Caribs. According to the \"Catholic Encyclopedia\", the Caribs' superior weapons and seafaring prowess allowed them to defeat most of the West Indian Arawak nations, enslaving some and possibly cannibalising others.\nThe \"Catholic Encyclopedia\" makes it clear that the European invaders had difficulty differentiating between the various groups of the native peoples they encountered. As a result, the number and types of ethnic/tribal groups in existence at that time may have been much more varied and numerous than just the two mentioned in this article.\n\nEuropean and African diseases, malnutrition, and slavery eventually killed most of the Caribbean's native population. Smallpox was probably the greatest killer. Some historians believe that the psychological stress of slavery may also have played a part in the massive number of deaths amongst enslaved natives. Others believe the reportedly abundant but starchy, low-protein diet may have contributed to their severe malnutrition as they were used to a diet fortified with protein from the sea.\n\nThe Spaniards did not colonise Antigua because it lacked fresh water but not aggressive Caribs. The English settled on Antigua in 1632; Sir Christopher Codrington settled on Barbuda in 1684. Slavery, established to run sugar plantations around 1684, was abolished in 1834. The British ruled from 1632 to 1981, with a brief French interlude in 1666.\n\nThe islands became an independent state within the Commonwealth of Nations on 1 November 1981, with Elizabeth II as the first Queen of Antigua and Barbuda. The Right Honourable Vere Cornwall Bird Sr became the first Prime Minister.\n\nAntigua and Barbuda both are generally low-lying islands whose terrain has been influenced more by limestone formations than volcanic activity. The highest point on Antigua is Mount Obama (formerly Boggy Peak), the remnant of a volcanic crater rising .\n\nThe shorelines of both islands are greatly indented with beaches, lagoons, and natural harbours. The islands are rimmed by reefs and shoals. There are few streams as rainfall is slight. Both islands lack adequate amounts of fresh groundwater.\n\nAntigua\n\nBarbuda\nRedonda\nRainfall averages per year, with the amount varying widely from season to season. In general the wettest period is between September and November. The islands generally experience low humidity and recurrent droughts. Hurricanes strike on an average of once a year. Temperatures average , with a range from in the winter to in the summer and autumn. The coolest period is between December and February. Its low humidity makes it one of the most temperate climates in the world.\n\nThe sandy soil on much of the islands has only scrub vegetation. Some parts of Antigua are more fertile–most notably the central plain–due to the volcanic ash in the soil. These areas support some tropical vegetation and agricultural uses. The planting of acacia, mahogany, and red and white cedar on Antigua has led to as much as 11% of the land becoming forested, helping to conserve the soil and water.\n\nThe politics of Antigua and Barbuda take place within a framework of a unitary, parliamentary, representative democratic monarchy, in which the Head of State is the Monarch who appoints the Governor General as vice-regal representative. Elizabeth II is the present Queen of Antigua and Barbuda, having served in that position since the islands' independence from the United Kingdom in 1981. The Queen is currently represented by Governor General Sir Rodney Williams. A Council of Ministers is appointed by the Governor General on the advice of the Prime Minister, currently Gaston Browne (2014–). The Prime Minister is the Head of Government.\n\nExecutive power is exercised by the government while legislative power is vested in both the government and the two Chambers of Parliament. The bicameral Parliament consists of the Senate (17 members appointed by members of the government and the opposition party, and approved by the Governor-General), and the House of Representatives (17 members elected by first past the post) to serve five-year terms.\n\nThe current Leader of Her Majesty's Loyal Opposition is the United Progressive Party Member of Parliament (MP), the Honourable Baldwin Spencer.\n\nGaston Browne defeated his predecessor Lester Bryant Bird at the Antigua Labour Party's biennial convention in November 2012 held to elect a political leader and other officers. The party then altered its name from the Antigua Labour Party (ALP) to the Antigua & Barbuda Labour Party (ABLP). This was done to officially include the party's presence on the sister island of Barbuda in its organisation, the only political party on the mainland to have a physical branch in Barbuda.\n\nThe last elections held were on 12 June 2014, during which the Antigua Labour Party won 14 seats, and the United Progressive Party 3 seats.\n\nSince 1949, the party system had been dominated by the populist Antigua Labour Party. However, the Antigua and Barbuda legislative election of 2004 saw the defeat of the longest-serving elected government in the Caribbean. Prime Minister Lester Bryant Bird, who had succeeded his father Vere Cornwall Bird Sr., and Deputy Robin Yearwood had been in office since 1976.\n\nThe elder Bird was Prime Minister from 1981 to 1994 and Chief Minister of Antigua from 1960 to 1981, except for the 1971–1976 period when the Progressive Labour Movement (PLM) defeated his party. Vere Cornwall Bird, the nation's first Prime Minister, is credited with having brought Antigua and Barbuda and the Caribbean into a new era of independence.\n\nThe Judicial branch is the Eastern Caribbean Supreme Court (based in Saint Lucia; one judge of the Supreme Court is a resident of the islands and presides over the High Court of Justice). Antigua is also a member of the Caribbean Court of Justice. The Judicial Committee of the Privy Council serves as its Supreme Court of Appeal.\n\nAntigua and Barbuda is a member of the United Nations, the Bolivarian Alliance for the Americas, the Commonwealth of Nations, the Caribbean Community, the Organization of Eastern Caribbean States, the Organization of American States, the World Trade Organization and the Eastern Caribbean's Regional Security System.\n\nAntigua and Barbuda is also a member of the International Criminal Court (with a Bilateral Immunity Agreement of Protection for the US military as covered under Article 98 of the Rome Statute).\n\nIn 2013, Antigua and Barbuda called for reparations for slavery at the United Nations. Prime Minister Baldwin Spencer said \"We have recently seen a number of leaders apologising\", and that they should now \"match their words with concrete and material benefits\".\n\nThe Royal Antigua and Barbuda Defence Force has around 260 members dispersed between the line infantry regiment, service and support unit and coast guard. There is also the Antigua and Barbuda Cadet Corps made up of 200 teenagers between the ages of 12 to 18.\n\nAntigua and Barbuda is divided into six parishes and two dependencies:\n\nNote: Though Barbuda and Redonda are called dependencies they are integral parts of the state, making them essentially administrative divisions. Dependency is simply a title.\n\nTourism dominates the economy, accounting for more than half of the Gross Domestic Product (GDP). Antigua is famous for its many luxury resorts. Weak tourist activity since early 2000 has slowed the economy, however, and squeezed the government into a tight fiscal corner.\n\nInvestment banking and financial services also make up an important part of the economy. Major world banks with offices in Antigua include the Royal Bank of Canada (RBC) and Scotiabank. Financial-services corporations with offices in Antigua include PriceWaterhouseCoopers. The US Securities and Exchange Commission has accused the Antigua-based Stanford International Bank, owned by Texas billionaire Allen Stanford, of orchestrating a huge fraud which may have bilked investors of some $8 billion. (check status 20100312)\n\nThe twin-island nation's agricultural production is focused on its domestic market and constrained by a limited water supply and a labour shortage stemming from the lure of higher wages in tourism and construction work.\n\nManufacturing is made up of enclave-type assembly for export, the major products being bedding, handicrafts and electronic components. Prospects for economic growth in the medium term will continue to depend on income growth in the industrialised world, especially in the United States, from which about one-third of all tourists come.\n\nFollowing the opening of the American University of Antigua College of Medicine by investor and attorney Neil Simon in 2003, a new source of revenue was established. The university employs many local Antiguans and the approximate 1000 students consume a large amount of the goods and services.\n\nAntigua has a population of 89,090, mostly made up of people of West African, British, and Madeiran descent. The ethnic distribution consists of 91% Black & Mulatto, 4.4% mixed race, 1.7% White, and 2.9% other (primarily East Indian and Asian). Most Whites are of Irish or British descent. Christian Levantine Arabs, and a small number of Asians and Sephardic Jews make up the remainder of the population.\n\nAn increasingly large percentage of the population lives abroad, most notably in the United Kingdom (Antiguan Britons), United States and Canada. A minority of Antiguan residents are immigrants from other countries, particularly from Dominica, Guyana and Jamaica, and, increasing, from the Dominican Republic, St. Vincent and the Grenadines and Nigeria. An estimated 4,500 American citizens also make their home in Antigua and Barbuda, making their numbers one of the largest American populations in the English-speaking Eastern Caribbean.\n\nEnglish is the official language.The Barbudan accent is slightly different from the Antiguan.\n\nIn the years before Antigua and Barbuda's independence, Standard English was widely spoken in preference to Antiguan Creole. Generally, the upper and middle classes shun Antiguan Creole. The educational system dissuades the use of Antiguan Creole and instruction is done in Standard (British) English.\n\nMany of the words used in the Antiguan dialect are derived from British as well as African languages. This can be easily seen in phrases such as: \"Ent it?\" meaning \"Ain't it?\" which is itself dialectal and means \"Isn't it?\". Common island proverbs can often be traced to Africa.\n\nSpanish is spoken by around 10,000 inhabitants.\n\nA majority of 74% of Antiguans are Christians, with the Anglicans (about 44%) being the largest single denomination. Other Christian denominations present are Baptists, Presbyterians and Roman Catholics.\n\nNon-Christian religions practised in the islands include the Rastafari, Islam, Judaism and the Bahá'í Faith.\n\nAntigua & Barbuda has a greater than 90% literacy rate. In 1998, Antigua and Barbuda adopted a national mandate to become the pre-eminent provider of medical services in the Caribbean. As part of this mission, Antigua and Barbuda built the most technologically advanced hospital in the Caribbean, the Mt. St. John Medical Centre. The island of Antigua currently has two foreign-owned for-profit offshore medical schools, the American University of Antigua (AUA), founded in 2004, and The University of Health Sciences Antigua (UHSA), founded in 1982. The island's sole medical schools cater mostly to foreign students but contribute tremendously to the local economy and health care and help give the small country international attention.\n\nThere is also a government owned state college in Antigua as well as the Antigua and Barbuda Institute of Information Technology (ABIIT) and the Antigua and Barbuda Hospitality Training Institute (ABHTI). The University of the West Indies has a branch in Antigua for locals to continue university studies.\n\nAntigua has two international primary/secondary schools Including CCSET International, which offers the Ontario Secondary School Diploma, and Island Academy, which offers the International Baccalaureate. There are also many other private schools but these institutions tend to follow the same local curriculum (CXCs) as government schools. Both international schools are relatively inexperienced with offering international degrees. CCSET international has existed for several years but only began offering an International Degree in 2007. While CCSET's graduating classes have consistently been awarded the OSSD, this is somewhat controversial because CCSET students receive their diplomas from one of CCSET's (constantly changing) partner schools based in Ontario.\n\nThe culture is predominantly a mixture of West African and British cultural influences.\n\nCricket is the national sport and Antigua has produced several famous cricket players including Sir Vivian Richards, Anderson \"Andy\" Roberts, and Richard \"Richie\" Richardson. Other popular sports include football, boat racing and surfing. (Antigua Sailing Week attracts locals and visitors from all over the world).\n\nAmerican popular culture and fashion also have a heavy influence. Most of the country's media is made up of major United States networks. Many Antiguans prefer to make shopping trips to San Juan, Puerto Rico.\n\nFamily and religion play an important roles in the lives of Antiguans. Most attend religious services on Sunday, although there is a growing number of Seventh-day Adventists who observe the Sabbath on Saturday.\n\nCalypso and soca music, both originating primarily out of Trinidad, are important in Antigua and Barbuda.\n\nThe national Carnival held each August commemorates the abolition of slavery in the British West Indies, although on some islands, Carnival may celebrate the coming of Lent. Its festive pageants, shows, contests and other activities are a major tourist attraction.\n\nCorn and sweet potatoes play an important role in Antiguan cuisine. For example, a popular Antiguan dish, Dukuna is a sweet, steamed dumpling made from grated sweet potatoes, flour and spices. One of the Antiguan staple foods, fungi , is a cooked paste made of cornmeal and water.\n\nThere are two daily newspapers: the \"Daily Observer\" and \"Caribbean Times\". Besides most American television networks, the local channel ABS TV 10 is available (it is the only station which shows exclusively local programs). There are also several local and regional radio stations, such as V2C-AM 620, ZDK-AM 1100, VYBZ-FM 92.9, ZDK-FM 97.1, Observer Radio 91.1 FM, DNECA Radio 90.1 FM, Second Advent Radio 101.5 FM, Abundant Life Radio 103.9 FM, Crusader Radio 107.3 FM, Nice FM 104.3\n\nThe Antigua and Barbuda national cricket team represented the country at the 1998 Commonwealth Games, but Antiguan cricketers otherwise play for the Leeward Islands cricket team in domestic matches and the West Indies cricket team internationally. The 2007 Cricket World Cup was hosted in the West Indies from 11 March to 28 April 2007.\n\nAntigua hosted eight matches at the Sir Vivian Richards Stadium, which was completed on 11 February 2007 and can hold up to 20,000 people.\nAntigua is a Host of Stanford Twenty20 – Twenty20 Cricket, a version started by Allen Stanford in 2006 as a regional cricket game with almost all Caribbean islands taking part. Antiguan Viv Richards scored the fastest Test Century and Brian Lara twice scored the World Test Record at the Antigua Recreation Ground.\n\nRugby and netball are popular as well.\n\nAssociation football, or soccer, is also a very popular sport. Antigua has a national football team which entered World Cup qualification for the 1974 tournament and for 1986 and onwards. A professional team was formed in 2011, Antigua Barracuda FC, which played in the USL Pro, a lower professional league in the USA. The nation's team had a major achievement in 2012, getting out of its preliminary group for the 2014 World Cup, notably due to a victory over powerful Haiti. In its first game in the next CONCACAF group play on 8 June 2012 in Tampa, FL, Antigua and Barbuda, comprising 17 Barracuda players and 7 from the lower English professional leagues, scored a goal against the United States, authored by Peter Byers; however, the team lost 3:1 to the US.\n\nAthletics are popular. Talented athletes are trained from a young age, and Antigua and Barbuda has produced a few fairly adept athletes. Janill Williams, a young athlete with much promise comes from Gray's Farm, Antigua. Sonia Williams and Heather Samuel represented Antigua and Barbuda at the Olympic Games. Other prominent rising stars include Brendan Christian (100 m, 200 m), Daniel Bailey (100 m, 200 m) and James Grayman (high jump).\n\n\n", "id": "951", "title": "Antigua and Barbuda"},{"url": "https://en.wikipedia.org/wiki?curid=953", "text": "Azincourt\n\nAzincourt (; historically, Agincourt in English) is a commune in the Pas-de-Calais department in northern France.\n\nIt is named after the Battle of Agincourt of 1415 which took place here.\n\nSituated north-west of Saint-Pol-sur-Ternoise on the D71 road between Hesdin and Fruges\n\nThe toponym is attested as \"Aisincurt\" in 1175, derived from a Germanic masculine name Aizo, Aizino and the early Northern French word \"curt\" 'farm with a courtyard' (Late Latin \"cortem\"). It has no etymological connection in French with Agincourt, Meurthe-et-Moselle (attested as \"Egincourt\" 875), which is derived from another Germanic male name \"*Ingin-\".\nThe battle was named after a nearby castle called Azincourt. The modern settlement has in turn been named after the battle in the 17th century.\n\nAzincourt is famous as being near the site of the battle fought on 25 October 1415 in which the army led by King Henry V of England defeated the forces led by Charles d'Albret on behalf of Charles VI of France, which has gone down in English history as the Battle of Agincourt. According to M. Forrest, the French knights were so encumbered by their armour that they were exhausted even before the start of the battle.\n\nLater on, when he became king in 1509, Henry VIII is supposed to have commissioned an English translation of a Life of Henry V so that he could emulate him, on the grounds that he thought that launching a campaign against France would help him to impose himself on the European stage. In 1513, Henry VIII conclusively crossed the English Channel and stopped at Azincourt. \nThe battle, as was the tradition, was named after a nearby castle called Azincourt. The castle has since disappeared and the settlement now known as Azincourt adopted the name in the seventeenth century.\nJohn Cassell wrote in 1857 that \"the village of Azincourt itself is a group of dirty farmhouses and wretched cottages, but where the hottest of the battle raged, between that village and the commune of Tramecourt, there still remains a wood precisely corresponding with the one in which Henry placed his ambush; and there are yet existing the foundations of the castle of Azincourt, from which the king named the field.\"\n\nThe original battlefield museum in the village featured model knights made out of Action Man figures. However, this has now been replaced by the Centre Historique Medieval (CHM) a more professional museum, conference centre and exhibition space incorporating laser, video, slide shows, audio commentaries, and some interactive elements. The museum building is shaped like a longbow similar to those used at the battle by archers under King Henry.\n\nSince 2004 a large medieval festival organised by the local community, the CHM, The Azincourt Alliance, and various other UK societies commemorating the battle, local history and medieval life, arts and crafts has been held in the village, on a July. Prior to this date the festival was held in October, but due to the inclement weather and local heavy clay soil (like the battle) making the festival difficult it was moved to July. No festival will be held in 2014, with a number of events planned for 2015 on the 600th anniversary of the original battle.\nAzincourt is twinned with:\n\n\n\n", "id": "953", "title": "Azincourt"},{"url": "https://en.wikipedia.org/wiki?curid=954", "text": "Albert Speer\n\nBerthold Konrad Hermann Albert Speer (; March 19, 1905 – September 1, 1981) was a German architect who was, for most of World War II, Reich Minister of Armaments and War Production for Nazi Germany. Speer was Adolf Hitler's chief architect before assuming ministerial office. As \"the Nazi who said sorry\", he accepted moral responsibility at the Nuremberg trials and in his memoirs for complicity in crimes of the Nazi regime, while insisting he had been ignorant of the Holocaust.\n\nSpeer joined the Nazi Party in 1931, launching himself on a political and governmental career which lasted fourteen years. His architectural skills made him increasingly prominent within the Party and he became a member of Hitler's inner circle. Hitler instructed him to design and construct structures including the Reich Chancellery and the \"Zeppelinfeld\" stadium in Nuremberg where Party rallies were held. Speer also made plans to reconstruct Berlin on a grand scale, with huge buildings, wide boulevards, and a reorganized transportation system.\n\nIn February 1942, Hitler appointed Speer Reich Minister of Armaments and War Production. He was fêted at the time, and long afterwards, for performing an \"armaments miracle\" in which German war production dramatically increased; this \"miracle\", however, was brought to a halt by the summer of 1943 by, among other factors, the first sustained Allied bombing of 1943.\n\nAfter the war, he was tried at Nuremberg and sentenced to 20 years in prison for his role in the Nazi regime, principally for the use of forced labor. Despite repeated attempts to gain early release, he served his full sentence, most of it at Spandau Prison in West Berlin. Following his release in 1966, Speer published two bestselling autobiographical works, \"Inside the Third Reich\" and \"\", detailing his close personal relationship with Hitler, and providing readers and historians with a unique perspective on the workings of the Nazi regime. He later wrote a third book, \"Infiltration\", about the SS. Speer died of a stroke in 1981 while on a visit to London.\n\nSpeer was born in Mannheim, into an upper-middle-class family. He was the second of three sons of Luise Máthilde Wilhelmine (Hommel) and Albert Friedrich Speer. In 1918, the family moved permanently to their summer home Villa Speer on Schloss-Wolfsbrunnenweg, Heidelberg. According to Henry T. King, deputy prosecutor at Nuremberg who later wrote a book about Speer, \"Love and warmth were lacking in the household of Speer's youth.\" Speer was active in sports, taking up skiing and mountaineering. Speer's Heidelberg school offered rugby football, unusual for Germany, and Speer was a participant. He wanted to become a mathematician, but his father said if Speer chose this occupation he would \"lead a life without money, without a position and without a future\". Instead, Speer followed in the footsteps of his father and grandfather and studied architecture.\n\nSpeer began his architectural studies at the University of Karlsruhe instead of a more highly acclaimed institution because the hyperinflation crisis of 1923 limited his parents' income. In 1924 when the crisis had abated, he transferred to the \"much more reputable\" Technical University of Munich. In 1925 he transferred again, this time to the Technical University of Berlin where he studied under Heinrich Tessenow, whom Speer greatly admired. After passing his exams in 1927, Speer became Tessenow's assistant, a high honor for a man of 22. As such, Speer taught some of Tessenow's classes while continuing his own postgraduate studies. In Munich, and continuing in Berlin, Speer began a close friendship, ultimately spanning over 50 years, with Rudolf Wolters, who also studied under Tessenow.\n\nIn mid-1922, Speer began courting Margarete (Margret) Weber (1905–1987), the daughter of a successful craftsman who employed 50 workers. The relationship was frowned upon by Speer's class-conscious mother, who felt that the Webers were socially inferior. Despite this opposition, the two married in Berlin on August 28, 1928; seven years were to elapse before Margarete Speer was invited to stay at her in-laws' home.\n\nSpeer stated he was apolitical when he was a young man, and that he attended a Berlin Nazi rally in December 1930 at the urging of some of his students. On March 1, 1931, he applied to join the Nazi Party and became member number 474,481.\n\nIn 1931, Speer surrendered his position as Tessenow's assistant and moved to Mannheim. His father gave him a job as manager of the elder Speer's properties. In July 1932, the Speers visited Berlin to help out the Party prior to the \"Reichstag\" elections. While they were there, his friend, Nazi Party official Karl Hanke, recommended the young architect to Joseph Goebbels to help renovate the Party's Berlin headquarters. Speer agreed to do the work. When the commission was completed, Speer returned to Mannheim and remained there as Hitler took office in January 1933.\n\nThe organizers of the 1933 Nuremberg Rally asked Speer to submit designs for the rally, bringing him into contact with Hitler for the first time. Neither the organizers nor Rudolf Hess were willing to decide whether to approve the plans, and Hess sent Speer to Hitler's Munich apartment to seek his approval. This work won Speer his first national post, as Nazi Party \"Commissioner for the Artistic and Technical Presentation of Party Rallies and Demonstrations\".\n\nShortly after Hitler had come into power, he had started to make plans to rebuild the chancellery. At the end of 1933 he contracted Paul Troost to renovate the entire building. Hitler appointed Speer, whose work for Goebbels had impressed him, to manage the building site for Troost. As Chancellor, Hitler had a residence in the building and came by every day to be briefed by Speer and the building supervisor on the progress of the renovations. After one of these briefings, Hitler invited Speer to lunch, to the architect's great excitement. Hitler evinced considerable interest in Speer during the luncheon, and later told Speer that he had been looking for a young architect capable of carrying out his architectural dreams for the new Germany. Speer quickly became part of Hitler's inner circle; he was expected to call on Hitler in the morning for a walk or chat, to provide consultation on architectural matters, and to discuss Hitler's ideas. Most days he was invited to dinner.\n\nThe two men found much in common: Hitler spoke of Speer as a \"kindred spirit\" for whom he had always maintained \"the warmest human feelings\". The young, ambitious architect was dazzled by his rapid rise and close proximity to Hitler, which guaranteed him a flood of commissions from the government and from the highest ranks of the Party. Speer testified at Nuremberg, \"I belonged to a circle which consisted of other artists and his personal staff. If Hitler had had any friends at all, I certainly would have been one of his close friends.\"\n\nWhen Troost died on January 21, 1934, Speer effectively replaced him as the Party's chief architect. Hitler appointed Speer as head of the Chief Office for Construction, which placed him nominally on Hess's staff.\n\nOne of Speer's first commissions after Troost's death was the \"Zeppelinfeld\" stadium—the Nürnberg parade grounds seen in Leni Riefenstahl's propaganda masterpiece \"Triumph of the Will\". This huge work was able to hold 340,000 people. Speer insisted that as many events as possible be held at night, both to give greater prominence to his lighting effects and to hide the individual Nazis, many of whom were overweight. Speer surrounded the site with 130 anti-aircraft searchlights. Speer described this as his most beautiful work, and as the only one that stood the test of time.\n\nNürnberg was to be the site of many more official Nazi buildings, most of which were never built; for example, the German Stadium would have accommodated 400,000 spectators, while an even larger rally ground would have held half a million people. While planning these structures, Speer conceived the concept of \"ruin value\": that major buildings should be constructed in such a way they would leave aesthetically pleasing ruins for thousands of years into the future. Such ruins would be a testament to the greatness of Nazi Germany, just as ancient Greek or Roman ruins were symbols of the greatness of those civilizations.\n\nWhen Hitler deprecated Werner March's design for the for the 1936 Summer Olympics as too modern, Speer modified the plans by adding a stone exterior. Speer designed the German Pavilion for the 1937 international exposition in Paris. The German and Soviet pavilion sites were opposite each other. On learning (through a clandestine look at the Soviet plans) that the Soviet design included two colossal figures seemingly about to overrun the German site, Speer modified his design to include a cubic mass which would check their advance, with a huge eagle on top looking down on the Soviet figures. Speer received, from Hitler Youth leader and later fellow Spandau prisoner Baldur von Schirach, the Golden Hitler Youth Honor Badge with oak leaves.\n\nIn 1937, Hitler appointed Speer as with the rank of undersecretary of state in the Reich government. The position carried with it extraordinary powers over the Berlin city government and made Speer answerable to Hitler alone. It also made Speer a member of the \"Reichstag\", though the body by then had little effective power. Hitler ordered Speer to develop plans to rebuild Berlin. The plans centered on a three-mile long grand boulevard running from north to south, which Speer called the \"Prachtstrasse\", or Street of Magnificence; he also referred to it as the \"North-South Axis\". At the northern end of the boulevard, Speer planned to build the \"Volkshalle\", a huge assembly hall with a dome which would have been over high, with floor space for 180,000 people. At the southern end of the avenue a great triumphal arch would rise; it would be almost high, and able to fit the Arc de Triomphe inside its opening. The outbreak of World War II in 1939 led to the postponement, and later the abandonment, of these plans. Part of the land for the boulevard was to be obtained by consolidating Berlin's railway system. Speer hired Wolters as part of his design team, with special responsibility for the \"Prachtstrasse\". When Speer's father saw the model for the new Berlin, he said to his son, \"You've all gone completely insane.\"\n\nAll the while plans to build a new Reich chancellery had been underway since 1934. Land had been purchased by the end of 1934 and starting in March 1936 the first buildings were demolished to create space at Voßstraße. Speer was involved virtually from the beginning. He had been commissioned to renovate the Borsig Palace on the corner of Voßstraße and Wilhelmstraße as a headquarter for the SA, who were about to be relocated from Munich to Berlin in the aftermath of the Röhm purge. and completed the preliminary work for the new chancellery by May 1936. In June 1936 he charged a personal honorarium of 30,000 Reichsmark and estimated that the chancellery would be completed within three to four years. Detailed plans were completed in July 1937 and the first shell of the new chancellery was complete on 1 January 1938. On 27 January 1938 Speer received plenipotentiary powers from Hitler to finish the new chancellery by 1 January 1939. Yet for propagandistic reasons, to prove the vigor and organizational skills of National Socialism, Hitler claimed during the topping-out ceremony on 2 August 1938 that he had ordered Speer to build the new chancellery just that year. Speer reiterated this claim in his memoirs to show that he had been up to that supposed challenge, and some of his biographers, most notably Joachim Fest, have followed that account. The building itself, hailed by Hitler as the \"crowning glory of the greater German political empire\", was designed as a theatrical set for representation, \"to intimidate and humiliate\", as historian Martin Kitchen puts it. Because of shortages of labor, the construction workers had to work in two ten- to twelve-hour shifts to have the chancellery completed by early January 1939.\n\nDuring the war the chancellery was destroyed, except for the exterior walls, by air raids and in the Battle of Berlin in 1945. It was eventually dismantled by the Soviets and rumors have it, that the remains have been used for other building projects like the Humboldt University, Mohrenstraße metro station or Soviet war memorials in Berlin, but none of these are true.\n\nDuring the Chancellery project, the pogrom of Kristallnacht took place. Speer made no mention of it in the first draft of \"Inside the Third Reich\", and it was only on the urgent advice of his publisher that he added a mention of seeing the ruins of the Central Synagogue in Berlin from his car.\n\nSpeer was under significant psychological pressure during this period of his life. He would later remember:\n\nSpeer supported the German invasion of Poland and subsequent war, though he recognized that it would lead to the postponement, at the least, of his architectural dreams. In his later years, Speer, talking with his biographer-to-be Gitta Sereny, explained how he felt in 1939: \"Of course I was perfectly aware that [Hitler] sought world domination ...<nowiki>[A]</nowiki>t that time I asked for nothing better. That was the whole point of my buildings. They would have looked grotesque if Hitler had sat still in Germany. All I \"wanted\" was for this great man to dominate the globe.\"\n\nSpeer placed his department at the disposal of the \"Wehrmacht\". When Hitler remonstrated, and said it was not for Speer to decide how his workers should be used, Speer simply ignored him. Among Speer's innovations were quick-reaction squads to construct roads or clear away debris; before long, these units would be used to clear bomb sites. As the war progressed, initially to great German success, Speer continued preliminary work on the Berlin and Nürnberg plans. Speer also oversaw the construction of buildings for the \"Wehrmacht\" and \"Luftwaffe\".\n\nIn 1940, Joseph Stalin proposed that Speer pay a visit to Moscow. Stalin had been particularly impressed by Speer's work in Paris, and wished to meet the \"Architect of the Reich\". Hitler, alternating between amusement and anger, did not allow Speer to go, fearing that Stalin would put Speer in a \"rat hole\" until a new Moscow arose. When Germany invaded the Soviet Union in 1941, Speer came to doubt, despite Hitler's reassurances, that his projects for Berlin would ever be completed.\n\nOn February 8, 1942, Minister of Armaments Fritz Todt died in a plane crash shortly after taking off from Hitler's eastern headquarters at Rastenburg. Speer, who had arrived in Rastenburg the previous evening, had accepted Todt's offer to fly with him to Berlin, but had canceled some hours before takeoff (Speer stated in his memoirs that the cancellation was because of exhaustion from travel and a late-night meeting with Hitler). Later that day, Hitler appointed Speer as Todt's successor to all of his posts. In \"Inside the Third Reich\", Speer recounts his meeting with Hitler and his reluctance to take ministerial office, saying that he only did so because Hitler commanded it. Speer also states that Hermann Göring raced to Hitler's headquarters on hearing of Todt's death, hoping to claim Todt's powers. Hitler instead presented Göring with the \"fait accompli\" of Speer's appointment.\n\nAt the time of Speer's accession to the office, the German economy, unlike the British one, was not fully geared for war production. Consumer goods were still being produced at nearly as high a level as during peacetime. No fewer than five \"Supreme Authorities\" had jurisdiction over armament production—one of which, the Ministry of Economic Affairs, had declared in November 1941 that conditions did not permit an increase in armament production. Few women were employed in the factories, which were running only one shift. One evening soon after his appointment, Speer went to visit a Berlin armament factory; he found no one on the premises.\n\nSpeer overcame these difficulties by centralizing power over the war economy in himself. Factories were given autonomy, or as Speer put it, \"self-responsibility\", and each factory concentrated on a single product. Backed by Hitler's strong support (the dictator stated, \"Speer, I'll sign anything that comes from you\"), he divided the armament field according to weapon system, with experts rather than civil servants overseeing each department. No department head could be older than 55—anyone older being susceptible to \"routine and arrogance\"—and no deputy older than 40. Over these departments was a central planning committee headed by Speer, which took increasing responsibility for war production, and as time went by, for the German economy itself. According to the minutes of a conference at \"Wehrmacht\" High Command in March 1942, \"It is only Speer's word that counts nowadays. He can interfere in all departments. Already he overrides all departments ... On the whole, Speer's attitude is to the point.\" Goebbels would note in his diary in June 1943, \"Speer is still tops with the \"Führer\". He is truly a genius with organization.\" Speer was so successful in his position that by late 1943, he was widely regarded among the Nazi elite as a possible successor to Hitler.\nWhile Speer had tremendous power, he was of course subordinate to Hitler. Nazi officials sometimes went around Speer by seeking direct orders from the dictator. When Speer ordered peacetime building work suspended, the \"Gauleiters\" (Nazi Party district leaders) obtained an exemption for their pet projects. When Speer sought the appointment of Hanke as a labor czar to optimize the use of German labor, Hitler, under the influence of Martin Bormann, instead appointed Fritz Sauckel. Rather than increasing female labor and taking other steps to better organize German labor, as Speer favored, Sauckel advocated importing labor from the occupied nations – and did so, obtaining workers for (among other things) Speer's armament factories, often using the most brutal methods.\n\nOn December 10, 1943, Speer visited the underground Mittelwerk V-2 rocket factory that used concentration camp labor. Speer later said he had been shocked by the conditions there (5.7 percent of the work force died that month).\n\nBy 1943, the Allies had gained air superiority over Germany, and bombings of German cities and industry had become commonplace. However, the Allies in their strategic bombing campaign did not concentrate on industry, and Speer, with his improvisational skill, was able to overcome bombing losses. In spite of these losses, German production of tanks more than doubled in 1943, production of planes increased by 80 percent, and production time for \"Kriegsmarine\" submarines was reduced from one year to two months. Production would continue to increase until the second half of 1944, by which time enough equipment to supply 270 army divisions was being produced—although the \"Wehrmacht\" had only 150 divisions in the field.\n\nIn January 1944, Speer fell ill with complications from an inflamed knee, necessitating a leave. According to Speer's post-war memoirs, his political rivals (mainly Göring and Martin Bormann), attempted to have some of his powers permanently transferred to them during his absence. Speer claimed that SS chief Heinrich Himmler tried to have him physically isolated by having Himmler's personal physician Karl Gebhardt treat him, though his \"care\" did not improve his health. Speer's case was transferred to his friend Dr. Karl Brandt, and he slowly recovered.\nIn response to the Allied air raids that crippled aircraft production, Adolf Hitler authorised the creation of a Jägerstab, a governmental task force composed of Reich Aviation Ministry, Armaments Ministry and SS personnel. Its aim was to ensure the preservation and growth of fighter aircraft production. The task force was established by the 1 March 1944 order of Speer, with support from Erhard Milch of the Reich Aviation Ministry. Speer and Milch played a key role in directing the activities of the agency, while the day-to-day operations were handled by Chief of Staff Karl Saur, the head of the Technical Office in the Armaments Ministry.\n\nIn April, Speer's rivals for power succeeded in having him deprived of responsibility for construction. Speer sent Hitler a bitter letter, concluding with an offer of his resignation. Judging Speer indispensable to the war effort, Field Marshal Erhard Milch persuaded Hitler to try to get his minister to reconsider. Hitler sent Milch to Speer with a message not addressing the dispute but instead stating that he still regarded Speer as highly as ever. According to Milch, upon hearing the message, Speer burst out, \"The \"Führer\" can kiss my ass!\" After a lengthy argument, Milch persuaded Speer to withdraw his offer of resignation, on the condition his powers were restored. On April 23, 1944, Speer went to see Hitler who agreed that \"everything [will] stay as it was, [Speer will] remain the head of all German construction\". According to Speer, while he was successful in this debate, Hitler had also won, \"because he wanted and needed me back in his corner, and he got me\".\n\nThe Jägerstab was given extraordinary powers over labour, production and transportation resources, with its functions taking priority over housing repairs for bombed out civilians or restoration of vital city services. The factories that came under the Jägerstab program saw their work-weeks extended to 72 hours. At the same time, Milch took steps to rationalise production by reducing the number of variants of each type of aircraft produced.\nThe Jägerstab was instrumental in bringing about the increased exploitation of slave labour for the benefit of Germany's war industry and its air force, the Luftwaffe. The task force immediately began implementing plans to expand the use of slave labour in the aviation manufacturing. Records show that SS provided 64,000 prisoners for 20 separate projects at the peak of Jägerstab's construction activities. Taking into account the high mortality rate associated with the underground construction projects, the historian Marc Buggeln estimates that the workforce involved amounted to 80,000−90,000 inmates. They belonged to the various sub-camps of Mittelbau-Dora, Mauthausen-Gusen, Buchenwald and other camps. The prisoners worked for Junkers, Messerschmitt, Henschel and BMW, among others.\n\nThe cooperation between the Reich Ministry of Aviation, the Ministry of Armaments and the SS proved especially productive. Although intended to function for only six months, already in late May Speer and Milch discussed with Goring the possibility of centralising all of Germany's arms manufacturing under a similar task force. On 1 August 1944, Speer reorganised the Jägerstab into the Rüstungsstab (Armament Staff) to apply the same model of operation to all top-priority armament programs.\n\nThe formation of the Rüstungsstab allowed Speer, for the first time, to consolidate key arms manufacturing projects for the three branches of the Wehrmacht under the authority of his ministry, further marginalising the Reich Ministry of Aviation. Several departments, including the once powerful Technical Office, were disbanded or transferred to the new task force. The task force oversaw the day-to-day development and production activities relating to the He 162, the \"Volksjäger\" (\"people's fighter\"), as part of the Emergency Fighter Program.\n\nThe Rüstungsstab assumed responsibilities for the underground transfer projects of the Jägerstab. In November 1944, 1.8 million square meters of underground space were ready for occupancy, encompassing over 1,000 spaces commissioned by the task force. (Post-war, Speer sought to downplay his involvement with these projects and claimed that only 300,000 square meters had been completed). According Buggeln, the Rüstungsstab played a key role in maintaining and increasing production of fighter aircraft and V-2 rockets.\n\nSpeer's name was included on the list of members of a post-Hitler government drawn up by the conspirators behind the July 1944 assassination plot to kill Hitler. The list had a question mark and the annotation \"to be won over\" by his name, which likely saved him from the extensive purges that followed the scheme's failure.\n\nWhen Speer learned in February 1945 that the Red Army had overrun the Silesian industrial region, he drafted a memo to Hitler noting that Silesia's coal mines now supplied 60 percent of the Reich's coal. Without them, Speer wrote, Germany's coal production would only be a quarter of its 1944 total—not nearly enough to continue the war. He told Hitler in no uncertain terms that without Silesia, \"the war is lost.\" Hitler merely filed the memo in his safe.\n\nBy February 1945, Speer was working to supply areas about to be occupied with food and materials to get them through the hard times ahead. On March 19, 1945, Hitler issued his Nero Decree, ordering a scorched earth policy in both Germany and the occupied territories. Hitler's order, by its terms, deprived Speer of any power to interfere with the decree, and Speer went to confront Hitler, reiterating that the war was lost. Hitler gave Speer 24 hours to reconsider his position, and when the two met the following day, Speer answered, \"I stand unconditionally behind you.\" However, he demanded the exclusive power to implement the Nero Decree, and Hitler signed an order to that effect. Using this order, Speer worked to persuade generals and \"Gauleiters\" to circumvent the Nero Decree and avoid needless sacrifice of personnel and destruction of industry that would be needed after the war.\n\nSpeer managed to reach a relatively safe area near Hamburg as the Nazi regime finally collapsed, but decided on a final, risky visit to Berlin to see Hitler one more time. Speer stated at Nuremberg, \"I felt that it was my duty not to run away like a coward, but to stand up to him again.\" Speer visited the \"Führerbunker\" on April 22. Hitler seemed calm and somewhat distracted, and the two had a long, disjointed conversation in which the dictator defended his actions and informed Speer of his intent to commit suicide and have his body burned. In the published edition of \"Inside the Third Reich\", Speer relates that he confessed to Hitler that he had defied the Nero Decree, but then assured Hitler of his personal loyalty, bringing tears to the dictator's eyes. Speer biographer Gitta Sereny argued, \"Psychologically, it is possible that this is the way he remembered the occasion, because it was how he would have liked to behave, and the way he would have liked Hitler to react. But the fact is that none of it happened; our witness to this is Speer himself.\" Sereny notes that Speer's original draft of his memoirs lacks the confession and Hitler's tearful reaction, and contains an explicit denial that any confession or emotional exchange took place, as had been alleged in a French magazine article.\n\nThe following morning, Speer left the \"Führerbunker\"; Hitler curtly bade him farewell. Speer toured the damaged Chancellery one last time before leaving Berlin to return to Hamburg. On April 29, the day before committing suicide, Hitler dictated a final political testament which dropped Speer from the successor government. Speer was to be replaced by his own subordinate, Karl-Otto Saur.\n\nAfter Hitler's death, Speer offered his services to the so-called Flensburg Government, headed by Hitler's successor, Karl Dönitz, and took a significant role in that short-lived regime. On May 15, an allied delegation arrived and asked Speer if he would be willing to provide information on the effects of the air war. Speer agreed, and over the next several days, provided information on a broad range of subjects. On May 23, two weeks after the surrender of German forces, British troops arrested the members of the Flensburg Government and brought Nazi Germany to a formal end.\n\nSpeer was taken to several internment centres for Nazi officials and interrogated. In September 1945, he was told that he would be tried for war crimes, and several days later, he was taken to Nuremberg and incarcerated there. Speer was indicted on all four possible counts: first, participating in a common plan or conspiracy for the accomplishment of crime against peace; second, planning, initiating and waging wars of aggression and other crimes against peace; third, war crimes; and lastly, crimes against humanity.\n\nU.S. Supreme Court Justice Robert Jackson, the chief U.S. prosecutor at Nuremberg, alleged, \"Speer joined in planning and executing the program to dragoon prisoners of war and foreign workers into German war industries, which waxed in output while the workers waned in starvation.\" Speer's attorney, Dr. Hans Flächsner, presented Speer as an artist thrust into political life, who had always remained a non-ideologue and who had been promised by Hitler that he could return to architecture after the war. During his testimony, Speer accepted responsibility for the Nazi regime's actions.\n\nAn observer at the trial, journalist and author William L. Shirer, wrote that, compared to his codefendants, Speer \"made the most straightforward impression of all and ... during the long trial spoke honestly and with no attempt to shirk his responsibility and his guilt\". Speer claimed that he had planned to kill Hitler in early 1945 by introducing tabun poison gas into the \"Führerbunker\" ventilation shaft. He said his efforts were frustrated by the impracticability of tabun and his lack of ready access to a replacement nerve agent, and also by the unexpected construction of a tall chimney that put the air intake out of reach. Speer stated his motive was despair at realising that Hitler intended to take the German people down with him. Speer's supposed assassination plan subsequently met with some skepticism, with Speer's architectural rival Hermann Giesler sneering, \"the second most powerful man in the state did not have a ladder.\"\n\nSpeer was found guilty of war crimes and crimes against humanity, though he was acquitted on the other two counts. His claim that he was unaware of Nazi extermination plans, which probably saved him from hanging, was finally revealed to be false in a private correspondence written in 1971 and publicly disclosed in 2007. On 1 October 1946, he was sentenced to 20 years' imprisonment. While three of the eight judges (two Soviet and one American) initially advocated the death penalty for Speer, the other judges did not, and a compromise sentence was reached \"after two days' discussion and some rather bitter horse-trading\".\n\nThe court's judgment stated that:\n\nOn July 18, 1947, Speer and his six fellow prisoners, all former high officials of the Nazi regime, were flown from Nuremberg to Berlin under heavy guard. The prisoners were taken to Spandau Prison in the British Sector of what would become West Berlin, where they would be designated by number, with Speer given Number Five. Initially, the prisoners were kept in solitary confinement for all but half an hour a day, and were not permitted to address each other or their guards. As time passed, the strict regimen was relaxed, especially during the three months in four that the three Western powers were in control; the four occupying powers took overall control on a monthly rotation. Speer considered himself an outcast among his fellow prisoners for his acceptance of responsibility at Nuremberg.\n\nSpeer made a deliberate effort to make as productive a use of his time as possible. He wrote, \"I am obsessed with the idea of using this time of confinement for writing a book of major importance ... That could mean transforming prison cell into scholar's den.\" The prisoners were forbidden to write memoirs, and mail was severely limited and censored. However, as a result of an offer from a sympathetic orderly, Speer was able to have his writings, which eventually amounted to 20,000 sheets, sent to Wolters. By 1954, Speer had completed his memoirs, which became the basis of \"Inside the Third Reich\", and which Wolters arranged to have transcribed onto 1,100 typewritten pages. He was also able to send letters and financial instructions, and to obtain writing paper and letters from the outside. His many letters to his children, all secretly transmitted, eventually formed the basis for \"Spandau: The Secret Diaries\".\n\nWith the draft memoir complete and clandestinely transmitted, Speer sought a new project. He found one while taking his daily exercise, walking in circles around the prison yard. Measuring the path's distance carefully, Speer set out to walk the distance from Berlin to Heidelberg. He then expanded his idea into a worldwide journey, visualizing the places he was \"traveling\" through while walking the path around the prison yard. Speer ordered guidebooks and other materials about the nations through which he imagined he was passing, so as to envisage as accurate a picture as possible. Meticulously calculating every meter traveled, and mapping distances to the real-world geography, he began in northern Germany, passed through Asia by a southern route before entering Siberia, then crossed the Bering Strait and continued southwards, finally ending his sentence south of Guadalajara, Mexico.\n\nSpeer devoted much of his time and energy to reading. Though the prisoners brought some books with them in their personal property, Spandau Prison had no library so books were sent from Spandau's municipal library. From 1952 the prisoners were also able to order books from the Berlin central library in Wilmersdorf. Speer was a voracious reader and he completed well over 500 books in the first three years at Spandau alone. He read classic novels, travelogues, books on ancient Egypt, and biographies of such figures as Lucas Cranach, Édouard Manet, and Genghis Khan. Speer took to the prison garden for enjoyment and work, at first to do something constructive while afflicted with writer's block. He was allowed to build an ambitious garden, transforming what he initially described as a \"wilderness\" into what the American commander at Spandau described as \"Speer's Garden of Eden\".\n\nSpeer's supporters maintained a continual call for his release. Among those who pledged support for Speer's sentence to be commuted were Charles de Gaulle, U.S. diplomat George Ball, former U.S. High Commissioner John J. McCloy, and former Nuremberg prosecutor Hartley Shawcross. Willy Brandt was a strong advocate of Speer's, supporting his release, sending flowers to his daughter on the day of his release, and putting an end to the de-Nazification proceedings against Speer, which could have caused his property to be confiscated. A reduced sentence required the consent of all four of the occupying powers, and the Soviets adamantly opposed any such proposal. Speer served his full sentence, and was released at midnight on October 1, 1966.\n\nSpeer's release from prison was a worldwide media event, as reporters and photographers crowded both the street outside Spandau and the lobby of the Berlin hotel where Speer spent his first hours of freedom in over 20 years. He said little, reserving most comments for a major interview published in \"Der Spiegel\" in November 1966, in which he again took personal responsibility for crimes of the Nazi regime. Abandoning plans to return to architecture (two proposed partners died shortly before his release), he revised his Spandau writings into two autobiographical books, and later researched and published a third work, about Himmler and the SS. His books, most notably \"Inside the Third Reich\" (in German, \"Erinnerungen\", or \"Reminiscences\") and \"Spandau: The Secret Diaries\", provide a unique and personal look into the personalities of the Nazi era, and have become much valued by historians. Speer was aided in shaping the works by Joachim Fest and Wolf Jobst Siedler from the publishing house Ullstein. Speer found himself unable to re-establish his relationship with his children, even with his son Albert, who had also become an architect. According to Speer's daughter Hilde, \"One by one my sister and brothers gave up. There was no communication.\"\n\nFollowing the publication of his bestselling books, Speer donated a considerable amount of money to Jewish charities. According to Siedler, these donations were as high as 80% of his royalties. Speer kept the donations anonymous, both for fear of rejection, and for fear of being called a hypocrite.\n\nAs early as 1953, when Wolters strongly objected to Speer referring to Hitler in the memoirs draft as a criminal, Speer had predicted that were the writings to be published, he would lose a \"good many friends\". This came to pass, as following the publication of \"Inside the Third Reich\", close friends, such as Wolters and sculptor Arno Breker, distanced themselves from him. Hans Baur, Hitler's personal pilot, suggested, \"Speer must have taken leave of his senses.\" Wolters wondered that Speer did not now \"walk through life in a hair shirt, distributing his fortune among the victims of National Socialism, forswear all the vanities and pleasures of life and live on locusts and wild honey\".\n\nSpeer made himself widely available to historians and other enquirers. He did an extensive, in-depth interview for the June 1971 issue of \"Playboy\" magazine, in which he stated, \"If I didn't see it, then it was because I didn't want to see it.\" In October 1973, Speer made his first trip to Britain, flying to London under an assumed name to be interviewed by Ludovic Kennedy on the BBC \"Midweek\" programme. Upon arrival, he was detained for almost eight hours at Heathrow Airport when British immigration authorities discovered his true identity. The Home Secretary, Robert Carr, allowed Speer into the country for 48 hours. In the same year he appeared in the television programme \"The World at War\". While in London eight years later to participate in the BBC \"Newsnight\" program, Speer suffered a stroke and died on September 1, 1981. Speer had formed a relationship with an Englishwoman of German origin, and was with her at the time of his death.\n\nEven to the end of his life, Speer continued to question his actions under Hitler. In his final book, \"Infiltration\", he asks, \"What would have happened if Hitler had asked me to make decisions that required the utmost hardness? ... How far would I have gone? ... If I had occupied a different position, to what extent would I have ordered atrocities if Hitler had told me to do so?\" Speer leaves the questions unanswered.\n\nThe view of Speer as an unpolitical \"miracle man\" is challenged by Columbia historian Adam Tooze. In his 2006 book, \"The Wages of Destruction\", Tooze, following Gitta Sereny, argues that Speer's ideological commitment to the Nazi cause was greater than he claimed. Tooze further contends that an insufficiently challenged Speer \"mythology\" (partly fostered by Speer himself through politically motivated, tendentious use of statistics and other propaganda) had led many historians to assign Speer far more credit for the increases in armaments production than was warranted and give insufficient consideration to the \"highly political\" function of the so-called armaments miracle.\n\nLittle remains of Speer's personal architectural works, other than the plans and photographs. No buildings designed by Speer during the Nazi era are extant in Berlin, other than the \"Schwerbelastungskörper\" (heavy load bearing body), built around 1941. The high concrete cylinder was used to measure ground subsidence as part of feasibility studies for a massive triumphal arch and other large structures proposed as part of \"Welthauptstadt Germania\", Hitler's planned postwar renewal project for the city. The cylinder is now a protected landmark and is open to the public. Along the Strasse des 17. Juni, a double row of lampposts designed by Speer still stands. The tribune of the \"Zeppelinfeld\" stadium in Nuremberg, though partly demolished, can also be seen.\n\nMore of Speer's own personal work can be found in London, where he redesigned the interior of the German Embassy to the United Kingdom, then located at 7–9 Carlton House Terrace. Since 1967, it has served as the offices of the Royal Society. His work there, stripped of its Nazi fixtures and partially covered by carpets, survives in part.\n\nAnother legacy was the \"Arbeitsstab Wiederaufbau zerstörter Städte\" (Working group on Reconstruction of destroyed cities), authorized by Speer in 1943 to rebuild bombed German cities to make them more livable in the age of the automobile. Headed by Wolters, the working group took a possible military defeat into their calculations. The \"Arbeitsstab\"'s recommendations served as the basis of the postwar redevelopment plans in many cities, and \"Arbeitsstab\" members became prominent in the rebuilding.\n\nAs General Building Inspector, Speer was responsible for the Central Department for Resettlement. From 1939 onward, the Department used the Nuremberg Laws to evict Jewish tenants of non-Jewish landlords in Berlin, to make way for non-Jewish tenants displaced by redevelopment or bombing. Eventually, 75,000 Jews were displaced by these measures. Speer was aware of these activities, and inquired as to their progress. At least one original memo from Speer so inquiring still exists, as does the \"Chronicle\" of the Department's activities, kept by Wolters.\n\nFollowing his release from Spandau, Speer presented to the German Federal Archives an edited version of the \"Chronicle\", stripped by Wolters of any mention of the Jews. When David Irving discovered discrepancies between the edited \"Chronicle\" and other documents, Wolters explained the situation to Speer, who responded by suggesting to Wolters that the relevant pages of the original \"Chronicle\" should \"cease to exist\". Wolters did not destroy the \"Chronicle\", and, as his friendship with Speer deteriorated, allowed access to the original \"Chronicle\" to doctoral student (who, after obtaining his doctorate, developed his thesis into a book, \"Albert Speer: The End of a Myth\"). Speer considered Wolters' actions to be a \"betrayal\" and a \"stab in the back\". The original \"Chronicle\" reached the Archives in 1983, after both Speer and Wolters had died.\n\nSpeer maintained at Nuremberg and in his memoirs that he had no knowledge of the Holocaust. In \"Inside the Third Reich\", he wrote that in mid-1944, he was told by Hanke (by then \"Gauleiter\" of Lower Silesia) that the minister should never accept an invitation to inspect a concentration camp in neighbouring Upper Silesia, as \"he had seen something there which he was not permitted to describe and moreover could not describe\". Speer later concluded that Hanke must have been speaking of Auschwitz and blamed himself for not inquiring further of Hanke or seeking information from Himmler or Hitler:\n\nMuch of the controversy over Speer's knowledge of the Holocaust has centered on his presence at the Posen Conference on October 6, 1943, at which Himmler gave a speech detailing the ongoing Holocaust to Nazi leaders. Himmler said, \"The grave decision had to be taken to cause this people to vanish from the earth ... In the lands we occupy, the Jewish question will be dealt with by the end of the year.\" Speer is mentioned several times in the speech, and Himmler seems to address him directly. In \"Inside the Third Reich\", Speer mentions his own address to the officials (which took place earlier in the day) but does not mention Himmler's speech.\n\nIn October 1971, American historian Erich Goldhagen published an article arguing that Speer was present for Himmler's speech. According to Fest in his biography of Speer, \"Goldhagen's accusation certainly would have been more convincing\" had he not placed supposed incriminating statements linking Speer with the Holocaust in quotation marks, attributed to Himmler, which were in fact invented by Goldhagen. In response, after considerable research in the German Federal Archives in Koblenz, Speer said he had left Posen around noon (long before Himmler's speech) to journey to Hitler's headquarters at Rastenburg. In \"Inside the Third Reich\", published before the Goldhagen article, Speer recalled that on the evening after the conference, many Nazi officials were so drunk that they needed help boarding the special train which was to take them to a meeting with Hitler. One of his biographers, Dan van der Vat, suggests this necessarily implies he must have still been present at Posen then and must have heard Himmler's speech. In response to Goldhagen's article, Speer had alleged that in writing \"Inside the Third Reich\", he erred in reporting an incident that happened at another conference at Posen a year later, as happening in 1943. In 2007, \"The Guardian\" reported that a letter from Speer dated December 23, 1971, had been found in Britain in a collection of his correspondence to Hélène Jeanty, widow of a Belgian resistance fighter. In the letter, Speer states that he had been present for Himmler's presentation in Posen. Speer wrote: \"There is no doubt – I was present as Himmler announced on October 6, 1943, that all Jews would be killed.\"\n\nIn 2005, the \"Daily Telegraph\" reported that documents had surfaced indicating that Speer had approved the allocation of materials for the expansion of Auschwitz after two of his assistants toured the facility on a day when almost a thousand Jews were killed. The documents bore annotations in Speer's own handwriting. Speer biographer Gitta Sereny stated that, due to his workload, Speer would not have been personally aware of such activities.\n\nThe debate over Speer's knowledge of, or complicity in, the Holocaust made him a symbol for people who were involved with the Nazi regime yet did not have (or claimed not to have had) an active part in the regime's atrocities. As film director Heinrich Breloer remarked, \"[Speer created] a market for people who said, 'Believe me, I didn't know anything about [the Holocaust]. Just look at the \"Führer's\" friend, he didn't know about it either.\n\nJoined NSDAP: March 1, 1931\nParty Number: 474,481\n\n\nFrom 1934 to 1939, Speer was often referred to as \"First Architect of the Reich\", however this was mainly a title given to him by Hitler and not an actual political position within the Nazi Party or German government.\n\n\nAlbert Speer held the following Nazi Party political ranks.\n\n\nAlbert Speer held the following Nazi Party political awards.\n\n\n\n\n\n\n", "id": "954", "title": "Albert Speer"},{"url": "https://en.wikipedia.org/wiki?curid=956", "text": "Asteraceae\n\nAsteraceae or Compositae (commonly referred to as the aster, daisy, composite, or sunflower family) is a very large and widespread family of flowering plants (Angiospermae).\n\nThe family currently has 32,913 accepted species names, in 1,911 genera (list) and 13 subfamilies. In terms of numbers of species, the Asteraceae are rivaled only by the Orchidaceae. (Which of the two families is actually larger is unclear, owing to uncertainty about exactly how many species exist in each family.) Many members have composite flowers in the form of flower heads (capitula or pseudanthia) surrounded by involucral bracts. When viewed from a distance, each capitulum may have the appearance of being a single flower. The name Asteraceae comes from the type genus \"Aster\", from the Greek ἀστήρ, meaning star, and refers to the star-like form of the inflorescence. Compositae is an older (but still valid) name which refers to the fact that the family is one of the few angiosperm families to have composite flowers.\n\nMost members of Asteraceae are herbaceous, but a significant number are also shrubs, vines, or trees. The family has a worldwide distribution, from the polar regions to the tropics, colonizing a wide variety of habitats. It is most common in the arid and semiarid regions of subtropical and lower temperate latitudes. The Asteraceae may represent as much as 10% of autochthonous flora in many regions of the world.\n\nAsteraceae is an economically important family, providing products such as cooking oils, lettuce, sunflower seeds, artichokes, sweetening agents, coffee substitutes and herbal teas. Several genera are of horticultural importance, including pot marigold, \"Calendula officinalis\", \"Echinacea\" (cone flowers), various daisies, fleabane, chrysanthemums, dahlias, zinnias, and heleniums. Asteraceae are important in herbal medicine, including \"Grindelia\", yarrow, and many others. A number of species are considered invasive, including, most notably in North America, dandelion, which was originally introduced by European settlers who used the young leaves as a salad green.\n\nThe study of this family is known as synantherology.\n\nThe name Asteraceae () comes to international scientific vocabulary from New Latin, from \"Aster\", the type genus, + \"-aceae\", a standardized suffix for plant family names in modern taxonomy. The genus name comes from the Classical Latin word \"aster\", \"star\", which came from Ancient Greek ἀστήρ (astḗr), \"star\".\n\nCompositae (an alternate name) means \"composite\" and refers to the characteristic inflorescence, a special type of pseudanthium found in only a few other angiosperm families.\n\nThe vernacular name \"daisy\", widely applied to members of this family, is derived from the Old English name of daisy (\"Bellis perennis\"): \"dægesege\", from \"dæges eage\", meaning \"day's eye\". This is because the petals open at dawn and close at dusk.\n\nAsteraceae species have a cosmopolitan distribution, and are found everywhere except Antarctica and the extreme Arctic. They are especially numerous in tropical and subtropical regions (notably Central America, eastern Brazil, the Mediterranean, the Levant part of the Middle East, southern Africa, central Asia, and southwestern China).\n\nCompositae, the original name for Asteraceae, were first described in 1792 by the German botanist Paul Dietrich Giseke. Traditionally, two subfamilies were recognised: Asteroideae (or Tubuliflorae) and Cichorioideae (or Liguliflorae). The latter has been shown to be extensively paraphyletic, and has now been divided into 12 subfamilies, but the former still stands. The phylogenetic tree presented below is based on Panero & Funk (2002) updated in 2014, and now also includes the monotypic Famatinanthoideae.\nThe diamond denotes a very poorly supported node (<50% bootstrap support), the dot a poorly supported node (<80%).\n\nIt is noteworthy that the four subfamilies Asteroideae, Cichorioideae, Carduoideae and Mutisioideae contain 99% of the species diversity of the whole family (approximately 70%, 14%, 11% and 3% respectively).\n\nBecause of the morphological complexity exhibited by this family, agreeing on generic circumscriptions has often been difficult for taxonomists. As a result, several of these genera have required multiple revisions.\n\nMembers of the Asteraceae are mostly herbaceous plants, but some shrubs, trees and climbers do exist. They are generally easy to distinguish from other plants, mainly because of their characteristic inflorescence and other shared characteristics. However, determining genera and species of some groups such as \"Hieracium\" is notoriously difficult (see \"damned yellow composite\" for example).\n\nMembers of the Asteraceae generally produce taproots, but sometimes they possess fibrous root systems. Stems are herbaceous aerial branched cylindrical with glandular hairs generally erect but can be prostrate to ascending. Some species have underground stems in the form of caudices or rhizomes. These can be fleshy or woody depending on the species.\n\nThe leaves and the stems very often contain secretory canals with resin or latex (particularly common among the Cichorioideae). The leaves can be alternate, opposite, or whorled. They may be simple, but are often deeply lobed or otherwise incised, often conduplicate or revolute. The margins can be entire or lobed or toothed.\n\nIn plants of the family Asteraceae, what appears to be a single flower is actually a cluster of much smaller flowers. The overall appearance of the cluster, as a single flower, functions in attracting pollinators in the same way as the structure of an individual flower in some other plant families. The older family name, Compositae, comes from the fact that what appears to be a single flower, is actually a \"composite\" of smaller flowers. The \"petals\" or \"sunrays\" in a sunflower head are actually individual strap-shaped flowers called \"ray flowers\", and the \"sun disk\" is made of smaller circular shaped individual flowers called \"disc flowers\". The word \"aster\" means \"star\" in Greek, referring to the appearance of some family members, as a \"star\" surrounded by \"rays\". The cluster of flowers that may appear to be a single flower, is called a \"head\". The entire head may move tracking the sun, like a \"smart\" solar panel, which maximizes reflectivity of the whole unit and can thereby attract more pollinators.\nAt the base of the head, and surrounding the flowers before opening, is a bundle of sepal-like bracts or scales called \"phyllaries\", which together form the \"involucre\" that protects the individual flowers in the head before opening. The individual heads have the smaller individual flowers arranged on a round or dome-like structure called the \"receptacle\". The flowers mature first at the outside, moving toward the center, with the youngest in the middle.\n\nThe individual flowers in a head have 5 fused petals (rarely 4), but instead of sepals, have threadlike, hairy, or bristly structures called \"pappus\", which surround the fruit and can stick to animal fur or be lifted by wind, aiding in seed dispersal. The whitish fluffy head of a dandelion commonly blown on by children, is made of the pappus, with tiny seeds attached at the ends, whereby the pappus provides a parachute like structure to help the seed be carried away in the wind.\n\nA \"ray flower\" is a 3-tipped (3-lobed), strap-shaped, individual flower in the head of some members of the family Asteraceae. Sometimes a ray flower is 2-tipped (2-lobed). The corolla of the ray flower may have 2 tiny teeth opposite the 3-lobed strap, or tongue, indicating evolution by fusion from an originally 5-part corolla. Sometimes, the 3:2 arrangement is reversed, with 2 tips on the tongue, and 0 or 3 tiny teeth opposite the tongue. A \"ligulate flower\" is a 5-tipped, strap-shaped, individual flower in the heads of other members. A \"ligule\" is the strap-shaped tongue of the corolla of either a ray flower or of a ligulate flower. A \"disk flower\" (or \"disc flower\") is a radially symmetric (i.e., with identical shaped petals arranged in circle around the center) individual flower in the head, which is ringed by ray flowers when both are present. Sometimes ray flowers may be slightly off from radial symmetry, or weakly bilaterally symmetric, as in the case of desert pincushions \"Chaenactis fremontii\".\n\nA \"radiate head\" has disc flowers surrounded by ray flowers. A \"ligulate head\" has all ligulate flowers. When a sunflower family flower head has only disc flowers that are sterile, male, or have both male and female parts, it is a \"discoid head\". \"Disciform heads\" have only disc flowers, but may have two kinds (male flowers and female flowers) in one head, or may have different heads of two kinds (all male, or all female). \"Pistillate heads\" have all female flowers. \"Staminate heads\" have all male flowers.\n\nSometimes, but rarely, the head contains only a single flower, or has a single flowered pistillate (female) head, and a multi-flowered male staminate (male) head.\n\nThe distinguishing characteristic of Asteraceae is their inflorescence, a type of specialised, composite flower head or \"pseudanthium\", technically called a calathium or \"capitulum\", that may look superficially like a single flower. The \"capitulum\" is a contracted raceme composed of numerous individual sessile flowers, called \"florets\", all sharing the same receptacle.\n\nA set of bracts forms an involucre surrounding the base of the capitulum. These are called \"phyllaries\", or \"involucral bracts\". They may simulate the sepals of the pseudanthium. These are mostly herbaceous but can also be brightly coloured (e.g. \"Helichrysum\") or have a scarious (dry and membranous) texture. The phyllaries can be free or fused, and arranged in one to many rows, overlapping like the tiles of a roof (\"imbricate\") or not (this variation is important in identification of tribes and genera).\n\nEach floret may be subtended by a bract, called a \"palea\" or \"receptacular bract\". These bracts are often called \"chaff\". The presence or absence of these bracts, their distribution on the receptacle, and their size and shape are all important diagnostic characteristics for genera and tribes.\n\nThe florets have five petals fused at the base to form a corolla tube and they may be either actinomorphic or zygomorphic. \"Disc florets\" are usually actinomorphic, with five petal lips on the rim of the corolla tube. The petal lips may be either very short, or long, in which case they form deeply lobed petals. The latter is the only kind of floret in the Carduoideae, while the first kind is more widespread. \"Ray florets\" are always highly zygomorphic and are characterised by the presence of a \"ligule\", a strap-shaped structure on the edge of the corolla tube consisting of fused petals. In the Asteroideae and other minor subfamilies these are usually borne only on florets at the circumference of the capitulum and have a 3+2 scheme — above the fused corolla tube, three very long fused petals form the ligule, with the other two petals being inconspicuously small. The Cichorioideae has only ray florets, with a 5+0 scheme — all five petals form the ligule. A 4+1 scheme is found in the Barnadesioideae. The tip of the ligule is often divided into teeth, each one representing a petal. Some marginal florets may have no petals at all (filiform floret).\n\nThe calyx of the florets may be absent, but when present is always modified into a pappus of two or more teeth, scales or bristles and this is often involved in the dispersion of the seeds. As with the bracts, the nature of the pappus is an important diagnostic feature.\n\nThere are usually five stamens. The filaments are fused to the corolla, while the anthers are generally connate (\"syngenesious\" anthers), thus forming a sort of tube around the style (\"theca\"). They commonly have basal and/or apical appendages. Pollen is released inside the tube and is collected around the growing style, and then, as the style elongates, is pushed out of the tube (\"nüdelspritze\").\n\nThe pistil consists of two connate carpels. The style has two lobes. Stigmatic tissue may be located in the interior surface or form two lateral lines. The ovary is inferior and has only one ovule, with basal placentation.\n\nIn members of the Asteraceae the fruit is achene-like, and is called a \"cypsela\" (plural \"cypselae\"). Although there are two fused carpels, there is only one locule, and only one seed per fruit is formed. It may sometimes be winged or spiny because the pappus, which is derived from calyx tissue often remains on the fruit (for example in dandelion). In some species, however, the pappus falls off (for example in \"Helianthus\"). Cypsela morphology is often used to help determine plant relationships at the genus and species level. The mature seeds usually have little endosperm or none.\n\nIn Asteraceae, the energy store is generally in the form of inulin rather than starch. They produce iso/chlorogenic acid, sesquiterpene lactones, pentacyclic triterpene alcohols, various alkaloids, acetylenes (cyclic, aromatic, with vinyl end groups), tannins. They have terpenoid essential oils which never contain iridoids.\n\nThe oldest known fossils of members of Asteraceae are pollen grains from the Late Cretaceous of Antarctica, dated to ∼76–66 Mya (Campanian to Maastrichtian) and assigned to the extant genus \"Dasyphyllum\". Barreda, \"et al.\" (2015) estimated that the crown group of Asteraceae evolved at least 85.9 Mya (Late Cretaceous, Santonian) with a stem node age of 88-89 Mya (Late Cretaceous, Coniacian).\n\nIt is still unknown whether the precise cause of their great success was the development of the highly specialised capitulum, their ability to store energy as fructans (mainly inulin), which is an advantage in relatively dry zones, or some combination of these and possibly other factors.\n\nAsteraceans are especially common in open and dry environments.\n\nMany members of Asteraceae are pollinated by insects, which explains their value in attracting beneficial insects, but anemophyly is also present (e.g. \"Ambrosia\", \"Artemisia\"). There are many apomictic species in the family.\n\nSeeds are ordinarily dispersed intact with the fruiting body, the cypsela. \"Anemochory\" (wind dispersal) is common, assisted by a hairy pappus. \"Epizoochory\" is another common method, in which the dispersal unit, a single cypsela (e.g. \"Bidens\") or entire capitulum (e.g. \"Arctium\") has hooks, spines or some structure to attach to the fur or plumage (or even clothes, as in the photo) of an animal just to fall off later far from its mother plant.\n\nCommercially important plants in Asteraceae include the food crops \"Lactuca sativa\" (lettuce), \"Cichorium\" (chicory), \"Cynara scolymus\" (globe artichoke), \"Helianthus annuus\" (sunflower), \"Smallanthus sonchifolius\" (yacón), \"Carthamus tinctorius\" (safflower) and \"Helianthus tuberosus\" (Jerusalem artichoke). Plants are used as herbs and in herbal teas and other beverages. Chamomile, for example, comes from two different species: the annual \"Matricaria chamomilla\" (German chamomile) and the perennial \"Chamaemelum nobile\" (Roman chamomile). \"Calendula\" (known as pot marigold) is grown commercially for herbal teas and potpourri. Echinacea is used as a medicinal tea. The wormwood genus \"Artemisia\" includes absinthe (\"A. absinthium\") and tarragon (\"A. dracunculus\"). Winter tarragon (\"Tagetes lucida\"), is commonly grown and used as a tarragon substitute in climates where tarragon will not survive.\n\nMany members of the family are grown as ornamental plants for their flowers, and some are important ornamental crops for the cut flower industry. Some examples are \"Chrysanthemum\", \"Gerbera\", \"Calendula\", \"Dendranthema\", \"Argyranthemum\", \"Dahlia\", \"Tagetes\", \"Zinnia\", and many others.\n\nSeveral species of this family possess medicinal properties. These are medically important in areas that don't have access to Western medicine.\n\nMembers of the family are also commonly featured in medical and phytochemical journals because the sesquiterpene lactone compounds contained within them are an important cause of allergic contact dermatitis. Allergy to these compounds is the leading cause of allergic contact dermatitis in florists in the US. Pollen from ragweed \"Ambrosia\" is among the main causes of so-called hay fever in the United States.\n\nAsteraceae are also used for some industrial purposes. Marigold (\"Tagetes patula\") is common in commercial poultry feeds and its oil is extracted for uses in cola and the cigarette industry.\n\nSeveral members of the family are copious nectar producers and are useful for evaluating pollinator populations during their bloom. \"Centaurea\" (knapweed), \"Helianthus annuus\" (domestic sunflower), and some species of \"Solidago\" (goldenrod) are major \"honey plants\" for beekeepers. \"Solidago\" produces relatively high protein pollen, which helps honey bees over winter.\n\nSome members of Asteraceae are economically important as weeds. Notable in the United States are \"Senecio jacobaea\" (ragwort), \"Senecio vulgaris\" (groundsel), and \"Taraxacum\" (dandelion).\n\nThe genera \"Chrysanthemum\", \"Pulicaria\", \"Tagetes\", and \"Tanacetum\" contain species with useful insecticidal properties.\n\n\"Parthenium argentatum\" (guayule) is a source of hypoallergenic latex.\n\n\n", "id": "956", "title": "Asteraceae"},{"url": "https://en.wikipedia.org/wiki?curid=957", "text": "Apiaceae\n\nApiaceae or Umbelliferae, is a family of mostly aromatic flowering plants named after the type genus \"Apium\" and commonly known as the celery, carrot or parsley family. It is the 16th-largest family of flowering plants, with more than 3,700 species in 434 genera including such well-known and economically important plants such as angelica, anise, asafoetida, caraway, carrot, celery, chervil, coriander, cumin, dill, fennel, hemlock, lovage, cow parsley, parsley, parsnip, sea holly, giant hogweed and silphium (a plant whose identity is unclear and which may be extinct).\n\nMost Apiaceae are annual, biennial or perennial herbs (frequently with the leaves aggregated toward the base), though a minority are woody shrubs or small trees such as \"Bupleurum fruticosum\". Their leaves are of variable size and alternately arranged, or with the upper leaves becoming nearly opposite. The leaves may be petiolate or sessile. There are no stipules but the petioles are frequently sheathing and the leaves may be perfoliate. The leaf blade is usually dissected, ternate or pinnatifid, but simple and entire in some genera, e.g. \"Bupleurum\". Commonly, their leaves emit a marked smell when crushed, aromatic to foetid, but absent in some species. \n\nThe defining characteristic of this family is the inflorescence, the flowers nearly always aggregated in terminal umbels, that may be simple or more commonly compound, often umbelliform cymes. The flowers are usually perfect (hermaphroditic) and actinomorphic but there may be zygomorphic petals at the edges of the umbel, as in carrot (\"Daucus carota\"). Some are andromonoecious, polygamomonoecious, or even dioecious (as in \"Acronema\"), with a distinct calyx and corolla, but the calyx is often highly reduced, to the point of being undetectable in many species, while the corolla can be white, yellow, pink or purple. The flowers are nearly perfectly pentamerous, with five petals, sepals, and stamens.\nThe androecium consists of five stamens, but there is often variation in the functionality of the stamens even within a single inflorescence. Some flowers are functionally staminate (where a pistil may be present but has no ovules capable of being fertilized) while others are functionally pistillate (where stamens are present but their anthers do not produce viable pollen). Pollination of one flower by the pollen of a different flower of the same plant (geitonogamy) is common. The gynoecium consists of two carpels fused into a single, bicarpellate pistil with an inferior ovary. Stylopodia support two styles and secrete nectar, attracting pollinators like flies, mosquitoes, gnats, beetles, moths, and bees. The fruit is a schizocarp consisting of two fused carpels that separate at maturity into two mericarps, each containing a single seed. The fruits of many species are dispersed by wind but others such as those of \"Daucus\" spp., are covered in bristles, which may be hooked in sanicle \"Sanicula europaea\" and thus catch in the fur of animals. The seeds have an oily endosperm and often contain essential oils, containing aromatic compounds that are responsible for the flavour of commercially important umbelliferous seed such as anise, cumin and coriander. The shape and details of the ornamentation of the ripe fruits are important for identification to species level.\n\nApiaceae was first described by John Lindley in 1836. The name is derived from the type genus \"Apium\", which was originally used by Pliny the Elder circa 50 AD for a celery-like plant. The alternative name for the family, Umbelliferae, derives from the inflorescence being generally in the form of a compound umbel. The family was one of the first to be recognized as a distinct group in Jacques Daleschamps' 1586 \"Historia generalis plantarum\". With Robert Morison’s 1672 \"Plantarum umbelilliferarum distribution nova\" it became the first group of plants for which a systematic study was published.\n\nThe family is solidly placed within the Apiales order in the APG III classification system. It is closely related to Araliaceae and the boundaries between these families remain unclear. Traditionally groups within the family have been delimited largely based on fruit morphology, and the results from this have not been congruent with the more recent molecular phylogenetic analyses. The subfamilial and tribal classification for the family is currently in a state of flux, with many of the groups being found to be grossly paraphyletic or polyphyletic.\n\nAccording to the Angiosperm Phylogeny Website 434 genera are in the family Apiaceae.\n\nThe black swallowtail butterfly, \"Papilio polyxenes\", uses the Apiaceae family for food and host plants for oviposition.\n\nMany members of this family are cultivated for various purposes. Parsnips (\"Pastinaca sativa\"), carrots (\"Daucus carota\") and Hamburg parsley (\"Petroselinum crispum\"), produce tap roots that are large enough to be useful as food. Many species produce essential oils in their leaves or fruits and as a result are flavourful aromatic herbs. Examples are parsley (\"Petroselinum crispum\"), coriander (\"Coriandrum sativum\"), culantro, and dill (\"Anethum graveolens\"). The seeds may be used in cuisine, as with coriander (\"Coriandrum sativum\"), fennel (\"Foeniculum vulgare\"), cumin (\"Cuminum cyminum\"), and caraway (\"Carum carvi\").\n\nOther notable cultivated Apiaceae include chervil (\"Anthriscus cerefolium\"), angelica (\"Angelica\" spp.), celery (\"Apium graveolens\"), arracacha (\"Arracacia xanthorrhiza\"), sea holly (\"Eryngium\" spp.), asafoetida (\"Ferula asafoetida\"), galbanum (\"Ferula gummosa\"), cicely (\"Myrrhis odorata\"), anise (\"Pimpinella anisum\"), lovage (\"Levisticum officinale\"), and hacquetia (\"Hacquetia epipactis\").\n\nGenerally, all members of this family are best cultivated in the cool-season garden; indeed, they may not grow at all if the soils are too warm. Almost every widely cultivated plant of this group is a considered useful as a companion plant. One reason is because the tiny flowers clustered into umbels, are well suited for ladybugs, parasitic wasps, and predatory flies, which actually drink nectar when not reproducing. They then prey upon insect pests on nearby plants. Some of the members of this family considered \"herbs\" produce scents that are believed to ...mask the odours of nearby plants, thus making them harder for insect pests to find.\n\nThe poisonous members of the Apiaceae have been used for a variety of purposes globally. The poisonous \"Oenanthe crocata\" has been used to stupefy fish, \"Cicuta douglasii\" has been used as an aid in suicides, and arrow poisons have been made from various other family species.\n\n\"Daucus carota\" has been used as coloring for butter.\n\n\"Dorema ammoniacum\", \"Ferula galbaniflua\", and \"Ferula sumbul\" are sources of incense.\n\nThe woody \"Azorella compacta\" Phil. has been used in South America for fuel.\n\nApiaceae vegetables including carrot, celery, fennel, parsley and parsnip, contain polyynes, an unusual class of organic compounds that show cytotoxic activities. Many species contain coumarins or coumarin derivatives, such as furanocoumarins.\n\n\n", "id": "957", "title": "Apiaceae"},{"url": "https://en.wikipedia.org/wiki?curid=958", "text": "Axon\n\nAn axon (from Greek ἄξων \"áxōn\", axis), is a long, slender projection of a nerve cell, or neuron, that typically conducts electrical impulses away from the neuron's cell body. Axons are also known as nerve fibers. The function of the axon is to transmit information to different neurons, muscles and glands. In certain sensory neurons (pseudounipolar neurons), such as those for touch and warmth, the electrical impulse travels along an axon from the periphery to the cell body, and from the cell body to the spinal cord along another branch of the same axon. Axon dysfunction has caused many inherited and acquired neurological disorders which can affect both the peripheral and central neurons. Nerve fibers are classed into three types – A delta fibers, B fibers, and C fibres. A and B are myelinated and C are unmyelinated.\n\nAn axon is one of two types of protoplasmic protrusions from the cell body of a neuron; the other type is a dendrite. Axons are distinguished from dendrites by several features, including shape (dendrites often taper while axons usually maintain a constant radius), length (dendrites are restricted to a small region around the cell body while axons can be much longer), and function (dendrites receive signals whereas axons transmit them). All of these rules have exceptions, however. \nAxons are covered by a membrane known as axolemma; the cytoplasm of axon is called axoplasm.The branched end of an axon is formed by telodendria; the swollen end of a telodendron is known as the axon terminal; which joins the dendron or cell body of another neurone forming a synaptic connection.\n\nSome types of neurons have no axon and transmit signals from their dendrites. No neuron ever has more than one axon; however in invertebrates such as insects or leeches the axon sometimes consists of several regions that function more or less independently of each other. Most axons branch, in some cases very profusely.\n\nAxons make contact with other cells—usually other neurons but sometimes muscle or gland cells—at junctions called synapses. At a synapse, the membrane of the axon closely adjoins the membrane of the target cell, and special molecular structures serve to transmit electrical or electrochemical signals across the gap. Some synaptic junctions appear partway along an axon as it extends—these are called \"en passant\" (\"in passing\") synapses. Other synapses appear as terminals at the ends of axonal branches. A single axon, with all its branches taken together, can innervate multiple parts of the brain and generate thousands of synaptic terminals.\n\nAxons are the primary transmission lines of the nervous system, and as bundles they form nerves. Some axons can extend up to one meter or more while others extend as little as one millimeter. The longest axons in the human body are those of the sciatic nerve, which run from the base of the spinal cord to the big toe of each foot. The diameter of axons is also variable. Most individual axons are microscopic in diameter (typically about one micrometer (µm) across). The largest mammalian axons can reach a diameter of up to 20 µm. The squid giant axon, which is specialized to conduct signals very rapidly, is close to 1 millimetre in diameter, the size of a small pencil lead. Axonal arborization (the branching structure at the end of a nerve fiber) also differs from one nerve fiber to the next. Axons in the central nervous system typically show complex trees with many branch points. In comparison, the cerebellar granule cell axon is characterized by a single T-shaped branch node from which two parallel fibers extend. Elaborate arborization allows for the simultaneous transmission of messages to a large number of target neurons within a single region of the brain.\n\nThere are two types of axons occurring in the peripheral nervous system and the central nervous system: unmyelinated and myelinated axons. Myelin is a layer of a fatty insulating substance, which is formed by two types of glial cells: Schwann cells ensheathing peripheral neurons and oligodendrocytes insulating those of the central nervous system. Along myelinated nerve fibers, gaps in the myelin sheath known as nodes of Ranvier occur at evenly spaced intervals. The myelination enables an especially rapid mode of electrical impulse propagation called saltatory conduction. Demyelination of axons causes the multitude of neurological symptoms found in the disease multiple sclerosis.\n\nIf the brain of a vertebrate is extracted and sliced into thin sections, some parts of each section appear dark and other parts lighter in color. The dark parts are known as grey matter and the lighter parts as white matter. White matter gets its light color from the myelin sheaths of axons: the white matter parts of the brain are characterized by a high density of myelinated axons passing through them, and a low density of cell bodies of neurons. The cerebral cortex has a thick layer of grey matter on the surface and a large volume of white matter underneath: what this means is that most of the surface is filled with neuron cell bodies, whereas much of the area underneath is filled with myelinated axons that connect these neurons to each other.\nThe axon initial segment — the thick, unmyelinated part of an axon that connects directly to the cell body — consists of a specialized complex of proteins. It is approximately 25μm in length and functions as the site of action potential initiation. The density of voltage-gated sodium channels is much higher in the initial segment than in the remainder of the axon or in the adjacent cell body, excepting the axon hillock. The voltage-gated ion channels are known to be found within certain areas of the axonal membrane and initiate action potential, conduction, and synaptic transmission.\n\nNodes of Ranvier (also known as \"myelin sheath gaps\") are short unmyelinated segments of a myelinated axon, which are found periodically interspersed between segments of the myelin sheath. Therefore, at the point of the node of Ranvier, the axon is reduced in diameter. These nodes are areas where action potentials can be generated. In saltatory conduction, electrical currents produced at each node of Ranvier are conducted with little attenuation to the next node in line, where they remain strong enough to generate another action potential. Thus in a myelinated axon, action potentials effectively \"jump\" from node to node, bypassing the myelinated stretches in between, resulting in a propagation speed much faster than even the fastest unmyelinated axon can sustain.\n\nMost axons carry signals in the form of action potentials, which are discrete electrochemical impulses that travel rapidly along an axon, starting at the cell body and terminating at points where the axon makes synaptic contact with target cells. The defining characteristic of an action potential is that it is \"all-or-nothing\" — every action potential that an axon generates has essentially the same size and shape. This all-or-nothing characteristic allows action potentials to be transmitted from one end of a long axon to the other without any reduction in size. There are, however, some types of neurons with short axons that carry graded electrochemical signals, of variable amplitude.\n\nWhen an action potential reaches a presynaptic terminal, it activates the synaptic transmission process. The first step is rapid opening of calcium ion channels in the membrane of the axon, allowing calcium ions to flow inward across the membrane. The resulting increase in intracellular calcium concentration causes vesicles (tiny containers enclosed by a lipid membrane) filled with a neurotransmitter chemical to fuse with the axon's membrane and empty their contents into the extracellular space. The neurotransmitter is released from the presynaptic nerve through exocytosis. The neurotransmitter chemical then diffuses across to receptors located on the membrane of the target cell. The neurotransmitter binds to these receptors and activates them. Depending on the type of receptors that are activated, the effect on the target cell can be to excite the target cell, inhibit it, or alter its metabolism in some way. This entire sequence of events often takes place in less than a thousandth of a second. Afterward, inside the presynaptic terminal, a new set of vesicles is moved into position next to the membrane, ready to be released when the next action potential arrives. The action potential is the final electrical step in the integration of synaptic messages at the scale of the neuron.\n\nExtracellular recordings of action potential propagation in axons has been demonstrated in freely moving animals. While extracellular somatic action potentials have been used to study cellular activity in freely moving animals such as place cells, axonal activity in both white and gray matter can also be recorded. Extracellular recordings of axon action potential propagation is distinct from somatic action potentials in three ways: 1. The signal has a shorter peak-trough duration (~150μs) than of pyramidal cells (~500μs) or interneurons (~250μs). 2. The voltage change is triphasic. 3. Activity recorded on a tetrode is seen on only one of the four recording wires. In recordings from freely moving rats, axonal signals have been isolated in white matter tracts including the alveus and the corpus callosum as well hippocampal gray matter.\n\nIn fact, the generation of action potentials in vivo is sequential in nature, and these sequential spikes constitute the digital codes in the neurons. Although previous studies indicate an axonal origin of a single spike evoked by short-term pulses, physiological signals in vivo trigger the initiation of sequential spikes at the cell bodies of the neurons.\n\nIn addition to propagating action potentials to axonal terminals, the axon is able to amplify the action potentials, which makes sure a secure propagation of sequential action potentials toward the axonal terminal. In terms of molecular mechanisms, voltage-gated sodium channels in the axons possess lower threshold and shorter refractory period in response to short-term pulses.\n\nStudies done on cultured hippocampal neurons suggest that neurons initially produce multiple neurites that are equivalent, yet only one of these neurites is destined to become the axon. It is unclear whether axon specification precedes axon elongation or vice versa, although recent evidence points to the latter. If an axon that is not fully developed is cut, the polarity can change and other neurites can potentially become the axon. This alteration of polarity only occurs when the axon is cut at least 10 μm shorter than the other neurites. After the incision is made, the longest neurite will become the future axon and all the other neurites, including the original axon, will turn into dendrites. Imposing an external force on a neurite, causing it to elongate, will make it become an axon. Nonetheless, axonal development is achieved through a complex interplay between extracellular signaling, intracellular signaling and cytoskeletal dynamics.\n\nThe extracellular signals that propagate through the extracellular matrix surrounding neurons play a prominent role in axonal development. These signaling molecules include proteins, neurotrophic factors, and extracellular matrix and adhesion molecules. \nUNC-6 or netrin, a secreted protein, functions in axon formation. When the UNC-6 receptor is mutated, several neurites are irregularly projected out of neurons and finally a single axon is extended anteriorly. The neurotrophic factors nerve growth factor (NGF), brain-derived neurotrophic factor (BDNF) and neurotrophin 3 (NT3) are also involved in axon development and bind to Trk receptors.\n\nThe ganglioside-converting enzyme plasma membrane ganglioside sialidase (PMGS), which is involved in the activation of TrkA at the tip of neutrites, is required for the elongation of axons. PMGS asymmetrically distributes to the tip of the neurite that is destined to become the future axon.\n\nDuring axonal development, the activity of PI3K is increased at the tip of destined axon. Disrupting the activity of PI3K inhibits axonal development. Activation of PI3K results in the production of phosphatidylinositol (3,4,5)-trisphosphate (PtdIns) which can cause significant elongation of a neurite, converting it into an axon. As such, the overexpression of phosphatases that dephosphorylate PtdIns leads into the failure of polarization.\n\nThe neurite with the lowest actin filament content will become the axon. PGMS concentration and f-actin content are inversely correlated; when PGMS becomes enriched at the tip of a neurite, its f-actin content is substantially decreased. In addition, exposure to actin-depolimerizing drugs and toxin B (which inactivates Rho-signaling) causes the formation of multiple axons. Consequently, the interruption of the actin network in a growth cone will promote its neurite to become the axon.\n\nGrowing axons move through their environment via the growth cone, which is at the tip of the axon. The growth cone has a broad sheet like extension called lamellipodia which contain protrusions called filopodia. The filopodia are the mechanism by which the entire process adheres to surfaces and explores the surrounding environment. Actin plays a major role in the mobility of this system.\nEnvironments with high levels of cell adhesion molecules (CAMs) create an ideal environment for axonal growth. This seems to provide a \"sticky\" surface for axons to grow along. Examples of CAM's specific to neural systems include N-CAM, neuroglial CAM or NgCAM, TAG-1, and MAG all of which are part of the immunoglobulin superfamily. Another set of molecules called extracellular matrix adhesion molecules also provide a sticky substrate for axons to grow along. Examples of these molecules include laminin, fibronectin, tenascin, and perlecan. Some of these are surface bound to cells and thus act as short range attractants or repellents. Others are difusible ligands and thus can have long range effects.\n\nCells called guidepost cells assist in the guidance of neuronal axon growth. These cells are typically other, sometimes immature, neurons.\n\nIt has also been discovered through research that if the axons of a neuron were damaged, as long as the soma (the cell body of a neuron) is not damaged, the axons would regenerate and remake the synaptic connections with neurons with the help of guidepost cells. This is also referred to as neuroregeneration.\n\nNogo-A is a type of neurite growth inhibitory component that is present in the central nervous system myelin membranes (found in an axon). It has a crucial role in restricting axonal regeneration in adult mammalian central nervous system. In recent studies, if Nogo- A is blocked and neutralized, it is possible to induce long-distance axonal regeneration which leads to enhancement of functional recovery in rats and mouse spinal cord. This has yet to be done on humans. A recent study has also found that macrophages activated through a specific inflammatory pathway activated by the Dectin-1 receptor are capable of promoting axon recovery, also however causing neurotoxicity in the neuron.\n\nGerman anatomist Otto Friedrich Karl Deiters is generally credited with the discovery of the axon by distinguishing it from the dendrites. Swiss Rüdolf Albert von Kölliker and German Robert Remak were the first to identify and characterize the axon initial segment. Kölliker named the axon in 1896. Alan Hodgkin and Andrew Huxley also employed the squid giant axon (1939) and by 1952 they had obtained a full quantitative description of the ionic basis of the action potential, leading to the formulation of the Hodgkin–Huxley model. Hodgkin and Huxley were awarded jointly the Nobel Prize for this work in 1963. The formulas detailing axonal conductance were extended to vertebrates in the Frankenhaeuser–Huxley equations. Louis-Antoine Ranvier was the first to describe the gaps or nodes found on axons and for this contribution these axonal features are now commonly referred to as the nodes of Ranvier. Santiago Ramón y Cajal, a Spanish anatomist, proposed that axons were the output components of neurons, describing their functionality. Erlanger and Gasser earlier developed the classification system for peripheral nerve fibers, based on axonal conduction velocity, myelination, fiber size etc.\nEven recently our understanding of the biochemical basis for action potential propagation has advanced, and now includes many details about individual ion channels.\n\nThe longfin inshore squid has been used as a model organism – it has the longest known axon.\n\nIn order of degree of severity, injury to a nerve can be described as neurapraxia, axonotmesis, or neurotmesis.\nConcussion is considered a mild form of diffuse axonal injury. The dysfunction of axons in the nervous system is one of the major causes of many inherited neurological disorders that affect both peripheral and central neurons.\n\nThe axons that make up nerves in the human peripheral nervous system can be classified based on their physical features and signal conduction properties.\n\nLower motor neurons have two kind of fibers:\n\nDifferent sensory receptors are innervated by different types of nerve fibers. Proprioceptors are innervated by type Ia, Ib and II sensory fibers, mechanoreceptors by type II and III sensory fibers and nociceptors and thermoreceptors by type III and IV sensory fibers.\n\nThe autonomic nervous system has two kinds of peripheral fibers:\n\n\n", "id": "958", "title": "Axon"},{"url": "https://en.wikipedia.org/wiki?curid=960", "text": "Aramaic alphabet\n\nThe ancient Aramaic alphabet is adapted from the Phoenician alphabet and became distinctive from it by the 8th century BCE. It was used to write the Aramaic language and had displaced the Paleo-Hebrew alphabet, itself a derivative of the Phoenician alphabet, for the writing of Hebrew. The letters all represent consonants, some of which are also used as \"matres lectionis\" to indicate long vowels.\n\nThe Aramaic alphabet is historically significant since virtually all modern Middle Eastern writing systems can be traced back to it as well as numerous non-Chinese writing systems of Central and East Asia. That is primarily from the widespread usage of the Aramaic language as both a \"lingua franca\" and the official language of the Neo-Assyrian and Neo-Babylonian Empires, and their successor, the Achaemenid Empire. Among the scripts in modern use, the Hebrew alphabet bears the closest relation to the Imperial Aramaic script of the 5th century BC, with an identical letter inventory and, for the most part, nearly identical letter shapes. The Aramaic alphabet was an ancestor to the Nabataean alphabet and the later Arabic alphabet.\n\nWriting systems (like the Aramaic one) that indicate consonants but do not indicate most vowels other than by means of \"matres lectionis\" or added diacritical signs, have been called abjads by Peter T. Daniels to distinguish them from alphabets, such as the Greek alphabet, which represent vowels more systematically. The term was coined to avoid the notion that a writing system that represents sounds must be either a syllabary or an alphabet, which would imply that a system like Aramaic must be either a syllabary (as argued by Ignace Gelb) or an incomplete or deficient alphabet (as most other writers have said). Rather, it is a different type.\n\nThe earliest inscriptions in the Aramaic language use the Phoenician alphabet. Over time, the alphabet developed into the form shown below. Aramaic gradually became the \"lingua franca\" throughout the Middle East, with the script at first complementing and then displacing Assyrian cuneiform, as the predominant writing system.\n\nAround 500 BC, following the Persian Achaemenid conquest of Mesopotamia under Darius I, Old Aramaic was adopted by the Iranians as the \"vehicle for written communication between the different regions of the vast Persian empire with its different peoples and languages. The use of a single official language, which modern scholarship has dubbed as Official Aramaic, Imperial Aramaic or Achaemenid Aramaic, can be assumed to have greatly contributed to the astonishing success of the Achaemenid Persians in holding their far-flung empire together for as long as they did.\"\n\nImperial Aramaic was highly standardised; its orthography was based more on historical roots than any spoken dialect and was inevitably influenced by Old Persian. The Aramaic glyph forms of the period are often divided into two main styles, the \"lapidary\" form, usually inscribed on hard surfaces like stone monuments, and a cursive form whose lapidary form tended to be more conservative by remaining more visually similar to Phoenician and early Aramaic. Both were in use through the Achaemenid Persian period, but the cursive form steadily gained ground over the lapidary, which had largely disappeared by the 3rd century BC.\nFor centuries after the fall of the Achaemenid Empire in 331 BC, Imperial Aramaic, or something near enough to it to be recognisable, would remain an influence on the various native Iranian languages. The Aramaic script would survive as the essential characteristics of the Iranian Pahlavi writing system.\n\nA group of 30 Aramaic documents from Bactria has been recently discovered. An analysis was published in November 2006. The texts, which were rendered on leather, reflect the use of Aramaic in the 4th century BC in the Persian Achaemenid administration of Bactria and Sogdiana.\n\nThe widespread usage of Achaemenid Aramaic in the Middle East led to the gradual adoption of the Aramaic alphabet for writing Hebrew. Formerly, Hebrew had been written using an alphabet closer in form to that of Phoenician, the Paleo-Hebrew alphabet.\n\nSince the evolution of the Aramaic alphabet out of the Phoenician one was a gradual process, the division of the world's alphabets into the ones derived from the Phoenician one directly and the ones derived from Phoenician via Aramaic is somewhat artificial. In general, the alphabets of the Mediterranean region (Anatolia, Greece, Italy) are classified as Phoenician-derived, adapted from around the 8th century BC, and those of the East (the Levant, Persia, Central Asia and India) are considered Aramaic-derived, adapted from around the 6th century BC from the Imperial Aramaic script of the Achaemenid Empire.\n\nAfter the fall of the Achaemenid Empire, the unity of the Imperial Aramaic script was lost, diversifying into a number of descendant cursives.\n\nThe Hebrew and Nabataean alphabets, as they stood by the Roman era, were little changed in style from the Imperial Aramaic alphabet.\n\nA cursive Hebrew variant developed from the early centuries AD, but it remained restricted to the status of a variant used alongside the noncursive. By contrast, the cursive developed out of the Nabataean alphabet in the same period soon became the standard for writing Arabic, evolving into the Arabic alphabet as it stood by the time of the early spread of Islam.\n\nThe development of cursive versions of Aramaic also led to the creation of the Syriac, Palmyrene and Mandaic alphabets, which formed the basis of the historical scripts of Central Asia, such as the Sogdian and Mongolian alphabets.\n\nThe Old Turkic script is generally considered to have its ultimate origins in Aramaic, in particular via the Pahlavi or Sogdian alphabets, as suggested by V. Thomsen, or possibly via Karosthi (\"cf\"., Issyk inscription).\n\nAramaic is also considered to be the most likely source of the Brahmi script, ancestor of the Brahmic family of scripts, which includes Devanagari.\n\nToday, Biblical Aramaic, Jewish Neo-Aramaic dialects and the Aramaic language of the Talmud are written in the Hebrew alphabet. Syriac and Christian Neo-Aramaic dialects are written in the Syriac alphabet. Mandaic is written in the Mandaic alphabet. The near-identity of the Aramaic and the classical Hebrew alphabets caused Aramaic text to be typeset mostly in the standard Hebrew script in scholarly literature.\n\nIn Ma'loula, one of few surviving communities in which a Western Aramaic dialect is still spoken, the Arameans started a programme in 2007 to give their language a written abjad for the Aramaic alphabet. The program ran into trouble in early 2010 as a Syrian newspaper suggested that the alphabet being used to teach written Aramaic bore an uncanny resemblance to the Hebrew characters found in modern Israel. Worried that a flagship heritage scheme might in any way be associated with the country’s neighboring enemy, the government-run University of Damascus, which established the institute, acted quickly to freeze the Aramaic programme. They started to use the Syriac alphabet (serto) instead.\n\nIn Aramaic writing, Waw and Yodh serve a double function. Originally, they represented only the consonants \"w\" and \"y\", but they were later adopted to indicate the long vowels \"ū\" and \"ī\" respectively as well (often also \"ō\" and \"ē\" respectively). In the latter role, they are known as \"matres lectionis\" or \"mothers of reading\".\n\nĀlap, likewise, has some of the characteristics of a \"mater lectionis\" because in initial positions, it indicates a glottal stop (followed by a vowel), but otherwise, it often also stands for the long vowels \"ā\" or \"ē\". Among Jews, the influence of Hebrew often led to the use of Hē instead, at the end of a word.\n\nThe practice of using certain letters to hold vowel values spread to Aramaic-derived writing systems, such as in Arabic and Hebrew, which still follow the practice.\n\nThe Syriac Aramaic alphabet was added to the Unicode Standard in September 1999, with the release of version 3.0.\n\nThe Syriac Abbreviation (a type of overline) can be represented with a special control character called the Syriac Abbreviation Mark (U+070F). The Unicode block for Syriac Aramaic is U+0700–U+074F:\n\nThe Imperial Aramaic alphabet was added to the Unicode Standard in October 2009, with the release of version 5.2.\n\nThe Unicode block for Imperial Aramaic is U+10840–U+1085F:\n\n\n\n", "id": "960", "title": "Aramaic alphabet"},{"url": "https://en.wikipedia.org/wiki?curid=966", "text": "American shot\n\n\"American shot\" is a translation of a phrase from French film criticism, \"\"plan américain\"\" and refers to a medium-long (\"knee\") film shot of a group of characters, who are arranged so that all are visible to the camera. The usual arrangement is for the actors to stand in an irregular line from one side of the screen to the other, with the actors at the end coming forward a little and standing more in profile than the others. The purpose of the composition is to allow complex dialogue scenes to be played out without changes in camera position. In some literature, this is simply referred to as a 3/4 shot.\n\nOne of the other main reasons why French critics called it 'American Shot' was its frequent use in westerns. This was because a shot that started at knee level would reveal the weapon of a cowboy, usually holstered at his waist. It's actually the closest you can get to an actor while keeping both his face and his holstered gun in frame.\n\nThe French critics thought it was characteristic of American films of the 1930s or 1940s; however, it was mostly characteristic of \"cheaper\" American movies, such as Charlie Chan mysteries where people collected in front of a fireplace or at the foot of the stairs in order to explain what happened a few minutes ago.\n\nHoward Hawks legitimized this style in his films, allowing characters to act, even when not talking, when most of the audience would not be paying attention. It became his trademark style.\n", "id": "966", "title": "American shot"},{"url": "https://en.wikipedia.org/wiki?curid=967", "text": "Acute disseminated encephalomyelitis\n\nAcute disseminated encephalomyelitis (ADEM), or acute demyelinating encephalomyelitis, is a rare autoimmune disease marked by a sudden, widespread attack of inflammation in the brain and spinal cord. As well as causing the brain and spinal cord to become inflamed, ADEM also attacks the nerves of the central nervous system and damages their myelin insulation, which, as a result, destroys the white matter. It is often triggered after the patient has received a viral infection or, perhaps exceedingly rarely specific non-routine vaccinations.\n\nADEM's symptoms resemble the symptoms of multiple sclerosis (MS), so the disease itself is sorted into the classification of the multiple sclerosis borderline diseases. However, ADEM has several features that distinguish it from MS. Unlike MS, ADEM occurs usually in children and is marked with rapid fever, although adolescents and adults can get the disease too. ADEM consists of a single flare-up whereas MS is marked with several flare-ups (or relapses), over a long period of time. Relapses following ADEM are reported in up to a quarter of patients, but the majority of these 'multiphasic' presentations following ADEM likely represent MS. ADEM is also distinguished by a loss of consciousness, coma and death, which is very rare in MS, except in severe cases.\n\nThe incidence rate is about 8 per 1,000,000 people per year. Although it occurs in all ages, most reported cases are in children and adolescents, with the average age around 5 to 8 years old. The disease affects males and females almost equally. The mortality rate may be as high as 5%; however, full recovery is seen in 50 to 75% of cases with increase in survival rates up to 70 to 90% with figures including minor residual disability as well. The average time to recover from ADEM flare-ups is one to six months.\n\nADEM produces multiple inflammatory lesions in the brain and spinal cord, particularly in the white matter. Usually these are found in the subcortical and central white matter and cortical gray-white junction of both cerebral hemispheres, cerebellum, brainstem, and spinal cord, but periventricular white matter and gray matter of the cortex, thalami and basal ganglia may also be involved.\n\nWhen the patient suffers more than one demyelinating episode of ADEM, the disease is then called recurrent disseminated encephalomyelitis or multiphasic disseminated encephalomyelitis (MDEM). Also, a fulminant course in adults has been described.\n\nA preceding antigenic challenge can be identified in approximately two-thirds of patients. Viral infections thought to induce ADEM include influenza virus, enterovirus, measles, mumps, rubella, varicella zoster, Epstein Barr virus, cytomegalovirus, herpes simplex virus, hepatitis A, and coxsackievirus; while the bacterial infections include Mycoplasma pneumoniae, Borrelia burgdorferi, Leptospira, and beta-hemolytic Streptococci. The only vaccine proven to induce ADEM is the Semple form of the rabies vaccine, but hepatitis B, pertussis, diphtheria, measles, mumps, rubella, pneumococcus, varicella, influenza, Japanese encephalitis, and polio vaccines have all been implicated. The majority of the studies that correlate vaccination with ADEM onset use small samples or case studies. Large scale epidemiological studies (e.g., of MMR vaccine or smallpox vaccine) do not show increased risk of ADEM following vaccination. In rare cases, ADEM seems to follow from organ transplantation. An upper bound for the risk of ADEM from measles vaccination, if it exists, can be estimated to be 10 per million, which is far lower than the risk of developing ADEM from an actual measles infection, which is about 1 per 1,000 cases. For a rubella infection, the risk is 1 per 5,000 cases. Some early vaccines, later shown to have been contaminated with host animal CNS tissue, had ADEM incident rates as high as 1 in 600.\n\nADEM has an abrupt onset and a monophasic course. Symptoms usually begin 1–3 weeks after infection. Major symptoms include fever, headache, nausea and vomiting, confusion, vision impairment, drowsiness, seizures and coma. Although initially the symptoms are usually mild, they worsen rapidly over the course of hours to days, with the average time to maximum severity being about four and a half days. Additional symptoms include hemiparesis, paraparesis, and cranial nerve palsies.\n\nCurrently, the commonly accepted international standard for the clinical case definition is the one published by the International Pediatric MS Study Group, revision 2007.\n\nNo controlled clinical trials have been conducted on ADEM treatment, but aggressive treatment aimed at rapidly reducing inflammation of the CNS is standard. The widely accepted first-line treatment is high doses of intravenous corticosteroids, such as methylprednisolone or dexamethasone, followed by 3–6 weeks of gradually lower oral doses of prednisolone. Patients treated with methylprednisolone have shown better outcomes than those treated with dexamethasone. Oral tapers of less than three weeks duration show a higher chance of relapsing, and tend to show poorer outcomes. Other anti-inflammatory and immunosuppressive therapies have been reported to show beneficial effect, such as plasmapheresis, high doses of intravenous immunoglobulin (IVIg), mitoxantrone and cyclophosphamide. These are considered alternative therapies, used when corticosteroids cannot be used or fail to show an effect.\n\nThere is some evidence to suggest that patients may respond to a combination of methylprednisolone and immunoglobulins if they fail to respond to either separately\nIn a study of 16 children with ADEM, 10 recovered completely after high-dose methylprednisolone, one severe case that failed to respond to steroids recovered completely after IV Ig; the five most severe cases -with ADAM and severe peripheral neuropathy- were treated with combined high-dose methylprednisolone and immunoglobulin, two remained paraplegic, one had motor and cognitive handicaps, and two recovered. A recent review of IVIg treatment of ADEM (of which the previous study formed the bulk of the cases) found that 70% of children showed complete recovery after treatment with IVIg, or IVIg plus corticosteroids. A study of IVIg treatment in adults with ADEM showed that IVIg seems more effective in treating sensory and motor disturbances, while steroids seem more effective in treating impairments of cognition, consciousness and rigor. This same study found one subject, a 71-year-old man who had not responded to steroids, that responded to an IVIg treatment 58 days after disease onset.\n\nFull recovery is seen in 50 to 70% of cases, ranging to 70 to 90% recovery with some minor residual disability (typically assessed using measures such as mRS or EDSS), average time to recover is one to six months. The mortality rate may be as high as 5%. Poorer outcomes are associated with unresponsiveness to steroid therapy, unusually severe neurological symptoms, or sudden onset. Children tend to have more favorable outcomes than adults, and cases presenting without fevers tend to have poorer outcomes. The latter effect may be due to either protective effects of fever, or that diagnosis and treatment is sought more rapidly when fever is present.\n\nResidual motor deficits are estimated to remain in about 8 to 30% of cases, the range in severity from mild clumsiness to ataxia and hemiparesis.\n\nPatients with demyelinating illnesses, such as MS, have shown cognitive deficits even when there is minimal physical disability. Research suggests that similar effects are seen after ADEM, but that the deficits are less severe than those seen in MS. A study of six children with ADEM (mean age at presentation 7.7 years) were tested for a range of neurocognitive tests after an average of 3.5 years of recovery. All six children performed in the normal range on most tests, including verbal IQ and performance IQ, but performed at least one standard deviation below age norms in at least one cognitive domain, such as complex attention (one child), short-term memory (one child) and internalizing behaviour/affect (two children). Group means for each cognitive domain were all within one standard deviation of age norms, demonstrating that, as a group, they were normal. These deficits were less severe than those seen in similar aged children with a diagnosis of MS.\n\nAnother study compared nineteen children with a history of ADEM, of which 10 were five years of age or younger at the time (average age 3.8 years old, tested an average of 3.9 years later) and nine were older (mean age 7.7y at time of ADEM, tested an average of 2.2 years later) to nineteen matched controls. Scores on IQ tests and educational achievement were lower for the young onset ADEM group (average IQ 90) compared to the late onset (average IQ 100) and control groups (average IQ 106), while the late onset ADEM children scored lower on verbal processing speed. Again, all groups means were within one standard deviation of the controls, meaning that while effects were statistically reliable, the children were as a whole, still within the normal range. There were also more behavioural problems in the early onset group, although there is some suggestion that this may be due, at least in part, to the stress of hospitalization at a young age.\n\nWhile ADEM and MS both involve autoimmune demyelination, they differ in many clinical, genetic, imaging, and histopathological aspects. Some authors consider MS and its borderline forms to constitute a spectrum, differing only in chronicity, severity, and clinical course, while others consider them discretely different diseases.\n\nTypically, ADEM appears in children following an antigenic challenge and remains monophasic. Nevertheless, ADEM does occur in adults, and can also be clinically multiphasic.\n\nProblems for differential diagnosis increase due to the lack of agreement for a definition of multiple sclerosis. If MS were defined just by the separation in time and space of the demyelinating lesions as McDonald did, it would not be enough to make a difference, as some cases of ADEM satisfy these conditions. Therefore, some authors propose to establish the separation line in the shape of the lesions around the veins, being therefore \"perivenous vs. confluent demyelination\".\n\nThe pathology of ADEM is very similar to that of MS with some differences. The pathological hallmark of ADEM is perivenular inflammation with limited \"sleeves of demyelination\". Nevertheless, MS-like plaques (confluent demyelination) can appear\n\nPlaques in the white matter in MS are sharply delineated, while the glial scar in ADEM is smooth. Axons are better preserved in ADEM lesions. Inflammation in ADEM is widely disseminated and ill-defined, and finally, lesions are strictly perivenous, while in MS they are disposed around veins, but not so sharply.\n\nNevertheless, the co-occurrence of perivenous and confluent demyelination in some individuals suggests pathogenic overlap between acute disseminated encephalomyelitis and multiple sclerosis and misclassification even with biopsy or even postmortem ADEM in adults can progress to MS\n\nWhen the patient suffers more than one demyelinating episode of ADEM, the disease is then called recurrent disseminated encephalomyelitis or multiphasic disseminated encephalomyelitis (MDEM).\n\nIt has been found that anti-MOG auto-antibodies are related to this kind of ADEM\n\nAnother variant of ADEM in adults has been described, also related to anti-MOG auto-antibodies, has been named fulminant disseminated encephalomyelitis, and it has been reported to be clinically ADEM, but showing MS-like lesions on autopsy. It has been classified inside the anti-MOG associated inflammatory demyelinating diseases.\n\nAcute hemorrhagic leukoencephalitis (AHL, or AHLE), also known as acute necrotizing encephalopathy (ANE), acute hemorrhagic encephalomyelitis (AHEM), acute necrotizing hemorrhagic leukoencephalitis (ANHLE), Weston-Hurst syndrome, or Hurst's disease, is a hyperacute and frequently fatal form of ADEM. AHL is relatively rare (less than 100 cases have been reported in the medical literature ), it is seen in about 2% of ADEM cases, and is characterized by necrotizing vasculitis of venules and hemorrhage, and edema. Death is common in the first week and overall mortality is about 70%, but increasing evidence points to favorable outcomes after aggressive treatment with corticosteroids, immunoglobulins, cyclophosphamide, and plasma exchange. About 70% of survivors show residual neurological deficits, but some survivors have shown surprisingly little deficit considering the magnitude of the white matter affected.\n\nThis disease has been occasionally associated with ulcerative colitis and Crohn's disease, malaria, septicemia associated with immune complex deposition, methanol poisoning, and other underlying conditions. Also anecdotal association with MS has been reported\n\nExperimental allergic encephalomyelitis (EAE) is an animal model of CNS inflammation and demyelination frequently used to investigate potential MS treatments. An acute monophasic illness, EAE is far more similar to ADEM than MS.\n\n\n", "id": "967", "title": "Acute disseminated encephalomyelitis"},{"url": "https://en.wikipedia.org/wiki?curid=969", "text": "Ataxia\n\nAtaxia is a neurological sign consisting of lack of voluntary coordination of muscle movements that includes gait abnormality. Ataxia is a non-specific clinical manifestation implying dysfunction of the parts of the nervous system that coordinate movement, such as the cerebellum. Ataxia can be limited to one side of the body, which is referred to as hemiataxia. Several possible causes exist for these patterns of neurological dysfunction. Dystaxia is a mild degree of ataxia. Friedreich's ataxia has gait abnormality as the most commonly presented symptom. The word is from Greek \"α-\" [a negative prefix] + \"-τάξις\" [order] = \"lack of order\".\n\nThe term cerebellar ataxia is used to indicate ataxia that is due to dysfunction of the cerebellum. The cerebellum is responsible for integrating a significant amount of neural information that is used to coordinate smoothly ongoing movements and to participate in motor planning. Although ataxia is not present with all cerebellar lesions, many conditions affecting the cerebellum do produce ataxia. People with cerebellar ataxia may have trouble regulating the force, range, direction, velocity and rhythm of muscle contractions. This results in a characteristic type of irregular, uncoordinated movement that can manifest itself in many possible ways, such as asthenia, asynergy, delayed reaction time, and dyschronometria. Individuals with cerebellar ataxia could also display instability of gait, difficulty with eye movements, dysarthria, dysphagia, hypotonia, dysmetria and dysdiadochokinesia. These deficits can vary depending on which cerebellar structures have been damaged, and whether the lesion is bilateral or unilateral.\n\nPeople with cerebellar ataxia may initially present with poor balance, which could be demonstrated as an inability to stand on one leg or perform tandem gait. As the condition progresses, walking is characterized by a widened base and high stepping, as well as staggering and lurching from side to side. Turning is also problematic and could result in falls. As cerebellar ataxia becomes severe, great assistance and effort are needed to stand and walk. Dysarthria, an impairment with articulation, may also be present and is characterized by \"scanning\" speech that consists of slower rate, irregular rhythm and variable volume. There may also be slurring of speech, tremor of the voice and ataxic respiration. Cerebellar ataxia could result with incoordination of movement, particularly in the extremities. There is overshooting (or hypermetria) with finger to nose testing, and heel to shin testing; thus, dysmetria is evident. Impairments with alternating movements (dysdiadochokinesia), as well as dysrhythmia, may also be displayed. There may also be tremor of the head and trunk (titubation) in individuals with cerebellar ataxia.\n\nIt is thought that dysmetria is caused by a deficit in the control of interaction torques in multijoint motion. Interaction torques are created at an associated joint when the primary joint is moved. For example, if a movement required reaching to touch a target in front of the body, flexion at the shoulder would create a torque at the elbow, while extension of the elbow would create a torque at the wrist. These torques increase as the speed of movement increases and must be compensated and adjusted for to create coordinated movement. This may, therefore, explain decreased coordination at higher movement velocities and accelerations.\n\n\nThe term sensory ataxia is employed to indicate ataxia due to loss of proprioception, the loss of sensitivity to the positions of joint and body parts. This is generally caused by dysfunction of the dorsal columns of the spinal cord, because they carry proprioceptive information up to the brain. In some cases, the cause of sensory ataxia may instead be dysfunction of the various parts of the brain which receive positional information, including the cerebellum, thalamus, and parietal lobes.\n\nSensory ataxia presents itself with an unsteady \"stomping\" gait with heavy heel strikes, as well as a postural instability that is usually worsened when the lack of proprioceptive input cannot be compensated for by visual input, such as in poorly lit environments.\n\nPhysicians can find evidence of sensory ataxia during physical examination by having the patient stand with his/her feet together and eyes shut. In affected patients, this will cause the instability to worsen markedly, producing wide oscillations and possibly a fall. This is called a positive Romberg's test. Worsening of the finger-pointing test with the eyes closed is another feature of sensory ataxia. Also, when the patient is standing with arms and hands extended toward the physician, if the eyes are closed, the patient's finger will tend to \"fall down\" and then be restored to the horizontal extended position by sudden muscular contractions (the \"ataxic hand\").\n\nThe term \"vestibular ataxia\" is employed to indicate ataxia due to dysfunction of the vestibular system, which in acute and unilateral cases is associated with prominent vertigo, nausea and vomiting. In slow-onset, chronic bilateral cases of vestibular dysfunction, these characteristic manifestations may be absent, and dysequilibrium may be the sole presentation.\n\nThe three types of ataxia have overlapping causes, and therefore can either coexist or occur in isolation.\n\nAny type of focal lesion of the central nervous system (such as stroke, brain tumor, multiple sclerosis) will cause the type of ataxia corresponding to the site of the lesion: cerebellar if in the cerebellum, sensory if in the dorsal spinal cord (and rarely in the thalamus or parietal lobe), vestibular if in the vestibular system (including the vestibular areas of the cerebral cortex).\n\nExogenous substances that cause ataxia mainly do so because they have a depressant effect on central nervous system function. The most common example is ethanol (alcohol), which is capable of causing reversible cerebellar and vestibular ataxia. Other examples include various prescription drugs (e.g. most antiepileptic drugs have cerebellar ataxia as a possible adverse effect), Lithium level over 1.5mEq/L, synthetic cannabinoid HU-211 ingestion and various other recreational drugs (e.g. ketamine, PCP or dextromethorphan, all of which are NMDA receptor antagonists that produce a dissociative state at high doses). A further class of pharmaceuticals which can cause short term ataxia, especially in high doses are the benzodiazepines. Exposure to high levels of methylmercury, through consumption of fish with high mercury concentrations, is also a known cause of ataxia and other neurological disorders.\n\nAtaxia can be induced as a result of severe acute radiation poisoning with an absorbed dose of more than 30 Grays.\n\nVitamin B deficiency may cause, among several neurological abnormalities, overlapping cerebellar and sensory ataxia.\n\nSymptoms of neurological dysfunction may be the presenting feature in some patients with hypothyroidism. These include reversible cerebellar ataxia, dementia, peripheral neuropathy, psychosis and coma. Most of the neurological complications improve completely after thyroid hormone replacement therapy.\n\nPeripheral neuropathies may cause generalised or localised sensory ataxia (e.g. a limb only) depending on the extent of the neuropathic involvement. Spinal disorders of various types may cause sensory ataxia from the lesioned level below, when they involve the dorsal columns\n\nNon-hereditary causes of cerebellar degeneration include chronic ethanol abuse, head injury, paraneoplastic and non-paraneoplastic autoimmune ataxia, high altitude cerebral oedema, coeliac disease, normal pressure hydrocephalus and infectious or post-infectious cerebellitis.\n\nAtaxia may depend on hereditary disorders consisting of degeneration of the cerebellum and/or of the spine; most cases feature both to some extent, and therefore present with overlapping cerebellar and sensory ataxia, even though one is often more evident than the other. Hereditary disorders causing ataxia include autosomal dominant ones such as spinocerebellar ataxia, episodic ataxia, and dentatorubropallidoluysian atrophy, as well as autosomal recessive disorders such as Friedreich's ataxia (sensory and cerebellar, with the former predominating) and Niemann Pick disease, ataxia-telangiectasia (sensory and cerebellar, with the latter predominating), and abetalipoproteinaemia. An example of X-linked ataxic condition is the rare fragile X-associated tremor/ataxia syndrome.\n\nArnold-Chiari malformation is a malformation of the brain. It consists of a downward displacement of the cerebellar tonsils and the medulla through the foramen magnum, sometimes causing hydrocephalus as a result of obstruction of cerebrospinal fluid outflow.\n\nSuccinic semialdehyde dehydrogenase deficiency is an autosomal-recessive gene disorder where mutations in the ALDH5A1 gene results in the accumulation of gamma-Hydroxybutyric acid (GHB) in the body. GHB accumulates in the nervous system and can cause ataxia as well as other neurological dysfunction.\n\nWilson's disease is an autosomal-recessive gene disorder whereby an alteration of the ATP7B gene results in an inability to properly excrete copper from the body. Copper accumulates in the nervous system and liver and can cause ataxia as well as other neurological and organ impairments.\n\nGluten ataxia is a gluten-related disorder, a wide spectrum of disorders marked by an abnormal immunological response to gluten. Like celiac disease, it is an autoimmune disease. With gluten ataxia, damage takes place in the cerebellum, the balance center of the brain that controls coordination and complex movements like walking, speaking and swallowing. Gluten ataxia is the single most common cause of sporadic idiopathic ataxia.\n\nGluten ataxia is an immune-mediated disease triggered by the ingestion of gluten in genetically susceptible individuals. It should be considered in the differential diagnosis of all patients with idiopathic sporadic ataxia. Early diagnosis and treatment with a gluten free diet can improve ataxia and prevent its progression. Readily available and sensitive markers of gluten ataxia include anti-gliadin antibodies. Immunoglobulin A (IgA) deposits against transglutaminase 2 (TG2) in the small bowel and at extraintestinal sites are proving to be additionally reliable and perhaps more specific markers of the whole spectrum of gluten sensitivity. They may also hold the key to its pathogenesis.\n\nGluten ataxia is defined as sporadic cerebellar ataxia associated with the presence circulating antigliadin antibodies and in the absence of an alternative cause for ataxia.\n\nMalfunction of the sodium-potassium pump may be a factor in some ataxias. The - pump has been shown to control and set the intrinsic activity mode of cerebellar Purkinje neurons. This suggests that the pump might not simply be a homeostatic, \"housekeeping\" molecule for ionic gradients; but could be a computational element in the cerebellum and the brain. Indeed, an ouabain block of - pumps in the cerebellum of a live mouse results in it displaying ataxia and dystonia. Ataxia is observed for lower ouabain concentrations, dystonia is observed at higher ouabain concentrations.\n\nAntibodies against the enzyme glutamic acid decarboxylase (GAD: enzyme changing glutamate in GABA) cause cerebellar deficits. The antibodies impair motor learning and cause behavioral deficits.\n\nThe treatment of ataxia and its effectiveness depend on the underlying cause. Treatment may limit or reduce the effects of ataxia, but it is unlikely to eliminate them entirely. Recovery tends to be better in individuals with a single focal injury (such as stroke or a benign tumour), compared to those who have a neurological degenerative condition. A review of the management of degenerative ataxia was published in 2009. A small number of rare conditions presenting with prominent cerebellar ataxia are amenable to specific treatment and recognition of these disorders is critical. Diseases include vitamin E deficiency, abetalipoproteinemia, cerebrotendinous xanthomatosis, Niemann–Pick type C disease, Refsum's disease, glucose transporter type 1 deficiency, episodic ataxia type 2, gluten ataxia, glutamic acid decarboxylase ataxia.\n\nThe movement disorders associated with ataxia can be managed by pharmacological treatments and through physical therapy and occupational therapy to reduce disability. Some drug treatments that have been used to control ataxia include: 5-hydroxytryptophan (5-HTP), idebenone, amantadine, physostigmine, L-carnitine or derivatives, trimethoprim/sulfamethoxazole, vigabatrin, phosphatidylcholine, acetazolamide, 4-aminopyridine, buspirone, and a combination of coenzyme Q10 and vitamin E.\n\nPhysical therapy requires a focus on adapting activity and facilitating motor learning for retraining specific functional motor patterns. A recent systematic review suggested that physical therapy is effective, but there is only moderate evidence to support this conclusion. The most commonly used physical therapy interventions for cerebellar ataxia are vestibular habituation, Frenkel exercises, proprioceptive neuromuscular facilitation (PNF), and balance training; however, therapy is often highly individualized and gait and coordination training are large components of therapy.\n\nCurrent research suggests that, if a person is able to walk with or without a mobility aid, physical therapy should include an exercise program addressing five components: static balance, dynamic balance, trunk-limb coordination, stairs, and contracture prevention. Once the physical therapist determines that the individual is able to safely perform parts of the program independently, it is important that the individual be prescribed and regularly engage in a supplementary home exercise program that incorporates these components to further improve long term outcomes. These outcomes include balance tasks, gait, and individual activities of daily living. While the improvements are attributed primarily to changes in the brain and not just the hip and/or ankle joints, it is still unknown whether the improvements are due to adaptations in the cerebellum or compensation by other areas of the brain.\n\nDecomposition, simplification, or slowing of multijoint movement may also be an effective strategy that therapists may use to improve function in patients with ataxia. Training likely needs to be intense and focused—as indicated by one study performed with stroke patients experiencing limb ataxia who underwent intensive upper limb retraining. Their therapy consisted of constraint-induced movement therapy which resulted in improvements of their arm function. Treatment should likely include strategies to manage difficulties with everyday activities such as walking. Gait aids (such as a cane or walker) can be provided to decrease the risk of falls associated with impairment of balance or poor coordination. Severe ataxia may eventually lead to the need for a wheelchair. To obtain better results, possible coexisting motor deficits need to be addressed in addition to those induced by ataxia. For example, muscle weakness and decreased endurance could lead to increasing fatigue and poorer movement patterns.\n\nThere are several assessment tools available to therapists and health care professionals working with patients with ataxia. The International Cooperative Ataxia Rating Scale (ICARS) is one of the most widely used and has been proven to have very high reliability and validity. Other tools that assess motor function, balance and coordination are also highly valuable to help the therapist track the progress of their patient, as well as to quantify the patient's functionality. These tests include, but are not limited to:\n\nThe term \"ataxia\" is sometimes used in a broader sense to indicate lack of coordination in some physiological process. Examples include optic ataxia (lack of coordination between visual inputs and hand movements, resulting in inability to reach and grab objects) and ataxic respiration (lack of coordination in respiratory movements, usually due to dysfunction of the respiratory centres in the medulla oblongata). Optic ataxia may be caused by lesions to the posterior parietal cortex, which is responsible for combining and expressing positional information and relating it to movement. Outputs of the posterior parietal cortex include the spinal cord, brain stem motor pathways, pre-motor and pre-frontal cortex, basal ganglia and the cerebellum. Some neurons in the posterior parietal cortex are modulated by intention. Optic ataxia is usually part of Balint's syndrome, but can be seen in isolation with injuries to the superior parietal lobule, as it represents a disconnection between visual-association cortex and the frontal premotor and motor cortex.\n\n\n\n", "id": "969", "title": "Ataxia"},{"url": "https://en.wikipedia.org/wiki?curid=972", "text": "Abdul Alhazred\n\nAbdul Alhazred is a fictional character created by American horror writer H. P. Lovecraft. He is the so-called \"Mad Arab\" credited with authoring the fictional book \"Kitab al-Azif\" (the \"Necronomicon\"), and as such is an integral part of Cthulhu Mythos lore.\n\n\"Abdul Alhazred\" was a pseudonym adopted by Lovecraft after reading \"1001 Arabian Nights\" in his early childhood. The name may have been invented by Lovecraft himself or the Phillips' family lawyer Albert Baker.\n\n\"Abdul\" is a common Arabic name component [meaning servant of the powerful] but never a name by itself. \"Alhazred\" may allude to \"Hazard\", a reference to the book's destructive and dangerous nature, or to Lovecraft's ancestors by that name. It might also have been a play on \"all-has-read\", since Lovecraft was an avid reader in youth. With Abdul meaning \"slave of\" Abdul Alhazred could mean a slave of all that has been read, in reference to Lovecraft and his youthful all-consuming pursuit, or to his creation of the Cthulhu mythos and being a slave of it even while its creator; it more aptly applies to the character Abdul Alhazred who truly was enslaved by what he read, and became a servant of unfathomable evil.\n\nAnother possibility, raised in an essay by the Swedish fantasy writer and editor Rickard Berghorn, is that the name \"Alhazred\" was influenced by references to two historical authors whose names were Latinized as \"Alhazen\": Alhazen ben Josef, who translated Ptolemy into Arabic; and Abu 'Ali al-Hasan ibn al-Haytham, who wrote about optics, mathematics and physics. Ibn al-Haytham is said to have pretended to be mad to escape the wrath of a ruler.\n\n\"Abdul Alhazred\" is not a real Arabic name, and seems to contain the Arabic definite article morpheme \"al-\" twice in a row (anomalous in terms of Arabic grammar). The more proper Arabic form might be \"Abd-al-Hazred\" or \"Abdul Hazred\". In Arabic translations, his name has appeared as \"Abdullah Alḥa ẓred\" (عبدالله الحظرد): Arabic \"\"حظر = \"he fenced in\", \"he prohibited\". Hazred could come from the Arabic word \"Hazrat\" meaning Great Lord with a twist that makes it sound like \"red\" and \"hazard\" both indicative of danger. It is also thought by some to be a corruption of sorts on the phrase \"All has read,\" to imply he has read much, and has immense amounts of knowledge. However Abdul is a common Arabic prefix meaning \"Servant\" and \"Al\" is Arabic for \"the\", and if \"hazra\" means \"he prohibited\", \"he fenced in\" or \"Great Lord\", then the name would mean \"Servant of the Prohibited\", \"Servant of the Fenced in\", or \"Servant of the Great Lord\" which would make sense considering his role, even if it is not a proper Arabic name.\n\nAn explanation that is more in sync with Arabic usage and existing Sufi tradition is that it is a corruption of \"Abd-al-Hazra[h]\" عبدالحضرة, where \"haẓrat\" is the Persian and Ottoman Turkish form of the Arabic word \"Haḍra[t]\" | Hadrat حضرة meaning \"presence\" used by some speakers as an honorific title before the names of prophets, saints, and also as a mnemonic for the name of Allah, as well as a common honorific title for ordinary people. The final taa marbuta is customarily variably turned into \"t\" or omitted in spoken Arabic in various varieties. \"Haḍra\" is also the name of the Sufi Dhikr.\n\nSimilarly, an article (written from an in-universe perspective) in the \"Call of Cthulhu\" tabletop role-playing game speculates that it may be a corruption of \"Abd Al-Azrad\", which it claims translates to \"The Worshipper of the Great Devourer\".\n\nThe phrase \"mad Arab\", sometimes with both words capitalized in Lovecraft's stories, is used so commonly before Alhazred's name that it almost constitutes a title. A reference to the \"Mad Arab\" in Cthulhu Mythos fiction is invariably a synonym for Abdul Alhazred. Later writers sometimes preface Alhazred with words such as \"monk\" (such as in the Chick parody tract \"Who will be Eaten First?\" by Howard Hallis) or \"scholar\" replacing Arab to avoid any racist overtones.\n\nAccording to Lovecraft's \"History of the Necronomicon\" (written 1927, first published 1938), Alhazred was:\n\nIn 730, while still living in Damascus, Alhazred supposedly wrote a book of ultimate evil in Arabic, \"al-Azif\", which would later become known as the \"Necronomicon\". Those who have dealings with this book usually come to an unpleasant end, and Alhazred was no exception. Again according to Lovecraft's \"History\":\n\nAugust Derleth later made alterations to the biography of Alhazred, such as redating his death to 731. Derleth also changed Alhazred's final fate, as described in his short story \"The Keeper of the Key\", first published in May 1951. In the story, Professor Laban Shrewsbury (a recurring Derleth character) and his assistant at the time, Nayland Colum, discover Alhazred's burial site.\n\nWhile the two are heading a caravan from Salalah, Oman, they cross the border into Yemen and find the unexplored desert area that the \"Necronomicon\" calls \"Roba el Ehaliyeh\" or \"Roba el Khaliyeh\" — presumably a reference to the Empty Quarter or \"Rub al Khali\".\n\nAt the center of the area they discover the Nameless City (the setting of the Lovecraft story of the same name) and in Derleth's text the domain of the Great Old One Hastur. Shrewsbury, an old agent of Hastur and the devoted enemy of Hastur's half-brother, Cthulhu, crosses its gates in search of Alhazred's burial site.\n\nHe indeed finds Alhazred's burial chamber and learns of his fate. Alhazred had been kidnapped in Damascus and brought to the Nameless City, where he had earlier studied and learned some of the \"Necronomicon\"s lore. As punishment for betraying their secrets, Alhazred was tortured. Then they blinded him, severed his tongue and executed him.\n\nAlthough the entrance to the chamber warns against disturbing him, Shrewsbury opens Alhazred's sarcophagus anyway, finding that only rags, bones, and dust remain of Alhazred. However, the sarcophagus also contains Alhazred's personal, incomplete copy of the \"Necronomicon\", written in the Arabic alphabet. Shrewsbury then uses necromancy to recall Alhazred's spirit and orders it to draw a map of the world as he knew it. After obtaining the map, which reveals the location of R'lyeh and other secret places, Shrewsbury finally lets Alhazred return to his eternal rest.\n\n\n", "id": "972", "title": "Abdul Alhazred"},{"url": "https://en.wikipedia.org/wiki?curid=974", "text": "Ada Lovelace\n\nAugusta Ada King-Noel, Countess of Lovelace (\"née\" Byron; 10 December 1815 – 27 November 1852) was an English mathematician and writer, chiefly known for her work on Charles Babbage's proposed mechanical general-purpose computer, the Analytical Engine. She was the first to recognise that the machine had applications beyond pure calculation, and created the first algorithm intended to be carried out by such a machine. As a result, she is often regarded as the first to recognise the full potential of a \"computing machine\" and the first computer programmer.\n\nAda Lovelace was the only legitimate child of the poet Lord Byron, and his wife Anne Isabella Milbanke (\"Annabella\"), Lady Wentworth. All of Byron's other children were born out of wedlock to other women. Byron separated from his wife a month after Ada was born and left England forever four months later, eventually dying of disease in the Greek War of Independence when Ada was eight years old. Her mother remained bitter towards Lord Byron and promoted Ada's interest in mathematics and logic in an effort to prevent her from developing what she saw as the insanity seen in her father, but Ada remained interested in him despite this (and was, upon her eventual death, buried next to him at her request). Often ill, she spent most of her childhood sick. Ada married William King in 1835. King was made Earl of Lovelace in 1838, and she became Countess of Lovelace.\n\nHer educational and social exploits brought her into contact with scientists such as Andrew Crosse, Sir David Brewster, Charles Wheatstone, Michael Faraday and the author Charles Dickens, which she used to further her education. Ada described her approach as \"poetical science\" and herself as an \"Analyst (& Metaphysician)\".\n\nWhen she was a teenager, her mathematical talents led her to a long working relationship and friendship with fellow British mathematician Charles Babbage, also known as \"the father of computers\", and in particular, Babbage's work on the Analytical Engine. Lovelace first met him in June 1833, through their mutual friend, and her private tutor, Mary Somerville. Between 1842 and 1843, Ada translated an article by Italian military engineer Luigi Menabrea on the engine, which she supplemented with an elaborate set of notes, simply called \"Notes\". These notes contain what many consider to be the first computer program—that is, an algorithm designed to be carried out by a machine. Lovelace's notes are important in the early history of computers. She also developed a vision of the capability of computers to go beyond mere calculating or number-crunching, while many others, including Babbage himself, focused only on those capabilities. Her mindset of \"poetical science\" led her to ask questions about the Analytical Engine (as shown in her notes) examining how individuals and society relate to technology as a collaborative tool.\n\nShe died of uterine cancer in 1852 at the age of 36.\n\nByron expected his baby to be a \"glorious boy\" and was disappointed when his wife gave birth to a girl. Augusta was named after Byron's half-sister, Augusta Leigh, and was called \"Ada\" by Byron himself.\nOn 16 January 1816 Ada's mother, Annabella, at Byron's behest, left for her parents' home at Kirkby Mallory taking one-month-old Ada with her. Although English law at the time gave fathers full custody of their children in cases of separation, Byron made no attempt to claim his parental rights but did request that his sister keep him informed of Ada's welfare. On 21 April Byron signed the Deed of Separation, although very reluctantly, and left England for good a few days later. Aside from an acrimonious separation, Annabella continually made allegations about Byron's immoral behaviour throughout her life.\n\nThis set of events made Ada famous in Victorian society. Byron did not have a relationship with his daughter, and never saw her again. He died in 1824 when she was eight years old. Her mother was the only significant parental figure in her life. Ada was not shown the family portrait of her father (covered in green shroud) until her twentieth birthday. Her mother became Baroness Wentworth in her own right in 1856.\n\nAnnabella did not have a close relationship with the young Ada and often left her in the care of her own mother Judith, Hon. Lady Milbanke who doted on her grandchild. However, because of societal attitudes of the time—which favoured the husband in any separation, with the welfare of any child acting as mitigation—Annabella had to present herself as a loving mother to the rest of society. This included writing anxious letters to Lady Milbanke about Ada's welfare, with a cover note saying to retain the letters in case she had to use them to show maternal concern. In one letter to Lady Milbanke, she referred to Ada as \"it\": \"I talk to it for your satisfaction, not my own, and shall be very glad when you have it under your own.\" In her teenage years, several of her mother's close friends watched Ada for any sign of moral deviation. Ada dubbed these observers the \"Furies\" and later complained they exaggerated and invented stories about her.\nAda was often ill, beginning in early childhood. At the age of eight, she experienced headaches that obscured her vision. In June 1829, she was paralysed after a bout of measles. She was subjected to continuous bed rest for nearly a year, which may have extended her period of disability. By 1831, she was able to walk with crutches. Despite being ill Ada developed her mathematical and technological skills. At age 12 this future \"Lady Fairy\", as Charles Babbage affectionately called her, decided she wanted to fly. Ada went about the project methodically, thoughtfully, with imagination and passion. Her first step, in February 1828, was to construct wings. She investigated different material and sizes. She considered various materials for the wings: paper, oilsilk, wires, and feathers. She examined the anatomy of birds to determine the right proportion between the wings and the body. She decided to write a book, \"Flyology,\" illustrating, with plates, some of her findings. She decided what equipment she would need; for example, a compass, to \"cut across the country by the most direct road\", so that she could surmount mountains, rivers, and valleys. Her final step was to integrate steam with the \"art of flying\".\n\nIn early 1833 Ada had an affair with a tutor and, after being caught, tried to elope with him. The tutor's relatives recognised her and contacted her mother. Annabella and her friends covered the incident up to prevent a public scandal. Ada never met her younger half-sister, Allegra, the daughter of Lord Byron and Claire Clairmont. Allegra died in 1822 at the age of five. Ada did have some contact with Elizabeth Medora Leigh, the daughter of Byron's half-sister Augusta Leigh, who purposely avoided Ada as much as possible when introduced at Court.\n\nLovelace became close friends with her tutor Mary Somerville, who introduced her to Charles Babbage in 1833. She had a strong respect and affection for Somerville, and they corresponded for many years. Other acquaintances included the scientists Andrew Crosse, Sir David Brewster, Charles Wheatstone, Michael Faraday and the author Charles Dickens. She was presented at Court at the age of seventeen \"and became a popular belle of the season\" in part because of her \"brilliant mind.\" By 1834 Ada was a regular at Court and started attending various events. She danced often and was able to charm many people, and was described by most people as being dainty, although John Hobhouse, Byron's friend, described her as \"a large, coarse-skinned young woman but with something of my friend's features, particularly the mouth\". This description followed their meeting on 24 February 1834 in which Ada made it clear to Hobhouse that she did not like him, probably because of the influence of her mother, which led her to dislike all of her father's friends. This first impression was not to last, and they later became friends.\n\nOn 8 July 1835, she married William, 8th Baron King, becoming Lady King. They had three homes: Ockham Park, Surrey, a Scottish estate on Loch Torridon in Ross-shire, and a house in London. They spent their honeymoon at Worthy Manor in Ashley Combe near Porlock Weir, Somerset. The Manor had been built as a hunting lodge in 1799 and was improved by King in preparation for their honeymoon. It later became their summer retreat and was further improved during this time. From 1845 the family's main house was East Horsley Towers, rebuilt in the Victorian Gothic fashion by the architect of the Houses of Parliament, Charles Barry.\n\nThey had three children: Byron (born 12 May 1836); Anne Isabella (called Annabella; born 22 September 1837); and Ralph Gordon (born 2 July 1839). Immediately after the birth of Annabella, Lady King experienced \"a tedious and suffering illness, which took months to cure.\" Ada was a descendant of the extinct Barons Lovelace and in 1838, her husband was made Earl of Lovelace and Viscount Ockham, meaning Ada became the Countess of Lovelace. In 1843–44, Ada's mother assigned William Benjamin Carpenter to teach Ada's children and to act as a \"moral\" instructor for Ada. He quickly fell for her and encouraged her to express any frustrated affections, claiming that his marriage meant he would never act in an \"unbecoming\" manner. When it became clear that Carpenter was trying to start an affair, Ada cut it off.\n\nIn 1841 Lovelace and Medora Leigh (the daughter of Lord Byron's half-sister Augusta Leigh) were told by Ada's mother that her father was also Medora's father. On 27 February 1841, Ada wrote to her mother: \"I am not in the least \"astonished\". In fact, you merely \"confirm\" what I have for \"years and years\" felt scarcely a doubt about, but should have considered it most improper in me to hint to you that I in any way suspected.\" She did not blame the incestuous relationship on Byron, but instead blamed Augusta Leigh: \"I fear she is more inherently wicked than he ever was.\" In the 1840s Ada flirted with scandals: first, from a relaxed relationship with men who were not her husband, which led to rumours of affairs—and secondly, her love of gambling. She apparently lost more than £3,000 on the horses during the later 1840s. The gambling led to her forming a syndicate with male friends, and an ambitious attempt in 1851 to create a mathematical model for successful large bets. This went disastrously wrong, leaving her thousands of pounds in debt to the syndicate, forcing her to admit it all to her husband. She had a shadowy relationship with Andrew Crosse's son John from 1844 onwards. John Crosse destroyed most of their correspondence after her death as part of a legal agreement. She bequeathed him the only heirlooms her father had personally left to her. During her final illness, she would panic at the idea of the younger Crosse being kept from visiting her.\n\nThroughout her illnesses, she continued her education. Her mother's obsession with rooting out any of the insanity of which she accused Byron was one of the reasons that Ada was taught mathematics from an early age. She was privately schooled in mathematics and science by William Frend, William King, and Mary Somerville, the noted researcher and scientific author of the 19th century. One of her later tutors was the mathematician and logician Augustus De Morgan. From 1832, when she was seventeen, her mathematical abilities began to emerge, and her interest in mathematics dominated the majority of her adult life. In a letter to Lady Byron, De Morgan suggested that her daughter's skill in mathematics could lead her to become \"an original mathematical investigator, perhaps of first-rate eminence\".\n\nLovelace often questioned basic assumptions by integrating poetry and science. While studying differential calculus, she wrote to De Morgan:\nI may remark that the curious transformations many formulae can undergo, the unsuspected and to a beginner apparently impossible identity of forms exceedingly dissimilar at first sight, is I think one of the chief difficulties in the early part of mathematical studies. I am often reminded of certain sprites and fairies one reads of, who are at one's elbows in \"one\" shape now, and the next minute in a form most dissimilar \nLovelace believed that intuition and imagination were critical to effectively applying mathematical and scientific concepts. She valued metaphysics as much as mathematics, viewing both as tools for exploring \"the unseen worlds around us\".\n\nLovelace died at the age of 36 – the same age that her father had died – on 27 November 1852, from uterine cancer probably exacerbated by bloodletting by her physicians. The illness lasted several months, in which time Annabella took command over whom Ada saw, and excluded all of her friends and confidants. Under her mother's influence, she had a religious transformation and was coaxed into repenting of her previous conduct and making Annabella her executor. She lost contact with her husband after she confessed something to him on 30 August which caused him to abandon her bedside. What she told him is unknown. She was buried, at her request, next to her father at the Church of St. Mary Magdalene in Hucknall, Nottinghamshire. A memorial plaque in Latin to her and her father is in the chapel attached to Horsley Towers.\n\nThroughout her life, Lovelace was strongly interested in scientific developments and fads of the day, including phrenology and mesmerism. After her work with Babbage, Lovelace continued to work on other projects. In 1844 she commented to a friend Woronzow Greig about her desire to create a mathematical model for how the brain gives rise to thoughts and nerves to feelings (\"a calculus of the nervous system\"). She never achieved this, however. In part, her interest in the brain came from a long-running pre-occupation, inherited from her mother, about her 'potential' madness. As part of her research into this project, she visited the electrical engineer Andrew Crosse in 1844 to learn how to carry out electrical experiments. In the same year, she wrote a review of a paper by Baron Karl von Reichenbach, \"Researches on Magnetism\", but this was not published and does not appear to have progressed past the first draft. In 1851, the year before her cancer struck, she wrote to her mother mentioning \"certain productions\" she was working on regarding the relation of maths and music.\nLovelace first met Charles Babbage in June 1833, through their mutual friend Mary Somerville. Later that month Babbage invited Lovelace to see the prototype for his Difference Engine. She became fascinated with the machine and used her relationship with Somerville to visit Babbage as often as she could. Babbage was impressed by Lovelace's intellect and analytic skills. He called her \"The Enchantress of Number\". In 1843 he wrote of her:\n\nDuring a nine-month period in 1842–43, Lovelace translated the Italian mathematician Luigi Menabrea's article on Babbage's newest proposed machine, the Analytical Engine. With the article, she appended a set of notes. Explaining the Analytical Engine's function was a difficult task, as even many other scientists did not really grasp the concept and the British establishment was uninterested in it. Lovelace's notes even had to explain how the Analytical Engine differed from the original Difference Engine. Her work was well received at the time; the scientist Michael Faraday described himself as a supporter of her writing.\n\nThe notes are around three times longer than the article itself and include (in Section G), in complete detail, a method for calculating a sequence of Bernoulli numbers with the Engine, which could have run correctly had Babbage's Analytical Engine been built. (Only his Difference Engine has been built, completed in London in 2002.) Based on this work Lovelace is now widely considered the first computer programmer and her method is recognised as the world's first computer program.\n\nSection G also contains Lovelace's dismissal of artificial intelligence. She wrote that \"The Analytical Engine has no pretensions whatever to \"originate\" anything. It can do \"whatever we know how to order it\" to perform. It can follow analysis; but it has no power of anticipating any analytical relations or truths.\" This objection has been the subject of much debate and rebuttal, for example by Alan Turing in his paper \"Computing Machinery and Intelligence\".\n\nLovelace and Babbage had a minor falling out when the papers were published when he tried to leave his own statement (a criticism of the government's treatment of his Engine) as an unsigned preface—which would imply that she had written that also. When Taylor's \"Scientific Memoirs\" ruled that the statement should be signed, Babbage wrote to Lovelace asking her to withdraw the paper. This was the first that she knew he was leaving it unsigned, and she wrote back refusing to withdraw the paper. The historian Benjamin Woolley theorised that: \"His actions suggested he had so enthusiastically sought Ada's involvement, and so happily indulged her ... because of her 'celebrated name'.\" Their friendship recovered, and they continued to correspond. On 12 August 1851, when she was dying of cancer, Lovelace wrote to him asking him to be her executor, though this letter did not give him the necessary legal authority. Part of the terrace at Worthy Manor was known as \"Philosopher's Walk\", as it was there that Lovelace and Babbage were reputed to have walked while discussing mathematical principles.\n\nIn 1840, Babbage was invited to give a seminar at the University of Turin about his Analytical Engine. Luigi Menabrea, a young Italian engineer, and the future Prime Minister of Italy wrote up Babbage's lecture in French, and this transcript was subsequently published in the Bibliothèque universelle de Genève in October 1842.\nBabbage's friend Charles Wheatstone commissioned Ada Lovelace to translate Menabrea's paper into English. She then augmented the paper with notes, which were added to the translation. Ada Lovelace spent the better part of a year doing this, assisted with input from Babbage. These notes, which are more extensive than Menabrea's paper, were then published in Taylor's \"Scientific Memoirs\" under the initialism \"AAL\".\n\nAda Lovelace's notes were labelled alphabetically from A to G. In note G, she describes an algorithm for the Analytical Engine to compute Bernoulli numbers. It is considered the first published algorithm ever specifically tailored for implementation on a computer, and Ada Lovelace has often been cited as the first computer programmer for this reason. The engine was never completed so her program was never tested.\n\nIn 1953, more than a century after her death, Ada Lovelace's notes on Babbage's Analytical Engine were republished. The engine has now been recognised as an early model for a computer and her notes as a description of a computer and software.\n\nIn her notes, Lovelace emphasised the difference between the Analytical Engine and previous calculating machines, particularly its ability to be programmed to solve problems of any complexity. She realised the potential of the device extended far beyond mere number crunching. In her notes, she wrote:\nThis analysis was an important development from previous ideas about the capabilities of computing devices and anticipated the implications of modern computing one hundred years before they were realised. Walter Isaacson ascribes Lovelace's insight regarding the application of computing to \"any\" process based on logical symbols to an observation about textiles: \"When she saw some mechanical looms that used punchcards to direct the weaving of beautiful patterns, it reminded her of how Babbage's engine used punched cards to make calculations.\" This insight is seen as significant by writers such as Betty Toole and Benjamin Woolley, as well as the programmer John Graham-Cumming, whose project Plan 28 has the aim of constructing the first complete Analytical Engine.\n\nAccording to the historian of computing and Babbage specialist Doron Swade: Ada saw something that Babbage in some sense failed to see. In Babbage's world his engines were bound by number...What Lovelace saw—what Ada Byron saw—was that number could represent entities other than quantity. So once you had a machine for manipulating numbers, if those numbers represented other things, letters, musical notes, then the machine could manipulate symbols of which number was one instance, according to rules. It is this fundamental transition from a machine which is a number cruncher to a machine for manipulating symbols according to rules that is the fundamental transition from calculation to computation—to general-purpose computation—and looking back from the present high ground of modern computing, if we are looking and sifting history for that transition, then that transition was made explicitly by Ada in that 1843 paper.\n\nThough Lovelace is referred to as the first computer programmer, some biographers and historians of computing claim otherwise.\n\nAllan G. Bromley, in the 1990 article \"Difference and Analytical Engines\":\nBruce Collier, who later wrote a biography of Babbage, wrote in his 1970 Harvard University PhD thesis that Lovelace \"made a considerable contribution to publicizing the Analytical Engine, but there is no evidence that she advanced the design or theory of it in any way\".\n\nEugene Eric Kim and Betty Alexandra Toole consider it \"incorrect\" to regard Lovelace as the first computer programmer, as Babbage wrote the initial programs for his Analytical Engine, although the majority were never published. Bromley notes several dozen sample programs prepared by Babbage between 1837 and 1840, all substantially predating Lovelace's notes. Dorothy K. Stein regards Lovelace's notes as \"more a reflection of the mathematical uncertainty of the author, the political purposes of the inventor, and, above all, of the social and cultural context in which it was written, than a blueprint for a scientific development\".\n\nIn his book, \"Idea Makers\", Stephen Wolfram defends Lovelace's contributions. While acknowledging that Babbage wrote several unpublished algorithms for the Analytical Engine prior to Lovelace's notes, Wolfram argues that \"there's nothing as sophisticated—or as clean—as Ada's computation of the Bernoulli numbers. Babbage certainly helped and commented on Ada's work, but she was definitely the driver of it.\" Wolfram then suggests that Lovelace's main achievement was to distill from Babbage's correspondence \"a clear exposition of the abstract operation of the machine—something which Babbage never did.\"\n\nDoron Swade, a specialist on history of computing known for his work on Babbage, analyzed four claims about Lovelace during a lecture on Babbage's analytical engine:\n\nAccording to him, only the fourth claim had \"any substance at all\". He explained that Ada was only a \"promising beginner\" instead of genius in mathematics, that she began studying basic concepts of mathematics five years after Babbage conceived the analytical engine so she couldn't have made important contributions to it, and that she only published the first computer program instead of actually writing it. But he agrees that Ada was the only person to see the potential of the analytical engine as a machine capable of expressing entities other than quantities.\n\nLovelace has been portrayed in Romulus Linney's 1977 play \"Childe Byron\", the 1990 steampunk novel \"The Difference Engine\" by William Gibson and Bruce Sterling, the 1997 film \"Conceiving Ada\", and in John Crowley's 2005 novel \"Lord Byron's Novel: The Evening Land\", where she is featured as an unseen character whose personality is forcefully depicted in her annotations and anti-heroic efforts to archive her father's lost novel.\n\nIn Tom Stoppard's 1993 play \"Arcadia\", the precocious teenage genius Thomasina Coverly (a character \"apparently based\" on Ada Lovelace—the play also involves Lord Byron) comes to understand chaos theory, and theorises the second law of thermodynamics, before either is officially recognised. The 2015 play \"Ada and the Memory Engine\" by Lauren Gunderson portrays Lovelace and Charles Babbage in unrequited love, and it imagines a post-death meeting between Lovelace and her father.\n\nLovelace and Babbage are the main characters in Sydney Padua's webcomic and graphic novel \"The Thrilling Adventures of Lovelace and Babbage\". The comic features extensive footnotes on the history of Ada Lovelace, and many lines of dialogue are drawn from actual correspondence.\n\nLovelace and Mary Shelley as teenagers are the central characters in Jordan Stratford's steampunk series, The Wollstonecraft Detective Agency.\n\nIn 2017, a Google Doodle honoured her on International Women's Day.\n\nThe computer language Ada, created on behalf of the United States Department of Defense, was named after Lovelace. The reference manual for the language was approved on 10 December 1980 and the Department of Defense Military Standard for the language, \"MIL-STD-1815\", was given the number of the year of her birth.\n\nSince 1998 the British Computer Society (BCS) has awarded the Lovelace Medal, and in 2008 initiated an annual competition for women students. BCSWomen sponsors the Lovelace Colloquium, an annual conference for women undergraduates. Ada College is a further-education college in Tottenham Hale, London focused on digital skills.\n\nAda Lovelace Day is an annual event celebrated in mid-October whose goal is to \"... raise the profile of women in science, technology, engineering, and maths,\" (see Women in STEM fields) and to \"create new role models for girls and women\" in these fields. The Ada Initiative was a non-profit organisation dedicated to increasing the involvement of women in the free culture and open source movements.\n\nThe Engineering in Computer Science and Telecommunications College building in Zaragoza University is called the Ada Byron Building. The computer centre in the village of Porlock, near where Lovelace lived, is named after her. Ada Lovelace House is a council-owned building in Kirkby-in-Ashfield, Nottinghamshire, near where Lovelace spent her infancy; the building was once an internet centre \n\nShe is also the inspiration and influence for the Ada Developers Academy in Seattle, Washington. The academy is a non-profit that seeks to increase diversity in tech by training women, trans and non-binary people to be software engineers.\nOne of the tunnel boring machines excavating London's Crossrail project is named \"Ada\".\n\n\"Ada: A Journal of Gender, New Media, and Technology\" is an \"open-access, multi-modal, [open-]peer-reviewed feminist journal concerned with the intersections of gender, new media, and technology\" that began in 2012 and is run by the Fembot Collective.\n\n\nThe bicentenary of Ada Lovelace's birth was celebrated with a number of events, including:\n\n\nSpecial exhibitions were displayed by the Science Museum in London and the Weston Library (part of the Bodleian Library) in Oxford, England.\n\n\n", "id": "974", "title": "Ada Lovelace"},{"url": "https://en.wikipedia.org/wiki?curid=980", "text": "August Derleth\n\nAugust William Derleth (February 24, 1909 – July 4, 1971) was an American writer and anthologist. Though best remembered as the first book publisher of the writings of H. P. Lovecraft, and for his own contributions to the Cthulhu Mythos genre of horror, as well as his founding of the publisher Arkham House (which did much to bring supernatural fiction into print in hardcover in the US that had only been readily available in the UK), Derleth was a leading American regional writer of his day, as well as prolific in several other genres, including historical fiction, poetry, detective fiction, science fiction, and biography.\n\nA 1938 Guggenheim Fellow, Derleth considered his most serious work to be the ambitious \"Sac Prairie Saga\", a series of fiction, historical fiction, poetry, and non-fiction naturalist works designed to memorialize life in the Wisconsin he knew. Derleth can also be considered a pioneering naturalist and conservationist in his writing.\n\nThe son of William Julius Derleth and Rose Louise Volk, Derleth grew up in Sauk City, Wisconsin. He was educated in local parochial and public high school. Derleth wrote his first fiction at age 13. He was interested most in reading, and he made three trips to the library a week. He would save his money to buy books (his personal library exceeded 12,000 later on in life). Some of his biggest influences were Ralph Waldo Emerson's essays, Walt Whitman, H. L. Mencken's The American Mercury, Samuel Johnson's The History of Rasselas, Prince of Abissinia, Alexandre Dumas, Edgar Allan Poe, Walter Scott, and Henry David Thoreau's Walden.\n\nForty rejected stories and three years later, according to anthologist Jim Stephens, he sold his first story, \"Bat's Belfry\", to \"Weird Tales\" magazine. Derleth wrote throughout his four years at the University of Wisconsin, where he received a B.A. in 1930. During this time he also served briefly as associate editor of Minneapolis-based Fawcett Publications \"Mystic Magazine\".\n\nReturning to Sauk City in the summer of 1931, Derleth worked in a local canning factory and collaborated with childhood friend Mark Schorer (later Chairman of the University of California, Berkeley English Department). They rented a cabin, writing Gothic and other horror stories and selling them\nto \"Weird Tales\" magazine. Derleth won a place on the O'Brien Roll of Honor for \"Five Alone\", published in \"Place of Hawks\", but was first found in \"Pagany\" magazine.\n\nAs a result of his early work on the \"Sac Prairie Saga\", Derleth was awarded the prestigious Guggenheim Fellowship; his sponsors were Helen C. White, Nobel Prize-winning novelist Sinclair Lewis and poet Edgar Lee Masters of \"Spoon River Anthology\" fame.\n\nIn the mid-1930s, Derleth organized a Ranger's Club for young people, served as clerk and president of the local school board, served as a parole officer, organized a local men's club and a parent-teacher association. He also lectured in American regional literature at the University of Wisconsin and was a contributing editor of \"Outdoors Magazine\".\n\nWith longtime friend Donald Wandrei, Derleth in 1939 founded Arkham House. Its initial objective was to publish the works of H. P. Lovecraft, with whom Derleth had corresponded since his teenage years. At the same time, he began teaching a course in American Regional Literature at the University of Wisconsin.\n\nIn 1941, he became literary editor of \"The Capital Times\" newspaper in Madison, a post he held until his resignation in 1960. His hobbies included fencing, swimming, chess, philately and comic-strips (Derleth reportedly deployed the funding from his Guggenheim Fellowship to bind his comic book collection, most recently valued in the millions of dollars, rather than to travel abroad as the award intended.). Derleth's true avocation, however, was hiking the terrain of his native Wisconsin lands, and observing and recording nature with an expert eye.\n\nDerleth once wrote of his writing methods, \"I write very swiftly, from 750,000 to a million words yearly, very little of it pulp material.\"\n\nIn 1948, he was elected president of the Associated Fantasy Publishers at the 6th World Science Fiction Convention in Toronto.\n\nHe was married April 6, 1953, to Sandra Evelyn Winters. They divorced six years later. Derleth retained custody of the couple's two children, April Rose and Walden William. April earned a Bachelor of Arts degree in English from the University of Wisconsin-Madison in 1977. She became majority stockholder, President, and CEO of Arkham House in 1994. She remained in that capacity until her death. She was known in the community as a naturalist and humanitarian. April died on March 21, 2011.\n\nIn 1960, Derleth began editing and publishing a magazine called \"Hawk and Whippoorwill\", dedicated to poems of man and nature.\n\nDerleth died of a heart attack on July 4, 1971, and is buried in St. Aloysius Cemetery in Sauk City. The U.S. 12 bridge over the Wisconsin River is named in his honor.\n\nDerleth wrote more than 150 short stories and more than 100 books during his lifetime.\n\nDerleth wrote an expansive series of novels, short stories, journals, poems, and other works about Sac Prairie (whose prototype is Sauk City). Derleth intended this series to comprise up to 50 novels telling the projected life-story of the region from the 19th century onwards, with analogies to Balzac's \"Human Comedy\" and Proust's \"Remembrance of Things Past\".\n\nThis, and other early work by Derleth, made him a well-known figure among the regional literary figures of his time: early Pulitzer Prize winners Hamlin Garland and Zona Gale, as well as Sinclair Lewis, the last both an admirer and critic of Derleth.\n\nAs Edward Wagenknecht wrote in \"Cavalcade of the American Novel\", \"What Mr. Derleth has that is lacking...in modern novelists generally, is a country. He belongs. He writes of a land and a people that are bone of his bone and flesh of his flesh. In his fictional world, there is a unity much deeper and more fundamental than anything that can be conferred by an ideology. It is clear, too, that he did not get the best, and most fictionally useful, part of his background material from research in the library; like Scott, in his Border novels, he gives, rather, the impression of having drunk it in with his mother's milk.\"\n\nJim Stephens, editor of \"An August Derleth Reader\", (1992), argues: \"what Derleth accomplished...was to gather a Wisconsin mythos which gave respect to the ancient fundament of our contemporary life.\"\n\nThe author inaugurated the \"Sac Prairie Saga\" with four novellas comprising \"Place of Hawks\", published by Loring & Mussey in 1935. At publication, \"The Detroit News\" wrote: \"Certainly with this book Mr. Derleth may be added to the American writers of distinction.\"\n\nDerleth's first novel, \"Still is the Summer Night\", was published two years later by the famous Charles Scribners' editor Maxwell Perkins, and was the second in his Sac Prairie Saga.\n\n\"Village Year\", the first in a series of journals–meditations on nature, Midwestern village American life, and more–was published in 1941 to praise from \"The New York Times Book Review\": \"A book of instant sensitive responsiveness...recreates its scene with acuteness and beauty, and makes an unusual contribution to the Americana of the present day.\" The \"New York Herald Tribune\" observed that \"Derleth...deepens the value of his village setting by presenting in full the enduring natural background; with the people projected against this, the writing comes to have the quality of an old Flemish picture, humanity lively and amusing and loveable in the foreground and nature magnificent beyond.\" James Grey, writing in the \"St. Louis Dispatch\" concluded, \"Derleth has achieved a kind of prose equivalent of the \"Spoon River Anthology\".\"\n\nIn the same year, \"Evening in Spring\" was published by Charles Scribners & Sons. This work Derleth considered among his finest. What \"The Milwaukee Journal\" called \"this beautiful little love story\", is an autobiographical novel of first love beset by small-town religious bigotry. The work received critical praise: \"The New Yorker\" considered it a story told \"with tenderness and charm\", while the \"Chicago Tribune\" concluded: \"It's as though he turned back the pages of an old diary and told, with rekindled emotion, of the pangs of pain and the sharp, clear sweetness of a boy's first love.\" Helen Constance White, wrote in \"The Capital Times\" that it was \"...the best articulated, the most fully disciplined of his stories.\"\n\nThese were followed in 1943 with \"Shadow of Night\", a Scribners' novel of which \"The Chicago Sun\" wrote: \"Structurally it has the perfection of a carved jewel...A psychological novel of the first order, and an adventure tale that is unique and inspiriting.\"\n\nIn November 1945, however, Derleth's work was attacked by his one-time admirer and mentor, Sinclair Lewis. Writing in \"Esquire\", Lewis observed, \"It is a proof of Mr. Derleth's merit that he makes one want to make the journey and see his particular Avalon: The Wisconsin River shining among its islands, and the castles of Baron Pierneau and Hercules Dousman. He is a champion and a justification of regionalism. Yet he is also a burly, bounding, bustling, self-confident, opinionated, and highly-sweatered young man with faults so grievous that a melancholoy perusal of them may be of more value to apprentices than a study of his serious virtues. If he could ever be persuaded that he isn't half as good as he thinks he is, if he would learn the art of sitting still and using a blue pencil, he might become twice as good as he thinks he is–which would about rank him with Homer.\" Derleth good humoredly reprinted the criticism along with a photograph of himself sans sweater, on the back cover of his 1948 country journal: \"Village Daybook\".\n\nA lighter side to the \"Sac Prairie Saga\" is a series of quasi-autobiographical short stories known as the \"Gus Elker Stories\", amusing tales of country life that Peter Ruber, Derleth's last editor, said were \"...models of construction and...fused with some of the most memorable characters in American literature.\" Most were written between 1934 and the late 1940s, though the last, \"Tail of the Dog\", was published in 1959 and won the \"Scholastic Magazine\" short story award for the year. The series was collected and republished in \"Country Matters\" in 1996.\n\n\"Walden West\", published in 1961, is considered by many Derleth's finest work. This prose meditation is built out of the same fundamental material as the series of Sac Prairie journals, but is organized around three themes: \"the persistence of memory...the sounds and odors of the country...and Thoreau's observation that the 'mass of men lead lives of quiet desperation.'\" A blend of nature writing, philosophic musings, and careful observation of the people and place of \"Sac Prairie.\" Of this work, George Vukelich, author of \"North Country Notebook\", writes: \"Derleth's \"Walden West\" is...the equal of Sherwood Anderson's \"Winesburg,Ohio\", Thornton Wilder's \"Our Town\", and Edgar Lee Masters' \"Spoon River Anthology\".\" This was followed eight years later by \"Return to Walden West\", a work of similar quality, but with a more noticeable environmentalist edge to the writing, notes critic Norbert Blei.\n\nA close literary relative of the \"Sac Prairie Saga\" was Derleth's \"Wisconsin Saga\", which comprises several historical novels.\n\nDetective fiction represented another substantial body of Derleth's work. Most notable among this work was a series of 70 stories in affectionate pastiche of Sherlock Holmes, whose creator, Sir Arthur Conan Doyle, he admired greatly. These included one published novel as well (\"Mr. Fairlie's Final Journey\"). The series features a (Sherlock Holmes-styled) British detective named Solar Pons, of Praed Street in London. The series was greatly admired by such notable writers and critics of mystery and detective fiction as Ellery Queen (Frederic Dannay), Anthony Boucher, Vincent Starrett and Howard Haycraft.\n\nIn his 1944 volume \"The Misadventures of Sherlock Holmes\", Ellery Queen wrote of Derleth's \"The Norcross Riddle\", an early Pons story: \"How many budding authors, not even old enough to vote, could have captured the spirit and atmosphere with as much fidelity?\" Queen adds, \"...and his choice of the euphonic Solar Pons is an appealing addition to the fascinating lore of Sherlockian nomenclature.\" Vincent Starrett, in his foreword to the 1964 edition of \"The Casebook of Solar Pons\", wrote that the series is \"...as sparkling a galaxy of Sherlockian pastiches as we have had since the canonical entertainments came to an end.\"\n\nDespite close similarities to Doyle's creation, Pons lived in the post-World War I era, in the decade of the 1920s. Though Derleth never wrote a Pons novel to equal \"The Hound of the Baskervilles\", editor Peter Ruber wrote: \"...Derleth produced more than a few Solar Pons stories almost as good as Sir Arthur's, and many that had better plot construction.\"\n\nAlthough these stories were a form of diversion for Derleth, Ruber, who edited \"The Original Text Solar Pons Omnibus Edition\" (2000), argued: \"Because the stories were generally of such high quality, they ought to be assessed on their own merits as a unique contribution in the annals of mystery fiction, rather than suffering comparison as one of the endless imitators of Sherlock Holmes.\"\n\nSome of the stories were self-published, through a new imprint called \"Mycroft & Moran\", an appellation of humorous significance to Holmesian scholars. For approximately a decade, an active supporting group was the Praed Street Irregulars, patterned after the Baker Street Irregulars.\n\nIn 1946, Conan Doyle's two sons made some attempts to force Derleth to cease publishing the Solar Pons series, but the efforts were unsuccessful and eventually withdrawn.\n\nDerleth's mystery and detective fiction also included a series of works set in Sac Prairie and featuring Judge Peck as the central character.\n\nDerleth wrote many and varied children's works, including biographies meant to introduce younger readers to explorer Fr. Marquette, as well as Ralph Waldo Emerson and Henry David Thoreau. Arguably most important among his works for younger readers, however, is the Steve and Sim Mystery Series, also known as the Mill Creek Irregulars series. The ten-volume series, published between 1958 and 1970, is set in Sac Prairie of the 1920s and can thus be considered in its own right a part of the \"Sac Prairie Saga\", as well as an extension of Derleth's body of mystery fiction. Robert Hood, writing in the \"New York Times\" said: \"Steve and Sim, the major characters, are twentieth-century cousins of Huck Finn and Tom Sawyer; Derleth's minor characters, little gems of comic drawing.\" The first novel in the series, \"The Moon Tenders\", does, in fact, involve a rafting adventure down the Wisconsin River, which led regional writer Jesse Stuart to suggest the novel was one that \"older people might read to recapture the spirit and dream of youth.\" The connection to the \"Sac Prairie Saga\" was noted by the \"Chicago Tribune\": \"Once again a small midwest community in 1920s is depicted with perception, skill, and dry humor.\"\n\nDerleth was a correspondent and friend of H. P. Lovecraft – when Lovecraft wrote about \"le Comte d'Erlette\" in his fiction, it was in homage to Derleth. Derleth invented the term \"Cthulhu Mythos\" to describe the fictional universe described in the series of stories shared by Lovecraft and other writers in his circle.\n\nWhen Lovecraft died in 1937, Derleth and Donald Wandrei assembled a collection of Lovecraft's stories and tried to get them published. Existing publishers showed little interest, so Derleth and Wandrei founded Arkham House in 1939 for that purpose. The name of the company derived from Lovecraft's fictional town of Arkham, Massachusetts, which features in many of his stories. In 1939 Arkham House published \"The Outsider and Others\", a huge collection that contained most of Lovecraft's known short stories. Derleth and Wandrei soon expanded Arkham House and began a regular publishing schedule after its second book, \"Someone in the Dark\", a collection of some of Derleth's own horror stories, was published in 1941.\n\nFollowing Lovecraft's death, Derleth wrote a number of stories based on fragments and notes left by Lovecraft. These were published in \"Weird Tales\" and later in book form, under the byline \"H. P. Lovecraft and August Derleth\", with Derleth calling himself a \"posthumous collaborator.\" This practice has raised objections in some quarters that Derleth simply used Lovecraft's name to market what was essentially his own fiction; S. T. Joshi refers to the \"posthumous collaborations\" as marking the beginning of \"perhaps the most disreputable phase of Derleth's activities\".\n\nA significant number of H. P. Lovecraft fans and critics, such as Dirk W. Mosig, S. T. Joshi, and Richard L. Tierney were dissatisfied with Derleth's invention of the term \"Cthulhu Mythos\" (Lovecraft himself used \"Yog-Sothothery\") and his presentation of Lovecraft's fiction as having an overall pattern reflecting Derleth's own Christian world view, which they contrast with Lovecraft's depiction of an amoral universe. However Robert M. Price points out that while Derleth's tales are distinct from Lovecraft's in their use of hope and his depiction of a struggle between good and evil, nevertheless the basis of Derlerth's systemization are found in Lovecraft. He also suggests that the differences can be over stated:\n\nDerleth \"was\" more optimistic than Lovecraft in his conception of the Mythos, but we are dealing with a difference more of degree than kind. There are indeed tales wherein Derleth's protagonists get off scot-free (like \"The Shadow in the Attic\", \"Witches' Hollow\", or \"The Shuttered Room\"), but often the hero is doomed (e.g., \"The House in the Valley\", \"The Peabody Heritage\", \"Something in Wood\"), as in Lovecraft. And it must be remembered that an occasional Lovecraftian hero does manage to overcome the odds, e.g., in \"The Horror in the Museum\", \"The Shunned House\", and 'The Case of Charles Dexter Ward'. \n\nDerleth also treated Lovecraft's Old Ones as representatives of elemental forces, creating new fictional entities to flesh out this framework.\n\nSuch debates aside, Derleth's founding of Arkham House and his successful effort to rescue Lovecraft from literary obscurity are widely acknowledged by practitioners in the horror field as seminal events in the field. For instance, Ramsey Campbell has acknowledged Derleth's encouragement and guidance during the early part of his own writing career, and Kirby McCauley has cited Derleth and Arkham House as an inspiration for his own anthology, \"Dark Forces\". Arkham House and Derleth published \"Dark Carnival\", the first book by Ray Bradbury, as well. Brian Lumley cites the importance of Derleth to his own Lovecraftian work, and contends in a 2009 introduction to Derleth's work that he was \"...one of the first, finest, and most discerning editors and publishers of macabre fiction.\"\n\nImportant as was Derleth's work to rescue H.P. Lovecraft from literary obscurity at the time of Lovecraft's death, Derleth also built a body of horror and spectral fiction of his own; still frequently anthologized. The best of this work, recently reprinted in four volumes of short stories–most of which were originally published in \"Weird Tales\", illustrates Derleth's original abilities in the genre. While Derleth considered his work in this genre less important than his most serious literary efforts, the compilers of these four anthologies, including Ramsey Campbell, note that the stories still resonate after more than fifty years.\n\nIn 2009, The Library of America selected Derleth's story \"The Panelled Room\" for inclusion in its two-century retrospective of American Fantastic Tales.\n\nDerleth also wrote many historical novels, as part of both the \"Sac Prairie Saga\" and the \"Wisconsin Saga\". He also wrote history; arguably most notable among these was \"The Wisconsin: River of a Thousand Isles\", published in 1942. The work was one in a series entitled \"The Rivers of America\", conceived by writer Constance Lindsay Skinner in the Great Depression as a series that would connect Americans to their heritage through the history of the great rivers of the nation. Skinner wanted the series to be written by artists, not academicians. Derleth, while not a trained historian, was, according to former Wisconsin state historian William F. Thompson, \"...a very competent regional historian who based his historical writing upon research in the primary documents and who regularly sought the help of professionals... .\" In the foreword to the 1985 reissue of the work by The University of Wisconsin Press, Thompson concluded: \"No other writer, of whatever background or training, knew and understood his particular 'corner of the earth' better than August Derleth.\"\n\nDerleth wrote several volumes of poems, as well as biographies of Zona Gale, Ralph Waldo Emerson and Henry David Thoreau.\n\nHe also wrote introductions to several collections of classic early 20th century comics, such as \"Buster Brown\", \"Little Nemo in Slumberland\", and \"Katzenjammer Kids\", as well as a book of children's poetry entitled \"A Boy's Way\", and the foreword to \"Tales from an Indian Lodge\" by \"Phebe Jewell Nichols.\" Derleth also wrote under the noms de plume Stephen Grendon, Kenyon Holmes and Tally Mason.\n\nDerleth's papers and comic book collection (valued at a considerable sum upon his death) were donated to the Wisconsin Historical Society in Madison.\n\n\n\n Horror & Lovecraft-Mythos\n\nScience fiction\n\nOther\n\n\n\n\n\n\n\n\n\n\n", "id": "980", "title": "August Derleth"},{"url": "https://en.wikipedia.org/wiki?curid=981", "text": "Alps\n\nThe Alps (; ; ; ; ; ) are the highest and most extensive mountain range system that lies entirely in Europe, stretching approximately across eight Alpine countries: Austria, France, Germany, Italy, Liechtenstein, Monaco, Slovenia, and Switzerland. The mountains were formed over tens of millions of years as the African and Eurasian tectonic plates collided. Extreme shortening caused by the event resulted in marine sedimentary rocks rising by thrusting and folding into high mountain peaks such as Mont Blanc and the Matterhorn. Mont Blanc spans the French–Italian border, and at is the highest mountain in the Alps. The Alpine region area contains about a hundred peaks higher than 4000 metres (just over 13,000 feet).\n\nThe altitude and size of the range affects the climate in Europe; in the mountains precipitation levels vary greatly and climatic conditions consist of distinct zones. Wildlife such as ibex live in the higher peaks to elevations of , and plants such as Edelweiss grow in rocky areas in lower elevations as well as in higher elevations. Evidence of human habitation in the Alps goes back to the Palaeolithic era. A mummified man, determined to be 5,000 years old, was discovered on a glacier at the Austrian–Italian border in 1991.\n\nBy the 6th century BC, the Celtic La Tène culture was well established. Hannibal famously crossed the Alps with a herd of elephants, and the Romans had settlements in the region. In 1800, Napoleon crossed one of the mountain passes with an army of 40,000. The 18th and 19th centuries saw an influx of naturalists, writers, and artists, in particular the Romantics, followed by the golden age of alpinism as mountaineers began to ascend the peaks. In World War II, Adolf Hitler kept a base of operation in the Bavarian Alps throughout the war.\n\nThe Alpine region has a strong cultural identity. The traditional culture of farming, cheesemaking, and woodworking still exists in Alpine villages, although the tourist industry began to grow early in the 20th century and expanded greatly after World War II to become the dominant industry by the end of the century. The Winter Olympic Games have been hosted in the Swiss, French, Italian, Austrian and German Alps. At present, the region is home to 14 million people and has 120 million annual visitors.\n\nThe English word \"Alps\" derives from the Latin \"Alpes\" (through French). Maurus Servius Honoratus, an ancient commentator of Virgil, says in his commentary (\"A.\" X 13) that all high mountains are called \"Alpes\" by Celts. The term may be common to Italo-Celtic, because the Celtic languages have terms for high mountains derived from \"alp\".\n\nThis may be consistent with the theory that in Greek \"Alpes\" is a name of non-Indo-European origin (which is common for prominent mountains and mountain ranges in the Mediterranean region). According to the Old English Dictionary, the Latin \"Alpes\" might possibly derive from a pre-Indo-European word *\"alb\" \"hill\"; \"Albania\" is a related derivation. Albania, a name not native to the region known as the country of Albania, has been used as a name for a number of mountainous areas across Europe. In Roman times, \"Albania\" was a name for the eastern Caucasus, while in the English languages \"Albania\" (or \"Albany\") was occasionally used as a name for Scotland, although many scholars point out this is more likely derived from the Latin \"albus\", the color white.\n\nIn modern languages the term \"alp\", \"alm\", \"albe\" or \"alpe\" refers to a grazing pastures in the alpine regions below the glaciers, not the peaks. An \"alp\" refers to a high mountain pasture where cows are taken to be grazed during the summer months and where hay barns can be found, and the term \"the Alps\", referring to the mountains, is a misnomer. The term for the mountain peaks varies by nation and language: words such as \"Horn\", \"Kogel\", \"Kopf\", \"Gipfel\", \"Spitze\", \"Stock\", and \"Berg\" are used in German speaking regions; \"Mont\", \"Pic\", \"Tête\", \"Pointe\", \"Dent\", \"Roche\", and \"Aiguille\" in French speaking regions; and \"Monte\", \"Picco\", \"Corno\", \"Punta\", \"Pizzo\", or \"Cima\" in Italian speaking regions.\n\nThe Alps are a crescent shaped geographic feature of central Europe that ranges in a arc from east to west and is in width. The mean height of the mountain peaks is . The range stretches from the Mediterranean Sea north above the Po basin, extending through France from Grenoble, and stretching eastward through mid and southern Switzerland. The range continues onward toward Vienna, Austria, and east to the Adriatic Sea and Slovenia. To the south it dips into northern Italy and to the north extends to the southern border of Bavaria in Germany. In areas like Chiasso, Switzerland, and Allgäu, Bavaria, the demarcation between the mountain range and the flatlands are clear; in other places such as Geneva, the demarcation is less clear. The countries with the greatest alpine territory are Switzerland, France, Austria and Italy.\n\nThe highest portion of the range is divided by the glacial trough of the Rhone valley, with the Pennine Alps from Mont Blanc to the Matterhorn and Monte Rosa on the southern side, and the Bernese Alps on the northern. The peaks in the easterly portion of the range, in Austria and Slovenia, are smaller than those in the central and western portions.\n\nThe variances in nomenclature in the region spanned by the Alps makes classification of the mountains and subregions difficult, but a general classification is that of the Eastern Alps and Western Alps with the divide between the two occurring in eastern Switzerland according to geologist Stefan Schmid, near the Splügen Pass.\n\nThe highest peaks of the Western Alps and Eastern Alps, respectively, are Mont Blanc, at and Piz Bernina at . The second-highest major peaks are Monte Rosa at and Ortler at , respectively\n\nSeries of lower mountain ranges run parallel to the main chain of the Alps, including the French Prealps in France and the Jura Mountains in Switzerland and France. The secondary chain of the Alps follows the watershed from the Mediterranean Sea to the Wienerwald, passing over many of the highest and most well-known peaks in the Alps. From the Colle di Cadibona to Col de Tende it runs westwards, before turning to the northwest and then, near the Colle della Maddalena, to the north. Upon reaching the Swiss border, the line of the main chain heads approximately east-northeast, a heading it follows until its end near Vienna.\n\nThe Alps have been crossed for war and commerce, and by pilgrims, students and tourists. Crossing routes by road, train or foot are known as \"passes\", and usually consist of depressions in the mountains in which a valley leads from the plains and hilly pre-mountainous zones. In the medieval period hospices were established by religious orders at the summits of many of the main passes. The most important passes are the Col de l'Iseran (the highest), the Brenner Pass, the Mont-Cenis, the Great St. Bernard Pass, the Col de Tende, the Gotthard Pass, the Semmering Pass, the Simplon Pass, and the Stelvio Pass.\nCrossing the Italian-Austrian border, the Brenner Pass separates the Ötztal Alps and Zillertal Alps and has been in use as a trading route since the 14th century. The lowest of the Alpine passes at , the Semmering crosses from Lower Austria to Styria; since the 12th century when a hospice was built there it has seen continuous use. A railroad with a tunnel long was built along the route of the pass in the mid-19th century. With a summit of , the Great St. Bernard Pass is one of the highest in the Alps, crossing the Italian-Swiss border east of the Pennine Alps along the flanks of Mont Blanc. The pass was used by Napoleon Bonaparte to cross 40,000 troops in 1800. \n\nThe Mont Cenis pass has been a major commercial and military road between Western Europe and Italy. The pass was crossed by many troops on their way to the Italian peninsula. From Constantine I, Pepin the Short and Charlemagne to Henry IV, Napoléon and more recently the German Gebirgsjägers during World War II.\nNow the pass has been supplanted by the Fréjus Road (opened 1980) and Rail Tunnel (opened 1871).\n\nThe Saint Gotthard Pass crosses from Central Switzerland to Ticino; in 1882 the long Saint Gotthard Railway Tunnel was opened connecting Lucerne in Switzerland, with Milan in Italy. 98 years later followed Gotthard Road Tunnel ( long) connecting the A2 motorway in Göschenen on the German-Swiss side with Airolo on the Italian-Swiss side, exactly like the railway tunnel. On 1 June 2016 the world's longest railway tunnel, the Gotthard Base Tunnel was opened, which connects Erstfeld in canton of Uri with Bodio in canton of Ticino by two single tubes of . It is the first tunnel, which traverses the Alps on ground level. From 11 December 2016 it will be part of the official railway timetable for 2017 and be used hourly as standard way to ride between Basel/Luzern/Zurich and Bellinzona/Lugano/Milano.\n\nThe highest pass in the alps is the col de l'Iseran in Savoy (France) at , followed by the Stelvio Pass in northern Italy at ; the road was built in the 1820s.\n\nImportant geological concepts were established as naturalists began studying the rock formations of the Alps in the 18th century. In the mid-19th century the now defunct theory of geosynclines was used to explain the presence of \"folded\" mountain chains but by the mid-20th century the theory of plate tectonics became widely accepted.\n\nThe formation of the Alps (the Alpine orogeny) was an episodic process that began about 300 million years ago. In the Paleozoic Era the Pangaean supercontinent consisted of a single tectonic plate; it broke into separate plates during the Mesozoic Era and the Tethys sea developed between Laurasia and Gondwana during the Jurassic Period. The Tethys was later squeezed between colliding plates causing the formation of mountain ranges called the Alpide belt, from Gibraltar through the Himalayas to Indonesia—a process that began at the end of the Mesozoic and continues into the present. The formation of the Alps was a segment of this orogenic process, caused by the collision between the African and the Eurasian plates that began in the late Cretaceous Period.\n\nUnder extreme compressive stresses and pressure, marine sedimentary rocks were uplifted, creating characteristic recumbent folds, or \"nappes\", and thrust faults. As the rising peaks underwent erosion, a layer of marine flysch sediments was deposited in the foreland basin, and the sediments became involved in younger nappes (folds) as the orogeny progressed. Coarse sediments from the continual uplift and erosion were later deposited in foreland areas as molasse. The molasse regions in Switzerland and Bavaria were well-developed and saw further upthrusting of flysch.\nThe Alpine orogeny occurred in ongoing cycles through to the Paleogene causing differences in nappe structures, with a late-stage orogeny causing the development of the Jura Mountains. A series of tectonic events in the Triassic, Jurassic and Cretaceous periods caused different paleogeographic regions. The Alps are subdivided by different lithology (rock composition) and nappe structure according to the orogenic events that affected them. The geological subdivision differentiates the Western, Eastern Alps and Southern Alps: the Helveticum in the north, the Penninicum and Austroalpine system in the centre and, south of the Periadriatic Seam, the Southern Alpine system.\n\nAccording to geologist Stefan Schmid, because the Western Alps underwent a metamorphic event in the Cenozoic Era while the Austroalpine peaks underwent an event in the Cretaceous Period, the two areas show distinct differences in nappe formations. Flysch deposits in the Southern Alps of Lombardy probably occurred in the Cretaceous or later.\n\nPeaks in France, Italy and Switzerland lie in the \"Houillière zone\", which consists of basement with sediments from the Mesozoic Era. High \"massifs\" with external sedimentary cover are more common in the Western Alps and were affected by Neogene Period thin-skinned thrusting whereas the Eastern Alps have comparatively few high peaked massifs. Similarly the peaks in eastern Switzerland extending to western Austria (Helvetic nappes) consist of thin-skinned sedimentary folding that detached from former basement rock.\n\nIn simple terms the structure of the Alps consists of layers of rock of European, African and oceanic (Tethyan) origin. The bottom nappe structure is of continental European origin, above which are stacked marine sediment nappes, topped off by nappes derived from the African plate. The Matterhorn is an example of the ongoing orogeny and shows evidence of great folding. The tip of the mountain consists of gneisses from the African plate; the base of the peak, below the glaciated area, consists of European basement rock. The sequence of Tethyan marine sediments and their oceanic basement is sandwiched between rock derived from the African and European plates.\n\nThe core regions of the Alpine orogenic belt have been folded and fractured in such a manner that erosion created the characteristic steep vertical peaks of the Swiss Alps that rise seemingly straight out of the foreland areas. Peaks such as Mont Blanc, the Matterhorn, and high peaks in the Pennine Alps, the Briançonnais, and Hohe Tauern consist of layers of rock from the various orogenies including exposures of basement rock.\n\nThe Union Internationale des Associations d'Alpinisme (UIAA) has defined a list of 82 \"official\" Alpine summits that reach at least . The list includes not only mountains, but also subpeaks with little prominence that are considered important mountaineering objectives. Below are listed the 22 \"four-thousanders\" with at least of prominence.\n\nWhile Mont Blanc was first climbed in 1786, most of the Alpine four-thousanders were climbed during the second half of the 19th century; the ascent of the Matterhorn in 1865 marked the end of the golden age of alpinism. Karl Blodig (1859–1956) was among the first to successfully climb all the major 4,000 m peaks. He completed his series of ascents in 1911.\n\nThe first British Mont Blanc ascent was in 1788; the first female ascent in 1819. By the mid-1850s Swiss mountaineers had ascended most of the peaks and were eagerly sought as mountain guides. Edward Whymper reached the top of the Matterhorn in 1865 (after seven attempts), and in 1938 the last of the six great north faces of the Alps was climbed with the first ascent of the Eiger \"Nordwand\" (north face of the Eiger).\n\nThe Alps are a source of minerals that have been mined for thousands of years. In the 8th to 6th centuries BC during the Hallstatt culture, Celtic tribes mined copper; later the Romans mined gold for coins in the Bad Gastein area. Erzberg in Styria furnishes high-quality iron ore for the steel industry. Crystals are found throughout much of the Alpine region such as cinnabar, amethyst, and quartz. The cinnabar deposits in Slovenia are a notable source of cinnabar pigments.\n\nAlpine crystals have been studied and collected for hundreds of years, and began to be classified in the 18th century. Leonhard Euler studied the shapes of crystals, and by the 19th century crystal hunting was common in Alpine regions. David Friedrich Wiser amassed a collection of 8000 crystals that he studied and documented. In the 20th century Robert Parker wrote a well-known work about the rock crystals of the Swiss Alps; at the same period a commission was established to control and standardize the naming of Alpine minerals.\n\nIn the Miocene Epoch the mountains underwent severe erosion because of glaciation, which was noted in the mid-19th century by naturalist Louis Agassiz who presented a paper proclaiming the Alps were covered in ice at various intervals—a theory he formed when studying rocks near his Neuchâtel home which he believed originated to the west in the Bernese Oberland. Because of his work he came to be known as the \"father of the ice-age concept\" although other naturalists before him put forth similar ideas.\n\nAgassiz studied glacier movement in the 1840s at the Unteraar Glacier where he found the glacier moved per year, more rapidly in the middle than at the edges. His work was continued by other scientists and now a permanent laboratory exists inside a glacier under the Jungfraujoch, devoted exclusively to the study of Alpine glaciers.\n\nGlaciers pick up rocks and sediment with them as they flow. This causes erosion and the formation of valleys over time. The Inn valley is an example of a valley carved by glaciers during the ice ages with a typical terraced structure caused by erosion. Eroded rocks from the most recent ice age lie at the bottom of the valley while the top of the valley consists of erosion from earlier ice ages. Glacial valleys have characteristically steep walls (reliefs); valleys with lower reliefs and talus slopes are remnants of glacial troughs or previously infilled valleys. Moraines, piles of rock picked up during the movement of the glacier, accumulate at edges, centre and the terminus of glaciers.\n\nAlpine glaciers can be straight rivers of ice, long sweeping rivers, spread in a fan-like shape (Piedmont glaciers), and curtains of ice that hang from vertical slopes of the mountain peaks. The stress of the movement causes the ice to break and crack loudly, perhaps explaining why the mountains were believed to be home to dragons in the medieval period. The cracking creates unpredictable and dangerous crevasses, often invisible under new snowfall, which cause the greatest danger to mountaineers.\n\nGlaciers end in ice caves (the Rhone Glacier), by trailing into a lake or river, or by shedding snowmelt on a meadow. Sometimes a piece of glacier will detach or break resulting in flooding, property damage and loss of life. In the 17th century about 2500 people were killed by an avalanche in a village on the French-Italian border; in the 19th century 120 homes in a village near Zermatt were destroyed by an avalanche.\n\nHigh levels of precipitation cause the glaciers to descend to permafrost levels in some areas whereas in other, more arid regions, glaciers remain above about the level. The of the Alps covered by glaciers in 1876 had shrunk to by 1973, resulting in decreased river run-off levels. Forty percent of the glaciation in Austria has disappeared since 1850, and 30% of that in Switzerland.\n\nThe Alps provide lowland Europe with drinking water, irrigation, and hydroelectric power. Although the area is only about 11 percent of the surface area of Europe, the Alps provide up to 90 percent of water to lowland Europe, particularly to arid areas and during the summer months. Cities such as Milan depend on 80 percent of water from Alpine runoff. Water from the rivers is used in over 500 hydroelectricity power plants, generating as much as 2900 GWh of electricity.\n\nMajor European rivers flow from Switzerland, such as the Rhine, the Rhône, the Inn, the Ticino and the Po, all of which have headwaters in the Alps and flow into neighbouring countries, finally emptying into the North Sea, the Mediterranean Sea, the Adriatic Sea and the Black Sea. Other rivers such as the Danube have major tributaries flowing into them that originate in the Alps. The Rhone is second to the Nile as a freshwater source to the Mediterranean Sea; the river begins as glacial meltwater, flows into Lake Geneva, and from there to France where one of its uses is to cool nuclear power plants. The Rhine originates in a 30 square kilometre area in Switzerland and represents almost 60 percent of water exported from the country. Tributary valleys, some of which are complicated, channel water to the main valleys which can experience flooding during the snow melt season when rapid runoff causes debris torrents and swollen rivers.\n\nThe rivers form lakes, such as Lake Geneva, a crescent shaped lake crossing the Swiss border with Lausanne on the Swiss side and the town of Evian-les-Bains on the French side. In Germany, the medieval St. Bartholomew's chapel was built on the south side of the Königssee, accessible only by boat or by climbing over the abutting peaks.\n\nScientists have been studying the impact of climate change and water use. For example, each year more water is diverted from rivers for snowmaking in the ski resorts, the effect of which is yet unknown. Furthermore, the decrease of glaciated areas combined with a succession of winters with lower-than-expected precipitation may have a future impact on the rivers in the Alps as well as an effect on the water availability to the lowlands.\n\nThe Alps are a classic example of what happens when a temperate area at lower altitude gives way to higher-elevation terrain. Elevations around the world that have cold climates similar to those of the polar regions have been called Alpine. A rise from sea level into the upper regions of the atmosphere causes the temperature to decrease (see adiabatic lapse rate). The effect of mountain chains on prevailing winds is to carry warm air belonging to the lower region into an upper zone, where it expands in volume at the cost of a proportionate loss of temperature, often accompanied by precipitation in the form of snow or rain. The height of the Alps is sufficient to divide the weather patterns in Europe into a wet north and a dry south because moisture is sucked from the air as it flows over the high peaks.\n\nThe severe weather in the Alps has been studied since the 18th century; particularly the weather patterns such as the seasonal foehn wind. Numerous weather stations were placed in the mountains early in the early 20th century, providing continuous data for climatologists. Some of the valleys are quite arid such as the Aosta valley in Italy, the Maurienne in France, the Valais in Switzerland, and northern Tyrol.\n\nThe areas that are not arid and receive high precipitation experience periodic flooding from rapid snowmelt and runoff. The mean precipitation in the Alps ranges from a low of per year to per year, with the higher levels occurring at high altitudes. At altitudes between , snowfall begins in November and accumulates through to April or May when the melt begins. Snow lines vary from , above which the snow is permanent and the temperatures hover around the freezing point even July and August. High-water levels in streams and rivers peak in June and July when the snow is still melting at the higher altitudes.\n\nThe Alps are split into five climatic zones, each with different vegetation. The climate, plant life and animal life vary among the different sections or zones of the mountains. The lowest zone is the colline zone, which exists between , depending on the location. The montane zone extends from , followed by the sub-Alpine zone from . The Alpine zone, extending from tree line to snow line, is followed by the glacial zone, which covers the glaciated areas of the mountain. Climatic conditions show variances within the same zones; for example, weather conditions at the head of a mountain valley, extending directly from the peaks, are colder and more severe than those at the mouth of a valley which tend to be less severe and receive less snowfall.\n\nVarious models of climate change have been projected into the 22nd century for the Alps, with an expectation that a trend toward increased temperatures will have an effect on snowfall, snowpack, glaciation, and river runoff. Significant changes, of both natural and anthropogenic origins, have already been diagnosed from observations.\n\nThirteen thousand species of plants have been identified in the Alpine regions. Alpine plants are grouped by habitat and soil type which can be limestone or non-calcareous. The habitats range from meadows, bogs, woodland (deciduous and coniferous) areas to soil-less scree and moraines, and rock faces and ridges. A natural vegetation limit with altitude is given by the presence of the chief deciduous trees—oak, beech, ash and sycamore maple. These do not reach exactly to the same elevation, nor are they often found growing together; but their upper limit corresponds accurately enough to the change from a temperate to a colder climate that is further proved by a change in the presence of wild herbaceous vegetation. This limit usually lies about above the sea on the north side of the Alps, but on the southern slopes it often rises to , sometimes even to .\n\nAbove the forestry, there is often a band of short pine trees (\"Pinus mugo\"), which is in turn superseded by \"Alpenrosen\", dwarf shrubs, typically \"Rhododendron ferrugineum\" (on acid soils) or \"Rhododendron hirsutum\" (on alkaline soils). Although the Alpenrose prefers acidic soil, the plants are found throughout the region. Above the tree line is the area defined as \"alpine\" where in the alpine meadow plants are found that have adapted well to harsh conditions of cold temperatures, aridity, and high altitudes. The alpine area fluctuates greatly because of regional fluctuations in tree lines.\n\nAlpine plants such as the Alpine gentian grow in abundance in areas such as the meadows above the Lauterbrunnental. Gentians are named after the Illyrian king Gentius, and 40 species of the early-spring blooming flower grow in the Alps, in a range of . Writing about the gentians in Switzerland D. H. Lawrence described them as \"darkening the day-time, torch-like with the smoking blueness of Pluto's gloom.\" Gentians tend to \"appear\" repeatedly as the spring blooming takes place at progressively later dates, moving from the lower altitude to the higher altitude meadows where the snow melts much later than in the valleys. On the highest rocky ledges the spring flowers bloom in the summer.\n\nAt these higher altitudes, the plants tend to form isolated cushions. In the Alps, several species of flowering plants have been recorded above , including \"Ranunculus glacialis\", \"Androsace alpina\" and \"Saxifraga biflora\". \"Eritrichium nanum\", commonly known as the King of the Alps, is the most elusive of the alpine flowers, growing on rocky ridges at . Perhaps the best known of the alpine plants is Edelweiss which grows in rocky areas and can be found at altitudes as low as and as high as . The plants that grow at the highest altitudes have adapted to conditions by specialization such as growing in rock screes that give protection from winds.\n\nThe extreme and stressful climatic conditions give way to the growth of plant species with secondary metabolites important for medicinal purposes. Origanum vulgare, Prunella vulgaris, Solanum nigrum and Urtica dioica are some of the more useful medicinal species found in the Alps.\n\nHuman interference has nearly exterminated the trees in many areas, and, except for the beech forests of the Austrian Alps, forests of deciduous trees are rarely found after the extreme deforestation between the 17th and 19th centuries. The vegetation has changed since the second half of the 20th century, as the high alpine meadows cease to be harvested for hay or used for grazing which eventually might result in a regrowth of forest. In some areas the modern practice of building ski runs by mechanical means has destroyed the underlying tundra from which the plant life cannot recover during the non-skiing months, whereas areas that still practice a natural \"piste\" type of ski slope building preserve the fragile underlayers.\n\nThe Alps are a habitat for 30,000 species of wildlife, ranging from the tiniest snow fleas to brown bears, many of which have made adaptations to the harsh cold conditions and high altitudes to the point that some only survive in specific micro-climates either directly above or below the snow line.\n\nThe largest mammal to live in the highest altitudes are the alpine ibex, which have been sighted as high as . The ibex live in caves and descend to eat the succulent alpine grasses. Classified as antelopes, chamois are smaller than ibex and found throughout the Alps, living above the tree line and are common in the entire alpine range. Areas of the eastern Alps are still home to brown bears. In Switzerland the canton of Bern was named for the bears but the last bear is recorded as having been killed in 1792 above Kleine Scheidegg by three hunters from Grindelwald.\n\nMany rodents such as voles live underground. Marmots live almost exclusively above the tree line as high as . They hibernate in large groups to provide warmth, and can be found in all areas of the Alps, in large colonies they build beneath the alpine pastures. Golden eagles and bearded vultures are the largest birds to be found in the Alps; they nest high on rocky ledges and can be found at altitudes of . The most common bird is the alpine chough which can be found scavenging at climber's huts or at the Jungfraujoch, a high altitude tourist destination.\n\nReptiles such as adders and vipers live up to the snow line; because they cannot bear the cold temperatures they hibernate underground and soak up the warmth on rocky ledges. The high-altitude Alpine salamanders have adapted to living above the snow line by giving birth to fully developed young rather than laying eggs. Brown trout can be found in the streams up to the snow line. Molluscs such as the wood snail live up the snow line. Popularly gathered as food, the snails are now protected.\n\nA number of species of moths live in the Alps, some of which are believed to have evolved in the same habitat up to 120 million years ago, long before the Alps were created. Blue moths can commonly be seen drinking from the snow melt; some species of blue moths fly as high as . The butterflies tend to be large, such as those from the swallowtail Parnassius family, with a habitat that ranges to . Twelve species of beetles have habitats up to the snow line; the most beautiful and formerly collected for its colours but now protected is \"Rosalia alpina\". Spiders, such as the large wolf spider, live above the snow line and can be seen as high as . Scorpions can be found in the Italian Alps.\n\nSome of the species of moths and insects show evidence of having been indigenous to the area from as long ago as the Alpine orogeny. In Emosson in Valais, Switzerland, dinosaur tracks were found in the 1970s, dating probably from the Triassic Period.\n\nAbout 10,000 years ago, when the ice melted after the last glacial period, late Palaeolithic communities were established along the lake shores and in cave systems. Evidence of human habitation has been found in caves near Vercors, close to Grenoble; in Austria the Mondsee culture shows evidence of houses built on piles to keep them dry. Standing stones have been found in Alpine areas of France and Italy. The rock drawings in Valcamonica are more than 5000 years old; more than 200,000 drawings and etchings have been identified at the site.\n\nIn 1991 a mummy of a neolithic body, known as Ötzi the Iceman, was discovered by hikers on the Similaun glacier. His clothing and gear indicate that he lived in an alpine farming community, while the location and manner of his death – an arrowhead was discovered in his shoulder – suggests he was travelling from one place to another. Analysis of the mitochondrial DNA of Ötzi, has shown that he belongs to the K1 subclade which cannot be categorized into any of the three modern branches of that subclade. The new subclade has provisionally been named \"K1ö\" for \"Ötzi\".\n\nCeltic tribes settled in Switzerland between 1000 and 1500 BC. The Raetians lived in the eastern regions, while the west was occupied by the Helvetii and the Allobrogi settled in the Rhone valley and in Savoy. Among the many substances Celtic tribes mined was salt in areas such as Salzburg in Austria where evidence of the Hallstatt culture was found by a mine manager in the 19th century. By the 6th century BC the La Tène culture was well established in the region, and became known for high quality decorated weapons and jewellery. The Celts were the most widespread of the mountain tribes—they had warriors that were strong, tall and fair skinned, and skilled with iron weapons, which gave them an advantage in warfare.\n\nDuring the Second Punic War in 218 BC, the Carthaginian general Hannibal probably crossed the Alps with an army numbering 38,000 infantry, 8,000 cavalry, and 37 war elephants. This was one of the most celebrated achievements of any military force in ancient warfare, although no evidence exists of the actual crossing or the place of crossing. The Romans, however, had built roads along the mountain passes, which continued to be used through the medieval period to cross the mountains and Roman road markers can still be found on the mountain passes.\n\nThe Roman expansion brought the defeat of the Allobrogi in 121 BC and during the Gallic Wars in 58 BC Julius Caesar overcame the Helvetii. The Rhaetians continued to resist but were eventually conquered when the Romans turned northward to the Danube valley in Austria and defeated the Brigantes. The Romans built settlements in the Alps; towns such as Aosta (named for Augustus) in Italy, Martigny and Lausanne in Switzerland, and Partenkirchen in Bavaria show remains of Roman baths, villas, arenas and temples. Much of the Alpine region was gradually settled by Germanic tribes, (Lombards, Alemanni, Bavarii, and Franks) from the 6th to the 13th centuries mixing with the local Celtic tribes.\n\nChristianity was established in the region by the Romans, and saw the establishment of monasteries and churches in the high regions. The Frankish expansion of the Carolingian Empire and the Bavarian expansion in the eastern Alps introduced feudalism and the building of castles to support the growing number of dukedoms and kingdoms. Castello del Buonconsiglio in Trento, Italy, still has intricate frescoes, excellent examples of Gothic art, in a tower room. In Switzerland, Château de Chillon is preserved as an example of medieval architecture.\n\nMuch of the medieval period was a time of power struggles between competing dynasties such as the House of Savoy, the Visconti in northern Italy and the House of Habsburg in Austria and Slovenia. In 1291 to protect themselves from incursions by the Habsburgs, four cantons in the middle of Switzerland drew up a charter that is considered to be a declaration of independence from neighbouring kingdoms. After a series of battles fought in the 13th, 14th and 15th centuries, more cantons joined the confederacy and by the 16th century Switzerland was well-established as a separate state.\nDuring the Napoleonic Wars in the late 18th century and early 19th century, Napoleon annexed territory formerly controlled by the Habsburgs and Savoys. In 1798 he established the Helvetic Republic in Switzerland; two years later he led an army across the St. Bernard pass and conquered almost all of the Alpine regions.\n\nAfter the fall of Napoléon, many alpine countries developed heavy protections to prevent any new invasion. Thus, Savoy built a series of fortifications in the Maurienne valley in order to protect the major alpine passes, such as the col du Mont-Cenis that was even crossed by Charlemagne and his father to defeat the Lombards. The later indeed became very popular after the construction of a paved road ordered by Napoléon Bonaparte.\nThe Barrière de l'Esseillon is a serie of forts with heavy batteries, built on a cliff with a perfect view on the valley, a gorge on one side and steep mountains on the other side.\n\nIn the 19th century, the monasteries built in the high Alps during the medieval period to shelter travellers and as places of pilgrimage, became tourist destinations. The Benedictines had built monasteries in Lucerne, Switzerland, and Oberammergau; the Cistercians in the Tyrol and at Lake Constance; and the Augustinians had abbeys in the Savoy and one in the centre of Interlaken, Switzerland. The Great St Bernard Hospice, built in the 9th or 10th centuries, at the summit of the Great Saint Bernard Pass was shelter for travellers and place for pilgrims since its inception; by the 19th century it became a tourist attraction with notable visitors such as author Charles Dickens and mountaineer Edward Whymper.\n\nRadiocarbon dated charcoal placed around 50,000 years ago was found in the \"Drachloch\" (Dragon's Hole) cave above the village of Vattis in the canton of St. Gallen, proving that the high peaks were visited by prehistoric people. Seven bear skulls from the cave may have been buried by the same prehistoric people. The peaks, however, were mostly ignored except for a few notable examples, and long left to the exclusive attention of the people of the adjoining valleys. The mountain peaks were seen as terrifying, the abode of dragons and demons, to the point that people blindfolded themselves to cross the Alpine passes. The glaciers remained a mystery and many still believed the highest areas to be inhabited by dragons.\n\nCharles VII of France ordered his chamberlain to climb Mont Aiguille in 1356. The knight reached the summit of Rocciamelone where he left a bronze triptych of three crosses, a feat which he conducted with the use of ladders to traverse the ice. In 1492 Antoine de Ville climbed Mont Aiguille, without reaching the summit, an experience he described as \"horrifying and terrifying.\" Leonardo da Vinci was fascinated by variations of light in the higher altitudes, and climbed a mountain—scholars are uncertain which one; some believe it may have been Monte Rosa. From his description of a \"blue like that of a gentian\" sky it is thought that he reached a significantly high altitude. In the 18th century four Chamonix men almost made the summit of Mont Blanc but were overcome by altitude sickness and snowblindness.\n\nConrad Gessner was the first naturalist to ascend the mountains in the 16th century, to study them, writing that in the mountains he found the \"theatre of the Lord\". By the 19th century more naturalists began to arrive to explore, study and conquer the high peaks. Two men who first explored the regions of ice and snow were Horace-Bénédict de Saussure (1740–1799) in the Pennine Alps, and the Benedictine monk of Disentis Placidus a Spescha (1752–1833). Born in Geneva, Saussure was enamoured with the mountains from an early age; he left a law career to become a naturalist and spent many years trekking through the Bernese Oberland, the Savoy, the Piedmont and Valais, studying the glaciers and the geology, as he became an early proponent of the theory of rock upheaval. Saussure, in 1787, was a member of the third ascent of Mont Blanc—today the summits of all the peaks have been climbed.\n\nAlbrecht von Haller's poem \"Die Alpen\" (1732) described the mountains as an area of mythical purity. Jean-Jacques Rousseau was another writer who presented the Alps as a place of allure and beauty, in his novel \"Julie, or the New Heloise\" (1761), Later the first wave of Romantics such as Goethe and Turner came to admire the scenery; Wordsworth visited the area in 1790, writing of his experiences in \"The Prelude\" (1799). Schiller later wrote the play \"William Tell\" (1804), which tells the story the legendary Swiss marksman William Tell as part of the greater Swiss struggle for independence from the Habsburg Empire in the early 14th century. At the end of the Napoleonic Wars, the Alpine countries began to see an influx of poets, artists, and musicians, as visitors came to experience the sublime effects of monumental nature.\n\nIn 1816 Byron, Percy Bysshe Shelley and his wife Mary Shelley visited Geneva and all three were inspired by the scenery in their writings. During these visits Shelley wrote the poem \"Mont Blanc\", Byron wrote \"The Prisoner of Chillon\" and the dramatic poem \"Manfred\", and Mary Shelley, who found the scenery overwhelming, conceived the idea for the novel \"Frankenstein\" in her villa on the shores of Lake Geneva in the midst of a thunderstorm. When Coleridge travelled to Chamonix, he declaimed, in defiance of Shelley, who had signed himself \"Atheos\" in the guestbook of the Hotel de Londres near Montenvers, \"Who would be, who could be an atheist in this valley of wonders\".\n\nBy the mid-19th century scientists began to arrive en masse to study the geology and ecology of the region.\n\nAustrian-born Adolf Hitler had a lifelong romantic fascination with the Alps and by the 1930s established a home in the Obersalzberg region outside of Berchtesgaden. His first visit to the area was in 1923 and he maintained a strong tie there until the end of his life. At the end of World War II the US Army occupied Obersalzberg, to prevent Hitler from retreating with the Wehrmacht into the mountains.\n\nBy 1940 the Third Reich had occupied many of the Alpine countries. Austria underwent a political coup that made it part of the Third Reich; France had been invaded and Italy was a fascist regime. Switzerland was the only country to avoid invasion. The Swiss Confederation mobilized its troops—the country follows the doctrine of \"armed neutrality\" with all males required to have military training—a number that General Eisenhower estimated to be about 850,000. The Swiss commanders wired the infrastructure leading into the country with explosives, and threatened to destroy bridges, railway tunnels and roads across passes in the event of a Nazi invasion; and if there was an invasion the Swiss army would then retreated to the heart of the mountain peaks, where conditions were harsher, and a military invasion would involve difficult and protracted battles.\n\nGerman Ski troops were trained for the war, and battles were waged in mountainous areas such as the battle at Riva Ridge in Italy, where the American 10th Mountain Division encountered heavy resistance in February 1945. At the end of the war, a substantial amount of Nazi plunder was found stored in Austria, where Hitler had hoped to retreat as the war drew to a close. The salt mines surrounding the Altaussee area, where American troops found 75 kilos of gold coins stored in a single mine, were used to store looted art, jewels, and currency; vast quantities of looted art were found and returned to the owners.\n\nThe population of the region is 14 million spread across eight countries. On the rim of the mountains, on the plateaus and the plains the economy consists of manufacturing and service jobs whereas in the higher altitudes and in the mountains farming is still essential to the economy. Farming and forestry continue to be mainstays of Alpine culture, industries that provide for export to the cities and maintain the mountain ecology.\nMuch of the Alpine culture is unchanged since the medieval period when skills that guaranteed survival in the mountain valleys and in the highest villages became mainstays, leading to strong traditions of carpentry, woodcarving, baking and pastry-making, and cheesemaking.\n\nFarming had been a traditional occupation for centuries, although it became less dominant in the 20th century with the advent of tourism. Grazing and pasture land are limited because of the steep and rocky topography of the Alps. In mid-June cows are moved to the highest pastures close to the snowline, where they are watched by herdsmen who stay in the high altitudes often living in stone huts or wooden barns during the summers. Villagers celebrate the day the cows are herded up to the pastures and again when they return in mid-September. The Almabtrieb, Alpabzug, Alpabfahrt, Désalpes («coming down from the alps») is celebrated by decorating the cows with garlands and enormous cowbells while the farmers dress in traditional costumes.\n\nCheesemaking is an ancient tradition in most Alpine countries. A wheel of cheese from the Emmental in Switzerland can weigh up to , and the Beaufort in Savoy can weight up to . Owners of the cows traditionally receive from the cheesemakers a portion in relation to the proportion of the cows' milk from the summer months in the high alps. Haymaking is an important farming activity in mountain villages which has become somewhat mechanized in recent years, although the slopes are so steep that usually scythes are necessary to cut the grass. Hay is normally brought in twice a year, often also on festival days. Alpine festivals vary from country to country and often include the display of local costumes such as dirndl and trachten, the playing of Alpenhorns, wrestling matches, some pagan traditions such as Walpurgis Night and, in many areas, Carnival is celebrated before Lent.\n\nIn the high villages people live in homes built according to medieval designs that withstand cold winters. The kitchen is separated from the living area (called the \"stube\", the area of the home heated by a stove), and second-floor bedrooms benefit from rising heat. The typical Swiss chalet originated in the Bernese Oberland. Chalets often face south or downhill, and are built of solid wood, with a steeply gabled roof to allow accumulated snow to slide off easily. Stairs leading to upper levels are sometimes built on the outside, and balconies are sometimes enclosed.\nFood is passed from the kitchen to the stube, where the dining room table is placed. Some meals are communal, such as fondue, where a pot is set in the middle of the table for each person to dip into. Other meals are still served in a traditional manner on carved wooden plates. Furniture has been traditionally elaborately carved and in many Alpine countries carpentry skills are passed from generation to generation.\n\nRoofs are traditionally constructed from Alpine rocks such as pieces of schist, gneiss or slate. Such chalets are typically found in the higher parts of the valleys, as in the Maurienne valley in Savoy, where the amount of snow during the cold months is important. The inclination of the roof cannot exceed 40%, allowing the snow to stay on top, thereby functioning as insulation from the cold. In the lower areas where the forests are widespread, wooden tiles are traditionally used. Commonly made of Norway spruce, they are called \"tavaillon\".\nThe Alpine regions are multicultural and linguistically diverse. Dialects are common, and vary from valley to valley and region to region. In the Slavic Alps alone 19 dialects have been identified. Some of the French dialects spoken in the French, Swiss and Italian alps of Aosta Valley derive from Arpitan, while the southern part of the western range is related to Old Provençal; the German dialects derive from Germanic tribal languages. Romansh, spoken by two percent of the population in southeast Switzerland, is an ancient Rhaeto-Romanic language derived from Latin, remnants of ancient Celtic languages and perhaps Etruscan.\n\nThe Alps are one of the more popular tourist destinations in the world with many resorts such Oberstdorf, in Bavaria, Saalbach in Austria, Davos in Switzerland, Chamonix in France, and Cortina d'Ampezzo in Italy recording more than a million annual visitors. With over 120 million visitors a year, tourism is integral to the Alpine economy with much it coming from winter sports, although summer visitors are also an important component.\n\nThe tourism industry began in the early 19th century when foreigners visited the Alps, travelled to the bases of the mountains to enjoy the scenery, and stayed at the spa-resorts. Large hotels were built during the Belle Époque; cog-railways, built early in the 20th century, brought tourists to ever higher elevations, with the Jungfraubahn terminating at the Jungfraujoch, well above the eternal snow-line, after going through a tunnel in Eiger. During this period winter sports were slowly introduced: in 1882 the first figure skating championship was held in St. Moritz, and downhill skiing became a popular sport with English visitors early in the 20th century, as the first ski-lift was installed in 1908 above Grindelwald.\n\nIn the first half of the 20th century the Olympic Winter Games were held three times in Alpine venues: the 1924 Winter Olympics in Chamonix, France; the 1928 Winter Olympics in St. Moritz, Switzerland; and the 1936 Winter Olympics in Garmisch-Partenkirchen, Germany. During World War II the winter games were cancelled but after that time the Winter Games have been held in St. Moritz (1948), Cortina d'Ampezzo (1956), Innsbruck, Austria (1964 and 1976), Grenoble, France, (1968), Albertville, France, (1992), and Torino (2006). In 1930 the \"Lauberhorn Rennen\" (Lauberhorn Race), was run for the first time on the Lauberhorn above Wengen; the equally demanding Hahnenkamm was first run in the same year in Kitzbühl, Austria. Both races continue to be held each January on successive weekends. The Lauberhorn is the more strenuous downhill race at and poses danger to racers who reach within seconds of leaving the start gate.\n\nDuring the post-World War I period ski-lifts were built in Swiss and Austrian towns to accommodate winter visitors, but summer tourism continued to be important; by the mid-20th century the popularity of downhill skiing increased greatly as it became more accessible and in the 1970s several new villages were built in France devoted almost exclusively to skiing, such as Les Menuires. Until this point Austria and Switzerland had been the traditional and more popular destinations for winter sports, but by the end of the 20th century and into the early 21st century, France, Italy and the Tyrol began to see increases in winter visitors. From 1980 to the present, ski-lifts have been modernized and snow-making machines installed at many resorts, leading to concerns regarding the loss of traditional Alpine culture and questions regarding sustainable development as the winter ski industry continues to develop quickly and the number of summer tourists decline.\n\nThe region is serviced by of roads used by 6 million vehicles. Train travel is well established in the Alps, with, for instance of track for every in a country such as Switzerland. Most of Europe's highest railways are located there. On 2007 the new Lötschberg Base Tunnel has been opened, which circumvents the 100 years older Lötschberg Tunnel. With the opening of the Gotthard Base Tunnel on 1 June 2016 it bypasses the Gotthard Tunnel built in the 19th century and realizes the first flat route through the Alps.\n\nSome high mountain villages, such as Avoriaz (in France), Chamois (in Italy), Wengen, and Zermatt (in Switzerland) are accessible only by cable car or cog-rail trains, and are car free. Other villages in the Alps are considering becoming car free zones or limiting the number of cars for reasons of sustainability of the fragile Alpine terrain.\n\nThe lower regions and larger towns of the Alps are well-served by motorways and main roads, but higher mountain passes and byroads, which are amongst the highest in Europe, can be treacherous even in summer due to steep slopes. Many passes are closed in winter. A number of airports around the Alps (and some within), as well as long-distance rail links from all neighbouring countries, afford large numbers of travellers easy access.\nWorks cited\n\n", "id": "981", "title": "Alps"},{"url": "https://en.wikipedia.org/wiki?curid=983", "text": "Albert Camus\n\nAlbert Camus (; 7 November 1913 – 4 January 1960) was a French philosopher, author, and journalist. His views contributed to the rise of the philosophy known as absurdism. He wrote in his essay \"The Rebel\" that his whole life was devoted to opposing the philosophy of nihilism while still delving deeply into individual freedom. He won the Nobel Prize in Literature in 1957.\n\nCamus did not consider himself to be an existentialist despite usually being classified as a follower of it, even in his lifetime. In a 1945 interview, Camus rejected any ideological associations: \"No, I am not an existentialist. Sartre and I are always surprised to see our names linked.\"\n\nCamus was born in French Algeria to a \"Pied-Noir\" family and studied at the University of Algiers, from which he graduated in 1936. In 1949, Camus founded the Group for International Liaisons to \"denounce two ideologies found in both the USSR and the USA\".\n\nAlbert Camus was born on 7 November 1913 in Dréan (then known as Mondovi) in French Algeria. His mother was of Spanish descent and could only hear out of her left ear. His father, Lucien, a poor agricultural worker of Alsatian descent, was wounded in the Battle of the Marne in 1914 during World War I, while serving as a member of a Zouave infantry regiment. Lucien died from his wounds in a makeshift army hospital on 11 October. Camus and his mother, an illiterate house cleaner, lived without many basic material possessions during his childhood in the Belcourt section of Algiers.\n\nIn 1923, Camus was accepted into the and eventually was admitted to the University of Algiers. After he contracted tuberculosis in 1930, he had to end his football activities; he had been a goalkeeper for a prominent Algerian university team. In addition, he was only able to study part-time. To earn money, he took odd jobs: as a private tutor, car parts clerk, and assistant at the Meteorological Institute. He completed his \"licence de philosophie\" (BA) in 1936; in May 1936, he successfully presented his thesis on Plotinus, \"Rapports de l'hellénisme et du christianisme à travers les oeuvres de Plotin et de saint Augustin\" (\"Relationship of Greek and Christian thought in Plotinus and St. Augustine\"), for his \"\" (roughly equivalent to an MA thesis).\n\nCamus joined the French Communist Party in early 1935, seeing it as a way to \"fight inequalities between Europeans and 'natives' in Algeria.\" He did not suggest he was a Marxist or that he had read \"Das Kapital\", but did write, \"We might see communism as a springboard and asceticism that prepares the ground for more spiritual activities.\" In 1936, the independence-minded Algerian Communist Party (PCA) was founded. Camus joined the activities of the Algerian People's Party (\"Le Parti du Peuple Algérien\"), which got him into trouble with his Communist party comrades, who in 1937 denounced him as a Trotskyite and expelled him from the party. Camus then became associated with the French anarchist movement.\n\nThe anarchist André Prudhommeaux first introduced him at a meeting in 1948 of the \"Cercle des Étudiants Anarchistes\" (Anarchist Student Circle) as a sympathiser familiar with anarchist thought. Camus wrote for anarchist publications such as \"Le Libertaire\", \"La révolution Prolétarienne\", and \"Solidaridad Obrera\" (Workers' Solidarity), the organ of the anarcho-syndicalist CNT (National Confederation of Labor). Camus stood with the anarchists when they expressed support for the uprising of 1953 in East Germany. He again allied with the anarchists in 1956, first in support of the workers' uprising in Poznań, Poland, and then later in the year with the Hungarian Revolution.\n\nCamus was an agnostic. “I do not believe in God and I am not an atheist.” ~Notebooks 1951-1959.\n\nIn 1934, Camus married Simone Hié, but the marriage ended as a consequence of infidelities on both sides. In 1935, he founded \"Théâtre du Travail\" (Worker's Theatre), renamed \"Théâtre de l'Equipe\" (Theatre of the Team) in 1937. It lasted until 1939. From 1937 to 1939 he wrote for a socialist paper, \"Alger-Républicain\". His work included a report on the poor conditions for peasants in Kabylie, which apparently cost him his job. From 1939 to 1940, he briefly wrote for a similar paper, \"Soir-Republicain\". He was rejected by the French army because of his tuberculosis.\n\nIn 1940, Camus married Francine Faure, a pianist and mathematician. Although he loved her, he had argued passionately against the institution of marriage, dismissing it as unnatural. Even after Francine gave birth to twins, Catherine and Jean, on 5 September 1945, he continued to joke to friends that he was not cut out for marriage. Camus had numerous affairs, particularly an irregular and eventually public affair with the Spanish-born actress María Casares. In the same year, Camus began to work for \"Paris-Soir\" magazine. In the first stage of World War II, during the so-called Phoney War, Camus was a pacifist. While in Lyon during the Wehrmacht occupation, on 15 December 1941, Camus read about the Paris execution of Gabriel Péri; it crystallized his revolt against the Germans. He moved to Bordeaux with the rest of the staff of \"Paris-Soir\". In the same year he finished his first books, \"The Stranger\" and \"The Myth of Sisyphus\". He returned briefly to Oran, Algeria, in 1942.\n\nCamus was once asked by his friend Charles Poncet which he preferred, football or the theatre. Camus is said to have replied, \"Football, without hesitation.\"\n\nCamus played as goalkeeper for Racing Universitaire d'Alger (RUA won both the North African Champions Cup and the North African Cup twice each in the 1930s) junior team from 1928 to 1930. The sense of team spirit, fraternity, and common purpose appealed to Camus enormously. In match reports Camus would often attract positive comment for playing with passion and courage. Any football ambitions disappeared when he contracted tuberculosis at the age of 17. The affliction, which was then incurable, caused Camus to be bedridden for long and painful periods.\n\nWhen Camus was asked in the 1950s by an alumni sports magazine for a few words regarding his time with the RUA, his response included the following: \"After many years during which I saw many things, what I know most surely about morality and the duty of man I owe to sport and learned it in the RUA.\" Camus was referring to a sort of simplistic morality he wrote about in his early essays, the principle of sticking up for your friends, of valuing bravery and fair-play. Camus's belief was that political and religious authorities try to confuse us with over-complicated moral systems to make things appear more complex than they really are, potentially to serve their own needs.\n\nA professional footballer appears as a character in \"The Plague\" and football is discussed in the dialogue.\n\nAs he wrote in \"L'Homme révolté\" (\"The Rebel\"), in the chapter about \"The Thought on Midday\", Camus was a follower of the ancient Greek 'Solar Tradition' (la \"pensée solaire\"). In 1947–48, he founded the Revolutionary Union Movement (\"Groupes de liaison internationale\" – GLI) a trade union movement in the context of revolutionary syndicalism (\"Syndicalisme révolutionnaire\"). According to Olivier Todd, in his biography \"Albert Camus, une vie\", it was a group opposed to some tendencies of the Surrealist movement of André Breton. For more, see the book \"Alfred Rosmer et le mouvement révolutionnaire international\" by Christian Gras.\n\nHis colleagues were Nicolas Lazarévitch, Louis Mercier, Roger Lapeyre, Paul Chauvet, Auguste Largentier, Jean de Boë (see the article: \"Nicolas Lazarévitch, Itinéraire d'un syndicaliste révolutionnaire\" by Sylvain Boulouque in the review \"Communisme\", n° 61, 2000). His main aim was to express the positive side of surrealism and existentialism, rejecting the negativity and the nihilism of André Breton.\n\nFrom 1943, Albert Camus had correspondence with Altiero Spinelli who founded the European Federalist Movement in Milan—see Ventotene Manifesto and the book \"Unire l'Europa, superare gli stati\", Altiero Spinelli nel Partito d'Azione del Nord Italia e in Francia dal 1944 al 1945-annexed a letter by Altiero Spinelli to Albert Camus.\n\nIn 1944, Camus founded the \"French Committee for the European Federation\" (\"Comité Français pour la Féderation Européenne\" – CFFE) declaring that Europe \"can only evolve along the path of economic progress, democracy and peace if the nation states become a federation.\"\n\nFrom 22 to 25 March 1945, the first conference of the European Federalist Movement was organised in Paris with the participation of Albert Camus, George Orwell, Emmanuel Mounier, Lewis Mumford, André Philip, Daniel Mayer, François Bondy and Altiero Spinelli. This specific branch of the European Federalist Movement disintegrated in 1957 after Winston Churchill's ideas about European integration rose to dominance.\n\nCamus died on 4 January 1960 at the age of 46, in a car accident near Sens, in Le Grand Fossard in the small town of Villeblevin. In his coat pocket was an unused train ticket. He had planned to travel by train with his wife and children, but at the last minute he accepted his publisher's proposal to travel with him.\n\nThe driver of the Facel Vega HK500 car, , who was Camus's publisher and close friend, died five days after the accident. In August 2011, the Milan newspaper \"Corriere della Sera\" reported a theory that the writer had been the victim of a Soviet plot, but Camus's biographer, , did not consider it credible. Camus was buried in the Lourmarin Cemetery, Lourmarin, Vaucluse, France.\n\nHe was the second-youngest recipient, at the age of 44, of the Nobel Prize in Literature, after Rudyard Kipling, at the age of 42.\n\nHe was survived by his wife and twin son and daughter, Jean and Catherine, who hold the copyrights to his work.\n\nTwo of Camus's works were published posthumously. The first, entitled \"A Happy Death\" (1970), featured a character named Patrice Mersault, comparable to \"The Stranger\"<nowiki>'</nowiki>s Meursault. There is scholarly debate as to the relationship between the two books. The second was an unfinished novel, \"The First Man\" (1995), which Camus was writing before he died. The novel was an autobiographical work about his childhood in Algeria.\n\nThe first publication of Camus (co-written by Jeanne-Paule Sicard, Yves Bourgeois and Alfred Poignant, and edited by Edmond Charlot) was Revolte dans les Asturies in May 1936. This concerned a revolt by Spanish miners brutally suppressed by the Spanish government. In May 1937 he wrote his first book L’Envers et l’Endroit – dedicated to Jean Grenier and edited by Charlot.\nDuring the war Camus joined the French Resistance cell \"Combat\", which published an underground newspaper of the same name. This group worked against the Nazis, and in it Camus assumed the \"nom de guerre\" \"Beauchard\". Camus became the paper's editor in 1943. He first met Sartre at the dress rehearsal of Sartre's play, \"The Flies\", in June 1943.\n\nWhen the Allies liberated Paris in August 1944, Camus witnessed and reported the last of the fighting. Soon after the event on 6 August 1945, he was one of the few French editors to publicly express opposition and disgust to the United States' dropping the atomic bombs on Japan. He resigned from \"Combat\" in 1947 when it became a commercial paper. After the war, Camus began frequenting the Café de Flore on the Boulevard Saint-Germain in Paris with Sartre and others. He also toured the United States to lecture about French thought. Although he leaned left, politically, his strong criticisms of Communist doctrine did not win him any friends in the Communist parties and eventually alienated Sartre.\n\nIn 1949, his tuberculosis returned, whereupon he lived in seclusion for two years. In 1951, he published \"The Rebel\", a philosophical analysis of rebellion and revolution which expressed his rejection of communism. Upsetting many of his colleagues and contemporaries in France, the book brought about the final split with Sartre. The dour reception depressed Camus; he began to translate plays.\n\nCamus's first significant contribution to philosophy was his idea of the absurd. He saw it as the result of our desire for clarity and meaning within a world and condition that offers neither, which he expressed in \"The Myth of Sisyphus\" and incorporated into many of his other works, such as \"The Stranger\" and \"The Plague\". Despite his split from his \"study partner\", Sartre, Camus was still categorized as an Existentialist. He specifically rejected that label in his essay \"Enigma\" and elsewhere. The current confusion arises, in part, because many recent applications of existentialism have much in common with many of Camus's \"practical\" ideas (see: \"Resistance, Rebellion, and Death\"). But, his personal understanding of the world (e.g., \"a benign indifference\", in \"The Stranger\"), and every vision he had for its progress (e.g., vanquishing the \"adolescent furies\" of history and society, in \"The Rebel\") undoubtedly set him apart.\n\nIn the 1950s, Camus devoted his efforts to human rights. In 1952, he resigned from his work for UNESCO when the UN accepted Spain as a member under the leadership of General Franco. In 1953, he criticized Soviet methods to crush a workers' strike in East Berlin. In 1956, he protested against similar methods in Poland (protests in Poznań) and the Soviet repression of the Hungarian revolution in October.\nCamus maintained his pacifism and resisted capital punishment anywhere in the world. He wrote an essay against capital punishment in collaboration with Arthur Koestler, the writer, intellectual and founder of the League Against Capital Punishment. He was consistent in his call for non-aggression in Algeria (see below).\n\nFrom 1955 to 1956, Camus wrote for \"L'Express\". In 1957, he was awarded the Nobel Prize in literature \"for his important literary production, which with clear-sighted earnestness illuminates the problems of the human conscience in our times\".\n\nCamus remained active and ambitious until the end of his life. Financed by the money he received with his Nobel Prize, he adapted and directed for the stage Dostoyesvsky's Demons. The play opened in January 1959 at the Antoine Theatre in Paris. It was a critical success as well as an artistic and technical tour de force: 33 actors, 4 hours long, 7 sets, 24 scenes. The walls could move sideways to reduce the size of each depicted location and the whole stage rotated to allow for immediate set transformations. Camus put the painter and set decorator Mayo, who had already illustrated several of Camus' novels (\"The Stranger\" - 1948 Ed.), in charge of the demanding task of designing these multiple and complex theater sets.\n\nCamus once confided that the troubles in Algeria \"affected him as others feel pain in their lungs.\"\n\nIn the 1930s, Camus was affiliated with Left-wing groups like the \"Maison de Culture\" in Algiers which were highly critical of the French colonial regime's treatment of Algeria's Arab and indigenous inhabitants, supporting the Blum-Viollette proposal to grant Algerians full French citizenship. His 1938 address on \"The New Mediterranean Culture\" represents Camus' most systematic statement on his views at this time. In 1939, Camus wrote a stinging series of articles for \"Alger Republicain\" on the atrocious living conditions of the inhabitants of the Kabylie highlands, advocating for economic, educational and political reforms as a matter of emergency. In 1945, following the Sétif and Guelma massacre after Arab revolts against French mistreatment, Camus was one of only a few mainland journalists to visit the colony, again writing a series of article reports on conditions, and advocating for French concessions and reforms to the demands of the Algerian people.\n\nWhen the Algerian War began in 1954, Camus was confronted with a moral dilemma. He identified with the \"Pieds-Noirs\" such as his own parents and defended the French government's actions against the revolt. He argued that the Algerian uprising was an integral part of the 'new Arab imperialism' led by Egypt and an 'anti-Western' offensive orchestrated by Russia to 'encircle Europe' and 'isolate the United States'. Although favoring greater Algerian autonomy or even federation, though not full-scale independence, he believed that the \"Pieds-Noirs\" and Arabs could co-exist. During the war he advocated a civil truce that would spare the civilians, which was rejected by both sides, who regarded it as foolish. Behind the scenes, he began to work for imprisoned Algerians who faced the death penalty.\nWhen he spoke to students at the University of Stockholm, he defended his apparent inactivity in the Algerian question; he stated that he was worried about what might happen to his mother, who still lived in Algeria. This led to further ostracism by French left-wing intellectuals. At the time of his death, Camus was working on an incomplete novel with a strong biographical component, \"The First Man.\" The publication of this book in 1994 has sparked a widespread reconsideration of Camus' allegedly unrepentant colonialism in the work of figures such as David Carroll in the English-speaking world.\n\nMany writers have addressed the Absurd, each with his or her own interpretation of what the Absurd is and what comprises its importance. For example, Sartre recognizes the absurdity of individual experience, while Kierkegaard explains that the absurdity of certain religious truths prevents us from reaching God rationally. Camus regretted the continued reference to himself as a \"philosopher of the absurd\". He showed less interest in the Absurd shortly after publishing \"Le Mythe de Sisyphe\" (\"The Myth of Sisyphus\"). To distinguish his ideas, scholars sometimes refer to the Paradox of the Absurd, when referring to \"Camus' Absurd\".\n\nHis early thoughts appeared in his first collection of essays, \"L'Envers et l'endroit\" (\"Betwixt and Between)\" in 1937. Absurd themes were expressed with more sophistication in his second collection of essays, \"Noces\" (\"Nuptials\"), in 1938. In these essays Camus reflects on the experience of the Absurd. In 1942 he published the story of a man living an absurd life as \"L'Étranger\" (\"The Stranger\"). In the same year he released \"Le Mythe de Sisyphe\" (\"The Myth of Sisyphus\"), a literary essay on the Absurd. He also wrote a play about Caligula, a Roman Emperor, pursuing an absurd logic. The play was not performed until 1945.\n\nThe turning point in Camus's attitude to the Absurd occurs in a collection of four letters to an anonymous German friend, written between July 1943 and July 1944. The first was published in the \"Revue Libre\" in 1943, the second in the \"Cahiers de Libération\" in 1944, and the third in the newspaper \"Libertés\", in 1945. The four letters were published as \"Lettres à un ami allemand\" (\"Letters to a German Friend\") in 1945, and were included in the collection \"Resistance, Rebellion, and Death\".\n\nCamus presents the reader with dualisms such as happiness and sadness, dark and light, life and death, etc. He emphasizes the fact that happiness is fleeting and that the human condition is one of mortality; for Camus, this is cause for a greater appreciation for life and happiness. In \"Le Mythe\", dualism becomes a paradox: we value our own lives in spite of our mortality and in spite of the universe's silence. While we can live with a dualism (\"I can accept periods of unhappiness, because I know I will also experience happiness to come\"), we cannot live with the paradox (\"I think my life is of great importance, but I also think it is meaningless\"). In \"Le Mythe\", Camus investigates our experience of the Absurd and asks how we live with it. Our life must have meaning for us to value it. If we accept that life has no meaning and therefore no value, should we kill ourselves?\n\nIn \"Le Mythe\", Camus suggests that 'creation of meaning' would entail a logical leap or a kind of philosophical suicide in order to find psychological comfort. But Camus wants to know if he can live with what logic and lucidity have uncovered – if one can build a foundation on what one knows and nothing more. Creation of meaning is not a viable alternative but a logical leap and an evasion of the problem. He gives examples of how others would seem to make this kind of leap. The alternative option, namely suicide, would entail another kind of leap, where one attempts to kill absurdity by destroying one of its terms (the human being). Camus points out, however, that there is no more meaning in death than there is in life, and that it simply evades the problem yet again. Camus concludes that we must instead \"entertain\" both death and the absurd, while never agreeing to their terms.\n\nMeursault, the absurdist hero of \"L'Étranger,\" has killed a man and is scheduled to be executed. Caligula ends up admitting his absurd logic was wrong and is killed by an assassination he has deliberately brought about. However, while Camus possibly suggests that Caligula's absurd reasoning is wrong, the play's anti-hero does get the last word, as the author similarly exalts Meursault's final moments.\n\nCamus made a significant contribution to a viewpoint of the Absurd, and always rejected nihilism as a valid response. If nothing had any meaning, you would be right. But there is something that still has a meaning. — \"Second Letter to a German Friend\", December 1943.\n\nCamus's understanding of the Absurd promotes public debate; his various offerings entice us to think about the Absurd and offer our own contribution. Concepts such as cooperation, joint effort and solidarity are of key importance to Camus, though they are most likely sources of 'relative' versus 'absolute' meaning. In \"The Rebel,\" Camus identifies rebellion (or rather, the values indicated by rebellion) as a basis for human solidarity. When he rebels, a man identifies himself with other men and so surpasses himself, and from this point of view human solidarity is metaphysical. But for the moment we are only talking of the kind of solidarity that is born in chains. \n\nDespite his opposition to the label, Camus addressed one of the fundamental questions of existentialism: the problem of suicide. He wrote, \"There is only one really serious philosophical question, and that is suicide. Deciding whether or not life is worth living is to answer the fundamental question in philosophy. All other questions follow from that.\" Camus viewed the question of suicide as arising naturally as a solution to the absurdity of life. In \"The Myth of Sisyphus\", Camus seeks to identify the kinds of life that could be worth living despite their inherent meaninglessness.\n\nThroughout his life, Camus spoke out against and actively opposed totalitarianism in its many forms. Early on, Camus was active within the French Resistance to the German occupation of France during World War II, even directing the famous Resistance journal, \"Combat\". On the French collaboration with Nazi occupiers he wrote: \"Now the only moral value is courage, which is useful here for judging the puppets and chatterboxes who pretend to speak in the name of the people.\" After liberation, Camus remarked, \"This country does not need a Talleyrand, but a Saint-Just.\" The reality of the bloody postwar tribunals soon changed his mind: Camus publicly reversed himself and became a lifelong opponent of capital punishment.\n\nCamus's well-known falling out with Sartre is linked to his opposition to communism. Camus detected a reflexive totalitarianism in the mass politics espoused by Sartre in the name of radical Marxism. This was apparent in his work \"L'Homme Révolté\" (\"The Rebel\") which not only was an assault on the Soviet police state, but also questioned the very nature of mass revolutionary politics. Camus continued to speak out against the atrocities of the Soviet Union, a sentiment captured in his 1957 speech, \"The Blood of the Hungarians\", commemorating the anniversary of the 1956 Hungarian Revolution, an uprising crushed in a bloody assault by the Red Army.\n\nOne further important, often neglected component of Camus' philosophical and literary persona was his love of classical Greek thought and literature, or philhellenism. This love looks back to his youthful encounters with Friedrich Nietzsche, his teacher Jean Grenier, and his own sense of a \"Mediterranean\" identity, based in a common experience of sunshine, beaches, and living in proximity to the near-Eastern world. Camus' \"Diplomes\" thesis (roughly like an MA thesis in most anglophone countries) was on the transition between classical Greek and Roman, and Christian culture, featuring chapters on the early Church, gnosticism, Plotinus and Saint Augustine's \"second revelation\", bringing Greek philosophical conceptuality to Christian revelation. Camus' early essay collection \"Noces (Nuptials)\" features essays set amidst classical Roman ruins; as the \"Myth of Sisyphus\" and \"The Rebel\" (which takes as its hero Prometheus) both are rooted in Camus' classical paideia. The culmination of the latter work defends a \"midday thought\" based in classical moderation or \"mesure\", in opposition to the tendency of modern political ideologies to exclusively valorise race or class, and to dream of a total redemptive revolution. Camus' conception of classical moderation also has deep roots in his lifelong love of Greek tragic theatre, about which he gave an intriguing address in Athens in 1956.\n\n\n\n\n\n\n\n\n", "id": "983", "title": "Albert Camus"},{"url": "https://en.wikipedia.org/wiki?curid=984", "text": "Agatha Christie\n\nDame Agatha Mary Clarissa Christie, Lady Mallowan, DBE (\"née\" Miller; 15 September 1890 – 12 January 1976) was an English crime novelist, short story writer and playwright. She is best known for her 66 detective novels and 14 short story collections, particularly those revolving around her fictional detectives Hercule Poirot and Miss Marple. She also wrote the world's longest-running play, a murder mystery, \"The Mousetrap\", and six romances under the name Mary Westmacott. In 1971 she was made a Dame for her contribution to literature.\n\nChristie was born into a wealthy upper-middle-class family in Torquay, Devon. She served in a Devon hospital during the First World War, tending to troops coming back from the trenches, before marrying and starting a family in London. She was initially an unsuccessful writer with six rejections, but this changed when \"The Mysterious Affair at Styles\", featuring Hercule Poirot, was published in 1920. During the Second World War she worked as a pharmacy assistant at University College Hospital, London, during the Blitz and acquired a good knowledge of poisons which featured in many of her novels.\n\n\"Guinness World Records\" lists Christie as the best-selling novelist of all time. Her novels have sold roughly 2 billion copies, and her estate claims that her works come third in the rankings of the world's most-widely published books, behind only Shakespeare's works and the Bible. According to Index Translationum, she remains the most-translated individual author – having been translated into at least 103 languages. \"And Then There Were None\" is Christie's best-selling novel, with 100 million sales to date, making it the world's best-selling mystery ever, and one of the best-selling books of all time. \nChristie's stage play \"The Mousetrap\" holds the world record for longest initial run. It opened at the Ambassadors Theatre in the West End on 25 November 1952 and is still running after more than 25,000 performances.\n\nIn 1955, Christie was the first recipient of the Mystery Writers of America's highest honour, the Grand Master Award. Later the same year, \"Witness for the Prosecution\" received an Edgar Award by the MWA for Best Play.\nIn 2013, \"The Murder of Roger Ackroyd\" was voted the best crime novel ever by 600 fellow writers of the Crime Writers' Association. On 15 September 2015, coinciding with her 125th birthday, \"And Then There Were None\" was named the \"World's Favourite Christie\" in a vote sponsored by the author's estate. Most of her books and short stories have been adapted for television, radio, video games and comics, and more than thirty feature films have been based on her work.\n\nAgatha Mary Clarissa Miller was born on 15 September 1890, into a wealthy upper middle-class family in Ashfield, Torquay, Devon. Her mother, Clara Boehmer, was an Englishwoman who was born in Belfast in 1854 to Captain Frederick Boehmer and Mary Ann West, the couple's only daughter. Clara Boehmer had four brothers, one of whom died young. Captain Boehmer was killed in a riding accident while stationed on Jersey in April 1863, leaving Mary Ann (Agatha Christie's grandmother) to raise her children alone on a meagre income. Under financial strain, she sent Clara (Christie's mother) to live with her aunt Margaret Miller (née West), who had married a wealthy American, Nathaniel Frary Miller, in 1863. The couple lived in Prinsted, West Sussex. Clara stayed with Margaret, and there she met her future husband, an American stockbroker named Frederick Alvah Miller, who was the son of Nathaniel.\n\nChristie's father, Frederick, was a member of the American upper class, and had been sent to Switzerland for his education. He was considered personable and friendly by those who knew him. He soon developed a romantic relationship with Clara, and they were married in April 1878. Their first child, Margaret Frary Miller (1879–1950), was born in Torquay, where the couple were renting lodgings, while their second, Louis \"Monty\" Montant (1880–1929), was born in the U.S. state of New York, where Frederick was on a business trip. Clara soon purchased a villa in Torquay named \"Ashfield\" in which to raise her family, and it was here that her third and final child, Agatha, was born.\nChristie described her childhood as \"very happy\". She was surrounded by a series of strong and independent women from an early age. Her time was spent alternating between her home in Devon, her step-grandmother and aunt's house in Ealing, West London, and parts of Southern Europe, where her family would holiday during the winter. Agatha was raised in a household with various esoteric beliefs and, like her siblings, believed that her mother Clara was a psychic with the ability of second sight. Her mother insisted that she receive a home education, and so her parents were responsible for teaching her to read and write and to be able to perform basic arithmetic, a subject that she particularly enjoyed. They also taught her about music, and she learned to play both the piano and the mandolin. According to biographer Laura Thomson, Clara believed that Agatha should not learn to read till she was eight. However, due to her curiosity, Agatha taught herself to read much earlier. One of the first known photographs of Christie (now a part of the Christie family's heirlooms) depicts her as a little girl with her first dog, whom she called George Washington.\n\nChristie was a voracious reader from an early age. Among her earliest memories were those of reading the children's books written by Mrs Molesworth, including \"The Adventures of Herr Baby\" (1881), \"Christmas Tree Land\" (1897), and \"The Magic Nuts\" (1898). She also read the work of Edith Nesbit, including \"The Story of the Treasure Seekers\" (1899), \"The Phoenix and the Carpet\" (1903), and \"The Railway Children\" (1906). When a little older, she moved on to reading the surreal verse of Edward Lear and Lewis Carroll. In April 1901, as age 10, she wrote her first poem, \"The cowslip\".\n\nShe spent much of her childhood apart from other children, although she devoted much time to her pets, whom she adored. She eventually made friends with a group of other girls in Torquay, and she noted that \"one of the highlights of my existence\" was her appearance with them in a youth production of Gilbert and Sullivan's \"The Yeomen of the Guard\", in which she played the hero, Colonel Fairfax. This was her last operatic role for, as she later wrote, \"an experience that you really enjoyed should never be repeated.\"\n\nHer father was often ill, suffering from a series of heart attacks, and he died in November 1901, aged 55. His death left the family devastated and in an uncertain economic situation. Clara and Agatha continued to live together in their Torquay home, Madge had moved to Abney Hall in Cheadle, Cheshire, with her new husband, and Monty had joined the army and been sent to South Africa to fight in the Boer War. Agatha later claimed that her father's death, occurring when she was eleven years old, marked the end of her childhood. In 1902, Agatha was sent to receive a formal education at Miss Guyer's Girls School in Torquay, but found it difficult to adjust to the disciplined atmosphere. In 1905, she was sent to Paris where she was educated in three \"pensions\" – Mademoiselle Cabernet's, Les Marroniers, and then Miss Dryden's – the last of which served primarily as a finishing school.\n\nAgatha returned to England in 1910 and found that her mother Clara was ill. They decided to spend time together in the warmer climate of Cairo, then a regular tourist destination for wealthy Britons; they stayed for three months at the Gezirah Palace Hotel. Agatha, always chaperoned by her mother, attended many social functions in search of a husband. She visited such ancient Egyptian monuments as the Great Pyramid of Giza, but did not exhibit the great interest in archaeology and Egyptology that became prominent in her later years.\n\nReturning to Britain, she continued her social activities, writing and performing in amateur theatrics. She also helped put on a play called \"The BlueBeard of Unhappiness\" with female friends. Her writing extended to both poetry and music. Some early works saw publication, but she decided against focusing on either of these as future professions.\n\nChristie wrote her first short story, \"The House of Beauty\" (an early version of her later-published story \"The House of Dreams\"), while recovering in bed from an undisclosed illness. This was about 6,000 words on the topic of \"madness and dreams\", a subject of fascination for her. Biographer Janet Morgan commented that, despite \"infelicities of style\", the story was nevertheless \"compelling\".\n\nOther stories followed, most of them illustrating her interest in spiritualism and the paranormal. These included \"The Call of Wings\" and \"The Little Lonely God\". Magazines rejected all her early submissions, made under pseudonyms, although some were revised and published later, often with new titles.\n\nChristie then set her first novel, \"Snow Upon the Desert\", in Cairo, and drew from her recent experiences in that city, written under the pseudonym Monosyllaba. She was perturbed when various publishers all declined. Clara suggested that her daughter ask for advice from a family friend and neighbour, writer Eden Philpotts, who obliged her enquiry, encouraged her writing, and sent her an introduction to his own literary agent, Hughes Massie, who rejected \"Snow Upon the Desert\", and suggested a second novel.\n\nChristie continued searching for a husband, and entered into short-lived relationships with four separate men and an engagement with another. She then met Archibald Christie (1889–1962) at a dance given by Lord and Lady Clifford at Ugbrooke, about from Torquay. Archie was born in India, the son of a judge in the Indian Civil Service. He was an army officer who was seconded to the Royal Flying Corps in April 1913. The couple quickly fell in love. Upon learning that he would be stationed in Farnborough, Archie proposed marriage, and Agatha accepted.\n\nWith the outbreak of World War I in August 1914, Archie was sent to France to fight the German forces. They married on the afternoon of Christmas Eve 1914 at Emmanuel Church, Clifton, Bristol, which was close to the home of his parents, while Archie was on home leave. Rising through the ranks, he was eventually stationed back to Britain in September 1918 as a colonel in the Air Ministry.\n\nAgatha involved herself in the war effort. She joined the Voluntary Aid Detachment (VAD) in 1914, and attended to wounded soldiers at a hospital in Torquay as an unpaid VAD nurse. Responsible for aiding the doctors and maintaining morale; she performed 3,400 hours of unpaid work between October 1914 and December 1916. After qualifying as an \"apothecaries' assistant\" (or dispenser) in 1917 and working as a dispenser, she earned £16 a year until the end of her service in September 1918. After the war, Agatha and Archie Christie settled into a flat at 5 Northwick Terrace in St. John's Wood, northwest London.\n\nChristie had long been a fan of detective novels, having enjoyed Wilkie Collins's \"The Woman in White\" and \"The Moonstone\" as well as Sir Arthur Conan Doyle's early Sherlock Holmes stories. She wrote her own detective novel, \"The Mysterious Affair at Styles\", featuring Hercule Poirot, a former Belgian police officer noted for his twirly large \"magnificent moustaches\" and egg-shaped head. Poirot had taken refuge in Britain after Germany invaded Belgium. Christie's inspiration for the character stemmed from real Belgian refugees who were living in Torquay and the Belgian soldiers whom she helped treat as a volunteer nurse in Torquay during the First World War.\n\nAgatha began writing \"The Mysterious Affair at Styles\" in 1916 and wrote most of it at Dartmoor. Her original manuscript was rejected by such publishing companies as Hodder and Stoughton and Methuen. After keeping the submission for several months, John Lane at The Bodley Head offered to accept it, provided that Christie change the ending. She did so, and signed a contract which she later felt was exploitative. It was finally published in 1920 after a number of rejections. Christie meanwhile settled into married life, giving birth to her only child, daughter Rosalind Margaret Hicks, in August 1919 at Ashfield, where the couple spent much of their time, having few friends in London. Archie left the Air Force at the end of the war and started working in the City financial sector at a relatively low salary, though they still employed a maid.\n\nChristie's second novel, \"The Secret Adversary\" (1922), featured a new detective couple Tommy and Tuppence, again published by The Bodley Head. It earned her £50. A third novel again featured Poirot, \"Murder on the Links\" (1923), as did short stories commissioned by Bruce Ingram, editor of \"The Sketch\" magazine. In order to tour the world promoting the British Empire Exhibition, the couple left their daughter Rosalind with Agatha's mother and sister. They travelled to South Africa, Australia, New Zealand, and Hawaii. They learned to surf prone in South Africa; then, in Waikiki, they were among the first Britons to surf standing up.\n\nIn late 1926, Archie asked Agatha for a divorce. He was in love with Nancy Neele, who had been a friend of Major Belcher, director of the British Empire Mission, on the promotional tour a few years earlier. On 3 December 1926, the Christies quarrelled, and Archie left their house, Styles, in Sunningdale, Berkshire, to spend the weekend with his mistress at Godalming, Surrey. That same evening, around 9:45 pm, Christie disappeared from her home, leaving behind a letter for her secretary saying that she was going to Yorkshire. Her car, a Morris Cowley, was later found at Newlands Corner, perched above a chalk quarry, with an expired driving licence and clothes.\n\nHer disappearance caused an outcry from the public. The Home Secretary, William Joynson-Hicks, pressured police, and a newspaper offered a £100 reward. Over a thousand police officers, 15,000 volunteers, and several aeroplanes scoured the rural landscape. Sir Arthur Conan Doyle even gave a spirit medium one of Christie's gloves to find the missing woman. Dorothy L. Sayers visited the house in Surrey, later using the scenario in her book \"Unnatural Death\".\n\nChristie's disappearance was featured on the front page of \"The New York Times\". Despite the extensive manhunt, she was not found for 10 days. On 14 December 1926, she was found at the Swan Hydropathic Hotel (now the Old Swan Hotel) in Harrogate, Yorkshire, registered as Mrs Teresa Neele (the surname of her husband's lover) from Cape Town.\n\nChristie's autobiography makes no reference to her disappearance. Two doctors diagnosed her as suffering from amnesia (see Fugue state), yet opinion remains divided as to why she disappeared. Biographer Laura Thompson suggested that Christie let this out in the six novels that she wrote between 1930 and 1956 under the nom de plume Mary Westmacott, in a style quite different from her regular detective stories. She was known to be in a depressed state from literary overwork, her mother's death earlier that year, and her husband's infidelity. Public reaction at the time was largely negative, supposing a publicity stunt or attempt to frame her husband for murder.\n\nThe 1979 Michael Apted film \"Agatha\" features a disclaimer in the opening credits stating that what follows is an imaginary solution to an authentic mystery. The film starred Vanessa Redgrave and Timothy Dalton as Agatha and Archie, and depicts Christie planning suicide in such a way as to frame her husband's mistress for her \"murder\". An American reporter, played by Dustin Hoffman, follows her closely and stops the plan. Christie's heirs unsuccessfully sued to prevent the film's distribution.\n\nAuthor Jared Cade interviewed numerous witnesses and relatives for his sympathetic biography \"Agatha Christie and the Eleven Missing Days\", revised 2011. He provided substantial evidence to suggest that she planned the event to embarrass her husband, never anticipating the resulting escalated melodrama.\n\nThe Christies divorced in 1928, and Archie married Nancy Neele. Agatha retained custody of daughter Rosalind and the Christie name for her writing. During their marriage, she published six novels, a collection of short stories, and a number of short stories in magazines. \n\nIn 1928, Christie left England for Istanbul and subsequently for Baghdad on the Orient Express. During this trip, she encountered her first archaeological dig and met a young archaeologist, Max Mallowan, whom she married in September 1930. Their marriage was happy and lasted until Christie's death in 1976. In a 1977 interview, Mallowan recounted his first meeting with Christie, wherein he took her and a group of tourists on a tour of his expedition site in Iraq.\n\nChristie frequently used settings that were familiar to her for her stories. She often accompanied Mallowan on his archaeological expeditions, and her travels with him contributed background to several of her novels set in the Middle East. Other novels (such as \"And Then There Were None\") were set in and around Torquay, where she was raised. Christie's 1934 novel \"Murder on the Orient Express\" was written in the Pera Palace Hotel in Istanbul, Turkey, the southern terminus of the railway. The hotel maintains Christie's room as a memorial to the author. The Greenway Estate in Devon, acquired by the couple as a summer residence in 1938, is now in the care of the National Trust. Christie often stayed at Abney Hall, Cheshire, owned by her brother-in-law, James Watts, basing at least two stories there: a short story \"The Adventure of the Christmas Pudding\", in the story collection of the same name, and the novel \"After the Funeral\". \"Abney became Agatha's greatest inspiration for country-house life, with all its servants and grandeur being woven into her plots. The descriptions of the fictional Chimneys, Stoneygates, and other houses in her stories are mostly Abney in various forms.\"\n\nDuring the Second World War, Christie worked in the pharmacy at University College Hospital, London, where she acquired a knowledge of poisons that she put to good use in her post-war crime novels. For example, the use of thallium as a poison was suggested to her by UCH Chief Pharmacist Harold Davis (later appointed Chief Pharmacist at the UK Ministry of Health), and in \"The Pale Horse\", published in 1961, she employed it to dispatch a series of victims, the first clue to the murder method coming from the victims' loss of hair. So accurate was her description of thallium poisoning that on at least one occasion it helped solve a case that was baffling doctors.\n\nChristie lived in Chelsea, first in Cresswell Place and later in Sheffield Terrace. Both properties are now marked by blue plaques. In 1934, she and Max Mallowan purchased Winterbrook House in Winterbrook, a hamlet adjoining the small market town of Wallingford which was then within the bounds of Cholsey and in Berkshire. This was their main residence for the rest of their lives and the place where Christie did most of her writing. This house, too, bears a blue plaque. Christie led a very low-profile life despite being known in the town of Wallingford, where she was for many years President of the local amateur dramatic society.\n\nAround 1941–42, the British intelligence agency MI5 investigated Christie after a character called Major Bletchley appeared in her 1941 thriller \"N or M?\", which was about a hunt for a pair of deadly fifth columnists in wartime England. MI5 was afraid that Christie had a spy in Britain's top-secret codebreaking centre, Bletchley Park. The agency's fears were allayed when Christie told friend (and codebreaker) Dilly Knox, \"I was stuck there on my way by train from Oxford to London and took revenge by giving the name to one of my least lovable characters.\"\n\nTo honour her many literary works, she was appointed Commander of the Order of the British Empire (CBE) in the 1956 New Year Honours. The next year, she became the President of the Detection Club. In the 1971 New Year Honours, she was promoted Dame Commander of the Order of the British Empire (DBE), three years after her husband had been knighted for his archaeological work in 1968. They were one of the few married couples where both partners were honoured in their own right. From 1968, owing to her husband's knighthood, Christie could also be styled Lady Mallowan.\n\nFrom 1971 to 1974, Christie's health began to fail, although she continued to write. Recently, using experimental tools of textual analysis, Canadian researchers have suggested that Christie may have begun to suffer from Alzheimer's disease or other dementia.\n\nDame Agatha Christie died on 12 January 1976 at age 85 from natural causes at her home in Winterbrook, Cholsey. She is buried in the nearby churchyard of St Mary's, Cholsey, having chosen the plot for their final resting place with her husband Sir Max some ten years before she died. The simple funeral service was attended by about 20 newspaper and TV reporters, some having travelled from as far away as South America. Thirty wreaths adorned Dame Agatha's grave, including one from the cast of her long-running play \"The Mousetrap\" and one sent 'on behalf of the multitude of grateful readers' by the Ulverscroft Large Print Book Publishers.\n\nShe was survived by her only child, Rosalind Hicks. Her husband, Max, died in 1978, aged 74.\n\nChristie had set up a private company, Agatha Christie Limited, to hold the rights to her works, and around 1959 she had transferred her 278-acre home, Greenway Estate, to her daughter Rosalind. In 1968, when Christie was almost 80 years old, she sold a 51% stake in Agatha Christie Limited (and therefore the works it owned) to Booker Books (better known as Booker Author's Division), a subsidiary of the food and transport conglomerate Booker-McConnell (now Booker Group), the founder of the Booker Prize for literature, which later increased its stake to 64%. Agatha Christie Limited remains the owner of the worldwide rights for over 80 of Christie's novels and short stories, 19 plays, and nearly 40 TV films.\n\nAfter Christie's death in 1976, her remaining 36% share of the company was inherited by her daughter, Rosalind Hicks, who passionately preserved her mother's works, image, and legacy until her own death 28 years later. The family's share of the company allowed them to appoint 50% of the board and the chairman, and thereby to retain a veto over new treatments, updated versions, and republications of her works.\n\nIn 1993, Hicks founded the Agatha Christie Society and became its first president. In 2004 her obituary in \"The Telegraph\" commented that Hicks had been \"determined to remain true to her mother's vision and to protect the integrity of her creations\" and disapproved of \"merchandising\" activities. Upon Hicks's death on 28 October 2004, both this and the Greenway Estate passed to Christie's grandson, Mathew Prichard. After his parents' deaths, Prichard donated Greenway – both the house and its contents – to the National Trust.\n\nChristie's family and family trusts, including Prichard, continue to own the remaining 36% stake in Agatha Christie Limited, and remain associated with the company. Prichard remains as the company's chairman, and also in his own right holds the copyright to some of his grandmother's later literary works (including \"The Mousetrap\").\n\nIn 1998, Booker sold a number of its non-food assets to focus on its core business. As part of that, its shares in Agatha Christie Limited (at the time earning £2.1m annual revenue) were sold for £10m to Chorion, a major international media company whose portfolio of well-known authors' works also included the literary estates of Enid Blyton and Dennis Wheatley. In February 2012, some years after a management buyout, Chorion found itself in financial difficulties and began to sell off their literary assets on the market, selling their 64% stake in Agatha Christie Limited to the current owner, Acorn Media UK (part of RLJ Entertainment, Inc. and the RLJ Companies, owned by American entrepreneur Robert L. Johnson) during that same month.\n\n, media reports state that the BBC had acquired the exclusive television rights to Christie's works in the UK (previously associated with ITV) and plans with Acorn's co-operation to air new productions for the 125th anniversary of Christie's birth in 2015. The BBC broadcast \"Partners In Crime\" and \"And Then There Were None\" in 2015 as part of the deal.\n\nChristie's first book, \"The Mysterious Affair at Styles\", was published in 1920 and introduced the detective Hercule Poirot, who became a long-running character in many of Christie's works, appearing in 33 novels and 54 short stories.\n\nMiss Marple, introduced in the short-story collection \"The Thirteen Problems\" in 1927, was based on Christie's grandmother and her \"Ealing cronies\". Both Jane and Gran \"always expected the worst of everyone and everything, and were, with almost frightening accuracy, usually proved right.\" Marple appeared in 12 novels and 20 stories.\n\nDuring the Second World War, Christie wrote two novels, \"Curtain\" and \"Sleeping Murder\", intended as the last cases of these two great detectives, Hercule Poirot and Miss Marple. Both books were sealed in a bank vault for over thirty years and were released for publication by Christie only at the end of her life, when she realised that she could not write any more novels. These publications came on the heels of the success of the film version of \"Murder on the Orient Express\" in 1974.\n\nChristie became increasingly tired of Poirot, much as Sir Arthur Conan Doyle had grown weary of his character Sherlock Holmes. By the end of the 1930s, Christie wrote in her diary that she was finding Poirot \"insufferable\", and by the 1960s she felt that he was \"an egocentric creep\". However, unlike Conan Doyle, Christie resisted the temptation to kill her detective off while he was still popular. She saw herself as an entertainer whose job was to produce what the public liked, and the public liked Poirot.\n\nShe did marry off Poirot's companion Colonel Hastings in an attempt to trim her cast commitments. In contrast, Christie was fond of Miss Marple. However, the Belgian detective's titles outnumber the Marple titles more than two to one. This is largely because Christie wrote numerous Poirot novels early in her career, while \"The Murder at the Vicarage\" remained the sole Marple novel until the 1940s. Christie never wrote a novel or short story featuring both Poirot and Miss Marple. In a recording discovered and released in 2008, Christie revealed the reason for this: \"Hercule Poirot, a complete egoist, would not like being taught his business or having suggestions made to him by an elderly spinster lady\".\n\nPoirot is the only fictional character to date to be given an obituary in \"The New York Times\", following the publication of \"Curtain\". It appeared on the front page of the paper on 6 August 1975.\n\nFollowing the great success of \"Curtain\", Christie gave permission for the release of \"Sleeping Murder\" sometime in 1976 but died in January 1976 before the book could be released. This may explain some of the inconsistencies compared to the rest of the Marple series — for example, Colonel Arthur Bantry, husband of Miss Marple's friend Dolly, is still alive and well in \"Sleeping Murder\" although he is noted as having died in books published earlier. It may be that Christie simply did not have time to revise the manuscript before she died.\n\nIn 2013, the Christie family gave their \"full backing\" to the release of a new Poirot story, \"The Monogram Murders\", which was written by British author Sophie Hannah.\n\nChristie's reputation as \"The Queen of Crime\" was built upon the large number of classic motifs that she introduced, or for which she provided the most famous example. Christie built these tropes into what is now considered classic mystery structure: a murder is committed, there are multiple suspects who are all concealing secrets, and the detective gradually uncovers these secrets over the course of the story, discovering the most shocking twists towards the end. Culprits in Christie's mysteries have included children, policemen, narrators, already deceased individuals, and sometimes comprise no known suspects (\"And Then There Were None\") or all of the suspects (\"Murder on the Orient Express\").\n\nAt the end, in a Christie hallmark, the detective usually gathers the surviving suspects into one room, explains the course of his deductive reasoning, and reveals the guilty party, although there are exceptions in which it is left to the guilty party to explain all (such as \"And Then There Were None\" and \"Endless Night\", both rather nihilistic in nature).\n\nChristie allows some culprits to escape earthly justice for a variety of reasons, such as the passage of time (retrospective cases), in which the most important characters have already died, or by active prescription. Such cases include \"The Witness for the Prosecution\", \"Murder on the Orient Express\", \"The Man in the Brown Suit\", \"Elephants Can Remember\", and \"The Unexpected Guest\". There are instances in which a killer is not brought to justice in the legal sense but does die as a direct result of his plot, sometimes by his own hand at the direction or with the collusion of the detective (usually Hercule Poirot). This occurs in \"The Murder of Roger Ackroyd\", \"Death on the Nile\", \"Dumb Witness\", \"Crooked House\", \"The Hollow\", \"The Mirror Crack'd from Side to Side\", \"Cat Among the Pigeons\", \"Peril at End House\", \"Nemesis\", \"Appointment with Death\", \"The Secret Adversary\", and \"Curtain\". In the last of these (\"Curtain\"), no fewer than three culprits die during the course of the story.\n\nIn \"The A.B.C. Murders\", the murderer has killed four innocent people and attempted to frame an unstable man for the crimes. Hercule Poirot, however, prevents this easy way out, ensuring a trial and hanging. In \"And Then There Were None\", the killer's own death is intrinsic to the plot; the red herring is when and how the killer actually died. However, stage, film, and television productions of some of these mysteries were traditionally sanitized with the culprits not evading some form of justice, for a variety of reasons – e.g., censors, plot clarity, and Christie's own changing tastes. (When Christie adapted \"Witness for the Prosecution\" into a stage play, she lengthened the ending so that the murderer was also killed; this format was followed in film and television productions, most famously the Charles Laughton/Marlene Dietrich film.) In \"Death Comes as the End\", set in ancient Egypt, the culprit is killed by one of the few surviving characters before he can claim another victim .\n\nIn some stories, the question remains unresolved of whether formal justice will ever be delivered, such as \"Five Little Pigs\" and \"Endless Night\". According to P. D. James, Christie often, but not always, made the unlikeliest character the guilty party. Savvy readers could sometimes identify the culprit by simply identifying the least likely suspect.\n\nOn an edition of \"Desert Island Discs\" in 2007, Brian Aldiss claimed that Christie had told him that she wrote her books up to the last chapter, then decided who the most unlikely suspect was, after which she would go back and make the necessary changes to \"frame\" that person. However, John Curran's \"Agatha Christie: The Secret Notebooks\" describes different working methods for every book in Christie's bibliography, contradicting the claim by Aldiss. \n\nChristie's mature novels, from 1940 onwards, often have titles drawn from literature.\n\nFour are from Shakespeare: \n\nThree are from the Bible: \n\nAnother six are from other works of literature:\n\nIn such cases, the original context of the title is usually printed as an epigraph. Similarly, the title of Christie's autobiographical travel book \"Come, Tell Me How You Live\" is a quote from verse three of the White Knight's poem, \"Haddocks' Eyes\" from chapter eight of \"Through the Looking-Glass\" by Lewis Carroll, and is a play on the word \"tell\", an archaeological mound. \n\nThe title of \"The Mousetrap\" is purportedly an allusion to Shakespeare's play \"Hamlet\", in which \"The Mousetrap\" is Hamlet's answer to Claudius's inquiry about the name of the play whose prologue and first scene he and his court have just watched (III, ii).\n\nSeven stories are built around words from well known children's nursery rhymes: \"And Then There Were None\" (from \"Ten Little Indians\"), \"One, Two, Buckle My Shoe\" (from \"One, Two, Buckle My Shoe\"), \"Five Little Pigs\" (from \"This Little Piggy\"), \"Crooked House\" (from \"There Was a Crooked Man\"), \"A Pocket Full of Rye\" (from \"Sing a Song of Sixpence\"), \"Hickory Dickory Dock\" (from \"Hickory Dickory Dock\"), and \"Three Blind Mice\" (from \"Three Blind Mice\"). Similarly, the novel Mrs McGinty's Dead is named after a children's game that is explained in the course of the novel.\n\nChristie occasionally inserted stereotyped descriptions of characters into her work, particularly before the end of the Second World War (when such attitudes were more commonly expressed publicly), and particularly in regard to Italians, Jews, non-Europeans, and sometimes Americans, the last usually as impossibly naïve or uninformed. For example, she described \"Hebraic men with hook-noses wearing rather flamboyant jewellery\" in the first editions of the collection \"The Mysterious Mr Quin\" (1930), in the short story \"The Soul of the Croupier\"; in later editions, the passage was edited to describe \"sallow men\" wearing same. \n\nIn \"The Hollow\", published as late as 1946, one of the more unsympathetic characters is \"a Whitechapel Jewess with dyed hair and a voice like a corncrake ... a small woman with a thick nose, henna red and a disagreeable voice\". To contrast with the more stereotyped descriptions, Christie sometimes showed \"foreigners\" as victims or potential victims at the hands of English malefactors, such as, respectively, Olga Seminoff (\"Hallowe'en Party\") and Katrina Reiger (in the short story \"How Does Your Garden Grow?\"). Jewish characters are often seen as un-English (such as Oliver Manders in \"Three Act Tragedy\"), but they are rarely the culprits.\n\nOften, she is affectionate or teasing with her prejudices. After four years of war-torn London, Christie hoped to return some day to Syria, which she described as \"gentle fertile country and its simple people, who know how to laugh and how to enjoy life; who are idle and gay, and who have dignity, good manners, and a great sense of humour, and to whom death is not terrible.\"\n\nShe had trouble with an incompetent Swiss French nursery helper (Marcelle) for toddler Rosalind, and as a result she decided, \"Scottish preferred ... good with the young. The French were hopeless disciplinarians ... Germans good and methodical, but it was not German that I really wanted Rosalind to learn. The Irish were gay but made trouble in the house; the English were of all kinds\".\n\nChristie published relatively few nonfiction works:\n\nAgatha Christie is the world's best-selling mystery writer, often referred to as the \"Queen of Crime\", and considered a master of suspense, plotting, and characterisation. Some critics, however, regarded Christie's plotting abilities as considerably greater than her literary ones. Novelist Raymond Chandler criticised her in his essay \"The Simple Art of Murder\", and American literary critic Edmund Wilson was dismissive of Christie and the detective fiction genre generally in his \"New Yorker\" essay, \"Who Cares Who Killed Roger Ackroyd?\"\n\nIn honour of the 125th anniversary of her birth, 25 contemporary mystery writers and one publisher revealed their views on Christie's works. Many of the authors read Christie's novels first, before other mystery writers, in English or in their native language, influencing their own writing, and nearly all still view her as the \"Queen of Crime\", and creator of the plot twists used by mystery authors. Nearly all had one or more favourites among Christie's mysteries, and find her books good to read now, nearly 100 years after her first novel was published. Several of the authors would be very pleased to have their own novels in print in 100 years. Just one of the 25 authors held with Edmund Wilson's views. Harper Collins also published a souvenir magazine \"Shocking Real Murders: Behind Her Classic Mysteries\".\n\nThe \"Guinness Book of World Records\" lists Christie as the best-selling novelist of all time. Her novels have sold roughly 2 billion copies, and her estate claims that her works come third in the rankings of the world's most-widely published books, behind only Shakespeare's works and the Bible. Half of the sales are of English language editions, and the other half in translation. According to Index Translationum, she remains the most-translated individual author – having been translated into at least 103 languages. \"And Then There Were None\" is Christie's best-selling novel, with 100 million sales to date, making it the world's best-selling mystery ever, and one of the best-selling books of all time.\n\nIn 2012, Christie was among the British cultural icons selected by artist Sir Peter Blake to appear in a new version of his most famous artwork – the Beatles' \"Sgt. Pepper's Lonely Hearts Club Band\" album cover – to celebrate the British cultural figures of his life that he most admires.\n\nChristie had a lifelong interest in archaeology. She met her second husband, Sir Max Mallowan, a distinguished archaeologist, on a trip to the excavation site at Ur in 1930. But her fame as an author far surpassed his fame in archaeology. Prior to meeting Mallowan, Christie had not had any extensive brushes with archaeology, but once the two married, they made sure to only go to sites where they could work together. Christie accompanied Mallowan on countless archaeological trips, spending 3–4 months at a time in Syria and Iraq at excavation sites at Ur, Nineveh, Tell Arpachiyah, Chagar Bazar, Tell Brak, and Nimrud. She wrote novels and short stories, but also contributed work to the archaeological sites, more specifically to the archaeological restoration and labelling of ancient exhibits, including tasks such as cleaning and conserving delicate ivory pieces, reconstructing pottery, developing photos from early excavations which later led to taking photographs of the site and its findings, and taking field notes.\n\nChristie would always pay for her own board and lodging and her travel expenses so as to not influence the funding of the archaeological excavations, and she also supported excavations as an anonymous sponsor. During their time in the Middle East, there was also a large amount of time spent travelling to and from Mallowan's sites. Their extensive travelling had a strong influence on her writing, as some type of transportation often plays a part in her murderer's schemes. The large amount of travel was reused in novels such as \"The Murder on the Orient Express\", as well as suggesting the idea of archaeology as an adventure itself.\n\nAfter the Second World War, she chronicled her time in Syria with fondness in \"Come Tell Me How You Live\". Anecdotes, memories, funny episodes are strung in a rough timeline, with more emphasis on eccentric characters and lovely scenery than on factual accuracy. From 8 November 2001 to 24 March 2002, The British Museum had an exhibit named \"Agatha Christie and Archaeology: Mystery in Mesopotamia\", which presented the life of Agatha Christie and the influences of archaeology in her life and works.\n\nMany of the settings for Christie's books were directly inspired by the many archaeological field seasons spent in the Middle East on the sites managed by her husband Max. The extent of her time spent at the many locations featured in her books is apparent from the extreme detail in which she describes them. One such site featured in her work is the temple site of Abu Simbel, depicted in \"Death on the Nile\". Also there is the great detail in which she describes life at the dig site in \"Murder in Mesopotamia\". Among the characters in her books, Christie has often given prominence to the archaeologists and experts in Middle Eastern cultures and artifacts. Most notable are the characters of Dr. Eric Leidner in \"Murder in Mesopotamia\" and Signor Richetti in \"Death on the Nile\", while many minor characters were archaeologists in \"They Came to Baghdad\".\n\nSome of Christie's best known novels with heavy archaeological influences are:\n\nChristie has been portrayed on a number of occasions in film and television. Several biographical programmes have been made, such as BBC television's \"\" (2004; in which she was portrayed by Olivia Williams, Anna Massey, and Bonnie Wright, at different stages in her life), and in Season 3, Episode 1 of \"ITV Perspectives\": \"The Mystery of Agatha Christie\" (2013), hosted by David Suchet, who plays Hercule Poirot on television.\n\nChristie has also been portrayed fictionally. Some of these portrayals have explored and offered accounts of Christie's disappearance in 1926, including the film \"Agatha\" (1979) (with Vanessa Redgrave, in which she sneaks away to plan revenge against her husband), and the \"Doctor Who\" episode \"The Unicorn and the Wasp\" (17 May 2008), with Fenella Woolgar, in which her disappearance is the result of her suffering a temporary breakdown owing to a brief psychic link being formed between her and an alien. Others, such as Hungarian film, \"Kojak Budapesten\" (1980; not to be confused with the 1986 comedy by the same name) create their own scenarios involving Christie's criminal skill. In the TV play, \"Murder by the Book\" (1986), Christie herself (Dame Peggy Ashcroft) murdered one of her fictional-turned-real characters, Poirot. The heroine of Liar-Soft's visual novel \"\" (2008), Mary Clarissa Christie, is based on the real-life Christie. Christie features as a character in Gaylord Larsen's \"Dorothy and Agatha\" and \"The London Blitz Murders\" by Max Allan Collins. A fictionalized account of Christie's disappearance is the central theme of a Korean musical, \"Agatha\".\n\n\n\n\n\n", "id": "984", "title": "Agatha Christie"},{"url": "https://en.wikipedia.org/wiki?curid=986", "text": "The Plague\n\nThe Plague (French: La Peste) is a novel by Albert Camus, published in 1947, that tells the story of a plague sweeping the French Algerian city of Oran. It asks a number of questions relating to the nature of destiny and the human condition. The characters in the book, ranging from doctors to vacationers to fugitives, all help to show the effects the plague has on a populace.\n\nThe novel is believed to be based on the cholera epidemic that killed a large percentage of Oran's population in 1849 following French colonization, but the novel is placed in the 1940s. Oran and its environs were struck by disease multiple times before Camus published this novel. According to a research report by the Centers for Disease Control and Prevention, Oran was decimated by the plague in 1556 and 1678, but all later outbreaks, in 1921 (185 cases), 1931 (76 cases), and 1944 (95 cases), were very far from the scale of the epidemic described in the novel.\n\n\"The Plague\" is considered an existentialist classic despite Camus' objection to the label. The narrative tone is similar to Kafka's, especially in \"The Trial\" whose individual sentences potentially have multiple meanings, the material often pointedly resonating as stark allegory of phenomenal consciousness and the human condition.\n\nCamus included a dim-witted character misreading \"The Trial\" as a mystery novel as an oblique homage. The novel has been read as a metaphorical treatment of the French resistance to Nazi occupation during World War II. Additionally, he further illustrates the human reaction towards the \"absurd\". \"The Plague\" represents how the world deals with the philosophical notion of the Absurd, a theory that Camus himself helped to define.\n\n\nThe text of \"The Plague\" is divided into five parts.\n\nIn the town of Oran, thousands of rats, initially unnoticed by the populace, begin to die in the streets. Hysteria develops soon afterward, causing the local newspapers to report the incident. Authorities responding to public pressure order the collection and cremation of the rats, unaware that the collection itself was the catalyst for the spread of the bubonic plague.\n\nThe main character, Dr. Bernard Rieux, lives comfortably in an apartment building when strangely the building's concierge, M. Michel, a confidante, dies from a fever. Dr. Rieux consults his colleague, Dr. Castel, about the illness until they come to the conclusion that a plague is sweeping the town. They both approach fellow doctors and town authorities about their theory but are eventually dismissed on the basis of one death. However, as more and more deaths quickly ensue, it becomes apparent that there is an epidemic. Meanwhile, Rieux's wife has been sent to a sanatorium in another city, to be treated for an unrelated chronic illness.\n\nAuthorities, including the Prefect, are slow to accept that the situation is serious and quibble over the appropriate action to take. Official notices enacting control measures are posted, but the language used is optimistic and downplays the seriousness of the situation. A \"special ward\" is opened at the hospital, but its 80 beds are filled within three days. As the death toll begins to rise, more desperate measures are taken. Homes are quarantined; corpses and burials are strictly supervised. A supply of plague serum finally arrives, but there is enough to treat only existing cases, and the country's emergency reserves are depleted. When the daily number of deaths jumps to 30, the town is sealed, and an outbreak of plague is officially declared.\n\nThe town is sealed off. The town gates are shut, rail travel is prohibited, and all mail service is suspended. The use of telephone lines is restricted only to \"urgent\" calls, leaving short telegrams as the only means of communicating with friends or family outside the town. The separation affects daily activity and depresses the spirit of the townspeople, who begin to feel isolated and introverted, and the plague begins to affect various characters.\n\nOne character, Raymond Rambert, devises a plan to escape the city to join his wife in Paris after city officials refused his request to leave. He befriends some underground criminals so that they may smuggle him out of the city. Another character, Father Paneloux, uses the plague as an opportunity to advance his stature in the town by suggesting that the plague was an act of God punishing the citizens' sinful nature. His diatribe falls on the ears of many citizens of the town, who turned to religion in droves but would not have done so under normal circumstances. Cottard, a criminal remorseful enough to attempt suicide but fearful of being arrested, becomes wealthy as a major smuggler. Meanwhile, Dr. Rieux; a vacationer, Jean Tarrou; and a civil servant, Joseph Grand, exhaustively treat patients in their homes and in the hospital.\n\nRambert informs Tarrou of his escape plan, but when Tarrou tells him that there are others in the city, including Dr. Rieux, who have loved ones outside the city whom they are not allowed to see, Rambert becomes sympathetic and changes his mind. He then decides to join Tarrou and Dr. Rieux to help fight the epidemic.\n\nIn mid-August, the situation continues to worsen. People try to escape the town, but some are shot by armed sentries. Violence and looting break out on a small scale, and the authorities respond by declaring martial law and imposing a curfew. Funerals are conducted with more and more speed, no ceremony, and little concern for the feelings of the families of the deceased. The inhabitants passively endure their increasing feelings of exile and separation. Despondent, they waste away emotionally as well as physically.\n\nIn September and October, the town remains at the mercy of the plague. Rieux hears from the sanatorium that his wife's condition is worsening. He also hardens his heart regarding the plague victims so that he can continue to do his work. Cottard, on the other hand, seems to flourish during the plague because it gives him a sense of being connected to others, since everybody faces the same danger. Cottard and Tarrou attend a performance of Gluck's opera \"Orpheus and Eurydice\", but the actor portraying Orpheus collapses with plague symptoms during the performance.\n\nAfter extended negotiations with guards, Rambert finally has a chance to escape, but he decides to stay, saying that he would feel ashamed of himself if he left.\n\nTowards the end of October, Castel's new antiplague serum is tried for the first time, but it cannot save the life of Othon's young son, who suffers greatly, as Paneloux, Rieux, and Tarrou tend to his bedside in horror.\n\nPaneloux, who has joined the group of volunteers fighting the plague, gives a second sermon. He addresses the problem of an innocent child's suffering and says it is a test of a Christian's faith since it requires him either to deny everything or believe everything. He urges the congregation not to give up the struggle but to do everything possible to fight the plague.\n\nA few days after the sermon, Paneloux is taken ill. His symptoms do not conform to those of the plague, but the disease still proves fatal.\n\nTarrou and Rambert visit one of the isolation camps, where they meet Othon. When Othon's period of quarantine ends, he chooses to stay in the camp as a volunteer because this will make him feel less separated from his dead son. Tarrou tells Rieux the story of his life and, to take their mind off the epidemic, the two men go swimming together in the sea. Grand catches the plague and instructs Rieux to burn all his papers. However, Grand makes an unexpected recovery, and deaths from the plague start to decline.\n\nBy late January the plague is in full retreat, and the townspeople begin to celebrate the imminent opening of the town gates. Othon, however, does not escape death from the disease. Cottard is distressed by the ending of the epidemic from which he has profited by shady dealings. Two government employees approach him, and he flees. Despite the epidemic's ending, Tarrou contracts the plague and dies after a heroic struggle. Rieux is later informed via telegram that his wife has also died.\n\nIn February, the town gates open and people are reunited with their loved ones from other cities. Rambert is reunited with his wife. Cottard goes mad and shoots at people from his home. He is arrested. Grand begins working on his novel again. The narrator of the chronicle reveals his identity and states and that he tried to present an objective view of the events. The narrator reflects on the epidemic and reaches the conclusion that there is more to admire than to despise in humans.\n\nGermaine Brée has characterised the struggle of the characters against the plague as \"undramatic and stubborn\", and in contrast to the ideology of \"glorification of power\" in the novels of André Malraux, whereas Camus' characters \"are obscurely engaged in saving, not destroying, and this in the name of no ideology\". Lulu Haroutunian has discussed Camus' own medical history, including a bout with tuberculosis, and how it informs the novel. Marina Warner has noted the lack of female characters and the total absence of Arab characters in the novel, but also notes its larger philosophical themes of \"engagement\", \"paltriness and generosity\", \"small heroism and large cowardice\", and \"all kinds of profoundly humanist problems, such as love and goodness, happiness and mutual connection\".\n\nThomas L Hanna and John Loose have separately discussed themes related to Christianity in the novel, with particular respect to Father Paneloux and Dr Rieux. Louis R Rossi briefly discusses the role of Tarrou in the novel, and the sense of philosophical guilt behind his character. Elwyn Sterling has analysed the role of Cottard and his final actions at the end of the novel.\n\nAs early as April 1941, Camus had been working on the novel, as evidenced in his diaries in which he wrote down a few ideas on \"the redeeming plague\". On March 13, 1942, he informed André Malraux that he was writing \"a novel on the plague\", adding \"Said like that it might sound strange, […] but this subject seems so natural to me.\"\n\n\n\n\n", "id": "986", "title": "The Plague"},{"url": "https://en.wikipedia.org/wiki?curid=988", "text": "Applied ethics\n\nApplied ethics is the branch of ethics concerned with the analysis of particular moral issues in private and public life. For example, the bioethics community is concerned with identifying the correct approach to moral issues in the life sciences, such as euthanasia, the allocation of scarce health resources, or the use of human embryos in research. Environmental ethics is concerned with ecological issues such as the responsibility of government and corporations to clean up pollution. Business ethics includes questions regarding the duties or duty of 'whistleblowers' to the general public or to their loyalty to their employers. Applied ethics is distinguished from normative ethics, which concerns standards for right and wrong behavior, and from meta-ethics, which concerns the nature of ethical properties, statements, attitudes, and judgments.\n\nAn emerging typology for applied ethics uses six domains to help improve organizations and social issues at the national and global level:\n\n\nMuch of applied ethics is concerned with just three theories:\n\n\nOne modern approach which attempts to overcome the seemingly impossible divide between deontology and utilitarianism (of which the divide is caused by the opposite takings of an absolute and relativist moral view) is case-based reasoning, also known as casuistry. Casuistry does not begin with theory, rather it starts with the immediate facts of a real and concrete case. While casuistry makes use of ethical theory, it does not view ethical theory as the most important feature of moral reasoning. Casuists, like Albert Jonsen and Stephen Toulmin (\"The Abuse of Casuistry\" 1988), challenge the traditional paradigm of applied ethics. Instead of starting from theory and applying theory to a particular case, casuists start with the particular case itself and then ask what morally significant features (including both theory and practical considerations) ought to be considered for that particular case. In their observations of medical ethics committees, Jonsen and Toulmin note that a consensus on particularly problematic moral cases often emerges when participants focus on the facts of the case, rather than on ideology or theory. Thus, a Rabbi, a Catholic priest, and an agnostic might agree that, in this particular case, the best approach is to withhold extraordinary medical care, while disagreeing on the reasons that support their individual positions. By focusing on cases and not on theory, those engaged in moral debate increase the possibility of agreement.\n\n\n\n", "id": "988", "title": "Applied ethics"},{"url": "https://en.wikipedia.org/wiki?curid=991", "text": "Absolute value\n\nIn mathematics, the absolute value or modulus of a real number  is the non-negative value of  without regard to its sign. Namely, for a positive , for a negative  (in which case is positive), and . For example, the absolute value of 3 is 3, and the absolute value of −3 is also 3. The absolute value of a number may be thought of as its distance from zero.\n\nGeneralisations of the absolute value for real numbers occur in a wide variety of mathematical settings. For example, an absolute value is also defined for the complex numbers, the quaternions, ordered rings, fields and vector spaces. The absolute value is closely related to the notions of magnitude, distance, and norm in various mathematical and physical contexts.\n\nIn 1806, Jean-Robert Argand introduced the term \"module\", meaning \"unit of measure\" in French, specifically for the \"complex\" absolute value, and it was borrowed into English in 1866 as the Latin equivalent \"modulus\". The term \"absolute value\" has been used in this sense from at least 1806 in French and 1857 in English. The notation , with a vertical bar on each side, was introduced by Karl Weierstrass in 1841. Other names for \"absolute value\" include \"numerical value\" and \"magnitude\". In programming languages and computational software packages, the absolute value of \"x\" is generally represented by abs(\"x\"), or a similar expression.\n\nThe vertical bar notation also appears in a number of other mathematical contexts: for example, when applied to a set, it is used to denote its cardinality; when applied to a matrix, it is used to denote its determinant. Thus, care must be taken to interpret vertical bars as an absolute value sign only when the argument is an algebraic object for which the notion of an absolute value is defined (e.g., an element of a normed division algebra like a real number, complex number, quaternion, etc.). A closely related but distinct notation is the use of vertical bars for either the euclidean norm or sup norm of a vector in formula_1, although double vertical bars with subscripts (formula_2 and formula_3, respectively) are a more common and less ambiguous notation.\n\nFor any real number  the absolute value or modulus of  is denoted by (a vertical bar on each side of the quantity) and is defined as\n\nAs can be seen from the above definition, the absolute value of  is always either positive or zero, but never negative.\n\nFrom an analytic geometry point of view, the absolute value of a real number is that number's distance from zero along the real number line, and more generally the absolute value of the difference of two real numbers is the distance between them. Indeed, the notion of an abstract distance function in mathematics can be seen to be a generalisation of the absolute value of the difference (see \"Distance\" below).\n\nSince the square root notation without sign represents the \"positive\" square root, it follows that\n\nfor real values of \"a\" (equation (1)). This identity is sometimes used as a definition of absolute value of real numbers.\n\nThe absolute value has the following four fundamental properties (\"a\", \"b\" are real numbers):\n\nThe properties given by equations (2)-(4) are readily apparent from the definition. To see that equation (5) holds, choose formula_5 from formula_6 so that formula_7. Since formula_8 for real formula_9 regardless of the value of formula_5 chosen, (5) follows from the calculation formula_11. (For a generalization of this argument to complex numbers, see \"Proof of the triangle inequality for complex numbers\" below.)\n\nSome additional useful properties are given below. These properties are either implied by or equivalent to the properties given by equations (2)-(5).\n\nTwo other useful properties concerning inequalities are:\n\nThese relations may be used to solve inequalities involving absolute values. For example:\n\nAbsolute value is used to define the absolute difference, the standard metric on the real numbers.\n\nSince the complex numbers are not ordered, the definition given above for the real absolute value cannot be directly generalised for a complex number. However the geometric interpretation of the absolute value of a real number as its distance from 0 can be generalised. The absolute value of a complex number is defined as its distance in the complex plane from the origin using the Pythagorean theorem. More generally the absolute value of the difference of two complex numbers is equal to the distance between those two complex numbers.\n\nIn the context of abstract algebra, since the positive real numbers form a subgroup of the complex numbers under multiplication, we may think of absolute value as an endomorphism of the multiplicative group of the complex numbers.\n\nFor any complex number\n\nwhere and are real numbers, the absolute value or modulus of  is denoted and is given by\n\nwhere Re(\"z\") = \"x\" and Im(\"z\") = \"y\" denote the real and imaginary parts of \"z\", respectively. When the imaginary part is zero this coincides with the definition of the absolute value of the real number .\n\nWhen a complex number  is expressed in polar form as\n\nwith and θ = the phase of \"z\", its absolute value is\n\nThe absolute value of a complex number can be written in the complex analogue of equation (1) above as:\n\nwhere is the complex conjugate of .\nNote that, equation (1) is not, in general, true for complex \"z\":\n\nThe complex absolute value shares all the properties of the real absolute value given in equations (2)–(11) above.\n\nImportantly, the property of subadditivity (\"triangle inequality\", equation (5)) extends to any finite collection of complex numbers formula_21:\nThis inequality also applies to infinite series formula_23, provided formula_24 is absolutely convergent. If (Lebesgue) integration is viewed as the continuous analog of summation, then this inequality is analogously obeyed by complex-valued, measurable functions formula_25 when integrated over a measurable subset formula_26:\n\nThe triangle inequality, as given by formula_29, can be demonstrated by applying a few easily verified properties of the complex numbers: Namely, for every complex number formula_30, (i): there exists formula_31 such that formula_32, formula_33, and (ii): formula_34; and also, if formula_35are complex numbers but formula_36 is real, then formula_37.\n\nProof of formula_29: Choose formula_39 such that formula_40, formula_41 (summed over \"k\" = 1, 2, ... , \"n\"). The following computation then affords the desired inequality: \nIt is clear from this proof that equality holds in formula_29 if and only if the formula_44 are non-negative real numbers for formula_45, which in turn occurs if and only if all nonzero formula_46 have the same argument, i.e., formula_47 for a complex constant formula_48 and real constants formula_49.\n\nAfter arguing that formula_50 is also measurable, the proof of the inequality formula_51 proceeds via the same technique, by replacing formula_52 with formula_53 and formula_46 with formula_55.\n\nThe real absolute value function is continuous everywhere. It is differentiable everywhere except for  = 0. It is monotonically decreasing on the interval and monotonically increasing on the interval . Since a real number and its opposite have the same absolute value, it is an even function, and is hence not invertible. The real absolute value function is a piecewise linear, convex function.\n\nBoth the real and complex functions are idempotent.\n\nThe absolute value function of a real number returns its value irrespective of its sign, whereas the sign (or signum) function returns a number's sign irrespective of its value. The following equations show the relationship between these two functions:\nor\nand for ,\n\nThe real absolute value function has a derivative for every , but is not differentiable at . Its derivative for is given by the step function:\n\nThe subdifferential of  at  is the interval .\n\nThe complex absolute value function is continuous everywhere but complex differentiable \"nowhere\" because it violates the Cauchy–Riemann equations.\n\nThe second derivative of  with respect to  is zero everywhere except zero, where it does not exist. As a generalised function, the second derivative may be taken as two times the Dirac delta function.\n\nThe antiderivative (indefinite integral) of the absolute value function is\n\nwhere is an arbitrary constant of integration.\n\nThe absolute value is closely related to the idea of distance. As noted above, the absolute value of a real or complex number is the distance from that number to the origin, along the real number line, for real numbers, or in the complex plane, for complex numbers, and more generally, the absolute value of the difference of two real or complex numbers is the distance between them.\n\nThe standard Euclidean distance between two points\n\nand\n\nin Euclidean -space is defined as:\n\nThis can be seen to be a generalisation of , since if and are real, then by equation (1),\n\nWhile if\n\nand\n\nare complex numbers, then\n\nThe above shows that the \"absolute value\" distance for the real numbers or the complex numbers, agrees with the standard Euclidean distance they inherit as a result of considering them as the one and two-dimensional Euclidean spaces respectively.\n\nThe properties of the absolute value of the difference of two real or complex numbers: non-negativity, identity of indiscernibles, symmetry and the triangle inequality given above, can be seen to motivate the more general notion of a distance function as follows:\n\nA real valued function on a set is called a metric (or a \"distance function\") on , if it satisfies the following four axioms:\n\nThe definition of absolute value given for real numbers above can be extended to any ordered ring. That is, if  is an element of an ordered ring \"R\", then the absolute value of , denoted by , is defined to be:\n\nwhere is the additive inverse of , and 0 is the additive identity element.\n\nThe fundamental properties of the absolute value for real numbers given in (2)–(5) above, can be used to generalise the notion of absolute value to an arbitrary field, as follows.\n\nA real-valued function  on a field  is called an \"absolute value\" (also a \"modulus\", \"magnitude\", \"value\", or \"valuation\") if it satisfies the following four axioms:\n\nWhere 0 denotes the additive identity element of . It follows from positive-definiteness and multiplicativity that , where 1 denotes the multiplicative identity element of . The real and complex absolute values defined above are examples of absolute values for an arbitrary field.\n\nIf is an absolute value on , then the function  on , defined by , is a metric and the following are equivalent:\n\n\nAn absolute value which satisfies any (hence all) of the above conditions is said to be non-Archimedean, otherwise it is said to be Archimedean.\n\nAgain the fundamental properties of the absolute value for real numbers can be used, with a slight modification, to generalise the notion to an arbitrary vector space.\n\nA real-valued function on a vector space  over a field , represented as , is called an absolute value, but more usually a norm, if it satisfies the following axioms:\n\nFor all  in , and , in ,\n\nThe norm of a vector is also called its \"length\" or \"magnitude\".\n\nIn the case of Euclidean space , the function defined by\n\nis a norm called the Euclidean norm. When the real numbers  are considered as the one-dimensional vector space , the absolute value is a norm, and is the -norm (see L space) for any . In fact the absolute value is the \"only\" norm on , in the sense that, for every norm on , . The complex absolute value is a special case of the norm in an inner product space. It is identical to the Euclidean norm, if the complex plane is identified with the Euclidean plane .\n\nEvery composition algebra \"A\" has an involution \"x\" → \"x\"* called its conjugation. The product in \"A\" of an element \"x\" and its conjugate \"x\"* is written \"N\"(\"x\") = \"x x\"* and called the norm of x.\n\nThe real numbers ℝ, complex numbers ℂ, and quaternions ℍ are all composition algebras with norms given by definite quadratic forms. The absolute value in these division algebras is given by the square root of the composition algebra norm.\n\nIn general the norm of a composition algebra may be a quadratic form that is not definite and has null vectors. However, as in the case of division algebras, when an element \"x\" has a non-zero norm, then \"x\" has a multiplicative inverse given by \"x\"*/\"N\"(\"x\").\n\n\n", "id": "991", "title": "Absolute value"},{"url": "https://en.wikipedia.org/wiki?curid=993", "text": "Analog signal\n\nAn analog signal is any continuous signal for which the time varying feature (variable) of the signal is a representation of some other time varying quantity, i.e., \"analogous\" to another time varying signal. For example, in an analog audio signal, the instantaneous voltage of the signal varies continuously with the pressure of the sound waves. It differs from a digital signal, in which the continuous quantity is a representation of a sequence of discrete values which can only take on one of a finite number of values. The term analog signal usually refers to electrical signals; however, mechanical, pneumatic, hydraulic, human speech, and other systems may also convey or be considered analog signals.\nAn analog signal uses some property of the medium to convey the signal's information. For example, an aneroid barometer uses rotary position as the signal to convey pressure information. In an electrical signal, the voltage, current, or frequency of the signal may be varied to represent the information.\nAny information may be conveyed by an analog signal; often such a signal is a measured response to changes in physical phenomena, such as sound, light, temperature, position, or pressure. The physical variable is converted to an analog signal by a transducer. For example, in sound recording, fluctuations in air pressure (that is to say, sound) strike the diaphragm of a microphone which induces corresponding fluctuations in the current produced by a coil in an electromagnetic microphone, or the voltage produced by a condenser microphone. The voltage or the current is said to be an \"analog\" of the sound.\nAn analog signal has a theoretically infinite resolution. In practice an analog signal is subject to electronic noise and distortion introduced by communication channels and signal processing operations, which can progressively degrade the signal-to-noise ratio (SNR). In contrast, digital signals have a finite resolution. Converting an analog signal to digital form introduces a constant low-level noise called quantization noise into the signal which determines the noise floor, but once in digital form the signal can in general be processed or transmitted without introducing additional noise or distortion. In analog systems, it is difficult to detect when such degradation occurs. However, in digital systems, degradation can not only be detected but corrected as well.\n\nThe primary disadvantage of analog signals is that any system has noise – i.e., unwanted variation. As the signal is copied and re-copied, or transmitted over long distances, or electronically processed, the unavoidable noise introduced by each step in the signal path is additive, progressively degrading the signal-to-noise ratio, until in extreme cases the signal can be overwhelmed. This is called generation loss. Noise can show up as \"hiss\" and intermodulation distortion in audio signals, or \"snow\" in video signals. This degradation is impossible to recover, since there is no sure way to distinguish the noise from the signal; amplifying the signal to recover attenuated parts of the signal amplifies the noise (distortion/interference) as well. Digital signals can often be transmitted, stored and processed without introducing noise. Electrically, analog noise can be diminished by shielding, good connections and several cable types such as coaxial or twisted pair.\n\n", "id": "993", "title": "Analog signal"},{"url": "https://en.wikipedia.org/wiki?curid=994", "text": "Arecales\n\nArecales is an order of flowering plants. The order has been widely recognised only for the past few decades; until then, the accepted name for the order including these plants was Principes.\n\nThe Cronquist system of 1981 assigned the order to the subclass Arecidae in the class Liliopsida (= monocotyledons).\n\nThe Thorne system (1992) and the Dahlgren system assigned the order to the superorder Areciflorae, also called Arecanae in the subclass Liliidae (= monocotyledons), with the single family Arecaceae.\n\nThe APG II system of 2003 recognised the order and placed it in the clade commelinids in the monocots and uses this circumscription:\n\n\nThis was unchanged from the APG system of 1998, although it used the spelling \"commelinoids\" instead of commelinids.\n\nThe APG IV system of 2016 places Dasypogonaceae in this order, after studies shown Dasypogonaceae as sister to Arecaceae.\n\n", "id": "994", "title": "Arecales"},{"url": "https://en.wikipedia.org/wiki?curid=1000", "text": "Hercule Poirot\n\nHercule Poirot (; ) is a fictional Belgian detective, created by Agatha Christie. Poirot is one of Christie's most famous and long-lived characters, appearing in 33 novels, one play (\"Black Coffee\"), and more than 50 short stories published between 1920 and 1975.\n\nPoirot has been portrayed on radio, in film and on television by various actors, including Austin Trevor, John Moffatt, Albert Finney, Sir Peter Ustinov, Sir Ian Holm, Tony Randall, Alfred Molina, Orson Welles, David Suchet and Sir Kenneth Branagh.\n\nPoirot's name was derived from two other fictional detectives of the time: Marie Belloc Lowndes' Hercule Popeau and Frank Howel Evans' Monsieur Poiret, a retired Belgian police officer living in London.\n\nA more obvious influence on the early Poirot stories is that of Arthur Conan Doyle. In \"An Autobiography\", Christie states, \"I was still writing in the Sherlock Holmes tradition – eccentric detective, stooge assistant, with a Lestrade-type Scotland Yard detective, Inspector Japp\". For his part, Conan Doyle acknowledged basing his detective stories on the model of Edgar Allan Poe's C. Auguste Dupin and his anonymous narrator, and basing his character Sherlock Holmes on Joseph Bell, who in his use of \"ratiocination\" prefigured Poirot's reliance on his \"little grey cells\".\n\nPoirot also bears a striking resemblance to A. E. W. Mason's fictional detective, Inspector Hanaud of the French Sûreté, who first appeared in the 1910 novel \"At the Villa Rose\" and predates the first Poirot novel by ten years.\n\nUnlike the models mentioned above, Christie's Poirot was clearly the result of her early development of the detective in her first book, written in 1916 and published in 1920. His Belgian nationality was interesting because of Belgium's occupation by Germany, which also provided a plausible explanation of why such a skilled detective would be out of work and available to solve mysteries at an English country house. At the time of Christie's writing, it was considered patriotic to express sympathy towards the Belgians, since the invasion of their country had constituted Britain's \"casus belli\" for entering World War I, and British wartime propaganda emphasised the \"Rape of Belgium\".\n\nPoirot first appeared in \"The Mysterious Affair at Styles\" (published in 1920) and exited in \"Curtain\" (published in 1975). Following the latter, Poirot was the only fictional character to receive an obituary on the front page of \"The New York Times\".\n\nBy 1930, Agatha Christie found Poirot \"insufferable\", and by 1960 she felt that he was a \"detestable, bombastic, tiresome, ego-centric little creep\". Yet the public loved him and Christie refused to kill him off, claiming that it was her duty to produce what the public liked.\n\nCaptain Arthur Hastings's first description of Poirot:\n\nHe was hardly more than five feet four inches but carried himself with great dignity. His head was exactly the shape of an egg, and he always perched it a little on one side. His moustache was very stiff and military. Even if everything on his face was covered, the tips of moustache and the pink-tipped nose would be visible.\nThe neatness of his attire was almost incredible; I believe a speck of dust would have caused him more pain than a bullet wound. Yet this quaint dandified little man who, I was sorry to see, now limped badly, had been in his time one of the most celebrated members of the Belgian police.\n\nAgatha Christie's initial description of Poirot in \"The Murder on the Orient Express\":\n\nBy the step leading up into the sleeping-car stood a young French lieutenant, resplendent in uniform, conversing with a small man [Hercule Poirot] muffled up to the ears of whom nothing was visible but a pink-tipped nose and the two points of an upward-curled moustache.\n\nIn the later books, his limp is not mentioned, suggesting it may have been a temporary wartime injury. (In \"\", Poirot admits he was wounded when he first came to England.) Poirot has green eyes that are repeatedly described as shining \"like a cat's\" when he is struck by a clever idea, and dark hair, which he dyes later in life. In \"Curtain\", he admits to Hastings that he wears a wig and a false moustache. However, in many of his screen incarnations, he is bald or balding.\n\nFrequent mention is made of his patent leather shoes, damage to which is frequently a source of misery for him, but comical for the reader. Poirot's appearance, regarded as fastidious during his early career, later falls hopelessly out of fashion. He employs pince-nez reading glasses.\n\nAmong Poirot's most significant personal attributes is the sensitivity of his stomach:\n\nThe plane dropped slightly. \"\"Mon estomac\",\" thought Hercule Poirot, and closed his eyes determinedly.\n\nHe suffers from sea sickness, and in \"Death in the Clouds\" he states that his air sickness prevents him from being more alert at the time of the murder. Later in his life, we are told:\n\nAlways a man who had taken his stomach seriously, he was reaping his reward in old age. Eating was not only a physical pleasure, it was also an intellectual research.\n\nPoirot is extremely punctual and carries a turnip pocket watch almost to the end of his career. He is also particular about his personal finances, preferring to keep a bank balance of 444 pounds, 4 shillings, and 4 pence.\n\nAs mentioned in \"Curtain\" and \"The Clocks\", he is fond of classical music, particularly Mozart and Bach.\n\nIn \"The Mysterious Affair at Styles\", Poirot operates as a fairly conventional, clue-based and logical detective; reflected in his vocabulary by two common phrases: his use of \"the little grey cells\" and \"order and method\". Hastings is irritated by the fact that Poirot sometimes conceals important details of his plans, as in \"The Big Four\". In this novel, Hastings is kept in the dark throughout the climax. This aspect of Poirot is less evident in the later novels, partly because there is rarely a narrator to mislead.\n\nIn \"Murder on the Links,\" still largely dependent on clues himself, Poirot mocks a rival \"bloodhound\" detective who focuses on the traditional trail of clues established in detective fiction (e.g., Sherlock Holmes depending on footprints, fingerprints, and cigar ash). From this point on, Poirot establishes his psychological bona fides. Rather than painstakingly examining crime scenes, he enquires into the nature of the victim or the psychology of the murderer. He predicates his actions in the later novels on his underlying assumption that particular crimes are committed by particular types of people.\n\nPoirot focuses on getting people to talk. In the early novels, he casts himself in the role of \"Papa Poirot\", a benign confessor, especially to young women. In later works, Christie made a point of having Poirot supply false or misleading information about himself or his background to assist him in obtaining information. In \"The Murder of Roger Ackroyd\", Poirot speaks of a non-existent mentally disabled nephew to uncover information about homes for the mentally unfit. In \"Dumb Witness\", Poirot invents an elderly invalid mother as a pretence to investigate local nurses. In \"The Big Four\", Poirot pretends to have (and poses as) an identical twin brother named Achille: however, this brother was mentioned again in \"The Labours of Hercules\". Poirot claimed to have a brother for a short time.\n\nTo this day Harold is not quite sure what made him suddenly pour out the whole story to a little man to whom he had only spoken a few minutes before.\n\nPoirot is also willing to appear more foreign or vain in an effort to make people underestimate him. He admits as much:\n\nIt is true that I can speak the exact, the idiomatic English. But, my friend, to speak the broken English is an enormous asset. It leads people to despise you. They say – a foreigner – he can't even speak English properly. [...] Also I boast! An Englishman he says often, \"A fellow who thinks as much of himself as that cannot be worth much.\" [...] And so, you see, I put people off their guard.\n\nIn later novels, Christie often uses the word \"mountebank\" when characters describe Poirot, showing that he has successfully passed himself off as a charlatan or fraud.\n\nPoirot's investigating techniques assist him solving cases; \"For in the long run, either through a lie, or through truth, people were bound to give themselves away...\" At the end, Poirot usually reveals his description of the sequence of events and his deductions to a room of suspects, often leading to the culprit's apprehension.\n\n\"I suppose you know pretty well everything there is to know about Poirot's family by this time\".\n\nChristie has been purposefully vague about Poirot's origins, as he is thought to be an elderly man even in the early novels. In \"An Autobiography,\" she admitted that she already imagined him to be an old man in 1920. At the time, however, she had no idea she would write works featuring him for decades to come.\n\nA brief passage in \"The Big Four\" provides original information about Poirot's birth or at least childhood in or near the town of Spa, Belgium: \"But we did not go into Spa itself. We left the main road and wound into the leafy fastnesses of the hills, till we reached a little hamlet and an isolated white villa high on the hillside.\" Christie strongly implies that this \"quiet retreat in the Ardennes\" near Spa is the location of the Poirot family home.\nAn alternate tradition holds that Poirot was born in the village of Ellezelles (province of Hainaut, Belgium). A few memorials dedicated to Hercule Poirot can be seen in the centre of this village. There appears to be no reference to this in Christie's writings, but the town of Ellezelles cherishes a copy of Poirot's birth certificate in a local memorial 'attesting' Poirot's birth, naming his father and mother as Jules-Louis Poirot and Godelieve Poirot.\n\nChristie wrote that Poirot is a Roman Catholic by birth, but not much is described about his later religious convictions, except sporadic references to his \"going to church\". Christie provides little information regarding Poirot’s childhood, only mentioning in \"Three Act Tragedy\" that he comes from a large family with little wealth, and has at least one younger sister.\n\nGustave[...] was not a policeman. I have dealt with policemen all my life and I \"know\". He could pass as a detective to an outsider but not to a man who was a policeman himself.\n\nHercule Poirot was active in the Brussels police force by 1893. Very little mention is made about this part of his life, but in \"The Nemean Lion\" (1939) Poirot refers to a Belgian case of his in which \"a wealthy soap manufacturer[...] poisoned his wife in order to be free to marry his secretary\". As Poirot was often misleading about his past to gain information, the truthfulness of that statement is unknown.\n\nInspector Japp offers some insight into Poirot's career with the Belgian police when introducing him to a colleague:\n\nYou've heard me speak of Mr Poirot? It was in 1904 he and I worked together – the Abercrombie forgery case – you remember he was run down in Brussels. Ah, those were the days Moosier. Then, do you remember \"Baron\" Altara? There was a pretty rogue for you! He eluded the clutches of half the police in Europe. But we nailed him in Antwerp – thanks to Mr. Poirot here.\n\nIn the short story \"The Chocolate Box\" (1923), Poirot reveals to Captain Arthur Hastings an account of what he considers to be his only failure. Poirot admits that he has failed to solve a crime \"innumerable\" times:\n\nI have been called in too late. Very often another, working towards the same goal, has arrived there first. Twice I have been struck down with illness just as I was on the point of success.\n\nNevertheless, he regards the 1893 case in \"The Chocolate Box\", as his only actual failure of detection. Again, Poirot is not reliable as a narrator of his personal history and there is no evidence that Christie sketched it out in any depth. During his police career Poirot shot a man who was firing from a roof into the public below. In \"Lord Edgware Dies\", Poirot reveals that he learned to read writing upside down during his police career. Around that time he met Xavier Bouc, director of the Compagnie Internationale des Wagons-Lits. Poirot also became a uniformed director, working on trains.\n\nIn \"The Double Clue,\" Poirot mentions that he was Chief of Police of Brussels, until \"the Great War\" (World War I) forced him to leave for England.\n\nI had called in at my friend Poirot's rooms to find him sadly overworked. So much had he become the rage that every rich woman who had mislaid a bracelet or lost a pet kitten rushed to secure the services of the great Hercule Poirot.\n\nDuring World War I, Poirot left Belgium for England as a refugee (although he returned a few times). On 16 July 1916 he again met his lifelong friend, Captain Arthur Hastings, and solved the first of his cases to be published, \"The Mysterious Affair at Styles\". It is clear that Hastings and Poirot are already friends when they meet in Chapter 2 of the novel, as Hastings tells Cynthia that he has not seen him for \"some years\". Particulars such as the date of 1916 for the case and that Hastings had met Poirot in Belgium, are given in \"Curtain: Poirot's Last Case\", Chapter 1. After that case, Poirot apparently came to the attention of the British secret service and undertook cases for the British government, including foiling the attempted abduction of the Prime Minister. Readers were told that the British authorities had learned of Poirot's keen investigative ability from certain members of Belgium's royal family.\nAfter the war Poirot became a private detective and began undertaking civilian cases. He moved into what became both his home and work address, Flat 203 at 56B Whitehaven Mansions. Hastings first visits the flat when he returns to England in June 1935 from Argentina in \"The A.B.C. Murders\", Chapter 1. The TV programmes place this in Florin Court, Charterhouse Square, in the wrong part of London. According to Hastings, it was chosen by Poirot \"entirely on account of its strict geometrical appearance and proportion\" and described as the \"newest type of service flat\". (The Florin Court building was actually built in 1936, decades after Poirot fictionally moved in.) His first case in this period was \"The Affair at the Victory Ball\", which allowed Poirot to enter high society and begin his career as a private detective.\n\nBetween the world wars, Poirot travelled all over Europe, Africa, Asia, and half of South America investigating crimes and solving murders. Most of his cases occurred during this time and he was at the height of his powers at this point in his life. In \"The Murder on the Links\", the Belgian pits his grey cells against a French murderer. In the Middle East, he solved the cases \"Death on the Nile\" and \"Murder in Mesopotamia\" with ease and even survived \"An Appointment with Death\". As he passed through Eastern Europe on his return trip, he solved \"The Murder on the Orient Express\". However he did not travel to North America, the West Indies, the Caribbean or Oceania, probably to avoid sea sickness.\n\nIt is this villainous sea that troubles me! The \"mal de mer\" – it is horrible suffering!\n\nIt was during this time he met the Countess Vera Rossakoff, a glamorous jewel thief. The history of the Countess is, like Poirot's, steeped in mystery. She claims to have been a member of the Russian aristocracy before the Russian Rebellion and suffered greatly as a result, but how much of that story is true is an open question. Even Poirot acknowledges that Rossakoff offered wildly varying accounts of her early life. Poirot later became smitten with the woman and allowed her to escape justice.\n\nIt is the misfortune of small, precise men always to hanker after large and flamboyant women. Poirot had never been able to rid himself of the fatal fascination that the Countess held for him.\n\nAlthough letting the Countess escape was morally questionable, it was not uncommon. In \"The Nemean Lion\", Poirot sided with the criminal, Miss Amy Carnaby, allowing her to evade prosecution by blackmailing his client Sir Joseph Hoggins, who, Poirot discovered, had plans to commit murder. Poirot even sent Miss Carnaby two hundred pounds as a final payoff prior to the conclusion of her dog kidnapping campaign. In \"The Murder of Roger Ackroyd\", Poirot allowed the murderer to escape justice through suicide and then withheld the truth to spare the feelings of the murderer's relatives. In \"The Augean Stables\", he helped the government to cover up vast corruption. In \"Murder on the Orient Express\", Poirot allowed the murderers to go free after discovering that twelve different people participated in the murder. The victim had been responsible for a disgusting crime which had led to the deaths of no fewer than five people. There was no question of his guilt, but he had been acquitted in America in a miscarriage of justice. Considering it poetic justice that twelve jurors had acquitted him and twelve people had stabbed him, Poirot produced an alternate sequence of events to explain the death.\n\nAfter his cases in the Middle East, Poirot returned to Britain. Apart from some of the so-called \"Labours of Hercules\" (see next section) he very rarely went abroad during his later career. He moved into Styles Court towards the end of his life.\n\nWhile Poirot was usually paid handsomely by clients, he was also known to take on cases that piqued his curiosity, although they did not pay well.\n\nPoirot shows a love of steam trains, which Christie contrasts with Hastings' love of autos: this is shown in \"The Plymouth Express\", \"The Mystery of the Blue Train\", \"Murder on the Orient Express\", and \"The ABC Murders\" (in the TV series, steam trains are seen in nearly all of the episodes).\n\nThat’s the way of it. Just a case or two, just one case more – the Prima Donna’s farewell performance won’t be in it with yours, Poirot.\n\nConfusion surrounds Poirot's retirement. Most of the cases covered by Poirot's private detective agency take place before his retirement to grow marrows, at which time he solves \"The Murder of Roger Ackroyd\". It has been said that the twelve cases related in \"The Labours of Hercules\" (1947) must refer to a different retirement, but the fact that Poirot specifically says that he intends to grow marrows indicates that these stories also take place before \"Roger Ackroyd\", and presumably Poirot closed his agency once he had completed them. There is specific mention in \"The Capture of Cerberus\" of the twenty-year gap between Poirot's previous meeting with Countess Rossakoff and this one. If the \"Labours\" precede the events in \"Roger Ackroyd\", then the Ackroyd case must have taken place around twenty years \"later\" than it was published, and so must any of the cases that refer to it. One alternative would be that having failed to grow marrows once, Poirot is determined to have another go, but this is specifically denied by Poirot himself. Also, in \"The Erymanthian Boar\", a character is said to have been turned out of Austria by the Nazis, implying that the events of \"The Labours of Hercules\" took place after 1937. Another alternative would be to suggest that the Preface to the \"Labours\" takes place at one date but that the labours are completed over a matter of twenty years. None of the explanations is especially attractive.\n\nIn terms of a rudimentary chronology, Poirot speaks of retiring to grow marrows in Chapter 18 of \"The Big Four\" (1927) which places that novel out of published order before \"Roger Ackroyd\". He declines to solve a case for the Home Secretary because he is retired in Chapter One of \"Peril at End House\" (1932). He is certainly retired at the time of \"Three Act Tragedy\" (1935) but he does not enjoy his retirement and repeatedly takes cases thereafter when his curiosity is engaged. He continues to employ his secretary, Miss Lemon, at the time of the cases retold in \"Hickory Dickory Dock\" and \"Dead Man's Folly\", which take place in the mid-1950s. It is therefore better to assume that Christie provided no authoritative chronology for Poirot's retirement, but assumed that he could either be an active detective, a consulting detective, or a retired detective as the needs of the immediate case required.\n\nOne consistent element about Poirot's retirement is that his fame declines during it, so that in the later novels he is often disappointed when characters (especially younger characters) recognise neither him nor his name:\n\n\"I should, perhaps, Madame, tell you a little more about myself. I am \"Hercule Poirot\".\"\nThe revelation left Mrs Summerhayes unmoved.\n\"What a lovely name,\" she said kindly. \"Greek, isn't it?\"\n\nPoirot is less active during the cases that take place at the end of his career. Beginning with \"Three Act Tragedy\" (1934), Christie had perfected during the inter-war years a subgenre of Poirot novel in which the detective himself spent much of the first third of the novel on the periphery of events. In novels such as \"Taken at the Flood\", \"After the Funeral\", and \"Hickory Dickory Dock\", he is even less in evidence, frequently passing the duties of main interviewing detective to a subsidiary character. In \"Cat Among the Pigeons\", Poirot's entrance is so late as to be almost an afterthought. Whether this was a reflection of his age or of Christie's distaste for him, is impossible to assess. \"Crooked House\" (1949) and \"Ordeal by Innocence\" (1957), which could easily have been Poirot novels, represent a logical endpoint of the general diminution of his presence in such works.\n\nTowards the end of his career, it becomes clear that Poirot's retirement is no longer a convenient fiction. He assumes a genuinely inactive lifestyle during which he concerns himself with studying famous unsolved cases of the past and reading detective novels. He even writes a book about mystery fiction in which he deals sternly with Edgar Allan Poe and Wilkie Collins. In the absence of a more appropriate puzzle, he solves such inconsequential domestic riddles as the presence of three pieces of orange peel in his umbrella stand. \n\nPoirot (and, it is reasonable to suppose, his creator) becomes increasingly bemused by the vulgarism of the up-and-coming generation's young people. In \"Hickory Dickory Dock\", he investigates the strange goings on in a student hostel, while in \"Third Girl\" (1966) he is forced into contact with the smart set of Chelsea youths. In the growing drug and pop culture of the sixties, he proves himself once again, but has become heavily reliant on other investigators (especially the private investigator, Mr. Goby) who provide him with the clues that he can no longer gather for himself.\nNotably, during this time his physical characteristics also change dramatically, and by the time Arthur Hastings meets Poirot again in \"Curtain\", he looks very different from his previous appearances, having become thin with age and with obviously dyed hair.\n\nOn the ITV television series, Poirot died in October 1949 from complications of a heart condition at the end of \"Curtain: Poirot's Last Case\". In Christie's novels, he lived into the late 1960s, perhaps even until 1975 when \"Curtain\" was published. In both the novel and the television adaptation, he had moved his amyl nitrite pills out of his own reach, possibly because of guilt. He thereby became the murderer in \"Curtain\", although it was for the benefit of others. Poirot himself noted that he wanted to kill his victim shortly before his own death so that he could avoid succumbing to the arrogance of the murderer, concerned that he might come to view himself as entitled to kill those whom he deemed necessary to eliminate.\n\nThe \"murderer\" that he was hunting had never actually killed anyone, but he had manipulated others to kill for him, subtly and psychologically manipulating the moments where others desire to commit murder so that they carry out the crime when they might otherwise dismiss their thoughts as nothing more than a momentary passion. Poirot thus was forced to kill the man himself, as otherwise he would have continued his actions and never been officially convicted, as he did not legally do anything wrong. It is revealed at the end of \"Curtain\" that he fakes his need for a wheelchair to fool people into believing that he is suffering from arthritis, to give the impression that he is more infirm than he is. His last recorded words are \"\"Cher ami!\"\", spoken to Hastings as the Captain left his room. (The TV adaptation adds that as Poirot is dying alone, he whispers out his final prayer to God in these words: \"Forgive me... forgive...\") Poirot was buried at Styles, and his funeral was arranged by his best friend Hastings and Hastings' daughter Judith. Hastings reasoned, \"Here was the spot where he had lived when he first came to this country. He was to lie here at the last.\"\n\nPoirot's actual death and funeral occurred in \"Curtain\", years after his retirement from active investigation, but it was not the first time that Hastings attended the funeral of his best friend. In \"The Big Four\" (1927), Poirot feigned his death and subsequent funeral to launch a surprise attack on the Big Four.\n\nHastings, a former British Army officer, first meets Poirot during Poirot's years as a police officer in Belgium and almost immediately after they both arrive in England. He becomes Poirot's lifelong friend and appears in many cases. Poirot regards Hastings as a poor private detective, not particularly intelligent, yet helpful in his way of being fooled by the criminal or seeing things the way the average man would see them and for his tendency to unknowingly \"stumble\" onto the truth. Hastings marries and has four children – two sons and two daughters.\nAs a loyal, albeit somewhat naïve companion, Hastings is to Poirot what Watson is to Sherlock Holmes.\n\nHastings is capable of great bravery and courage, facing death unflinchingly when confronted by \"The Big Four\" and displaying unwavering loyalty towards Poirot. However, when forced to choose between Poirot and his wife in that novel, he initially chooses to betray Poirot to protect his wife. Later, though, he tells Poirot to draw back and escape the trap.\n\nThe two are an airtight team until Hastings meets and marries Dulcie Duveen, a beautiful music hall performer half his age, after investigating the \"Murder on the Links\". They later emigrate to Argentina, leaving Poirot behind as a \"very unhappy old man\". Poirot and Hastings reunite for the final time in \"Curtain: Poirot's Last Case\", having been earlier reunited in \"The Big Four\", \"Peril at End House\", \"The ABC Murders\", \"Lord Edgware Dies\" and \"Dumb Witness\" when Hastings arrives in England for business.\n\nDetective novelist Ariadne Oliver is Agatha Christie's humorous self-caricature. Like Christie, she is not overly fond of the detective whom she is most famous for creating–in Ariadne's case, Finnish sleuth Sven Hjerson. We never learn anything about her husband, but we do know that she hates alcohol and public appearances and has a great fondness for apples until she is put off them by the events of \"Hallowe'en Party\". She also has a habit of constantly changing her hairstyle, and in every appearance by her much is made of her clothes and hats. Her maid Maria prevents the public adoration from becoming too much of a burden on her employer, but does nothing to prevent her from becoming too much of a burden on others.\n\nShe has authored over 56 novels and greatly dislikes people modifying her characters. She is the only one in Poirot's universe to have noted that \"It’s not natural for five or six people to be on the spot when B is murdered and all have a motive for killing B.\" She first met Poirot in the story \"Cards on the Table\" and has been bothering him ever since.\n\nPoirot's secretary, Miss Felicity Lemon, has few human weaknesses. The only mistakes she makes within the series are a typing error during the events of \"Hickory Dickory Dock\" and the mis-mailing of an electricity bill, although she was worried about strange events surrounding her sister at the time. Poirot described her as being \"Unbelievably ugly and incredibly efficient. Anything that she mentioned as worth consideration usually was worth consideration.\" She is an expert on nearly everything and plans to create the perfect filing system. She also worked for the government statistician-turned-philanthropist Parker Pyne. Whether this was during one of Poirot’s numerous retirements or before she entered his employ is unknown. In \"The Agatha Christie Hour\", she was portrayed by British actress Angela Easterling, while in \"Agatha Christie's Poirot\" she was portrayed by Pauline Moran. A marked difference from the text exists in Moran's portrayal, where she is an attractive, fashionable, and emotional woman showing an occasional soft corner for Poirot. She also appears far more often in the TV series, making an appearance in most episodes and often being a bigger part of the plot. On a number of occasions, she joins Poirot in his inquiries or seeks out answers alone at his request.\n\nJapp is a Scotland Yard Inspector and appears in many of the stories trying to solve cases that Poirot is working on. Japp is outgoing, loud and sometimes inconsiderate by nature and his relationship with the refined Belgian is one of the stranger aspects of Poirot’s world. He first met Poirot in Belgium in 1904, during the Abercrombie Forgery. Later that year they joined forces again to hunt down a criminal known as Baron Altara. They also meet in England where Poirot often helps Japp and lets him take credit in return for special favours. These favours usually entail Poirot being supplied with other interesting cases. In \"Agatha Christie's Poirot\", Japp was portrayed by Philip Jackson. In the film, \"Thirteen at Dinner\" (1985), adapted from \"Lord Edgware Dies\", the role of Japp was taken by the actor David Suchet, who would later star as Poirot in the ITV adaptations.\n\nThe Poirot books take readers through the whole of his life in England, from the first book (\"The Mysterious Affair at Styles\"), where he is a refugee staying at Styles, to the last Poirot book (\"Curtain\"), where he visits Styles before his death. In between, Poirot solves cases outside England as well, including his most famous case, \"Murder on the Orient Express\" (1934).\n\nHercule Poirot became famous in 1926 with the publication of \"The Murder of Roger Ackroyd\", whose surprising solution proved controversial. The novel is still among the most famous of all detective novels: Edmund Wilson alludes to it in the title of his well-known attack on detective fiction, \"Who Cares Who Killed Roger Ackroyd?\" Aside from \"Roger Ackroyd\", the most critically acclaimed Poirot novels appeared from 1932 to 1942, including \"Murder on the Orient Express\", \"The ABC Murders\" (1935), \"Cards on the Table\" (1936), and \"Death on the Nile\" (1937), a tale of multiple homicide upon a Nile steamer. \"Death on the Nile\" was judged by detective novelist John Dickson Carr to be among the ten greatest mystery novels of all time.\n\nThe 1942 novel \"Five Little Pigs\" (a.k.a. \"Murder in Retrospect\"), in which Poirot investigates a murder committed sixteen years before by analysing various accounts of the tragedy, is a \"Rashomon\"-like performance. In his analysis of this book, critic and mystery novelist Robert Barnard referred to it as \"the best Christie of all\".\n\nIn 2014, the Poirot canon was added to by the first author to be commissioned by the Christie estate to write an original story, Sophie Hannah. The novel was called \"The Monogram Murders\", and was set in the late 1920s, placing it chronologically between \"The Mystery of the Blue Train\" and \"Peril at End House\". A second Hannah-penned Poirot came out in 2016, called \"Closed Casket\".\n\nThe first actor to portray Hercule Poirot was Charles Laughton. He appeared on the West End in 1928 in the play \"Alibi\" which had been adapted by Michael Morton from the novel \"The Murder of Roger Ackroyd\".\n\nAustin Trevor debuted the role of Poirot on screen in the 1931 British film \"Alibi\". The film was based on the stage play. Trevor reprised the role of Poirot twice, in \"Black Coffee\" and \"Lord Edgware Dies\". Trevor said once that he was probably cast as Poirot simply because he could do a French accent. Leslie S. Hiscott directed the first two films, with Henry Edwards taking over for the third.\n\nTony Randall portrayed Poirot in \"The Alphabet Murders\", a 1965 film also known as \"The ABC Murders\". This was more a satire of Poirot than a straightforward adaptation, and was greatly changed from the original. Much of the story, set in modernistic times, was played for comedy, with Poirot investigating the murders while evading the attempts by Hastings (Robert Morley) and the police to get him out of England and back to Belgium.\n\nAlbert Finney played Poirot in 1974 in the cinematic version of \"Murder on the Orient Express\". Finney is the only actor to receive an Academy Award nomination for playing Poirot, though he did not win.\nPeter Ustinov played Poirot six times, starting with \"Death on the Nile\" (1978). He reprised the role in \"Evil Under the Sun\" (1982) and \"Appointment with Death\" (1988).\n\nChristie's daughter Rosalind Hicks observed Ustinov during a rehearsal and said, \"\"That's\" not Poirot! He isn't at all like that!\" Ustinov overheard and remarked \"He is \"now!\"\"\n\nHe appeared again as Poirot in three made-for-television movies: \"Thirteen at Dinner\" (1985), \"Dead Man's Folly\" (1986), and \"Murder in Three Acts\" (1986). Earlier adaptations were set during the time in which the novels were written, but these TV movies were set in the contemporary era. The first of these was based on \"Lord Edgware Dies\" and was made by Warner Bros. It also starred Faye Dunaway, with David Suchet as Inspector Japp, just before Suchet began to play Poirot. David Suchet considers his performance as Japp to be \"possibly the worst performance of [his] career\".\n\n\nDavid Suchet starred as Poirot in the ITV series \"Agatha Christie's Poirot\" from 1989 until June 2013, when he announced that he was bidding farewell to the role. \"No one could've guessed then that the series would span a quarter-century or that the classically trained Suchet would complete the entire catalogue of whodunits featuring the eccentric Belgian investigator, including 33 novels and dozens of short stories.\" His final appearance was in an adaptation of \"Curtain: Poirot's Last Case\", aired on 13 November 2013. During the time that it was filmed, Suchet expressed his sadness at his final farewell to the Poirot character whom he had loved:\n\nPoirot's death was the end of a long journey for me. I had only ever wanted to play Dame Agatha's true Poirot [...] He was as real to me as he had been to her: a great detective, a remarkable man, if, perhaps, just now and then, a little irritating.\n\nI think back to Poirot’s last words in the scene before he dies. That second ‘Cher ami’ was for someone other than Hastings. It was for my dear, dear friend Poirot. I was saying goodbye to him as well — and I felt it with all my heart.\n\nThe writers of the \"Binge!\" article of \"Entertainment Weekly\" Issue #1343-44 (26 December 2014 – 3 January 2015) picked Suchet as \"Best Poirot\" in the \"Hercule Poirot & Miss Marple\" timeline.\n\n\nIn 2004, NHK (Japanese public TV network) produced a 39 episode anime series titled \"Agatha Christie's Great Detectives Poirot and Marple\", as well as a manga series under the same title released in 2005. The series, adapting several of the best-known Poirot and Marple stories, ran from 4 July 2004 through 15 May 2005, and in repeated reruns on NHK and other networks in Japan. Poirot was voiced by Kōtarō Satomi and Miss Marple was voiced by Kaoru Yachigusa.\n\nRadio adaptations of the Poirot stories also appeared, most recently twenty seven of them on BBC Radio 4 (and regularly repeated on BBC 7, later BBC Radio 4 Extra), starring John Moffatt; Maurice Denham and Peter Sallis have also played Poirot on BBC Radio 4 in \"The Mystery of the Blue Train\" and in \"Hercule Poirot's Christmas\", respectively.\n\nIn 1939, Orson Welles and the Mercury Players dramatised \"Roger Ackroyd\" on CBS's \"Campbell Playhouse\".\n\nA 1945 radio series of at least 13 original half-hour episodes (none of which apparently adapt any Christie stories) transferred Poirot from London to New York and starred character actor Harold Huber, perhaps better known for his appearances as a police officer in various Charlie Chan films. On 22 February 1945, \"speaking from London, Agatha Christie introduced the initial broadcast of the Poirot series via shortwave\".\n\nAn adaptation of \"Murder in the Mews\" was broadcast on the BBC Light Programme in March 1955 starring Richard Williams as Poirot; this program was thought lost, but was recently discovered in the BBC archives in 2015.\n\nRecorded and released (John Moffatt stars as Poirot unless otherwise indicated):\n\nIn a 1964 episode of the TV series \"Burke's Law\" entitled \"Who Killed Supersleuth?\", Ed Begley plays a parody of Poirot named Bascule Doirot.\n\nIn \"Revenge of the Pink Panther\", Poirot makes a cameo appearance in a mental asylum, portrayed by Andrew Sachs and claiming to be \"the greatest detective in all of France, the greatest in all the world\".\n\nIn Neil Simon's \"Murder By Death\", American actor James Coco plays \"Milo Perrier\", a parody of Poirot. The film also features parodies of Charlie Chan, Sam Spade, Nick and Nora Charles, Hildegarde Withers, and Miss Marple.\n\nIn season 7 episode 2 of \"The Benny Hill Show\", a sketch entitled \"Murder on the Oregon Express\" had Benny Hill parodying Poirot (also Deputy Sam McCloud, Frank Cannon, Theo Kojak and Robert Ironside). Hill played Poirot as French, not Belgian).\n\nDudley Jones played Poirot in the film \"The Strange Case of the End of Civilization as We Know It\" (1977).\n\nIn the movie \"Spice World\", Poirot (Hugh Laurie) \"accuses\" a weapons-packing Emma Bunton of the crime.\n\nMuch the same joke had already been done in \"The Mary Whitehouse Experience\", with Poirot played by Steve Punt, failing to accuse Hannibal Lecter of an obvious murder.\n\nIn \"\", Poirot appears as a young boy on the train transporting Holmes and Watson. Holmes helps the boy in opening a puzzle-box, with Watson giving the boy advice about using his \"little grey cells\", giving the impression that Poirot first heard about grey cells and their uses from Dr. Watson.\n\nThe Belgian brewery Brasserie Ellezelloise makes a highly rated stout called \"Hercule\" with a moustachioed caricature of Hercule Poirot on the label.\n\nIn the final host segment of \"Mystery Science Theater 3000\"s episode \"The Rebel Set\", Tom Servo dresses up as Poirot and impersonates him in an attempt to discover the identity of B-movie actor Merritt Stone.\n\nJason Alexander played Poirot in episode 8 of \"Muppets Tonight\" in a spoof called \"Murder on the Disoriented Express\".\n\nPoirot is parodied twice in sketch show \"That Mitchell and Webb Look\", where he is played by David Mitchell; one sketch sees him identifying a killer due to her use of \"the evil voice\"—a voice that only murderers use—admitting that he otherwise had no evidence, and a later sketch sees him meeting a ship captain who is also played by Mitchell.\n\nPeter Serafinowicz parodied Poirot in \"The Peter Serafinowicz Show\", in which the detective is paired up with Miss Marple to crack a case, and the two promptly begin an illicit affair instead of solving the crime.\n\nLeo Bruce parodied Hercule Poirot with the character Amer Picon in his book \"Case for Three Detectives\" (1936); the other two characters were parodies of Lord Peter Wimsey and Father Brown.\n\nIn C. Northcote Parkinson's charity biography based on the P. G. Wodehouse character, \"Jeeves, A Gentleman's Personal Gentleman\", Poirot is one of a number of famous detectives beaten to a mystery's solution by the eponymous valet.\n\nIn season 2, episode 4 of TVFPlay's Indian web series \"Permanent Roommates\", one of the characters refers to Hercule Poirot as her inspiration while she attempts to solve the mystery of the cheating spouse. Throughout the episode, she is mocked as Hercule Poirot and Agatha Christie by the suspects. TVFPlay also telecasted a spoof of Indian TV suspense drama \"CID\" as \"\"Qissa Missing Dimaag Ka: C.I.D Qtiyapa\"\". In the first episode, when Ujjwal is shown to browse for the best detectives of the world, David Suchet appears as Poirot in his search.\n\n\n\n\n", "id": "1000", "title": "Hercule Poirot"},{"url": "https://en.wikipedia.org/wiki?curid=1002", "text": "Miss Marple\n\nJane Marple, usually referred to as Miss Marple, is a fictional character appearing in 12 of Agatha Christie's crime novels and in 20 short stories. Miss Marple is an elderly spinster who lives in the village of St. Mary Mead and acts as an amateur consulting detective. Alongside Hercule Poirot, she is one of the most loved and famous of Christie's characters and has been portrayed numerous times on screen. Her first appearance was in a short story published in \"The Royal Magazine\" in December 1927, \"The Tuesday Night Club\", which later became the first chapter of \"The Thirteen Problems\" (1932). Her first appearance in a full-length novel was in \"The Murder at the Vicarage\" in 1930.\n\nThe character of Miss Marple is based on Christie's step grandmother, or her aunt (Margaret West), and her cronies. Agatha Christie attributed the inspiration for the character of Miss Marple to a number of sources, stating that Miss Marple was \"the sort of old lady who would have been rather like some of my step grandmother's Ealing cronies – old ladies whom I have met in so many villages where I have gone to stay as a girl\". Christie also used material from her fictional creation, spinster Caroline Sheppard, who appeared in \"The Murder of Roger Ackroyd\". When Michael Morton adapted the novel for the stage, he replaced the character of Caroline with a young girl. This change saddened Christie and she determined to give old maids a voice: Miss Marple was born.\n\nThere is no definitive source for the derivation of the name 'Marple'. The most common explanation is that the name was taken from Marple railway station in Stockport, through which Christie passed. Alternatively, Christie may have taken the name from a family named Marple, who lived at Marple Hall near her sister Madge's home at Abney Hall.\n\nThe character of Jane Marple in the first Miss Marple book, \"The Murder at the Vicarage\", is markedly different from how she appears in later books. This early version of Miss Marple is a gleeful gossip and not an especially nice woman. The citizens of St. Mary Mead like her but are often tired by her nosy nature and how she seems to expect the worst of everyone. In later books she becomes more modern and a kinder person.\n\nMiss Marple solves difficult crimes because of her shrewd intelligence, and St. Mary Mead, over her lifetime, has given her seemingly infinite examples of the negative side of human nature. Crimes always remind her of a parallel incident, although acquaintances may be bored by analogies that often lead her to a deeper realization about the true nature of a crime. She also has a remarkable ability to latch onto a casual comment and connect it to the case at hand. In several stories, she is able to rely on her acquaintance with Sir Henry Clithering, a retired commissioner of the Metropolitan Police, for official information when required.\n\nMiss Marple never married and has no close living relatives. Her nephew, the \"well-known author\" Raymond West appears in some stories including \"Sleeping Murder\" and \"Ingots of Gold\", which also feature his wife Joan, a modern artist (though prior to their marriage she is referred to as \"Joyce Lemprière\", in \"The Thirteen Problems\" stories). Raymond overestimates himself and underestimates his aunt's mental acuity. Miss Marple employs young women (Clara, Emily, Alice, Esther, Gwenda and Amy) from a nearby orphanage, whom she trains for service as general housemaids after the retirement of her long-time maid-housekeeper faithful Florence. She was briefly looked after by her irritating maid, Miss Knight. In her later years, companion Cherry Baker, first introduced in \"The Mirror Crack'd From Side to Side\", lives in.\n\nMiss Marple has never worked for her living and is of independent means, although she benefits in her old age from the financial support of Raymond West, her nephew (\"A Caribbean Mystery\", 1964). She is not herself from the aristocracy or landed gentry, but is quite at home among them and would probably have been happy to describe herself as \"genteel\"; indeed, a \"gentlewoman\". Miss Marple may thus be considered a female version of that staple of British detective fiction, the gentleman detective. She demonstrates a remarkably thorough education, including some art courses that involved study of human anatomy through the study of human cadavers. In \"They Do It with Mirrors\" (1952), it is revealed that Miss Marple grew up in a cathedral close, and that she studied at an Italian finishing school with Americans Ruth Van Rydock and Caroline \"Carrie\" Louise Serrocold.\n\nWhile Miss Marple is described as 'an old lady' in many of the stories, her age is mentioned in \"At Bertram's Hotel\", where it is said she visited the hotel when she was fourteen and almost sixty years have passed since then. Excluding \"Sleeping Murder\", 41 years passed between the first and last-written novels, and many characters grow and age. An example would be the Vicar's nephew: in \"The Murder at the Vicarage\", the Reverend Clement's nephew Dennis is a teenager; in \"The Mirror Crack'd from Side to Side\", it is mentioned that the nephew is now grown and successful and has a career. The effects of ageing are seen on Miss Marple, such as needing a holiday after illness in \"A Caribbean Mystery\".\n\nLittle is known about Marple's background, except that she has two younger sisters. One of them is the mother of Raymond, and the other is mother to Mabel Denham, a young woman who was accused of poisoning her husband Geoffrey (\"The Thumb Mark of St. Peter\").\n\n\n\nMiss Marple also appears in \"Greenshaw's Folly\", a short story traditionally included as part of the Poirot collection \"The Adventure of the Christmas Pudding\" (1960). Four stories in the \"Three Blind Mice\" collection (1950) feature Miss Marple: \"Strange Jest\", \"Tape-Measure Murder\", \"The Case of the Caretaker\", and \"The Case of the Perfect Maid\".\n\nThe Autograph edition of \"Miss Marple's Final Cases\" includes the 8 in the original plus \"Greenshaw's Folly\".\n\n\nAlthough popular from her first appearance in 1930, Jane Marple had to wait thirty-two years for her first big-screen appearance, starring Margaret Rutherford. These were popular and successful light comedies, but were disappointing to Christie herself. Nevertheless, Agatha Christie dedicated the novel \"The Mirror Crack'd from Side to Side\" to Rutherford.\n\nRutherford presented the character as a bold and eccentric old lady, different from the prim and birdlike character Christie created in her novels. As penned by Christie, Miss Marple has never worked for a living, but the character as portrayed by Margaret Rutherford briefly works as a cook, a stage actress, a sailor and is offered the chance to run a riding establishment-cum-hotel. Her education and genteel background are hinted at when she mentions her awards at marksmanship, fencing and equestrianism (although these hints are played for comedic value).\n\n\"Murder, She Said\" (1961, directed by George Pollock) was the first of four British MGM productions starring Rutherford. This first film was based on the 1957 novel \"4:50 from Paddington\" (U.S. title, \"What Mrs. McGillicuddy Saw!\"), and the changes made in the plot were typical of the series. In the film, Mrs. McGillicuddy is cut from the plot. Miss Marple herself sees an apparent murder committed on a train running alongside hers. Likewise, it is Miss Marple herself who poses as a maid to find out the facts of the case, not a young friend of hers who has made a business of it.\n\nThe other Rutherford films, all directed by Pollock, were \"Murder at the Gallop\" (1963), based on the 1953 Hercule Poirot novel \"After the Funeral\" (in this film, she is identified as Miss JTV Marple, though there was no indication as to what the extra initials might stand for); \"Murder Most Foul\" (1964), based on the 1952 Poirot novel \"Mrs McGinty's Dead\"; and \"Murder Ahoy!\" (1964). The last film is not based on any Christie work but displays a few plot elements from \"They Do It With Mirrors\" (viz., the ship is used as a reform school for wayward boys and one of the teachers uses them as a crime force), and there is a kind of salute to \"The Mousetrap\". Rutherford also appeared briefly as Miss Marple in the spoof Hercule Poirot adventure \"The Alphabet Murders\" (1965).\n\nThe music to all four films was composed and conducted by Ron Goodwin and is still played on radio today. The same theme is used on all four films with slight variations on each. The main theme has a distinct 1960s feel to it and is known to be a highly complex piece of music due to the quick playing of the violin. The score was written within a couple of weeks by Goodwin who was approached by Pollock after Pollock had heard about him from Stanley Black. Black had worked with Pollock on \"Stranger in Town\" in 1957 and had previously used Goodwin as his orchestrator.\n\nRutherford, who was 70 years old when the first film was made, insisted that she wear her own clothes during the filming of the movie, as well as having her real-life husband, Stringer Davis, appear alongside her as the character 'Mr Stringer'. The Rutherford films are frequently repeated on television in Germany, and in that country Miss Marple is generally identified with Rutherford's quirky portrayal.\n\nIn 1980, Angela Lansbury played Miss Marple in \"The Mirror Crack'd\" (EMI, directed by Guy Hamilton), based on Christie's 1962 novel. The film featured an all-star cast that included Elizabeth Taylor, Rock Hudson, Geraldine Chaplin, Tony Curtis, and Kim Novak. Edward Fox appeared as Inspector Craddock, who did Miss Marple's legwork. Lansbury's Marple was a crisp, intelligent woman who moved stiffly and spoke in clipped tones. Unlike most incarnations of Miss Marple, this one smoked cigarettes.\n\nLansbury later starred in the TV series \"Murder, She Wrote\" as Jessica Fletcher, a mystery novelist who also solves crimes. The character of Jessica Fletcher is thought to be based on a combination of Miss Marple, Agatha Christie herself, and another Christie character, Ariadne Oliver, who often appears in the Hercule Poirot mysteries.\n\nHelen Hayes starred in two Miss Marple films for television: \"A Caribbean Mystery\" (1983) and \"Murder with Mirrors\" (1985), near the end of her decades long acting career. She had earlier appeared in a TV movie adaptation of the non-Marple Christie story \"Murder Is Easy\", playing an elderly lady somewhat similar to Miss Marple.\n\nIn 1983, Estonian stage and film actress Ita Ever starred in the Russian language film adaptation of Agatha Christie's novel \"A Pocket Full of Rye\" (using the Russian edition's translated title, \"The Secret of the Blackbirds\") as the character of Miss Marple.\n\nAmerican TV was the setting for the first dramatic portrayal of Miss Marple with Gracie Fields, the legendary British actress, playing her in a 1956 episode of \"Goodyear TV Playhouse\" based on \"A Murder Is Announced\", the 1950 Christie novel.\n\nIn 1970, the character of Miss Marple was portrayed by Inge Langen in a West German television adaptation of \"The Murder at the Vicarage \" (\"Mord im Pfarrhaus\").\n\nAmerican stage and screen actress Helen Hayes portrayed Miss Marple in two American made-for-TV movies, both for CBS: \"A Caribbean Mystery\" (1983) and \"Murder with Mirrors\" (1985). Sue Grafton contributed to the screenplay of the former. Hayes's Marple was benign and chirpy.\n\nIn 2015, CBS plans a \"much younger\" version of the character, a granddaughter who takes over a California bookstore.\n\nFrom 1984 to 1992, the BBC adapted all of the original Miss Marple novels as a series titled \"Miss Marple\". Joan Hickson played the lead role. In the 1940s, Joan appeared on-stage in an Agatha Christie play, \"Appointment with Death\", which was seen by Christie who wrote in a note to her, \"I hope one day you will play my dear Miss Marple\". (Coincidentally, Hickson had played a housekeeper in \"Murder, She Said\", the first film in which Margaret Rutherford played Miss Marple.) In addition she portrayed a maid in the 1937 film, \"Love from a Stranger\", which starred Ann Harding and Basil Rathbone, another Agatha Christie play adaptation. As well as portraying Miss Marple on television, Hickson also narrated a number of Miss Marple stories on audio books. In the \"Binge!\" article of \"Entertainment Weekly\" Issue #1343-44 (26 December 2014–3 January 2015), the writers picked Hickson as \"Best Marple\" in the \"Hercule Poirot & Miss Marple\" timeline.\n\nListing of the TV series featuring Joan Hickson:\n\nBeginning in 2004, ITV broadcast a series of adaptations of Agatha Christie's books under the title \"Agatha Christie's Marple\", usually referred to as \"Marple.\" Geraldine McEwan starred in the first three series. Julia McKenzie took over the role in the fourth season.\n\nThe adaptations are notable for changing the plots and characters of the original books (e.g. incorporating lesbian affairs, changing the identities of some killers, renaming or removing significant characters, and even using stories from other books in which Miss Marple did not originally feature). In the Geraldine McEwan series it is revealed that when she was young, Miss Marple had an affair with a married soldier, Captain Ainsworth, who was killed in action in World War I, in December 1915. It is also said (in \"A Murder Is Announced\") that she served as a nurse during World War II.\n\nListing of the TV series featuring Geraldine McEwan and Julia McKenzie:\n\nFrom 2004 to 2005, Japanese TV network NHK produced a 39 episode anime series titled \"Agatha Christie's Great Detectives Poirot and Marple\", which features both Miss Marple and Hercule Poirot. Miss Marple's voice is provided by Kaoru Yachigusa. Episodes adapted both short stories and novels.\n\nThe anime series dramatised the following Miss Marple stories:\n\nIn 1974, Barbara Mullen played Miss Marple in \"Murder at the Vicarage\" at the Savoy Theatre, London.\n\nIn September 1977, veteran actress and author Dulcie Gray played the Miss Marple character in a stage adaptation of \"A Murder Is Announced\" at the Vaudeville Theatre in London, England that also featured Dinah Sheridan, Eleanor Summerfield, Patricia Brake and Barbara Flynn.\n\nBBC Radio 4 dramatised all of the novels from 1993 to 2001 with June Whitfield as Miss Marple.\nMiss Marple was also referred to several times in the episode \"Paris\" of the BBC Radio 4 comedy programme Cabin Pressure.\n\nMarple was highlighted in volume 20 of the \"Case Closed\" manga's edition of \"Gosho Aoyama's Mystery Library\", a section of the graphic novels (usually the last page) where the author introduces a different detective (or occasionally, a villain) from mystery literature, television, or other media.\n\nIn the 1976 Neil Simon spoof \"Murder By Death\", Miss Marple is parodied as \"Miss Marbles\" by Elsa Lanchester.\n\n\n", "id": "1002", "title": "Miss Marple"},{"url": "https://en.wikipedia.org/wiki?curid=1004", "text": "April\n\nApril is the fourth month of the year in the Gregorian calendar, the fifth in the early Julian and the first month to have the length of 30 days.\n\nApril is commonly associated with the season of spring in parts of the Northern Hemisphere and autumn in parts of the Southern Hemisphere, where it is the seasonal equivalent to October in the Northern Hemisphere and vice versa.\n\nThe Romans gave this month the Latin name \"Aprilis\" but the derivation of this name is uncertain. The traditional etymology is from the verb \"aperire\", \"to open\", in allusion to its being the season when trees and flowers begin to \"open\", which is supported by comparison with the modern Greek use of άνοιξη (\"ánixi\") (opening) for spring. Since some of the Roman months were named in honor of divinities, and as April was sacred to the goddess Venus, her Veneralia being held on the first day, it has been suggested that Aprilis was originally her month Aphrilis, from her equivalent Greek goddess name Aphrodite (\"Aphros\"), or from the Etruscan name \"Apru\". Jacob Grimm suggests the name of a hypothetical god or hero, \"Aper\" or \"Aprus\".\n\nApril was the second month of the earliest Roman calendar, before \"Ianuarius\" and \"Februarius\" were added by King Numa Pompilius about 700 BC. It became the fourth month of the calendar year (the year when twelve months are displayed in order) during the time of the decemvirs about 450 BC, when it also was given 29 days. The 30th day was added during the reform of the calendar undertaken by Julius Caesar in the mid-40s BC, which produced the Julian calendar.\n\nThe Anglo-Saxons called April \"ēastre-monaþ\". The Venerable Bede says in \"The Reckoning of Time\" that this month \"ēastre\" is the root of the word Easter. He further states that the month was named after a goddess \"Eostre\" whose feast was in that month. It is also attested by Einhard in his work, Vita Karoli Magni.\n\nSt George's day is the twenty-third of the month; and St Mark's Eve, with its superstition that the ghosts of those who are doomed to die within the year will be seen to pass into the church, falls on the twenty-fourth.\n\nIn China the symbolic ploughing of the earth by the emperor and princes of the blood took place in their third month, which frequently corresponds to April. In Finnish April is \"huhtikuu\", meaning \"slash-and-burn moon\", when gymnosperms for beat and burn clearing of farmland were felled.\n\nIn Slovene, the most established traditional name is \"mali traven\", meaning the month when plants start growing. It was first written in 1466 in the Škofja Loka manuscript.'\n\nThe month Aprilis had 30 days; Numa Pompilius made it 29 days long; finally Julius Caesar’s calendar reform made it again 30 days long, which was not changed in the calendar revision of Augustus Caesar in 8 BC.\n\nIn Ancient Rome, the festival of Cerealia was held for seven days from mid-to-late April, but exact dates are uncertain. Feriae Latinae was also held in April, with the date varying. Other ancient Roman observances include Veneralia (April 1), Megalesia (April 10–16), Fordicidia (April 15), Parilia (April 21), Vinalia Urbana, Robigalia, and Serapia were celebrated on (April 25). Floralia was held April 27 during the Republican era, or April 28 on the Julian calendar, and lasted until May 3. However, these dates do not correspond to the modern Gregorian calendar.\n\nThe Lyrids meteor shower appears on April 16 – April 26 each year, with the peak generally occurring on April 22. Eta Aquariids meteor shower also appears in April. It is visible from about April 21 to about May 20 each year with peak activity on or around May 6. The Pi Puppids appear on April 23, but only in years around the parent comet's perihelion date. The Virginids also shower at various dates in April.\n\nThe \"Days of April\" (\"journées d'avril\") is a name appropriated in French history to a series of insurrections at Lyons, Paris and elsewhere, against the government of Louis Philippe in 1834, which led to violent repressive measures, and to a famous trial known as the \"procès d'avril\".\n\n\n\"This list does not necessarily imply either official status nor general observance.\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "1004", "title": "April"},{"url": "https://en.wikipedia.org/wiki?curid=1005", "text": "August\n\nAugust is the eighth month of the year in the Julian and Gregorian calendars, falling between July and September, and the fifth month to have the length of 31 days. It was originally named \"Sextilis\" in Latin because it was the sixth month in the original ten-month Roman calendar under Romulus in 753 BC, and March was the first month of the year. About 700 BC, it became the eighth month when January and February were added to the year before March by King Numa Pompilius, who also gave it 29 days. Julius Caesar added two days when he created the Julian calendar in 45 BC, giving it its modern length of 31 days. In 8 BC, it was renamed in honor of Augustus. According to a Senatus consultum quoted by Macrobius, he chose this month because it was the time of several of his great triumphs, including the conquest of Egypt.\n\nIn the Southern Hemisphere, August is the seasonal equivalent of February in the Northern Hemisphere. In many European countries, August is the holiday month for most workers. Numerous religious holidays occurred during August in ancient Rome.\n\nCertain meteor showers take place in August. The Kappa Cygnids take place in August, with the dates varying each year. The Alpha Capricornids meteor shower takes place as early as July 10 and ends at around August 10, and the Southern Delta Aquariids take place from mid-July to mid-August, with the peak usually around July 28–29. The Perseids, a major meteor shower, typically takes place between July 17 and August 24, with the days of the peak varying yearly. The star cluster of Messier 30 is best observed around August.\n\n\n\"This list does not necessarily imply either official status or general observance.\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "id": "1005", "title": "August"},{"url": "https://en.wikipedia.org/wiki?curid=1006", "text": "Aaron\n\nAaron (; or ) is a prophet, high priest, and the brother of Moses in the Abrahamic religions (elder brother in the case of Judaism).\n\nKnowledge of Aaron, along with his brother Moses, comes exclusively from religious texts, such as the Bible and Qur’an. The Hebrew Bible relates that, unlike Moses, who grew up in the Egyptian royal court, Aaron and his elder sister Miriam remained with their kinsmen in the eastern border-land of Egypt (Goshen). When Moses first confronted the Egyptian king about the Israelites, Aaron served as his brother's spokesman (\"prophet\") to the Pharaoh. Part of the Law (Torah) that Moses received from God at Sinai granted Aaron the priesthood for himself and his male descendants, and he became the first High Priest of the Israelites. Aaron died before the Israelites crossed the North Jordan river and he was buried on Mount Hor (Numbers 33:39; Deuteronomy 10:6 says he died and was buried at Moserah). Aaron is also mentioned in the New Testament of the Bible.\n\nAccording to the Book of Exodus, Aaron first functioned as Moses' assistant. Because Moses complained that he could not speak well, God appointed Aaron as Moses' \"prophet\" (Exodus 4:10-17; 7:1). At the command of Moses, he let his rod turn into a snake. Then he stretched out his rod in order to bring on the first three plagues. After that, Moses tended to act and speak for himself.\n\nDuring the journey in the wilderness, Aaron was not always prominent or active. At the battle with Amalek, he was chosen with Hur to support the hand of Moses that held the \"rod of God\". When the revelation was given to Moses at Mount Sinai, he headed the elders of Israel who accompanied Moses on the way to the summit. While Joshua went with Moses to the top, however, Aaron and Hur remained below to look after the people. From here on in Exodus, Leviticus and Numbers, Joshua appears in the role of Moses' assistant while Aaron functions instead as the first high priest.\n\nThe books of Exodus, Leviticus and Numbers maintain that Aaron received from God a monopoly over the priesthood for himself and his male descendants (Exodus 28:1). The family of Aaron had the exclusive right and responsibility to make offerings on the altar to the God of Israel. The rest of his tribe, the Levites, were given subordinate responsibilities within the sanctuary (Numbers 3). Moses anointed and consecrated Aaron and his sons to the priesthood, and arrayed them in the robes of office (Leviticus 8; cf. Exodus 28-29). He also related to them God's detailed instructions for performing their duties while the rest of the Israelites listened (Leviticus 1-7, 11-27). Aaron and his successors as high priest were given control over the Urim and Thummim by which the will of God could be determined (Exodus 28:30). God commissioned the Aaronide priests to distinguish the holy from the common and the clean from the unclean, and to teach the divine laws (the Torah) to the Israelites (Leviticus 10:10-11). The priests were also commissioned to bless the people (Numbers 6:22-27). When Aaron completed the altar offerings for the first time and, with Moses, \"blessed the people: and the glory of the appeared unto all the people: And there came a fire out from before the , and consumed upon the altar the burnt offering and the fat [which] when all the people saw, they shouted, and fell on their faces\" (Leviticus 9:23-24). In this way, the institution of the Aaronide priesthood was established.\n\nIn later books of the Old Testament, Aaron and his kin are not mentioned very often except in literature dating to the Babylonian Exile and later. The books of Judges, Samuel and Kings mention priests and Levites, but do not mention the Aaronides in particular. The book of Ezekiel, which devotes much attention to priestly matters, calls the priestly upper class the Zadokites after one of King David's priests. It does reflect a two-tier priesthood with the Levites in subordinate position. A two-tier hierarchy of Aaronides and Levites appears in Ezra, Nehemiah and Chronicles. As a result, many historians think that Aaronide families did not control the priesthood in pre-exilic Israel. What is clear is that high priests claiming Aaronide descent dominated the Second Temple period. Most scholars think the Pentateuch reached its final form early in this period, which may account for Aaron's prominence in Exodus, Leviticus and Numbers.\n\nAaron plays a leading role in several stories of conflicts over leadership during Israel's wilderness wanderings. During the prolonged absence of Moses on Mount Sinai, the people provoked Aaron to make a Golden Calf as a visible image of the divinity who had delivered them from Egypt (Exodus 32:1-6). This incident nearly caused God to destroy the Israelites for their unfaithfulness to the covenant (Exodus 32:10). Moses successfully intervened, but then led the loyal Levites in executing many of the culprits; a plague afflicted those who were left (Exodus 32:25-35). Aaron, however, escaped punishment for his role in the affair, because of the intercession of Moses according to Deuteronomy 9:20. Later retellings of this story almost always excuse Aaron for his role. For example, in rabbinic sources and in the Qur'an, Aaron was not the idol-maker and upon Moses' return begged his pardon because he felt mortally threatened by the Israelites (Quran 7:142-152).\n\nOn the day of Aaron's consecration, his oldest sons, Nadab and Abihu, were burned up by divine fire because they offered \"strange\" incense (Leviticus 10:1-3). Most interpreters think this story reflects a conflict between priestly families some time in Israel's past. Others argue that the story simply shows what can happen if the priests do not follow God's instructions given through Moses.\n\nThe Pentateuch generally depicts the siblings, Moses, Aaron, and Miriam, as the leaders of Israel after the Exodus, a view also reflected in the biblical book of Micah. Numbers 12, however, reports that on one occasion, Aaron and Miriam complained about Moses' exclusive claim to be the 's prophet. Their presumption was rebuffed by God who affirmed Moses' uniqueness as the one with whom the spoke face to face. Miriam was punished with skin disease (\"leprous\"), that turned her skin white. Aaron pleaded with Moses to intercede for her, and Miriam, after seven days' quarantine, was healed. Aaron once again escaped any retribution.\n\nAccording to Numbers 16-17, a Levite named Korah led many in challenging Aaron's exclusive claim to the priesthood. When the rebels were punished by being swallowed up by the earth, (Numbers 16:25-35), Eleazar, the son of Aaron, was commissioned to take charge of the censers of the dead priests. And when a plague broke out among the people who had sympathized with the rebels, Aaron, at the command of Moses, took his censer and stood between the living and the dead till the plague abated (Numbers 17:1-15, 16:36-50).\nTo emphasize the validity of the Levites' claim to the offerings and tithes of the Israelites, Moses collected a rod from the leaders of each tribe in Israel and laid the twelve rods over night in the tent of meeting. The next morning, Aaron's rod was found to have budded and blossomed and produced ripe almonds (Numbers 17:8). The following chapter then details the distinction between Aaron's family and the rest of the Levites: while all the Levites (and only Levites) were devoted to the care of the sanctuary, charge of its interior and the altar was committed to the Aaronites alone (Numbers 18:1-7).\n\nAaron, like Moses, was not permitted to enter Canaan with the Israelites because the two brothers showed impatience at Meribah (Kadesh) in the last year of the desert pilgrimage (Numbers 20:12-13), when Moses brought water out of a rock to quench the people's thirst. Though they had been commanded to speak to the rock, Moses struck it with the staff twice, which was construed as displaying a lack of deference to the (Numbers 20:7-11).\n\nThere are two accounts of the death of Aaron in the Pentateuch. Numbers says that soon after the incident at Meribah, Aaron with his son Eleazar and Moses ascended Mount Hor. There Moses stripped Aaron of his priestly garments and transferred them to Eleazar. Aaron died on the summit of the mountain, and the people mourned for him thirty days (Numbers 20:22-29; compare 33:38-39). The other account is found in Deuteronomy 10:6, where Aaron died at Moserah and was buried. There is a significant amount of travel between these two points, as the itinerary in Numbers 33:31–37 records seven stages between Moseroth (Mosera) and Mount Hor. Aaron was 123 at the time of his death.\n\nAaron married Elisheba, daughter of Amminadab and sister of Nahshon (Exodus 6:23) of the tribe of Judah. The sons of Aaron were Eleazar, Ithamar, and Nadab and Abihu. A descendant of Aaron is an Aaronite, or Kohen, meaning Priest. Any non-Aaronic Levite—i.e., descended from Levi but not from Aaron—assisted the Levitical priests of the family of Aaron in the care of the tabernacle; later of the temple.\n\nThe Gospel of Luke records that both Zechariah and Elizabeth and therefore their son John the Baptist were descendants of Aaron.\n\nThe older prophets and prophetical writers beheld in their priests the representatives of a religious form inferior to the prophetic truth; men without the spirit of God and lacking the will-power requisite to resist the multitude in its idolatrous proclivities. Thus Aaron, the first priest, ranks below Moses: he is his mouthpiece, and the executor of the will of God revealed through Moses, although it is pointed out that it is said fifteen times in the Pentateuch that \"the Lord spoke to Moses \"and\" Aaron.\" Under the influence of the priesthood that shaped the destinies of the nation under Persian rule, a different ideal of the priest was formed, according to Malachi 2:4–7, and the prevailing tendency was to place Aaron on a footing equal with Moses. \"At times Aaron, and at other times Moses, is mentioned first in Scripture—this is to show that they were of equal rank,\" says Mekilta,(12) who strongly implies this when introducing in his record of renowned men the glowing description of Aaron's ministration.\n\nIn fulfilment of the promise of peaceful life, symbolized by the pouring of oil upon his head (Leviticus Rabbah x., Midrash Teh. cxxxiii. 1), Aaron's death, as described in the Haggadah, was of a wonderful tranquility. Accompanied by Moses, his brother, and by Eleazar, his son, Aaron went to the summit of Mount Hor, where the rock suddenly opened before him and a beautiful cave lit by a lamp presented itself to his view. \"Take off thy priestly raiment and place it upon thy son Eleazar!\" said Moses; \"and then follow me.\" Aaron did as commanded; and they entered the cave, where was prepared a bed around which angels stood. \"Go lie down upon thy bed, my brother,\" Moses continued; and Aaron obeyed without a murmur. Then his soul departed as if by a kiss from God. The cave closed behind Moses as he left; and he went down the hill with Eleazar, with garments rent, and crying: \"Alas, Aaron, my brother! thou, the pillar of supplication of Israel!\" When the Israelites cried in bewilderment, \"Where is Aaron?\" angels were seen carrying Aaron's bier through the air. A voice was then heard saying: \"The law of truth was in his mouth, and iniquity was not found on his lips: he walked with me in righteousness, and brought many back from sin\" (Malachi 2:6). He died, according to Seder Olam Rabbah ix., R. H. 2, 3a, on the first of Ab.\" The pillar of cloud which proceeded in front of Israel's camp disappeared at Aaron's death (see Seder 'Olam, ix. and R. H. 2b-3a). The seeming contradiction between Numbers 20:22 et seq. and Deuteronomy 10:6 is solved by the rabbis in the following manner: Aaron's death on Mount Hor was marked by the defeat of the people in a war with the king of Arad, in consequence of which the Israelites fled, marching seven stations backward to Mosera, where they performed the rites of mourning for Aaron; wherefore it is said: \"There [at Mosera] died Aaron.\"\n\nThe rabbis also dwell with special laudation on the brotherly sentiment which united Aaron and Moses. When the latter was appointed ruler and Aaron high priest, neither betrayed any jealousy; instead they rejoiced in one another's greatness. When Moses at first declined to go to Pharaoh, saying: \"O my Lord, send, I pray thee, by the hand of him whom thou wilt send\" (Exodus 4:13), he was unwilling to deprive Aaron, his brother, of the high position the latter had held for so many years; but the Lord reassured him, saying: \"Behold, when he seeth thee, he will be glad in his heart\" (). Indeed, Aaron was to find his reward, says Shimon bar Yochai; for that heart which had leaped with joy over his younger brother's rise to glory greater than his was decorated with the Urim and Thummim, which were to \"be upon Aaron's heart when he goeth in before the Lord\" (Canticles Rabbah i. 10). Moses and Aaron met in gladness of heart, kissing each other as true brothers (Exodus 4:27; compare Song of Songs 8:1), and of them it is written: \"Behold how good and how pleasant [it is] for brethren to dwell together in unity!\" (Psalms 133:1). Of them it is said: \"Mercy and truth are met together; righteousness and peace have kissed [each other]\" (Psalms 85:10); for Moses stood for righteousness, according to Deuteronomy 33:21, and Aaron for peace, according to . Again, mercy was personified in Aaron, according to Deuteronomy 33:8, and truth in Moses, according to Numbers 12:7 .\n\nWhen Moses poured the oil of anointment upon the head of Aaron, Aaron modestly shrank back and said: \"Who knows whether I have not cast some blemish upon this sacred oil so as to forfeit this high office.\" Then the Shekhinah spoke the words: \"Behold the precious ointment upon the head, that ran down upon the beard of Aaron, that even went down to the skirts of his garment, is as pure as the dew of Hermon\" () .\n\nAccording to Tanhuma, Aaron's activity as a prophet began earlier than that of Moses. Hillel held Aaron up as an example, saying: \"Be of the disciples of Aaron, loving peace and pursuing peace; love your fellow creatures and draw them nigh unto the Law!\" This is further illustrated by the tradition preserved in Abot de-Rabbi Natan 12, Sanhedrin 6b, and elsewhere, according to which Aaron was an ideal priest of the people, far more beloved for his kindly ways than was Moses. While Moses was stern and uncompromising, brooking no wrong, Aaron went about as peacemaker, reconciling man and wife when he saw them estranged, or a man with his neighbor when they quarreled, and winning evil-doers back into the right way by his friendly intercourse. The mourning of the people at Aaron's death was greater, therefore, than at that of Moses; for whereas, when Aaron died the whole house of Israel wept, including the women, (Numbers 20:29) Moses was bewailed by \"the sons of Israel\" only (Deuteronomy 34:8). Even in the making of the Golden Calf the rabbis find extenuating circumstances for Aaron. His fortitude and silent submission to the will of God on the loss of his two sons are referred to as an excellent example to men how to glorify God in the midst of great affliction. Especially significant are the words represented as being spoken by God after the princes of the Twelve Tribes had brought their dedication offerings into the newly reared Tabernacle: \"Say to thy brother Aaron: Greater than the gifts of the princes is thy gift; for thou art called upon to kindle the light, and, while the sacrifices shall last only as long as the Temple lasts, thy light shall last forever.\"\n\nIn the Eastern Orthodox and Maronite churches, Aaron is venerated as a saint whose feast day is shared with his brother Moses and celebrated on September 4. (Those churches that follow the traditional Julian Calendar celebrate this day on September 17 of the modern Gregorian Calendar). Aaron is also commemorated with other Old Testament saints on the Sunday of the Holy Fathers, the Sunday before Christmas.\n\nAaron is commemorated as one of the Holy Forefathers in the Calendar of Saints of the Armenian Apostolic Church on July 30. He is commemorated on July 1 in the modern Latin calendar and in the Syriac Calendar.\n\nIn The Church of Jesus Christ of Latter-day Saints, the Aaronic order is the lesser order of priesthood, comprising the grades (from lowest to highest) of deacon, teacher, and priest. The chief office of the Aaronic priesthood is the presiding bishopric; the head of the priesthood is the bishop. Each ward includes a quorum of one or more of each office of the Aaronic priesthood.\n\nIn the Community of Christ, the Aaronic order of priesthood is regarded as an appendage to the Melchisedec order, and consists of the priesthood offices of deacon, teacher, and priest. While differing in responsibilities, these offices, along with those of the Melchisidec order, are regarded as equal before God.\n\nAaron (Arabic: هارون, \"Hārūn\") is also mentioned in the Qur’an as a prophet of God. The Qur’an praises Aaron repeatedly, calling him a \"believing servant\" as well as one who was \"guided\" and one of the \"victors\". Aaron is important in Islam for his role in the events of the Exodus, in which, according to the Qur’an and Muslim tradition, he preached with his elder brother, Moses, to the Pharaoh of the Exodus. Aaron's significance in Islam, however, is not limited to his role as the helper of Moses. Islamic tradition also accords Aaron the role of a patriarch, as tradition records that the priestly descent came through Aaron's lineage, which included the entire House of Amran.\n\nThe Qur’an contains numerous references to Aaron, both by name and without name. It says that he was a descendant of Abraham (Qur'an 4: 163) and makes it clear that both he and Moses were sent together to warn the Pharaoh about God's punishment (Qur'an 10: 75). It further adds that Moses had earlier prayed to God to strengthen his own ministry with Aaron (Qur'an 20: 29-30) and that Aaron helped Moses as he too was a prophet (Qur'an 19: 53), and very eloquent in matters of speech and discourse (Qur'an 28: 34). The Qur'an adds that both Moses and Aaron were entrusted to establish places of dwelling for the Israelites in Egypt, and to convert those houses into places of worship for God (Qur'an 10: 87).\n\nThe incident of the Golden Calf as it is narrated in the Qur'an paints Aaron in a positive light. The Qur'an says that Aaron was entrusted the leadership of Israel while Moses was up on \"Tur Sina’\" (, Mount Sinai) for a period of forty days (Qur'an 7: 142). It adds that Aaron tried his best to stop the worship of the Golden Calf, which was built not by Aaron but by a wicked man by the name of 'As-Samiri' (Qur'an 19: 50). When Moses returned from Mount Sinai, he rebuked Aaron for allowing the worship of the idol, to which Aaron pleaded with Moses to not blame him when he had no role in its construction (Qur'an 7: 150). The Qur'an then adds that Moses here lamented the sins of Israel, and said that he only had power over himself and Aaron (Qur'an 5: 25).\n\nAaron is later commemorated in the Qur'an as one who had a \"clear authority\" (Qur'an 23: 45) and one who was \"guided to the Right Path\" (Qur'an 37: 118). It further adds that Aaron's memory was left for people who came after him (Qur'an 37: 119) and he is blessed by God along with his brother (Qur'an 37: 120). The Qur'an also says that people called ‘Isa's mother Maryam (, Mary) a \"sister of Harun\" (Qur'an 19: 28). Muslim scholars debated as to who exactly this \"Harun\" was in terms of his historical persona, with some saying that it was a reference to Aaron of the Exodus, and the term \"sister\" designating only a metaphorical or spiritual link between the two figures, all the more evident when Mary was a descendant of the priestly lineage of Aaron, while others held it to be another righteous man living at the time of Christ by the name of \"Aaron\". Most scholars have agreed to the former perspective, and have linked Mary spiritually with the actual sister of Aaron, her namesake Miryam (, ), whom she resembled in many ways. The Qur'an also narrates that, centuries later, when the \"Tabut\" (, Ark of the Covenant) returned to Israel, it contained \"relics from the family of Moses and relics from the family of Aaron\" (Qur'an 2: 248).\n\nMuhammad, in many of his sayings, speaks of Aaron. In the event of the Mi'raj, his miraculous ascension through the Heavens, Muhammad is said to have encountered Aaron in the fifth heaven. According to old scholars, including Ibn Hisham, Muhammad, in particular, mentioned the beauty of Aaron when he encountered him in Heaven. Martin Lings, in his biographical \"Muhammad\", speaks of Muhammad's wonderment at seeing fellow prophets in their heavenly glory:\nAaron was also mentioned by Muhammad in likeness to ‘Ali. Muhammad had left ‘Ali to look after his family, but the hypocrites of the time begun to spread the rumor that the prophet found ‘Ali a burden and was relieved to be rid of his presence. ‘Ali, grieved at hearing this wicked taunt, told Muhammad what the local people were saying. In reply, the Prophet said: \"They lie, I bade thee remain for the sake of what I had left behind me. So return and represent me in my family and in thine. Art thou not content, O ‘Ali, that thou should be unto me as Aaron was unto Moses, save that after me there is no prophet.\"\n\nAccording to Islamic tradition, the tomb of Aaron is located on \"Jabal Harun\" (, Mountain of Aaron), near Petra in Jordan. At above sea-level, it is the highest peak in the area; and it is a place of great sanctity to the local people for here. A 14th-century Mamluk mosque stands here with its white dome visible from most areas in and around Petra.\n\nAlthough his father is described as both an apostle and a prophet, Aaron is merely described as a prophet. The Kitab-I-Iqan describes Imran as being his father.\n\nAaron appears paired with Moses frequently in Jewish and Christian art, especially in the illustrations of manuscript and printed Bibles. He can usually be distinguished by his priestly vestments, especially his turban or miter and jeweled breastplate. He frequently holds a censor or, sometimes, his flowering rod. (See at Wikimedia Commons.) Aaron also appears in scenes depicting the wilderness Tabernacle and its altar, as already in the third-century frescos in the synagogue at Dura-Europos in Syria. An eleventh-century portable silver altar from Fulda, Germany depicts Aaron with his censor, and is located in the Musée National de l’Age Médiévale in Paris. This is also how he appears in the frontispieces of early printed Passover Haggadot and occasionally in church sculptures. Aaron has rarely been the subject of portraits, such as those by Anton Kern [1710–1747] and by Pier Francesco Mola [c. 1650]. Christian artists sometimes portray Aaron as a prophet (Exod. 7:1) holding a scroll, as in a twelfth-century sculpture from the Cathedral of Noyon in the Metropolitan Museum of Art, New York and often in Eastern Orthodox icons. Illustrations of the Golden Calf story usually include him as well—most notably in Nicolas Poussin's \"The Adoration of the Golden Calf\" (ca. 1633–34, National Gallery London). Finally, some artists interested in validating later priesthoods have painted the ordination of Aaron and his sons (Leviticus 8). Harry Anderson's realistic portrayal is often reproduced in the literature of the Latter Day Saints.\n\n\n\n\n", "id": "1006", "title": "Aaron"},{"url": "https://en.wikipedia.org/wiki?curid=1008", "text": "April 6\n\n\n\n", "id": "1008", "title": "April 6"},{"url": "https://en.wikipedia.org/wiki?curid=1009", "text": "April 12\n\n\n\n", "id": "1009", "title": "April 12"},{"url": "https://en.wikipedia.org/wiki?curid=1010", "text": "April 15\n\n\n\n", "id": "1010", "title": "April 15"},{"url": "https://en.wikipedia.org/wiki?curid=1011", "text": "April 30\n\n\n\n", "id": "1011", "title": "April 30"},{"url": "https://en.wikipedia.org/wiki?curid=1012", "text": "August 22\n\n\n\n", "id": "1012", "title": "August 22"},{"url": "https://en.wikipedia.org/wiki?curid=1013", "text": "August 27\n\n\n\n", "id": "1013", "title": "August 27"},{"url": "https://en.wikipedia.org/wiki?curid=1014", "text": "Alcohol\n\nIn chemistry, an alcohol is any organic compound in which the hydroxyl functional group (–OH) is bound to a saturated carbon atom. The term alcohol originally referred to the primary alcohol ethanol (ethyl alcohol), the predominant alcohol in alcoholic beverages.\n\nThe suffix \"-ol\" appears in the IUPAC chemical name of all substances where the hydroxyl group is the functional group with the highest priority; in substances where a higher priority group is present the prefix \"hydroxy-\" will appear in the International Union of Pure and Applied Chemistry (IUPAC) name. The suffix \"-ol\" in non-systematic names (such as paracetamol or cholesterol) also typically indicates that the substance includes a hydroxyl functional group and, so, can be termed an alcohol. But many substances, particularly sugars (examples glucose and sucrose) contain hydroxyl functional groups without using the suffix. An important class of alcohols, of which methanol and ethanol are the simplest members is the saturated straight chain alcohols, the general formula for which is CHOH.\n\nMuhammad ibn Zakariya al-Razi ( \"Abūbakr Mohammad-e Zakariyyā-ye Rāzī\", also known by his Latinized name Rhazes or Rasis) (854 CE – 925 CE), was a Persian polymath, physician, alchemist, philosopher who discovered numerous compounds and chemicals including \"alcohol\" by developing several chemical instruments and methods of distillation.\n\nThe word \"alcohol\" is from the Arabic \"kohl\" (), a powder used as an eyeliner. Al- is the Arabic definite article, equivalent to \"the\" in English. \"Alcohol\" was originally used for the very fine powder produced by the sublimation of the natural mineral stibnite to form antimony trisulfide , hence the essence or \"spirit\" of this substance. It was used as an antiseptic, eyeliner, and cosmetic. The meaning of alcohol was extended to distilled substances in general, and then narrowed to ethanol, when \"spirits\" as a synonym for hard liquor.\n\nBartholomew Traheron, in his 1543 translation of John of Vigo, introduces the word as a term used by \"barbarous\" (Moorish) authors for \"fine powder.\" Vigo wrote: \"the barbarous auctours use alcohol, or (as I fynde it sometymes wryten) alcofoll, for moost fine poudre.\"\n\nThe 1657 \"Lexicon Chymicum\", by William Johnson glosses the word as \"antimonium sive stibium.\" By extension, the word came to refer to any fluid obtained by distillation, including \"alcohol of wine,\" the distilled essence of wine. Libavius in \"Alchymia\" (1594) refers to \"vini alcohol vel vinum alcalisatum\". Johnson (1657) glosses \"alcohol vini\" as \"quando omnis superfluitas vini a vino separatur, ita ut accensum ardeat donec totum consumatur, nihilque fæcum aut phlegmatis in fundo remaneat.\" The word's meaning became restricted to \"spirit of wine\" (the chemical known today as ethanol) in the 18th century and was extended to the class of substances so-called as \"alcohols\" in modern chemistry after 1850.\n\nThe term \"ethanol\" was invented 1892, based on combining the word ethane with \"ol\" the last part of \"alcohol\".\n\nIUPAC nomenclature is used in scientific publications and where precise identification of the substance is important, especially in cases where the relative complexity of the molecule does not make such a systematic name unwieldy. In the IUPAC system, in naming simple alcohols, the name of the alkane chain loses the terminal \"e\" and adds \"ol\", \"e.g.\", as in \"methanol\" and \"ethanol\". When necessary, the position of the hydroxyl group is indicated by a number between the alkane name and the \"ol\": propan-1-ol for , propan-2-ol for . If a higher priority group is present (such as an aldehyde, ketone, or carboxylic acid), then the prefix \"hydroxy\" is used, e.g., as in 1-hydroxy-2-propanone ().\n\nIn other less formal contexts, an alcohol is often called with the name of the corresponding alkyl group followed by the word \"alcohol\", e.g., methyl alcohol, ethyl alcohol. Propyl alcohol may be \"n\"-propyl alcohol or isopropyl alcohol, depending on whether the hydroxyl group is bonded to the end or middle carbon on the straight propane chain. As described under systematic naming, if another group on the molecule takes priority, the alcohol moiety is often indicated using the \"hydroxy-\" prefix.\nAlcohols are then classified into primary, secondary (\"sec-\", \"s-\"), and tertiary (\"tert-\", \"t-\"), based upon the number of carbon atoms connected to the carbon atom that bears the hydroxyl functional group. (The respective numeric shorthands 1°, 2°, and 3° are also sometimes used in informal settings.) The primary alcohols have general formulas RCHOH. The simplest primary alcohol is methanol (CHOH), for which R=H, and the next is ethanol, for which R=CH, the methyl group. Secondary alcohols are those of the form RR'CHOH, the simplest of which is 2-propanol (R=R'=CH). For the tertiary alcohols the general form is RR'R\"COH. The simplest example is tert-butanol (2-methylpropan-2-ol), for which each of R, R', and R\" is CH. In these shorthands, R, R', and R\" represent substituents, alkyl or other attached, generally organic groups.\n\nShort-chain alcohols have alkyl chains of 1–3 carbons. Medium-chain alcohols have alkyl chains of 4–7 carbons. Long-chain alcohols (also known as fatty alcohols) have alkyl chains of 8–21 carbons, and very long-chain alcohols have alkyl chains of 22 carbons or longer.\n\n\"Simple alcohols\" appears to be a completely undefined term. However, simple alcohols are often referred to by common names derived by adding the word \"alcohol\" to the name of the appropriate alkyl group. For instance, a chain consisting of one carbon (a methyl group, CH) with an OH group attached to the carbon is called \"methyl alcohol\" while a chain of two carbons (an ethyl group, CHCH) with an OH group connected to the CH is called \"ethyl alcohol.\" For more complex alcohols, the IUPAC nomenclature must be used.\n\nSimple alcohols, in particular ethanol and methanol, possess denaturing and inert rendering properties, leading to their use as anti-microbial agents in medicine, pharmacy, and industry.\n\nEncyclopædia Britannica states, \"The higher alcohols—those containing 4 to 10 carbon atoms—are somewhat viscous, or oily, and they have heavier fruity odours. Some of the highly branched alcohols and many alcohols containing more than 12 carbon atoms are solids at room temperature.\"\n\nLike ethanol, butanol can be produced by fermentation processes. Saccharomyces yeast are known to produce these higher alcohols at temperatures above . The bacterium \"Clostridium acetobutylicum\" can feed on cellulose to produce butanol on an industrial scale.\n\nAlcohol has a long history of several uses worldwide. It is found in alcoholic beverages sold to adults, as fuel, and also has many scientific, medical, and industrial uses. The term alcohol-free is often used to describe a product that does not contain alcohol.\n\nAlcoholic beverages, typically containing 3–40% ethanol by volume, have been produced and consumed by humans since pre-historic times. Other alcohols such as 2-methyl-2-butanol (found in beer) and γ-hydroxybutyric acid (GHB) are also consumed by humans for their psychoactive effects.\n\nA 50% v/v (by volume) solution of ethylene glycol in water is commonly used as an antifreeze.\n\nEthanol can be used as an antiseptic to disinfect the skin before injections are given, often along with iodine. Ethanol-based soaps are becoming common in restaurants and are convenient because they do not require drying due to the volatility of the compound. Alcohol based gels have become common as hand sanitizers.\n\nSome alcohols, mainly ethanol and methanol, can be used as an alcohol fuel. Fuel performance can be increased in forced induction internal combustion engines by injecting alcohol into the air intake after the turbocharger or supercharger has pressurized the air. This cools the pressurized air, providing a denser air charge, which allows for more fuel, and therefore more power.\n\nAlcohol is often used as a preservative for specimens in the fields of science and medicine.\n\nHydroxyl groups (-OH), found in alcohols, are polar and therefore hydrophilic (water loving) but their carbon chain portion is non-polar which make them hydrophobic. The molecule increasingly becomes overall more nonpolar and therefore less soluble in the polar water as the carbon chain becomes longer. Methanol has the shortest carbon chain of all alcohols (one carbon atom) followed by ethanol (two carbon atoms.)\n\nAlcohols have applications in industry and science as reagents or solvents. Because of its relatively low toxicity compared with other alcohols and ability to dissolve non-polar substances, ethanol can be used as a solvent in medical drugs, perfumes, and vegetable essences such as vanilla. In organic synthesis, alcohols serve as versatile intermediates.\n\n Ethanol is thought to cause harm partly as a result of direct damage to DNA caused by its metabolites.\nEthanol's toxicity is largely caused by its primary metabolite, acetaldehyde (systematically ethanal) and secondary metabolite, acetic acid. Many primary alcohols are metabolized into aldehydes then to carboxylic acids whose toxicities are similar to acetaldehyde and acetic acid. Metabolite toxicity is reduced in rats fed \"N\"-acetylcysteine and thiamine.\n\nAlthough the mechanism is unclear, a meta-analysis of 572 studies have shown increased cancer risk from consumption of ethanol.\n\nTertiary alcohols cannot be metabolized into aldehydes and as a result they cause no hangover or toxicity through this mechanism.\n\nSome secondary and tertiary alcohols are less poisonous than ethanol, because the liver is unable to metabolize them into toxic by-products. This makes them more suitable for pharmaceutical use as the chronic harms are lower. Ethchlorvynol and \"tert\"-amyl alcohol are tertiary alcohols which have seen both medicinal and recreational use.\n\nOther alcohols are substantially more poisonous than ethanol, partly because they take much longer to be metabolized and partly because their metabolism produces substances that are even more toxic. Methanol (wood alcohol), for instance, is oxidized to formaldehyde and then to the poisonous formic acid in the liver by alcohol dehydrogenase and formaldehyde dehydrogenase enzymes, respectively; accumulation of formic acid can lead to blindness or death. Likewise, poisoning due to other alcohols such as ethylene glycol or diethylene glycol are due to their metabolites, which are also produced by alcohol dehydrogenase.\n\nMethanol itself, while poisonous (LD 5628 mg/kg, oral, rat), has a much weaker sedative effect than ethanol.\n\nIsopropyl alcohol is oxidized to form acetone by alcohol dehydrogenase in the liver, but has occasionally been abused by alcoholics, leading to a range of adverse health effects.\n\nAn effective treatment to prevent toxicity after methanol or ethylene glycol ingestion is to administer ethanol. Alcohol dehydrogenase has a higher affinity for ethanol, thus preventing methanol from binding and acting as a substrate. Any remaining methanol will then have time to be excreted through the kidneys.\n\nAlcohols have an odor that is often described as \"biting\" and as \"hanging\" in the nasal passages. Ethanol has a slightly sweeter (or more fruit-like) odor than the other alcohols.\n\nIn general, the hydroxyl group makes the alcohol molecule polar. Those groups can form hydrogen bonds to one another and to other compounds (except in certain large molecules where the hydroxyl is protected by steric hindrance of adjacent groups). This hydrogen bonding means that alcohols can be used as protic solvents. Two opposing solubility trends in alcohols are: the tendency of the polar OH to promote solubility in water, and the tendency of the carbon chain to resist it. Thus, methanol, ethanol, and propanol are miscible in water because the hydroxyl group wins out over the short carbon chain. Butanol, with a four-carbon chain, is moderately soluble because of a balance between the two trends. Alcohols of five or more carbons such as pentanol and higher are effectively insoluble in water because of the hydrocarbon chain's dominance. All simple alcohols are miscible in organic solvents.\n\nBecause of hydrogen bonding, alcohols tend to have higher boiling points than comparable hydrocarbons and ethers. The boiling point of the alcohol ethanol is 78.29 °C, compared to 69 °C for the hydrocarbon hexane (a common constituent of gasoline), and 34.6 °C for diethyl ether.\n\nAlcohols, like water, can show either acidic or basic properties at the -OH group. With a pK of around 16-19, they are, in general, slightly weaker acids than water, but they are still able to react with strong bases such as sodium hydride or reactive metals such as sodium. The salts that result are called alkoxides, with the general formula RO M.\n\nMeanwhile, the oxygen atom has lone pairs of nonbonded electrons that render it weakly basic in the presence of strong acids such as sulfuric acid. For example, with methanol:\n\nAlcohols can be oxidised to give aldehydes, ketones or carboxylic acids, or they can be dehydrated to alkenes. They can react with carboxylic acids to form ester compounds, and they can (if activated first) undergo nucleophilic substitution reactions. The lone pairs of electrons on the oxygen of the hydroxyl group also makes alcohols nucleophiles. For more details, see the reactions of alcohols section below.\n\nAs one moves from primary to secondary to tertiary alcohols with the same backbone, the hydrogen bond strength, the boiling point, and the acidity typically decrease.\n\nEthanol occurs naturally as a byproduct of the metabolic process of yeast. As such, ethanol will be present in any yeast habitat. Ethanol can commonly be found in overripe fruit.\n\nMethanol is produced naturally in the anaerobic metabolism of many varieties of bacteria, and is commonly present in small amounts in the environment.\n\nAlcohols have been found outside the Solar System at low densities in star-forming regions of interstellar space.\n\nIn the Ziegler process, linear alcohols are produced from ethylene and triethylaluminium followed by oxidation and hydrolysis. An idealized synthesis of 1-octanol is shown:\n\nThe process generates a range of alcohols that are separated by distillation.\n\nMany higher alcohols are produced by hydroformylation of alkenes followed by hydrogenation. When applied to a terminal alkene, as is common, one typically obtains a linear alcohol:\n\nSuch processes give fatty alcohols, which are useful for detergents.\n\nLow molecular weight alcohols of industrial importance are produced by the addition of water to alkenes. Ethanol, isopropanol, 2-butanol, and tert-butanol are produced by this general method. Two implementations are employed, the direct and indirect methods. The direct method avoids the formation of stable intermediates, typically using acid catalysts. In the indirect method, the alkene is converted to the sulfate ester, which is subsequently hydrolyzed. The direct hydration using ethylene (ethylene hydration) or other alkenes from cracking of fractions of distilled crude oil.\n\nHydration is also used industrially to produce the diol ethylene glycol from ethylene oxide.\n\nEthanol is obtained by fermentation using glucose produced from sugar from the hydrolysis of starch, in the presence of yeast and temperature of less than 37 °C to produce ethanol. For instance, such a process might proceed by the conversion of sucrose by the enzyme invertase into glucose and fructose, then the conversion of glucose by the enzyme complex zymase into ethanol (and carbon dioxide).\n\nSeveral of the benign bacteria in the intestine use fermentation as a form of anaerobic metabolism. This metabolic reaction produces ethanol as a waste product, just like aerobic respiration produces carbon dioxide and water. Thus, human bodies contain some quantity of alcohol endogenously produced by these bacteria. In rare cases, this can be sufficient to cause \"auto-brewery syndrome\" in which intoxicating quantities of alcohol are produced.\n\nPrimary alkyl halides react with aqueous NaOH or KOH mainly to primary alcohols in nucleophilic aliphatic substitution. (Secondary and especially tertiary alkyl halides will give the elimination (alkene) product instead). Grignard reagents react with carbonyl groups to secondary and tertiary alcohols. Related reactions are the Barbier reaction and the Nozaki-Hiyama reaction.\n\nAldehydes or ketones are reduced with sodium borohydride or lithium aluminium hydride (after an acidic workup). Another reduction by aluminiumisopropylates is the Meerwein-Ponndorf-Verley reduction. Noyori asymmetric hydrogenation is the asymmetric reduction of β-keto-esters.\n\nAlkenes engage in an acid catalysed hydration reaction using concentrated sulfuric acid as a catalyst that gives usually secondary or tertiary alcohols. The hydroboration-oxidation and oxymercuration-reduction of alkenes are more reliable in organic synthesis. Alkenes react with NBS and water in halohydrin formation reaction. Amines can be converted to diazonium salts, which are then hydrolyzed.\n\nThe formation of a secondary alcohol via reduction and hydration is shown:\n\nAlcohols behave as weak acids, undergoing deprotonation, but strong bases are required. The deprotonation reaction to produce an alkoxide salt is performed with a strong base such as sodium hydride or sodium metal.\n\nWater is similar in pK to many alcohols, so with sodium hydroxide an equilibrium exists, which usually lies to the left:\n\nThe acidity of alcohols is strongly affected by solvation. In the gas phase, alcohols are more acidic than is water.\n\nThe OH group is not a good leaving group in nucleophilic substitution reactions, so neutral alcohols do not react in such reactions. However, if the oxygen is first protonated to give R−OH, the leaving group (water) is much more stable, and the nucleophilic substitution can take place. For instance, tertiary alcohols react with hydrochloric acid to produce tertiary alkyl halides, where the hydroxyl group is replaced by a chlorine atom by unimolecular nucleophilic substitution. If primary or secondary alcohols are to be reacted with hydrochloric acid, an activator such as zinc chloride is needed. In alternative fashion, the conversion may be performed directly using thionyl chloride.\n\nAlcohols may, likewise, be converted to alkyl bromides using hydrobromic acid or phosphorus tribromide, for example:\n\nIn the Barton-McCombie deoxygenation an alcohol is deoxygenated to an alkane with tributyltin hydride or a trimethylborane-water complex in a radical substitution reaction.\n\nAlcohols are themselves nucleophilic, so R−OH can react with ROH to produce ethers and water in a dehydration reaction, although this reaction is rarely used except in the manufacture of diethyl ether.\n\nMore useful is the E1 elimination reaction of alcohols to produce alkenes. The reaction, in general, obeys Zaitsev's Rule, which states that the most stable (usually the most substituted) alkene is formed. Tertiary alcohols eliminate easily at just above room temperature, but primary alcohols require a higher temperature.\n\nThis is a diagram of acid catalysed dehydration of ethanol to produce ethene:\n\nA more controlled elimination reaction is the Chugaev elimination with carbon disulfide and iodomethane.\n\nTo form an ester from an alcohol and a carboxylic acid the reaction, known as Fischer esterification, is usually performed at reflux with a catalyst of concentrated sulfuric acid:\n\nIn order to drive the equilibrium to the right and produce a good yield of ester, water is usually removed, either by an excess of HSO or by using a Dean-Stark apparatus. Esters may also be prepared by reaction of the alcohol with an acid chloride in the presence of a base such as pyridine.\n\nOther types of ester are prepared in a similar manner for example, tosyl (tosylate) esters are made by reaction of the alcohol with p-toluenesulfonyl chloride in pyridine.\n\nPrimary alcohols (R-CH-OH) can be oxidized either to aldehydes (R-CHO) or to carboxylic acids (R-COH), while the oxidation of secondary alcohols (RRCH-OH) normally terminates at the ketone (RRC=O) stage. Tertiary alcohols (RRRC-OH) are resistant to oxidation.\n\nThe direct oxidation of primary alcohols to carboxylic acids normally proceeds via the corresponding aldehyde, which is transformed via an \"aldehyde hydrate\" (R-CH(OH)) by reaction with water before it can be further oxidized to the carboxylic acid.\n\nReagents useful for the transformation of primary alcohols to aldehydes are normally also suitable for the oxidation of secondary alcohols to ketones. These include Collins reagent and Dess-Martin periodinane. The direct oxidation of primary alcohols to carboxylic acids can be carried out using potassium permanganate or the Jones reagent.\n\n", "id": "1014", "title": "Alcohol"},{"url": "https://en.wikipedia.org/wiki?curid=1016", "text": "Achill Island\n\nAchill Island (; ) in County Mayo is the largest island off the coast of Ireland, and is situated off the west coast. It has a population of 2,700. Its area is . Achill is attached to the mainland by Michael Davitt Bridge, between the villages of Gob an Choire (Achill Sound) and Poll Raithní (Polranny). A bridge was first completed here in 1887, replaced by another structure in 1949, and subsequently replaced with the current bridge which was completed in 2008. Other centres of population include the villages of Keel, Dooagh, Dumha Éige (Dooega), Dún Ibhir (Dooniver), The Valley and Dugort. The parish's main Gaelic football pitch and secondary school are on the mainland at Poll Raithní. Early human settlements are believed to have been established on Achill around 3000 BC. A paddle dating from this period was found at the crannóg near Dookinella.\nThe island is 87% peat bog. The parish of Achill also includes the Curraun peninsula. Some of the people of Curraun consider themselves Achill people, and most natives of Achill refer to this area as being \"in Achill\". There are between 500-600 native Irish speakers in Achill parish. In the summer of 1996, the RNLI decided to station a lifeboat at Kildownet.\n\nIt is believed that at the end of the Neolithic Period (around 4000 BC), Achill had a population of 500–1,000 people. The island would have been mostly forest until the Neolithic people began crop cultivation. Settlement increased during the Iron Age, and the dispersal of small promontory forts around the coast indicate the warlike nature of the times. Megalithic tombs (see picture, right) and forts can be seen at Slievemore, along the Atlantic Drive and on Achillbeg.\n\nAchill Island lies in the Barony of Burrishoole, in the territory of ancient Umhall (Umhall Uactarach and Umhall Ioctarach), that originally encompassed an area extending from the County Galway/Mayo border to Achill Head.\n\nThe hereditary chieftains of Umhall were the O'Malleys, recorded in the area in 814 AD when they successfully repelled an onslaught by the Vikings in Clew Bay. The Anglo-Norman invasion of Connacht in 1235 AD saw the territory of Umhall taken over by the Butlers and later by the de Burgos. The Butler Lordship of Burrishoole continued into the late 14th century when Thomas le Botiller was recorded as being in possession of Akkyll & Owyll.\n\nIn the 17th and 18th centuries, there was much migration to Achill from other parts of Ireland, particularly Ulster, due to the political and religious turmoil of the time. For a while there were two different dialects of Irish being spoken on Achill. This led to many townlands being recorded as having two names during the 1824 Ordnance Survey, and some maps today give different names for the same place. Achill Irish still has many traces of Ulster Irish.\n\nCarrickkildavnet Castle is a 15th-century tower house associated with the O'Malley Clan, who were once a ruling family of Achill. Grace O' Malley, or Granuaile, the most famous of the O'Malleys, was born on Clare Island around 1530. Her father was the chieftain of the barony of Murrisk. The O'Malleys were a powerful seafaring family, who traded widely. Grace became a fearless leader and gained fame as a sea captain and pirate. She is reputed to have met with Queen Elizabeth I in 1593. She died around 1603 and is buried in the O'Malley family tomb on Clare Island.\n\nOne of Achill's most famous historical sites is that of the Achill Mission or 'the Colony' at Dugort. In 1831 the Church of Ireland Reverend Edward Nangle founded a proselytising mission at Dugort. The Mission included schools, cottages, an orphanage, an infirmary and a guesthouse. The Colony was very successful for a time and regularly produced a newspaper called the \"Achill Herald and Western Witness\". Nangle expanded his mission into Mweelin, where a school was built. The Achill Mission began to decline slowly after Nangle was moved from Achill and was finally closed in the 1880s. Nangle died in 1883.\n\nIn 1894, the Westport - Newport railway line was extended to Achill Sound. The train station is now a hostel. The train provided a great service to Achill, but it also fulfilled an ancient prophecy. Brian Rua O' Cearbhain had prophesied that 'carts on iron wheels' would carry bodies into Achill on their first and last journey. In 1894, the first train on the Achill railway carried the bodies of victims of the Clew Bay Drowning. This tragedy occurred when a boat overturned in Clew Bay, drowning thirty-two young people. They had been going to meet the steamer which would take them to Scotland for potato picking.\n\nThe Kirkintilloch Fire in 1937 fulfilled the second part of the prophecy when the bodies of ten victims were carried by rail to Achill. These people had died in a fire in a bothy in Kirkintilloch. This term referred to the temporary accommodation provided for those who went to Scotland to pick potatoes, a migratory pattern that had been established in the early nineteenth century.\n\nKildamhnait on the south-east coast of Achill is named after St. Damhnait, or Dymphna, who founded a church there in the 16th century. There is also a holy well just outside the graveyard. The present church was built in the 1700s and the graveyard contains memorials to the victims of two of Achill's greatest tragedies, the Kirchintilloch Fire (1937) and the Clew Bay Drowning (1894).\n\nIn 1852, Dr. John McHale, Archbishop of Tuam set aside land in Bunnacurry for the building of a monastery. A Franciscan Monastery was built which, for many years provided an education for local children. The ruins of this monastery are still to be seen in Bunnacurry today.\n\nThe historic Valley House is located in The Valley, near Dugort in the north-east of Achill Island. The present building sits on the site of a hunting lodge built by the Earl of Cavan in the 19th century. Its notoriety arises from an incident in 1894 in which the then owner, an English landlady named Agnes McDonnell, was savagely beaten and the house set alight, allegedly by a local man, James Lynchehaun. Lynchehaun had been employed by McDonnell as her land agent, but the two fell out and he was sacked and told to quit his accommodation on her estate. A lengthy legal battle ensued, with Lynchehaun refusing to leave. At the time, in the 1890s, the issue of land ownership in Ireland was politically charged, and after the events at the Valley House in 1894 Lynchehaun was to claim that his actions were motivated by politics. He escaped custody and fled to the United States, where he successfully defeated legal attempts by the British authorities to have him extradited to face charges arising from the attack and the burning of the Valley House. Agnes McDonnell suffered terrible injuries from the attack but survived and lived for another 23 years, dying in 1923. Lynchehaun is said to have returned to Achill on two occasions, once in disguise as an American tourist, and eventually died in Girvan, Scotland, in 1937. The Valley House is now a Hostel and Bar.\n\nClose by Dugort, at the base of Slievemore mountain lies the Deserted Village. There are approximately 80 ruined houses in the village.\n\nThe houses were built of unmortared stone, which means that no cement or mortar was used to hold the stones together. Each house consisted of just one room and this room was used as a kitchen, living room, bedroom and even a stable.\n\nIf one looks at the fields around the Deserted Village and right up the mountain, one can see the tracks in the fields of 'lazy beds', which is the way crops like potatoes were grown. In Achill, as in many areas of Ireland, a system called 'Rundale' was used for farming. This meant that the land around a village was rented from a landlord. This land was then shared by all the villagers to graze their cattle and sheep. Each family would then have two or three small pieces of land scattered about the village, which they used to grow crops.\n\nFor many years people lived in the village and then in 1845 Famine struck in Achill as it did in the rest of Ireland. Most of the families moved to the nearby village of Dooagh, which is beside the sea, while some others emigrated. Living beside the sea meant that fish and shellfish could be used for food. The village was completely abandoned which is where the name 'Deserted Village' came from.\n\nNo one has lived in these houses since the time of the Famine, however, the families that moved to Dooagh and their descendants, continued to use the village as a 'booley village'. This means that during the summer season, the younger members of the family, teenage boys and girls, would take the cattle to graze on the hillside and they would stay in the houses of the Deserted Village. This custom continued until the 1940s. Boolying was also carried out in other areas of Achill, including Annagh on Croaghaun mountain and in Curraun.\n\nAt Ailt, Kildownet, you can see the remains of a similar deserted village. This village was deserted in 1855 when the tenants were evicted by the local landlord so the land could be used for cattle grazing, the tenants were forced to rent holdings in Currane, Dooega and Slievemore. Others emigrated to America.\n\nAchill Archaeological Field School is based at the Achill Archaeology Centre in Dooagh, which has served as a catalyst for a wide array of archaeological investigations on the island. It was founded in 1991 and is a training school for students of archaeology and anthropology. Since 1991, several thousand students from 21 countries have come to Achill to study and participate in ongoing excavations. The school is involved in a study of the prehistoric and historic landscape at Slievemore, incorporating a research excavation at a number of sites within the deserted village of Slievemore. Slievemore is rich in archaeological monuments that span a 5,000 year period from the Neolithic to the Post Medieval. Recent archaeological research suggests the village was occupied year-round at least as early as the 19th century, though it is known to have served as a seasonally occupied booley village by the first half of the 20th century. A booley village (a number of which exist in a ruined state on the island) is a village occupied only during part of the year, such as a resort community, a lake community, or (as the case on Achill) a place to live while tending flocks or herds of ruminants during winter or summer pasturing. Specifically, some of the people of Dooagh and Pollagh would migrate in the summer to Slievemore and then go back to Dooagh in the autumn. The summer 2009 field school excavated Round House 2 on Slievemore Mountain under the direction of archaeologist Stuart Rathbone. Only the outside north wall, entrance way and inside of the Round House were completely excavated.\n\nFrom 2004 to 2006, the Achill Island Maritime Archaeology Project directed by Chuck Meide was sponsored by the College of William and Mary, the Institute of Maritime History, the Achill Folklife Centre (now the Achill Archaeology Centre), and the Lighthouse Archaeological Maritime Program (LAMP). This project focused on the documentation of archaeological resources related to Achill's rich maritime heritage. Maritime archaeologists recorded 19th century fishing station, ice house, and boat house ruins, a number of anchors which had been salvaged from the sea, 19th century and more recent currach pens, a number of traditional vernacular watercraft including a possibly 100-year-old Achill yawl, and the remains of four historic shipwrecks.\n\nDespite some development, the island retains a striking natural beauty. The cliffs of Croaghaun on the western end of the island are the third highest sea cliffs in Europe but are inaccessible by road. Near the westernmost point of Achill, Achill Head, is Keem Bay. Keel Beach is quite popular with tourists and some locals as a surfing location. South of Keem beach is Moytoge Head, which with its rounded appearance drops dramatically down to the ocean. An old British observation post, built during World War I to prevent the Germans from landing arms for the Irish Republican Army, is still standing on Moytoge. During the Second World War this post was rebuilt by the Irish Defence Forces as a Look Out Post for the Coast Watching Service wing of the Defence Forces. It operated from 1939 to 1945.\n\nThe mountain Slievemore (672 m) rises dramatically in the north of the island and the Atlantic Drive (along the south/west of the island) has some dramatically beautiful views. On the slopes of Slievemore, there is an abandoned village (the \"Deserted Village\") The Deserted Village is traditionally thought to be a remnant village from An Gorta Mór (The Great Hunger of 1845-1849).\n\nJust west of the deserted village is an old Martello tower, again built by the British to warn of any possible French invasion during the Napoleonic Wars. The area also boasts an approximately 5000-year-old Neolithic tomb.\n\nAchillbeg (\"\", \"Little Achill\") is a small island just off Achill's southern tip. Its inhabitants were resettled on Achill in the 1960s. A plaque to Johnny Kilbane is situated on Achillbeg and was erected to celebrate 100 years since his first championship win.\n\nThe villages of Dooniver and Askill have very picturesque scenery and the cycle route is popular with tourists.\n\nCaisleán Ghráinne, also known as Kildownet Castle, is a small tower house built in the early 1400s. It is located in Cloughmore, on the south of Achill Island. It is noted for its associations with Grace O'Malley, along with the larger Rockfleet Castle in Newport.\n\nAchill Island also has a coast road along the south of the Island with some beautiful cliff views.\n\nWhile a number of attempts at setting up small industrial units on the island have been made, the economy of the island is largely dependent on tourism. Subventions from Achill people working abroad, in particular in the United Kingdom, the United States and Africa allowed many families to remain living in Achill throughout the 19th and 20th centuries. Since the advent of Ireland's \"Celtic Tiger\" economy fewer Achill people were forced to look for work abroad. Agriculture plays a small role and the fact that the island is mostly bog means that its potential for agriculture is limited largely to sheep farming. In the past, fishing was a significant activity but this aspect of the economy is small now. At one stage, the island was known for its shark fishing, basking shark in particular was fished for its valuable liver oil. There was a big spurt of growth in tourism in the 1960s and 1970s before which life was tough and difficult on the island. Despite healthy visitor numbers each year, the common perception is that tourism in Achill has been slowly declining since its heyday. Currently, the largest employers on Achill are two hotels. In late 2009 Ireland's only Turbot farm opened in the Bunnacurry Business Park.\n\nMost people on Achill are either Roman Catholic or Anglican (Church of Ireland). There are three priests on Achill and eight churches in total.\n\n\nHedge schools existed in most villages of Achill in various periods of history. A university was started by the missions to Achill in Mweelin. In the modern age, there used to be two secondary schools in Achill, Mc Hale College and Scoil Damhnait. However, in August 2011, the two schools amalgamated to form Coláiste Pobail Acla. For primary education, there are nine National Schools including Bullsmouth NS, Valley NS, Bunnacurry NS, Dookinella NS, Dooagh NS, Saulia NS, Achill Sound NS, Tonragee NS and Curanne NS. National schools closed down include Dooega NS, Crumpaun NS, Ashleam NS.\n\n\nAs a popular tourist destination, Achill has many bars, cafes and restaurants which serve a full range of food. However, with the island's Atlantic location seafood is a speciality on Achill with common foods including lobster, mussels, salmon, trout and winkles. With a large sheep population, Achill lamb is a very popular meal on the island too. Furthermore, Achill has a big population of cows which produces excellent beef.\n\nAchill has a Gaelic football club which competes in the intermediate championship and division 1C of the Mayo League. There are also Achill Rovers which play in the Mayo Association Football League. and Achill Golf Club. Card games, including Whist and 24 card game are also popular on Achill.\nThe island's primary recreational outdoor centre is Achill Outdoor Education Centre. Achill Island's rugged landscape and the surrounding ocean offers a prime location for outdoor adventure activities, like surfing, kite-surfing and sea kayaking. Fishing and watersports are popular with tourists and locals alike. Sailing regattas featuring a local vessel type, the Achill Yawl, have been popular since the 19th century, though most present-day yawls, unlike their traditional working boat ancestors, have been structurally modified to promote greater speed under sail. The island's waters and striking underwater sites are occasionally visited by scuba divers, though Achill's unpredictable weather generally has precluded a commercially successful recreational diving industry.\n\nIn 2011, the population was 2,569. The island's population has declined from around 6,000 before the Great Hunger.\n\nThe table below reports data on Achill Island's population taken from \"Discover the Islands of Ireland\" (Alex Ritsema, Collins Press, 1999) and the census of Ireland. \n\nBecause of the inhospitable climate, few inhabited houses date from before the 20th century, though there are many examples of abandoned stone structures dating to the 19th century.\n\nThe best known of these earlier can be seen in the \"Deserted Village\" ruins near the graveyard at the foot of Slievemore. Even the houses in this village represent a relatively comfortable class of dwelling as, even as recently as a hundred years ago, some people still used \"Beehive\" style houses (small circular single-roomed dwellings with a hole in the ceiling to let out smoke).\n\nMany of the oldest and most picturesque inhabited cottages date from the activities of the Congested Districts Board for Ireland—a body set up around the turn of the 20th century in Ireland to improve the welfare of the inhabitants of small villages and towns. Most of the homes in Achill at the time were very small and tightly packed together in villages. The CDB subsidised the building of new, more spacious (though still small by modern standards) homes outside of the traditional villages.\n\nSome of the recent building development (1980 and onwards) on the island does fit as nicely in the landscape as the earlier style of whitewashed raised gable cottages. Many holiday homes have been built but many of these houses have been built in prominent scenic areas and have damaged traditional views of the island while lying empty for most of the year.\n\n\nHeinrich Böll: \"Irisches Tagebuch\", Berlin 1957\nKingston, Bob: \"The Deserted Village at Slievemore\", Castlebar 1990\nMcDonald, Theresa: \"Achill: 5000 B.C. to 1900 A.D. Archeology History Folklore\", I.A.S. Publications [1992]\nMeehan, Rosa: \"The Story of Mayo\", Castlebar 2003\nCarney, James: \"The Playboy & the Yellow lady\", 1986 POOLBEG\nHugo Hamilton: The Island of Talking, 2007\nKevin Barry: \"Beatlebone\", 2015\n\n\n", "id": "1016", "title": "Achill Island"},{"url": "https://en.wikipedia.org/wiki?curid=1017", "text": "Allen Ginsberg\n\nIrwin Allen Ginsberg (; June 3, 1926 – April 5, 1997) was an American poet of Jewish origin, and one of the leading figures of both the Beat Generation of the 1950s and the counterculture that soon would follow. He vigorously opposed militarism, economic materialism and sexual repression and was known as embodying various aspects of this counterculture, such as his views on drugs, hostility to bureaucracy and openness to Eastern religions. He was one of many influential American writers of his time known as the Beat Generation, which included famous writers such as Jack Kerouac and William S. Burroughs.\n\nGinsberg is best known for his poem \"Howl\", in which he denounced what he saw as the destructive forces of capitalism and conformity in the United States. In 1956, \"Howl\" was seized by San Francisco police and US Customs. In 1957, it attracted widespread publicity when it became the subject of an obscenity trial, as it described heterosexual and homosexual sex at a time when sodomy laws made homosexual acts a crime in every U.S. state. \"Howl\" reflected Ginsberg's own homosexuality and his relationships with a number of men, including Peter Orlovsky, his lifelong partner. Judge Clayton W. Horn ruled that \"Howl\" was not obscene, adding, \"Would there be any freedom of press or speech if one must reduce his vocabulary to vapid innocuous euphemisms?\"\n\nGinsberg was a practicing Buddhist who studied Eastern religious disciplines extensively. He lived modestly, buying his clothing in second-hand stores and residing in downscale apartments in New York’s East Village. One of his most influential teachers was the Tibetan Buddhist the Venerable Chögyam Trungpa, the founder of the Naropa Institute in Boulder, Colorado. At Trungpa's urging, Ginsberg and poet Anne Waldman started The Jack Kerouac School of Disembodied Poetics there in 1974.\n\nGinsberg took part in decades of non-violent political protest against everything from the Vietnam War to the War on Drugs. His poem \"September on Jessore Road,\" calling attention to the plight of Bangladeshi refugees, exemplifies what the literary critic Helen Vendler described as Ginsberg's tireless persistence in protesting against \"imperial politics, and persecution of the powerless.\"\n\nHis collection \"The Fall of America\" shared the annual U.S. National Book Award for Poetry in 1974. In 1979 he received the National Arts Club gold medal and was inducted into the American Academy and Institute of Arts and Letters. Ginsberg was a Pulitzer Prize finalist in 1995 for his book \"Cosmopolitan Greetings: Poems 1986–1992\".\n\nGinsberg was born into a Jewish family in Newark, New Jersey, and grew up in nearby Paterson.\n\nAs a young teenager, Ginsberg began to write letters to \"The New York Times\" about political issues, such as World War II and workers' rights. While in high school, Ginsberg began reading Walt Whitman, inspired by his teacher's passionate reading.\n\nIn 1943, Ginsberg graduated from Eastside High School and briefly attended Montclair State College before entering Columbia University on a scholarship from the Young Men's Hebrew Association of Paterson. In 1945, he joined the Merchant Marines to earn money to continue his education at Columbia. While at Columbia, Ginsberg contributed to the \"Columbia Review\" literary journal, the \"Jester\" humor magazine, won the Woodberry Poetry Prize, served as president of the Philolexian Society (literary and debate group), and joined Boar's Head Society (poetry society).\nGinsberg has stated that he considered the required freshman seminar to be his favorite course while at Columbia University. Its subject was The Great Books and was taught by Lionel Trilling.\n\nAccording to The Poetry Foundation, Ginsberg spent several months in a mental institution after he pleaded insanity during a hearing. He was allegedly being prosecuted for harboring stolen goods in his dorm room. It was noted that the stolen property was not his, but belonged to an acquaintance.\n\nGinsberg referred to his parents, in a 1985 interview, as \"old-fashioned delicatessen philosophers\".\nHis father Louis Ginsberg was a published poet and a high school teacher. Ginsberg's mother, Naomi Livergant Ginsberg, was affected by a psychological illness that was never properly diagnosed. She was also an active member of the Communist Party and took Ginsberg and his brother Eugene to party meetings. Ginsberg later said that his mother \"made up bedtime stories that all went something like: 'The good king rode forth from his castle, saw the suffering workers and healed them.'\" Of his father Ginsberg said \"My father would go around the house either reciting Emily Dickinson and Longfellow under his breath or attacking T. S. Eliot for ruining poetry with his 'obscurantism.' I grew suspicious of both sides.\"\n\nNaomi Ginsberg's mental illness often manifested as paranoid delusions. She would claim, for example, that the president had implanted listening devices in their home and that her mother-in-law was trying to kill her. Her suspicion of those around her caused Naomi to draw closer to young Allen, \"her little pet,\" as Bill Morgan says in his biography of Ginsberg, titled, \"I Celebrate Myself: The Somewhat Private Life of Allen Ginsberg\". She also tried to kill herself by slitting her wrists and was soon taken to Greystone, a mental hospital; she would spend much of Ginsberg's youth in mental hospitals. His experiences with his mother and her mental illness were a major inspiration for his two major works, \"Howl\" and his long autobiographical poem \"Kaddish for Naomi Ginsberg (1894–1956)\".\n\nWhen he was in junior high school, he accompanied his mother by bus to her therapist. The trip deeply disturbed Ginsberg – he mentioned it and other moments from his childhood in \"Kaddish\". His experiences with his mother's mental illness and her institutionalization are also frequently referred to in \"Howl\". For example, \"Pilgrim State, Rockland, and Grey Stone's foetid halls\" is a reference to institutions frequented by his mother and Carl Solomon, ostensibly the subject of the poem: Pilgrim State Hospital and Rockland State Hospital in New York and Greystone Park Psychiatric Hospital in New Jersey. This is followed soon by the line \"with mother finally ******.\" Ginsberg later admitted the deletion was the expletive \"fucked.\" He also says of Solomon in section three, \"I'm with you in Rockland where you imitate the shade of my mother,\" once again showing the association between Solomon and his mother.\n\nGinsberg received a letter from his mother after her death responding to a copy of \"Howl\" he had sent her. It admonished Ginsberg to be good and stay away from drugs; she says, \"The key is in the window, the key is in the sunlight at the window – I have the key – Get married Allen don't take drugs – the key is in the bars, in the sunlight in the window\". In a letter she wrote to Ginsberg's brother Eugene, she said, \"God's informers come to my bed, and God himself I saw in the sky. The sunshine showed too, a key on the side of the window for me to get out. The yellow of the sunshine, also showed the key on the side of the window.\" These letters and the absence of a facility to recite kaddish inspired Ginsberg to write \"Kaddish\" which makes references to many details from Naomi's life, Ginsberg's experiences with her, and the letter, including the lines \"the key is in the light\" and \"the key is in the window\".\n\nIn Ginsberg's freshman year at Columbia he met fellow undergraduate Lucien Carr, who introduced him to a number of future Beat writers, including Jack Kerouac, William S. Burroughs, and John Clellon Holmes. They bonded because they saw in one another an excitement about the potential of American youth, a potential that existed outside the strict conformist confines of post–World War II, McCarthy-era America. Ginsberg and Carr talked excitedly about a \"New Vision\" (a phrase adapted from Yeats' \"A Vision\"), for literature and America. Carr also introduced Ginsberg to Neal Cassady, for whom Ginsberg had a long infatuation. In the first chapter of his 1957 novel \"On the Road\" Kerouac described the meeting between Ginsberg and Cassady. Kerouac saw them as the dark (Ginsberg) and light (Cassady) side of their \"New Vision\", a perception stemming partly from Ginsberg's association with communism, of which Kerouac had become increasingly distrustful. Though Ginsberg was never a member of the Communist Party, Kerouac named him \"Carlo Marx\" in \"On the Road\". This was a source of strain in their relationship.\n\nAlso, in New York, Ginsberg met Gregory Corso in the Pony Stable Bar. Corso, recently released from prison, was supported by the Pony Stable patrons and was writing poetry there the night of their meeting. Ginsberg claims he was immediately attracted to Corso, who was straight, but understanding of homosexuality after three years in prison. Ginsberg was even more struck by reading Corso's poems, realizing Corso was \"spiritually gifted.\" Ginsberg introduced Corso to the rest of his inner circle. In their first meeting at the Pony Stable, Corso showed Ginsberg a poem about a woman who lived across the street from him and sunbathed naked in the window. Amazingly, the woman happened to be Ginsberg's girlfriend that he was living with during one of his forays into heterosexuality. Ginsberg took Corso over to their apartment. There the woman proposed sex with Corso, who was still very young and fled in fear. Ginsberg introduced Corso to Kerouac and Burroughs and they began to travel together. Ginsberg and Corso remained lifelong friends and collaborators.\n\nShortly after this period in Ginsberg's life, he became romantically involved with Elise Nada Cowen after meeting her through Alex Greer, a philosophy professor at Barnard College whom she had dated for a while during the burgeoning Beat generation's period of development. As a Barnard student, Elise Cowen extensively read the poetry of Ezra Pound and T.S. Eliot, when she met Joyce Johnson and Leo Skir, among other Beat players. As Cowen had felt a strong attraction to darker poetry most of the time, Beat poetry seemed to provide an allure to what suggests a shadowy side of her persona. While at Barnard, Cowen earned the nickname \"Beat Alice\" as she had joined a small group of anti-establishment artists and visionaries known to outsiders as beatniks, and one of her first acquaintances at the college was the beat poet Joyce Johnson who later portrayed Cowen in her books, including \"Minor Characters\" and \"Come and Join the Dance\", which expressed the two women's experiences in the Barnard and Columbia Beat community. Through his association with Elise Cowen, Ginsberg discovered that they shared a mutual friend, Carl Solomon, to whom he later dedicated his most famous poem \"Howl\". This poem is considered an autobiography of Ginsberg up to 1955, and a brief history of the Beat Generation through its references to his relationship to other Beat artists of that time.\n\nIn 1948 in an apartment in Harlem, Ginsberg had an auditory hallucination while reading the poetry of William Blake (later referred to as his \"Blake vision\"). At first, Ginsberg claimed to have heard the voice of God, but later interpreted the voice as that of Blake himself reading \"Ah, Sunflower\", \"The Sick Rose\", and \"Little Girl Lost\", also described by Ginsberg as \"voice of the ancient of days\". The experience lasted several days. Ginsberg believed that he had witnessed the interconnectedness of the universe. He looked at lattice-work on the fire escape and realized some hand had crafted that; he then looked at the sky and intuited that some hand had crafted that also, or rather, that the sky was the hand that crafted itself. He explained that this hallucination was not inspired by drug use, but said he sought to recapture that feeling later with various drugs. Ginsberg stated: \"living blue hand itself. Or that God was in front of my eyes - existence itself was God\" and \"And it was a sudden awakening into a totally deeper real universe than I'd been existing in.\" \n\nGinsberg moved to San Francisco during the 1950s. Before \"Howl and Other Poems\" was published in 1956 by City Lights Bookshop, he worked as a market researcher.\n\nIn 1954, in San Francisco, Ginsberg met Peter Orlovsky (1933–2010), with whom he fell in love and who remained his lifelong partner. Selections from their correspondence have been published.\n\nAlso in San Francisco, Ginsberg met members of the San Francisco Renaissance (James Broughton, Robert Duncan, Madeline Gleason and Kenneth Rexroth) and other poets who would later be associated with the Beat Generation in a broader sense. Ginsberg's mentor William Carlos Williams wrote an introductory letter to San Francisco Renaissance figurehead Kenneth Rexroth, who then introduced Ginsberg into the San Francisco poetry scene. There, Ginsberg also met three budding poets and Zen enthusiasts who had become friends at Reed College: Gary Snyder, Philip Whalen, and Lew Welch. In 1959, along with poets John Kelly, Bob Kaufman, A. D. Winans, and William Margolis, Ginsberg was one of the founders of the \"Beatitude\" poetry magazine.\n\nWally Hedrick — a painter and co-founder of the Six Gallery – approached Ginsberg in mid-1955 and asked him to organize a poetry reading at the Six Gallery. At first, Ginsberg refused, but once he had written a rough draft of \"Howl\", he changed his \"fucking mind\", as he put it. Ginsberg advertised the event as \"Six Poets at the Six Gallery\". One of the most important events in Beat mythos, known simply as \"The Six Gallery reading\" took place on October 7, 1955. The event, in essence, brought together the East and West Coast factions of the Beat Generation. Of more personal significance to Ginsberg, the reading that night included the first public presentation of \"Howl\", a poem that brought worldwide fame to Ginsberg and to many of the poets associated with him. An account of that night can be found in Kerouac's novel \"The Dharma Bums\", describing how change was collected from audience members to buy jugs of wine, and Ginsberg reading passionately, drunken, with arms outstretched.\n\nGinsberg's principal work, \"Howl\", is well known for its opening line: \"I saw the best minds of my generation destroyed by madness, starving hysterical naked...\" \"Howl\" was considered scandalous at the time of its publication, because of the rawness of its language. Shortly after its 1956 publication by San Francisco's City Lights Bookstore, it was banned for obscenity. The ban became a cause célèbre among defenders of the First Amendment, and was later lifted, after Judge Clayton W. Horn declared the poem to possess redeeming artistic value. Ginsberg and Shig Murao, the City Lights manager who was jailed for selling \"Howl,\" became lifelong friends.\n\nGinsberg claimed at one point that all of his work was an extended biography (like Kerouac's \"Duluoz Legend\"). \"Howl\" is not only a biography of Ginsberg's experiences before 1955, but also a history of the Beat Generation. Ginsberg also later claimed that at the core of \"Howl\" were his unresolved emotions about his schizophrenic mother. Though \"Kaddish\" deals more explicitly with his mother, \"Howl\" in many ways is driven by the same emotions. \"Howl\" chronicles the development of many important friendships throughout Ginsberg’s life. He begins the poem with “I saw the best minds of my generation destroyed by madness”, which sets the stage for Ginsberg to describe Cassady and Solomon, immortalizing them into American literature. This madness was the “angry fix” that society needed to function—madness was its disease. In the poem, Ginsberg focused on “Carl Solomon! I’m with you in Rockland”, and, thus, turned Solomon into an archetypal figure searching for freedom from his “straightjacket”. Though references in most of his poetry reveal much about his biography, his relationship to other members of the Beat Generation, and his own political views, \"Howl\", his most famous poem, is still perhaps the best place to start.\n\nIn 1957, Ginsberg surprised the literary world by abandoning San Francisco. After a spell in Morocco, he and Peter Orlovsky joined Gregory Corso in Paris. Corso introduced them to a shabby lodging house above a bar at 9 rue Gît-le-Coeur that was to become known as the Beat Hotel. They were soon joined by Burroughs and others. It was a productive, creative time for all of them. There, Ginsberg began his epic poem \"Kaddish\", Corso composed \"Bomb\" and \"Marriage\", and Burroughs (with help from Ginsberg and Corso) put together \"Naked Lunch\" from previous writings. This period was documented by the photographer Harold Chapman, who moved in at about the same time, and took pictures constantly of the residents of the \"hotel\" until it closed in 1963. During 1962–3, Ginsberg and Orlovsky travelled extensively across India, living half a year at a time in Calcutta (Kolkata) and Benares (Varanasi). Also during this time, he formed friendships with some of the prominent young Bengali poets of the time including Shakti Chattopadhyay and Sunil Gangopadhyay. Ginsberg had several political connections in India; most notably Pupul Jayakar who helped him extend his stay in India when the authorities were eager to expel him.\n\nIn May 1965, Ginsberg arrived in London, and offered to read anywhere for free. Shortly after his arrival, he gave a reading at Better Books, which was described by Jeff Nuttall as \"the first healing wind on a very parched collective mind\". Tom McGrath wrote: \"This could well turn out to have been a very significant moment in the history of England – or at least in the history of English Poetry\".\n\nSoon after the bookshop reading, plans were hatched for the International Poetry Incarnation, which was held at the Royal Albert Hall in London on June 11, 1965. The event attracted an audience of 7,000, who heard readings and live and tape performances by a wide variety of figures, including Ginsberg, Adrian Mitchell, Alexander Trocchi, Harry Fainlight, Anselm Hollo, Christopher Logue, George Macbeth, Gregory Corso, Lawrence Ferlinghetti, Michael Horovitz, Simon Vinkenoog, Spike Hawkins and Tom McGrath. The event was organized by Ginsberg's friend, the filmmaker Barbara Rubin.\n\nPeter Whitehead documented the event on film and released it as \"Wholly Communion\". A book featuring images from the film and some of the poems that were performed was also published under the same title by Lorrimer in the UK and Grove Press in US.\n\nThough the term \"Beat\" is most accurately applied to Ginsberg and his closest friends (Corso, Orlovsky, Kerouac, Burroughs, etc.), the term \"Beat Generation\" has become associated with many of the other poets Ginsberg met and became friends with in the late 1950s and early 1960s. A key feature of this term seems to be a friendship with Ginsberg. Friendship with Kerouac or Burroughs might also apply, but both writers later strove to disassociate themselves from the name \"Beat Generation.\" Part of their dissatisfaction with the term came from the mistaken identification of Ginsberg as the leader. Ginsberg never claimed to be the leader of a movement. He claimed that many of the writers with whom he had become friends in this period shared many of the same intentions and themes. Some of these friends include: David Amram, Bob Kaufman; LeRoi Jones before he became Amiri Baraka, who, after reading \"Howl\", wrote a letter to Ginsberg on a sheet of toilet paper; Diane DiPrima; Jim Cohn; poets associated with the Black Mountain College such as Robert Creeley and Denise Levertov; poets associated with the New York School such as Frank O'Hara and Kenneth Koch.\n\nLater in his life, Ginsberg formed a bridge between the beat movement of the 1950s and the hippies of the 1960s, befriending, among others, Timothy Leary, Ken Kesey, and Bob Dylan. Ginsberg gave his last public reading at Booksmith, a bookstore in the Haight Ashbury neighborhood of San Francisco, a few months before his death.\n\nIn 1950, Kerouac began studying Buddhism and shared what he learned from Dwight Goddard’s \"Buddhist Bible\" with Ginsberg. Ginsberg first heard about the Four Noble Truths and such sutras as the Diamond Sutra at this time.\n\nGinsberg's spiritual journey began early on with his spontaneous visions, and continued with an early trip to India with Gary Snyder. Snyder had previously spent time in Kyoto to study at the First Zen Institute at Daitoku-ji Monastery. At one point, Snyder chanted the Prajnaparamita which in Ginsberg's words \"blew my mind.\" His interest piqued, Ginsberg traveled to meet the Dalai Lama as well as the Karmapa at Rumtek Monastery. Continuing on his journey, Ginsberg met Dudjom Rinpoche in Kalimpong who taught him \"If you see something horrible, don’t cling to it, and if you see something beautiful, don’t cling to it.\"\n\nAfter returning to the United States, a chance encounter on a New York City street with Chögyam Trungpa Rinpoche (they both tried to catch the same cab), a Kagyu and Nyingma Tibetan Buddhist master, led to Trungpa becoming his friend and lifelong teacher. Ginsberg helped Trungpa (and New York poet Anne Waldman) in founding the Jack Kerouac School of Disembodied Poetics at Naropa University in Boulder, Colorado.\n\nGinsberg was also involved with Krishnaism. He had started incorporating chanting the Hare Krishna mantra into his religious practice in the mid sixties. After learning that A.C. Bhaktivedanta Swami Prabhupada, the founder of the Hare Krishna movement in the Western world had rented a store front in New York, he befriended him, visiting him often and suggesting publishers for his books, and a fruitful relationship began. This relationship is documented by Satsvarupa Das Goswami in his biographical account \"Srila Prabhupada Lilamrta\". Ginsberg donated money, materials, and his reputation to help the Swami establish the first temple, and toured with him to promote his cause.\nDespite disagreeing with many of Bhaktivedanta Swami's required prohibitions, Ginsberg often sang the Hare Krishna mantra publicly as part of his philosophy and declared that it brought a state of ecstasy. He was glad that Bhaktivedanta Swami, an authentic swami from India, was now trying to spread the chanting in America. Along with other counterculture ideologists like Timothy Leary, Gary Snyder, and Alan Watts, Ginsberg hoped to incorporate Bhaktivedanta Swami and his chanting into the hippie movement, and agreed to take part in the Mantra-Rock Dance concert and to introduce the swami to the Haight-Ashbury hippie community.\n\nOn January 17, 1967, Ginsberg helped plan and organize a reception for Bhaktivedanta Swami at the San Francisco Airport, where fifty to a hundred hippies greeted the Swami, chanting Hare Krishna in the airport lounge with flowers in hands. To further support and promote Bhaktivendata Swami's message and chanting in San Francisco, Allen Ginsberg agreed to attend the Mantra-Rock Dance—a musical event 1967 held at the Avalon Ballroom by the San Francisco Hare Krishna temple. It featured some leading rock bands of the time: Big Brother and the Holding Company with Janis Joplin, The Grateful Dead, and Moby Grape, who performed there along with the Hare Krishna founder Bhaktivedanta Swami and donated proceeds to the Krishna temple. Ginsberg introduced Bhaktivedanta Swami to some three thousand hippies in the audience and led the chanting of the Hare Krishna mantra.\n\nMusic and chanting were both important parts of Ginsberg's live delivery during poetry readings. He often accompanied himself on a harmonium, and was often accompanied by a guitarist. It is believed that the Hindi and Buddhist poet Nagarjuna had introduced Ginsberg to the harmonium in Banaras. According to Malay Roy Choudhury, Ginsberg refined his practice while learning from his relatives, including his cousin sister Savitri Banerjee. When Ginsberg asked if he could sing a song in praise of Lord Krishna on William F. Buckley, Jr.'s TV show \"Firing Line\" on September 3, 1968, Buckley acceded and the poet chanted slowly as he played dolefully on a harmonium. According to Richard Brookhiser, an associate of Buckley's, the host commented that it was \"the most unharried Krishna I've ever heard.\"\n\nAt the 1967 Human Be-In in San Francisco's Golden Gate Park, the 1968 Democratic National Convention in Chicago, and the 1970 Black Panther rally at Yale campus Allen chanted \"Om\" repeatedly over a sound system for hours on end.\n\nGinsberg further brought mantras into the world of rock and roll when he recited the Heart Sutra in the song \"Ghetto Defendant\". The song appears on the 1982 album Combat Rock by British first wave punk band The Clash.\n\nGinsberg came in touch with the Hungryalist poets of Bengal, especially Malay Roy Choudhury, who introduced Ginsberg to the three fishes with one head of Indian emperor Jalaluddin Mohammad Akbar. The three fishes symbolised coexistence of all thought, philosophy and religion.\n\nIn spite of Ginsberg's attraction to Eastern religions, the journalist Jane Kramer argues that he, like Whitman, adhered to an \"American brand of mysticism\" that was \"rooted in humanism and in a romantic and visionary ideal of harmony among men.\"\n\nIn 1960, he was treated for a tropical disease, and it is speculated that he contracted hepatitis from an unsterilized needle administered by a doctor, which played a role in his death 37 years later.\nGinsberg was a lifelong smoker, and though he tried to quit for health and religious reasons, his busy schedule in later life made it difficult, and he always returned to smoking.\n\nIn the 1970s, Ginsberg suffered two minor strokes which were first diagnosed as Bell's Palsy, which gave him significant paralysis and stroke-like drooping of the muscles in one side of his face.\n\nLater in life, he also suffered constant minor ailments such as high blood pressure. Many of these symptoms were related to stress, but he never slowed down his schedule.\nIn 1986, Ginsberg was awarded the Golden Wreath by the Struga Poetry Evenings International Festival in Macedonia, the second American poet to be so awarded since W.H. Auden. At Struga, he met with the other Golden Wreath winners Bulat Okudzhava and Andrei Voznesensky. Ginsberg won a 1974 National Book Award for \"\" (split with Adrienne Rich, \"Diving into the Wreck\").\nIn 1993, the French Minister of Culture made him a Chevalier des Arts et des Lettres.\n\nGinsberg continued to help his friends as much as he could, going so far as to give money to Herbert Huncke out of his own pocket, and housing a broke and drug addicted Harry Smith.\n\nWith the exception of a special guest appearance at the NYU Poetry Slam on February 20, 1997, Ginsberg gave what is thought to be his last reading at The Booksmith in San Francisco on December 16, 1996.\n\nAfter returning home from the hospital for the last time, where he had been unsuccessfully treated for congestive heart failure, Ginsberg continued making phone calls to say goodbye to nearly everyone in his addressbook. Some of the phone calls, including one with Johnny Depp, were sad and interrupted by crying, and other were joyous and optimistic. Ginsberg continued to write through his final illness, with his last poem, \"Things I'll Not Do (Nostalgias)\", written on March 30.\n\nHe died surrounded by family and friends in his East Village loft in New York City, succumbing to liver cancer via complications of hepatitis. He was 70 years old.\n\nGregory Corso, Roy Lichtenstein, Patti Smith and others came by to pay their respects.\n\nOne third of Ginsberg's ashes were buried in his family plot in Gomel Chesed Cemetery in Newark, NJ. He was survived by Orlovsky. When Orlovsky died, as per Ginsberg's wishes, another third of his ashes were buried alongside Orlovsky at Shambhala Mountain Center in Colorado. The remaining third of the ashes are buried at Jewel Heart, Gelek Rimpoche’s sangha, in India.\n\nIn 1998, various writers, including Catfish McDaris read at a gathering at Ginsberg's farm to honor Allen and the beatniks.\n\nGinsberg's willingness to talk about taboo subjects made him a controversial figure during the conservative 1950s, and a significant figure in the 1960s. In the mid-1950s, no reputable publishing company would even consider publishing \"Howl\". At the time, such \"sex talk\" employed in \"Howl\" was considered by some to be vulgar or even a form of pornography, and could be prosecuted under law. Ginsberg used phrases such as \"cocksucker\", \"fucked in the ass\", and \"cunt\" as part of the poem's depiction of different aspects of American culture. Numerous books that discussed sex were banned at the time, including \"Lady Chatterley’s Lover\". The sex that Ginsberg painted did not portray the sex between heterosexual married couples, or even long time lovers. Instead, Ginsberg portrayed casual sex. For example, in \"Howl\", Ginsberg praises the man \"who sweetened the snatches of a million girls\". Ginsberg used gritty descriptions and explicit sexual language, pointing out the man \"who lounged hungry and lonesome through Houston seeking jazz or sex or soup.\" In his poetry, Ginsberg also discussed the then-taboo topic of homosexuality. The explicit sexual language that filled \"Howl\" eventually led to an important trial on First Amendment issues. Ginsberg's publisher was brought up on charges for publishing pornography, and the outcome led to a judge going on record dismissing charges because the poem carried \"redeeming social importance\", thus setting an important legal precedent. Ginsberg continued to broach controversial subjects throughout the 1970s, 1980s, and 1990s. From 1970–1996, Ginsberg had a long-term affiliation with PEN American Center with efforts to defend free expression. When explaining how he approached controversial topics, he often pointed to Herbert Huncke: he said that when he first got to know Huncke in the 1940s, Ginsberg saw that he was sick from his heroin addiction, but at the time heroin was a taboo subject and Huncke was left with nowhere to go for help.\n\nGinsberg was a signer of the anti-war manifesto \"A Call to Resist Illegitimate Authority,\" circulated among draft resistors in 1967 by members of the radical intellectual collective RESIST. Other signers and RESIST members included Mitchell Goodman, Henry Braun, Denise Levertov, Noam Chomsky, William Sloane Coffin, Dwight Macdonald, Robert Lowell, and Norman Mailer. \nIn 1968, Ginsberg signed the \"Writers and Editors War Tax Protest\" pledge, vowing to refuse tax payments in protest against the Vietnam War.\n\nHe was present the night of the Tompkins Square Park Police Riot in 1988 and provided an eyewitness account to \"The New York Times\".\n\nAllen Ginsberg called attention to the suffering of victims during the Bangladesh Liberation War in 1971. He wrote his legendary 152-line poem, \"September on Jessore Road\", after visiting refugee camps and witnessing the plight of millions fleeing the violence.\n\nMillions of daughters walk in the mud<br>\nMillions of children wash in the flood<br>\nA Million girls vomit & groan<br>\nMillions of families hopeless alone\n\nGinsberg's poem also serves as an indictment of the United States:\n\nWhere are the helicopters of U.S. AID?<br>\nSmuggling dope in Bangkok's green shade.<br>\nWhere is America's Air Force of Light?<br>\nBombing North Laos all day and all night?\n\nOut of the poem, he made a song that was performed by Bob Dylan, other musicians and Ginsberg himself.\n\nThe last few lines of the poem read: \nGinsberg talked openly about his connections with communism and his admiration for past communist heroes and the labor movement at a time when the Red Scare and McCarthyism were still raging. He admired Fidel Castro and many other quasi-Marxist figures from the 20th century. In \"America\" (1956), Ginsberg writes: \"America, I used to be a communist when I was a kid I'm not sorry\". Biographer Jonah Raskin has claimed that, despite his often stark opposition to communist orthodoxy, Ginsberg held \"his own idiosyncratic version of communism\". On the other hand, when Donald Manes, a New York City politician, publicly accused Ginsberg of being a member of the Communist Party, Ginsberg objected: \"I am not, as a matter of fact, a member of the Communist party, nor am I dedicated to the overthrow of the U.S. government or any government by violence. ... I must say that I see little difference between the armed and violent governments both Communist and Capitalist that I have observed\".\n\nGinsberg travelled to several communist countries to promote free speech. He claimed that communist countries, such as China, welcomed him because they thought he was an enemy of capitalism, but often turned against him when they saw him as a trouble maker. For example, in 1965 Ginsberg was deported from Cuba for publicly protesting the persecution of homosexuals and referring to Che Guevara as \"cute\". The Cubans sent him to Czechoslovakia, where one week after being named the \"Král majálesu\" (\"King of May\" – a students' festivity, celebrating spring and student life), Ginsberg was arrested for alleged drug use and public drunkenness, and the security agency StB confiscated several of his writings, which they considered to be lewd and morally dangerous. Ginsberg was then deported from Czechoslovakia on May 7, 1965 by order of the StB. Václav Havel points to Ginsberg as an important inspiration.\n\nOne contribution that is often considered his most significant and most controversial was his openness about homosexuality. Ginsberg was an early proponent of freedom for gay people. In 1943, he discovered within himself \"mountains of homosexuality.\" He expressed this desire openly and graphically in his poetry. He also struck a note for gay marriage by listing Peter Orlovsky, his lifelong companion, as his spouse in his Who's Who entry. Subsequent gay writers saw his frank talk about homosexuality as an opening to speak more openly and honestly about something often before only hinted at or spoken of in metaphor.\n\nIn writing about sexuality in graphic detail and in his frequent use of language seen as indecent, he challenged—and ultimately changed—obscenity laws. He was a staunch supporter of others whose expression challenged obscenity laws (William S. Burroughs and Lenny Bruce, for example).\n\nGinsberg was a supporter and member of North American Man/Boy Love Association (NAMBLA) which is a pedophile and pederasty advocacy organization in the United States that works to abolish age of consent laws and legalize sexual relations between adults and children, saying that \"Attacks on NAMBLA stink of politics, witchhunting for profit, humorlessness, vanity, anger and ignorance… I'm a member of NAMBLA because I love boys too—everybody does, who has a little humanity.\" In \"Thoughts on NAMBLA\", a 1994 essay published in the collection \"Deliberate Prose\", Ginsberg stated, \"NAMBLA's a forum for reform of those laws on youthful sexuality which members deem oppressive, a discussion society not a sex club. I joined NAMBLA in defense of free speech.\" In 1994, Ginsberg appeared in a documentary on NAMBLA called \"\" (playing on the gay male slang term \"Chickenhawk\"), in which he read a \"graphic ode to youth\".\n\nGinsberg also talked often about drug use. He organized the New York City chapter of LeMar (Legalize Marijuana). Throughout the 1960s he took an active role in the demystification of LSD, and, with Timothy Leary, worked to promote its common use. He remained for many decades an advocate of marijuana legalization, and, at the same time, warned his audiences against the hazards of tobacco in his \"Put Down Your Cigarette Rag (Don't Smoke):\" \"Don't Smoke Don't Smoke Nicotine Nicotine No / No don't smoke the official Dope Smoke Dope Dope.\"\n\n on the latter's book \"The Politics of Heroin in Southeast Asia\", which claimed that the CIA was knowingly involved in the production of heroin in the Golden Triangle of Burma, Thailand, and Laos. In addition to working with McCoy, Ginsberg personally confronted Richard Helms, the director of the CIA in the 1970s, about the matter, but Helms denied that the CIA had anything to do with selling illegal drugs. Allen wrote many essays and articles, researching and compiling evidence of the CIA's alleged involvement in drug trafficking, but it would take 10 years, and the publication of McCoy's book in 1972, before anyone took him seriously. In 1978 Ginsberg received a note from the chief editor of the \"New York Times\", apologizing for not taking his allegations seriously so many years previous. The political subject is dealt with in his song/poem \"CIA Dope calypso\". The United States Department of State responded to McCoy's initial allegations stating that they were \"unable to find any evidence to substantiate them, much less proof.\" Subsequent investigations by the Inspector General of the CIA, United States House Committee on Foreign Affairs, and United States Senate Select Committee to Study Governmental Operations with Respect to Intelligence Activities (i.e. the Church Committee) also found the charges to be unsubstantiated.\n\nMost of Ginsberg's very early poetry was written in formal rhyme and meter like that of his father and his idol William Blake. His admiration for the writing of Jack Kerouac inspired him to take poetry more seriously. In 1955, upon the advice of a psychiatrist, Ginsberg dropped out of the working world to devote his entire life to poetry. Soon after, he wrote \"Howl\", the poem that brought him and his Beat Generation contemporaries to national attention and allowed him to live as a professional poet for the rest of his life. Later in life, Ginsberg entered academia, teaching poetry as Distinguished Professor of English at Brooklyn College from 1986 until his death.\n\nGinsberg claimed throughout his life that his biggest inspiration was Kerouac's concept of \"spontaneous prose\". He believed literature should come from the soul without conscious restrictions. Ginsberg was much more prone to revise than Kerouac. For example, when Kerouac saw the first draft of \"Howl\" he disliked the fact that Ginsberg had made editorial changes in pencil (transposing \"negro\" and \"angry\" in the first line, for example). Kerouac only wrote out his concepts of Spontaneous Prose at Ginsberg's insistence because Ginsberg wanted to learn how to apply the technique to his poetry.\n\nThe inspiration for \"Howl\" was Ginsberg's friend, Carl Solomon, and \"Howl\" is dedicated to him. Solomon was a Dada and Surrealism enthusiast (he introduced Ginsberg to Artaud) who suffered bouts of clinical depression. Solomon wanted to commit suicide, but he thought a form of suicide appropriate to dadaism would be to go to a mental institution and demand a lobotomy. The institution refused, giving him many forms of therapy, including electroshock therapy. Much of the final section of the first part of \"Howl\" is a description of this.\n\nGinsberg used Solomon as an example of all those ground down by the machine of \"Moloch\". Moloch, to whom the second section is addressed, is a Levantine god to whom children were sacrificed. Ginsberg may have gotten the name from the Kenneth Rexroth poem \"Thou Shalt Not Kill\", a poem about the death of one of Ginsberg's heroes, Dylan Thomas. Moloch is mentioned a few times in the Torah and references to Ginsberg's Jewish background are frequent in his work. Ginsberg said the image of Moloch was inspired by peyote visions he had of the Francis Drake Hotel in San Francisco which appeared to him as a skull; he took it as a symbol of the city (not specifically San Francisco, but all cities). Ginsberg later acknowledged in various publications and interviews that behind the visions of the Francis Drake Hotel were memories of the Moloch of Fritz Lang's film \"Metropolis\" (1927) and of the woodcut novels of Lynd Ward. Moloch has subsequently been interpreted as any system of control, including the conformist society of post–World War II America, focused on material gain, which Ginsberg frequently blamed for the destruction of all those outside of societal norms.\n\nHe also made sure to emphasize that Moloch is a part of humanity in multiple aspects, in that the decision to \"defy\" socially created systems of control—and therefore go against Moloch—is a form of self-destruction. Many of the characters Ginsberg references in \"Howl\", such as Neal Cassady and Herbert Huncke, destroyed themselves through excessive substance abuse or a generally wild lifestyle. The personal aspects of \"Howl\" are perhaps as important as the political aspects. Carl Solomon, the prime example of a \"best mind\" destroyed by defying society, is associated with Ginsberg's schizophrenic mother: the line \"with mother finally ****** (fucked)\" comes after a long section about Carl Solomon, and in Part III, Ginsberg says: \"I'm with you in Rockland where you imitate the shade of my mother.\" Ginsberg later admitted that the drive to write \"Howl\" was fueled by sympathy for his ailing mother, an issue which he was not yet ready to deal with directly. He dealt with it directly with 1959's \"Kaddish\", which had its first public reading at a Catholic Worker Friday Night meeting, possibly due to its associations with Thomas Merton.\n\nGinsberg's poetry was strongly influenced by Modernism (most importantly the American style of Modernism pioneered by William Carlos Williams), Romanticism (specifically William Blake and John Keats), the beat and cadence of jazz (specifically that of bop musicians such as Charlie Parker), and his Kagyu Buddhist practice and Jewish background. He considered himself to have inherited the visionary poetic mantle handed down from the English poet and artist William Blake, the American poet Walt Whitman and the Spanish poet Federico Garcia Lorca. The power of Ginsberg's verse, its searching, probing focus, its long and lilting lines, as well as its New World exuberance, all echo the continuity of inspiration that he claimed.\n\nHe corresponded with William Carlos Williams, who was then in the middle of writing his epic poem Paterson about the industrial city near his home. After attending a reading by Williams, Ginsberg sent the older poet several of his poems and wrote an introductory letter. Most of these early poems were rhymed and metered and included archaic pronouns like \"thee.\" Williams disliked the poems and told Ginsberg, \"In this mode perfection is basic, and these poems are not perfect.\"\n\nThough he disliked these early poems, Williams loved the exuberance in Ginsberg's letter. He included the letter in a later part of \"Paterson\". He encouraged Ginsberg not to emulate the old masters, but to speak with his own voice and the voice of the common American. From Williams, Ginsberg learned to focus on strong visual images, in line with Williams' own motto \"No ideas but in things.\" Studying Williams' style led to a tremendous shift from the early formalist work to a loose, colloquial free verse style. Early breakthrough poems include \"Bricklayer's Lunch Hour\" and \"Dream Record\".\n\nCarl Solomon introduced Ginsberg to the work of Antonin Artaud (\"To Have Done with the Judgement of God\" and \"Van Gogh: The Man Suicided by Society\"), and Jean Genet (\"Our Lady of the Flowers\"). Philip Lamantia introduced him to other Surrealists and Surrealism continued to be an influence (for example, sections of \"Kaddish\" were inspired by André Breton's \"Free Union\"). Ginsberg claimed that the anaphoric repetition of \"Howl\" and other poems was inspired by Christopher Smart in such poems as \"Jubilate Agno\". Ginsberg also claimed other more traditional influences, such as: Franz Kafka, Herman Melville, Fyodor Dostoevsky, Edgar Allan Poe, and even Emily Dickinson.\n\nGinsberg also made an intense study of haiku and the paintings of Paul Cézanne, from which he adapted a concept important to his work, which he called the \"Eyeball Kick\". He noticed in viewing Cézanne's paintings that when the eye moved from one color to a contrasting color, the eye would spasm, or \"kick.\" Likewise, he discovered that the contrast of two seeming opposites was a common feature in haiku. Ginsberg used this technique in his poetry, putting together two starkly dissimilar images: something weak with something strong, an artifact of high culture with an artifact of low culture, something holy with something unholy. The example Ginsberg most often used was \"hydrogen jukebox\" (which later became the title of a song cycle composed by Philip Glass with lyrics drawn from Ginsberg's poems). Another example is Ginsberg's observation on Bob Dylan during Dylan's hectic and intense 1966 electric-guitar tour, fuelled by a cocktail of amphetamines, opiates, alcohol, and psychedelics, as a \"Dexedrine Clown\". The phrases \"eyeball kick\" and \"hydrogen jukebox\" both show up in \"Howl\", as well as a direct quote from Cézanne: \"Pater Omnipotens Aeterna Deus\".\n\nAllen Ginsberg also found inspiration in music. He frequently included music in his poetry. He wrote and recorded music to accompany William Blake’s \"Songs of Innocence\" and \"Songs of Experience\". He also recorded a handful of other albums. To create music for \"Howl\" and \"Wichita Vortex Sutra\" he worked with the minimalist composer, Philip Glass.\n\nGinsberg worked with, drew inspiration from, and inspired artists such as, Bob Dylan, The Clash, Patti Smith, Phil Ochs, and The Fugs. He worked with Bob Dylan on various projects and maintained a friendship over many years.\n\nFrom the study of his idols and mentors and the inspiration of his friends—not to mention his own experiments—Ginsberg developed an individualistic style that's easily identified as Ginsbergian. \"Howl\" came out during a potentially hostile literary environment, less welcoming to non-traditional, free verse poetry; there was a renewed focus on form and structure among academic poets and critics partly inspired by New Criticism. Consequently, Ginsberg often had to defend his choice to employ long, free verse lines, often citing Whitman's free verse used in \"Leaves of Grass\" as a precursor. Ginsberg claimed Whitman's long line was a dynamic technique few other poets had ventured to develop further, and Whitman is also often compared to Ginsberg because their poetry sexualized aspects of the male form.\n\nGinsberg believed strongly that traditional formalist considerations were archaic and did not apply to reality. Though some critics, like Diana Trilling, have pointed to Ginsberg's occasional use of meter (for example the anapest of \"who came back to Denver and waited in vain\"), Ginsberg denied any intention toward meter and claimed instead that his idea of meter followed the \"natural\" poetic voice. \n\nGinsberg said that he learned from William Carlos Williams that natural speech is occasionally dactylic so poetry that imitates natural speech will sometimes fall into a dactylic structure but only accidentally. Like Williams, Ginsberg's line breaks were often determined by breath: one line in \"Howl\", for example, should be read in one breath. Ginsberg claimed he developed such a long line because he had long breaths.\n\nMany of Ginsberg's early long line experiments contain some sort of anaphora, repetition of a \"fixed base\" (for example \"who\" in \"Howl\", \"America\" in \"America\") and this has become a recognizable feature of Ginsberg's style. He said later this was a crutch because he lacked confidence; he did not yet trust \"free flight\". In the 1960s, after employing it in some sections of \"Kaddish\" (\"caw\" for example) he, for the most part, abandoned the anaphoric form.\n\nSeveral of his earlier experiments with methods for formatting poems as a whole became regular aspects of his style in later poems. In the original draft of \"Howl\", each line is in a \"stepped triadic\" format reminiscent of William Carlos Williams. But he abandoned the \"stepped triadic\" when he developed his long line although the stepped lines showed up later, most significantly in the travelogues of \"The Fall of America.\" \"Howl\" and \"Kaddish\", arguably his two most important poems, are both organized as an inverted pyramid, with larger sections leading to smaller sections. In \"America\", he also experimented with a mix of longer and shorter lines.\n\nIn \"Howl\" and in his other poetry, Ginsberg drew inspiration from the epic, free verse style of the 19th-century American poet Walt Whitman. Both wrote passionately about the promise (and betrayal) of American democracy, the central importance of erotic experience, and the spiritual quest for the truth of everyday existence. J. D. McClatchy, editor of the \"Yale Review\", called Ginsberg \"the best-known American poet of his generation, as much a social force as a literary phenomenon.\" McClatchy added that Ginsberg, like Whitman, \"was a bard in the old manner – outsized, darkly prophetic, part exuberance, part prayer, part rant. His work is finally a history of our era's psyche, with all its contradictory urges.\" McClatchy's barbed eulogies define the essential difference between Ginsberg (\"a beat poet whose writing was ... journalism raised by combining the recycling genius with a generous mimic-empathy, to strike audience-accessible chords; always lyrical and sometimes truly poetic\") and Kerouac (\"a poet of singular brilliance, the brightest luminary of a 'beat generation' he came to symbolise in popular culture... [though] in reality he far surpassed his contemporaries... Kerouac is an originating genius, exploring then answering - like Rimbaud a century earlier, by necessity more than by choice - the demands of authentic self-expression as applied to the evolving quicksilver mind of America's only literary virtuoso...\"):\n\n\n\n\n\n", "id": "1017", "title": "Allen Ginsberg"},{"url": "https://en.wikipedia.org/wiki?curid=1018", "text": "Algebraically closed field\n\nIn abstract algebra, an algebraically closed field \"F\" contains a root for every non-constant polynomial in \"F\"[\"x\"], the ring of polynomials in the variable \"x\" with coefficients in \"F\".\n\nAs an example, the field of real numbers is not algebraically closed, because the polynomial equation \"x\" + 1 = 0  has no solution in real numbers, even though all its coefficients (1 and 0) are real. The same argument proves that no subfield of the real field is algebraically closed; in particular, the field of rational numbers is not algebraically closed. Also, no finite field \"F\" is algebraically closed, because if \"a\", \"a\", …, \"a\" are the elements of \"F\", then the polynomial (\"x\" − \"a\")(\"x\" − \"a\") ··· (\"x\" − \"a\") + 1\nhas no zero in \"F\". By contrast, the fundamental theorem of algebra states that the field of complex numbers is algebraically closed. Another example of an algebraically closed field is the field of (complex) algebraic numbers.\n\nGiven a field \"F\", the assertion \"\"F\" is algebraically closed\" is equivalent to other assertions:\n\nThe field \"F\" is algebraically closed if and only if the only irreducible polynomials in the polynomial ring \"F\"[\"x\"] are those of degree one.\n\nThe assertion \"the polynomials of degree one are irreducible\" is trivially true for any field. If \"F\" is algebraically closed and \"p\"(\"x\") is an irreducible polynomial of \"F\"[\"x\"], then it has some root \"a\" and therefore \"p\"(\"x\") is a multiple of \"x\" − \"a\". Since \"p\"(\"x\") is irreducible, this means that \"p\"(\"x\") = \"k\"(\"x\" − \"a\"), for some \"k\" ∈ \"F\" \\ {0},. On the other hand, if \"F\" is not algebraically closed, then there is some non-constant polynomial \"p\"(\"x\") in \"F\"[\"x\"] without roots in \"F\". Let \"q\"(\"x\") be some irreducible factor of \"p\"(\"x\"). Since \"p\"(\"x\") has no roots in \"F\", \"q\"(\"x\") also has no roots in \"F\". Therefore, \"q\"(\"x\") has degree greater than one, since every first degree polynomial has one root in \"F\".\n\nThe field \"F\" is algebraically closed if and only if every polynomial \"p\"(\"x\") of degree \"n\" ≥ 1, with coefficients in \"F\", splits into linear factors. In other words, there are elements \"k\", \"x\", \"x\", …, \"x\" of the field \"F\" such that \"p\"(\"x\") = \"k\"(\"x\" − \"x\")(\"x\" − \"x\") ··· (\"x\" − \"x\").\n\nIf \"F\" has this property, then clearly every non-constant polynomial in \"F\"[\"x\"] has some root in \"F\"; in other words, \"F\" is algebraically closed. On the other hand, that the property stated here holds for \"F\" if \"F\" is algebraically closed follows from the previous property together with the fact that, for any field \"K\", any polynomial in \"K\"[\"x\"] can be written as a product of irreducible polynomials.\n\nJ. Shipman showed in 2007 that if every polynomial over \"F\" of prime degree has a root in \"F\", then every non-constant polynomial has a root in \"F\", thus \"F\" is algebraically closed.\n\nThe field \"F\" is algebraically closed if and only if it has no proper algebraic extension.\n\nIf \"F\" has no proper algebraic extension, let \"p\"(\"x\") be some irreducible polynomial in \"F\"[\"x\"]. Then the quotient of \"F\"[\"x\"] modulo the ideal generated by \"p\"(\"x\") is an algebraic extension of \"F\" whose degree is equal to the degree of \"p\"(\"x\"). Since it is not a proper extension, its degree is 1 and therefore the degree of \"p\"(\"x\") is 1.\n\nOn the other hand, if \"F\" has some proper algebraic extension \"K\", then the minimal polynomial of an element in \"K\" \\ \"F\" is irreducible and its degree is greater than 1.\n\nThe field \"F\" is algebraically closed if and only if it has no finite algebraic extension because if, within the previous proof, the word \"algebraic\" is replaced by the word \"finite\", then the proof is still valid.\n\nThe field \"F\" is algebraically closed if and only if, for each natural number \"n\", every linear map from \"F\" into itself has some eigenvector.\n\nAn endomorphism of \"F\" has an eigenvector if and only if its characteristic polynomial has some root. Therefore, when \"F\" is algebraically closed, every endomorphism of \"F\" has some eigenvector. On the other hand, if every endomorphism of \"F\" has an eigenvector, let \"p\"(\"x\") be an element of \"F\"[\"x\"]. Dividing by its leading coefficient, we get another polynomial \"q\"(\"x\") which has roots if and only if \"p\"(\"x\") has roots. But if \"q\"(\"x\") = \"x\" + \"a\"\"x\"+ ··· + \"a\", then \"q\"(\"x\") is the characteristic polynomial of the companion matrix\n\nThe field \"F\" is algebraically closed if and only if every rational function in one variable \"x\", with coefficients in \"F\", can be written as the sum of a polynomial function with rational functions of the form \"a\"/(\"x\" − \"b\"), where \"n\" is a natural number, and \"a\" and \"b\" are elements of \"F\".\n\nIf \"F\" is algebraically closed then, since the irreducible polynomials in \"F\"[\"x\"] are all of degree 1, the property stated above holds by the theorem on partial fraction decomposition.\n\nOn the other hand, suppose that the property stated above holds for the field \"F\". Let \"p\"(\"x\") be an irreducible element in \"F\"[\"x\"]. Then the rational function 1/\"p\" can be written as the sum of a polynomial function \"q\" with rational functions of the form \"a\"/(\"x\" − \"b\"). Therefore, the rational expression\ncan be written as a quotient of two polynomials in which the denominator is a product of first degree polynomials. Since \"p\"(\"x\") is irreducible, it must divide this product and, therefore, it must also be a first degree polynomial.\n\nFor any field \"F\", if two polynomials \"p\"(\"x\"),\"q\"(\"x\") ∈ \"F\"[\"x\"] are relatively prime then they do not have a common root, for if \"a\" ∈ \"F\" was a common root, then \"p\"(\"x\") and  \"q\"(\"x\") would both be multiples of \"x\" − \"a\" and therefore they would not be relatively prime. The fields for which the reverse implication holds (that is, the fields such that whenever two polynomials have no common root then they are relatively prime) are precisely the algebraically closed fields.\n\nIf the field \"F\" is algebraically closed, let \"p\"(\"x\") and \"q\"(\"x\") be two polynomials which are not relatively prime and let \"r\"(\"x\") be their greatest common divisor. Then, since \"r\"(\"x\") is not constant, it will have some root \"a\", which will be then a common root of \"p\"(\"x\") and \"q\"(\"x\").\n\nIf \"F\" is not algebraically closed, let \"p\"(\"x\") be a polynomial whose degree is at least 1 without roots. Then \"p\"(\"x\") and \"p\"(\"x\") are not relatively prime, but they have no common roots (since none of them has roots).\n\nIf \"F\" is an algebraically closed field and \"n\" is a natural number, then \"F\" contains all \"n\"th roots of unity, because these are (by definition) the \"n\" (not necessarily distinct) zeroes of the polynomial \"x\" − 1. A field extension that is contained in an extension generated by the roots of unity is a \"cyclotomic extension\", and the extension of a field generated by all roots of unity is sometimes called its \"cyclotomic closure\". Thus algebraically closed fields are cyclotomically closed. The converse is not true. Even assuming that every polynomial of the form \"x\" − \"a\" splits into linear factors is not enough to assure that the field is algebraically closed.\n\nIf a proposition which can be expressed in the language of first-order logic is true for an algebraically closed field, then it is true for every algebraically closed field with the same characteristic. Furthermore, if such a proposition is valid for an algebraically closed field with characteristic 0, then not only is it valid for all other algebraically closed fields with characteristic 0, but there is some natural number \"N\" such that the proposition is valid for every algebraically closed field with characteristic \"p\" when \"p\" > \"N\".\n\nEvery field \"F\" has some extension which is algebraically closed. Among all such extensions there is one and (up to isomorphism, but not unique isomorphism) only one which is an algebraic extension of \"F\"; it is called the algebraic closure of \"F\".\n\nThe theory of algebraically closed fields has quantifier elimination.\n\n", "id": "1018", "title": "Algebraically closed field"},{"url": "https://en.wikipedia.org/wiki?curid=1019", "text": "August 6\n\n\n\n", "id": "1019", "title": "August 6"},{"url": "https://en.wikipedia.org/wiki?curid=1020", "text": "Anatoly Karpov\n\nAnatoly Yevgenyevich Karpov (; born May 23, 1951) is a Russian chess grandmaster and former World Champion. He was the official world champion from 1975 to 1985 when he was defeated by Garry Kasparov. He played three matches against Kasparov for the title from 1986 to 1990, before becoming FIDE World Champion once again after Kasparov broke away from FIDE in 1993. He held the title until 1999, when he resigned his title in protest against FIDE's new world championship rules. For his decades-long standing among the world's elite, Karpov is considered by many to be one of the greatest players of all time.\n\nHis tournament successes include over 160 first-place finishes. He had a peak Elo rating of 2780, and his 90 total months at world number one is the second longest of all-time, behind only Garry Kasparov, since the inception of the FIDE ranking list in 1970.\n\nKarpov was born on May 23, 1951 at Zlatoust in the Urals region of the former Soviet Union, and learned to play chess at the age of 4. His early rise in chess was swift, as he became a Candidate Master by age 11. At 12, he was accepted into Mikhail Botvinnik's prestigious chess school, though Botvinnik made the following remark about the young Karpov: \"The boy does not have a clue about chess, and there's no future at all for him in this profession.\" Karpov acknowledged that his understanding of chess theory was very confused at that time, and wrote later that the homework which Botvinnik assigned greatly helped him, since it required that he consult chess books and work diligently. Karpov improved so quickly under Botvinnik's tutelage that he became the youngest Soviet National Master in history at fifteen in 1966; this tied the record established by Boris Spassky in 1952.\n\nKarpov finished first in his first international tournament in Třinec several months later, ahead of Viktor Kupreichik. In 1967, he won the annual European Junior Championship at Groningen. Karpov won a gold medal for academic excellence in high school, and entered Moscow State University in 1968 to study mathematics. He later transferred to Leningrad State University, eventually graduating from there in economics. One reason for the transfer was to be closer to his coach, grandmaster Semyon Furman, who lived in Leningrad. In his writings, Karpov credits Furman as a major influence on his development as a world-class player.\n\nIn 1969, Karpov became the first Soviet player since Spassky (1955) to win the World Junior Chess Championship, scoring an undefeated 10/11 in the finals at Stockholm. In 1970, he tied for fourth place at an international tournament in Caracas, Venezuela, and was awarded the grandmaster title.\n\nHe won the 1971 Alekhine Memorial in Moscow (equal with Leonid Stein), ahead of a star-studded field, for his first significant adult victory. His Elo rating shot from 2540 in 1971 to 2660 in 1973, when he shared second in the USSR Chess Championship, and finished equal first with Viktor Korchnoi in the Leningrad Interzonal Tournament. The latter success qualified him for the 1974 Candidates Matches, which would determine the challenger to the reigning world champion, Bobby Fischer.\n\nKarpov defeated Lev Polugaevsky by the score of +3=5 in the first Candidates' match, earning the right to face former champion Boris Spassky in the semifinal round. Karpov was on record saying that he believed Spassky would easily beat him and win the Candidates' cycle to face Fischer, and that he (Karpov) would win the following Candidates' cycle in 1977.\nSpassky won the first game as Black in good style, but tenacious, aggressive play from Karpov secured him overall victory by +4−1=6.\nThe Candidates' final was played in Moscow with Korchnoi. Karpov took an early lead, winning the second game against the Sicilian Dragon, then scoring another victory in the sixth game. Following ten consecutive draws, Korchnoi threw away a winning position in the seventeenth game to give Karpov a 3–0 lead. In game 19, Korchnoi succeeded in winning a long endgame, then notched a speedy victory after a blunder by Karpov two games later. Three more draws, the last agreed by Karpov in a clearly better position, closed the match, as he thus prevailed +3−2=19, moving on to challenge Fischer for the world title.\n\nThough a world championship match between Karpov and Fischer was highly anticipated, those hopes were never realised. Fischer insisted that the match be the first to ten wins (draws not counting), but that the champion would retain the crown if the score was tied 9–9. FIDE, the International Chess Federation, refused to allow this proviso, and after Fischer's resignation of the championship on June 27, 1975, FIDE declared that Fischer forfeited his crown. Karpov later attempted to set up another match with Fischer, but all the negotiations fell through. This thrust the young Karpov into the role of World Champion without having faced the reigning champion.\nGarry Kasparov argued that Karpov would have had good chances, because he had beaten Spassky convincingly and was a new breed of tough professional, and indeed had higher quality games, while Fischer had been inactive for three years. Spassky thought that Fischer would have won in 1975 but Karpov would have qualified again and beaten Fischer in 1978.\n\nDetermined to prove himself a legitimate champion, Karpov participated in nearly every major tournament for the next ten years. He convincingly won the very strong Milan tournament in 1975, and captured his first of three Soviet titles in 1976. He created a phenomenal streak of tournament wins against the strongest players in the world. Karpov held the record for most consecutive tournament victories (nine) until it was shattered by Garry Kasparov (14).\nIn 1978, Karpov's first title defence was against Korchnoi, the opponent he had defeated in the 1973–75 Candidates' cycle; the match was played at Baguio, Philippines, with the winner needing six victories.\nAs in 1974, Karpov took an early lead, winning the eighth game after seven draws to open the match, but Korchnoi staged a comeback late in the match, as, after the score was +5−2=20 in Karpov's favour, he won three of the next four games to draw level with Karpov. Karpov then won the next game to retain the title (+6−5=21).\n\nThree years later Korchnoi re-emerged as the Candidates' winner against German finalist Dr. Robert Hübner to challenge Karpov in Merano, Italy. This match, however, was won handily by Karpov, the score being (11–7, +6−2=10) in what is remembered as the \"Massacre in Merano\".\n\nKarpov's tournament career reached a peak at the Montreal \"Tournament of Stars\" tournament in 1979, where he finished joint first (+7−1=10) with Mikhail Tal, ahead of a field of strong grandmasters completed by Jan Timman, Ljubomir Ljubojević, Boris Spassky, Vlastimil Hort, Lajos Portisch, Robert Hübner, Bent Larsen and Lubomir Kavalek. He dominated Las Palmas 1977 with 13½/15. He also won the prestigious Bugojno tournament in 1978 (shared) and 1980, the Linares tournament in 1981 (shared with Larry Christiansen) and 1994, the Tilburg tournament in 1977, 1979, 1980, 1982, and 1983, and the Soviet Championship in 1976, 1983, and 1988.\n\nKarpov represented the Soviet Union at six Chess Olympiads, in all of which the USSR won the team gold medal. He played first reserve at Skopje 1972, winning the board prize with 13/15. At Nice 1974, he advanced to board one and again won the board prize with 12/14. At La Valletta 1980, he was again board one and scored 9/12. At Lucerne 1982, he scored 6½/8 on board one. At Dubai 1986, he scored 6/9 on board two. His last was Thessaloniki 1988, where on board two he scored 8/10. In Olympiad play, Karpov lost only two games out of 68 played.\n\nTo illustrate Karpov's dominance over his peers as champion, his score was +11−2=20 versus Spassky, +5=12 versus Robert Hübner, +6−1=16 versus Ulf Andersson, +3−1=10 versus Vasily Smyslov, +1=16 versus Mikhail Tal, +10−2=13 versus Ljubojević.\n\nKarpov had cemented his position as the world's best player and world champion by the time Garry Kasparov arrived on the scene. In their first match, the World Chess Championship 1984, held in Moscow, with the victor again being the first to win six games outright, Karpov built a 4–0 lead after nine games. The next seventeen games were drawn, setting the record for world title matches, and it took Karpov until game 27 to gain his fifth win. In game 31, Karpov had a winning position but failed to take advantage and settled for a draw. He lost the next game, after which fourteen more draws ensued. In particular, Karpov held a solidly winning position in Game 41, but again blundered and had to settle for a draw. After Kasparov won games 47 and 48, FIDE President Florencio Campomanes unilaterally terminated the match, citing the health of the players. The match had lasted an unprecedented five months, with five wins for Karpov, three for Kasparov, and forty draws.\n\nA rematch was set for later in 1985, also in Moscow. The events of the so-called Marathon Match forced FIDE to return to the previous format, a match limited to 24 games (with Karpov remaining champion if the match should finish 12–12). Karpov needed to win the final game to draw the match and retain his title, but wound up losing, thus surrendering the title to his opponent. The final score was 13–11 (+3−5=16), in favour of Kasparov.\n\nKarpov remained a formidable opponent (and the world No. 2) until the early 1990s. He fought Kasparov in three more world championship matches in 1986 (held in London and Leningrad), 1987 (held in Seville), and 1990 (held in New York City and Lyon). All three matches were extremely close: the scores were 11½ to 12½ (+4−5=15), 12 to 12 (+4−4=16), and 11½ to 12½ (+3−4=17). In all three matches, Karpov had winning chances up to the very last games. In particular, the 1987 Seville match featured an astonishing blunder by Kasparov in the 23rd game. In the final game, needing only a draw to win the title, Karpov cracked under pressure from the clock at the end of the first session of play, missed a variation leading to an almost forced draw, and allowed Kasparov to adjourn the game with an extra pawn. After a further mistake in the second session, Karpov was slowly ground down and resigned on move 64, ending the match and allowing Kasparov to keep the title.\n\nIn their five world championship matches, Karpov scored 19 wins, 21 losses, and 104 draws in 144 games.\n\nKarpov is on record saying that if he had had the opportunity to play Fischer for the crown in his twenties, he could have been a much better player as a result.\n\nIn 1992, Karpov lost a Candidates Match against Nigel Short. But in 1993, Karpov reacquired the FIDE World Champion title when Kasparov and Short split from FIDE. Karpov defeated Timman – the loser of the Candidates' final against Short.\n\nThe next major meeting of Kasparov and Karpov was the 1994 Linares chess tournament. The field, in eventual finishing order, was Karpov, Kasparov, Shirov, Bareev, Kramnik, Lautier, Anand, Kamsky, Topalov, Ivanchuk, Gelfand, Illescas, Judit Polgár, and Beliavsky; with an average Elo rating of 2685, the highest ever at that time, making it the first Category XVIII tournament ever held. Impressed by the strength of the tournament, Kasparov had said several days before the tournament that the winner could rightly be called the world champion of tournaments. Perhaps spurred on by this comment, Karpov played the best tournament of his life. He was undefeated and earned 11 points out of 13 possible (the best world-class tournament winning percentage since Alekhine won San Remo in 1930), finishing 2½ points ahead of second-place Kasparov and Shirov. Many of his wins were spectacular (in particular, his win over Topalov is considered possibly the finest of his career). This performance against the best players in the world put his Elo rating tournament performance at 2985, the highest performance rating of any player in history up until 2009, when Magnus Carlsen won the category XXI Pearl Spring chess tournament with a performance of 3002. However, chess statistician Jeff Sonas considered Karpov's Linares performance to be the best tournament result in history.\n\nKarpov defended his FIDE title against Gata Kamsky (+6−3=9) in 1996. However, in 1998, FIDE largely scrapped the old system of Candidates' Matches, instead having a large knockout event in which a large number of players contested short matches against each other over just a few weeks. In the first of these events, the FIDE World Chess Championship 1998, champion Karpov was seeded straight into the final, defeating Viswanathan Anand (+2−2=2, rapid tiebreak 2:0). In the subsequent cycle, the format was changed, with the champion having to qualify. Karpov refused to defend his title, and ceased to be FIDE World Champion after the FIDE World Chess Championship 1999.\n\nKarpov's outstanding classical tournament play has been seriously limited since 1997, since he prefers to be more involved in politics of his home country of Russia. He had been a member of the Supreme Soviet Commission for Foreign Affairs and the President of the Soviet Peace Fund before the Soviet Union dissolved. In addition, he had been involved in several disputes with FIDE and became increasingly disillusioned with chess. In the September 2009 FIDE rating list, he dropped out of the world's Top 100 for the first time.\n\nKarpov usually limits his play to exhibition events, and has revamped his style to specialize in rapid chess. In 2002 he won a match against Kasparov, defeating him in a rapid time control match 2½–1½. In 2006, he tied for first with Kasparov in a blitz tournament, ahead of Korchnoi and Judit Polgár.\n\nKarpov and Kasparov played a mixed 12-game match from September 21–24, 2009, in Valencia, Spain. It consisted of four rapid (or semi rapid) and eight blitz games and took place exactly 25 years after the two players' legendary encounter at World Chess Championship 1984. Kasparov won the match 9–3.\n\nKarpov played a match against Yasser Seirawan in 2012 in St. Louis, Missouri, an important center of the North American chess scene, with Karpov winning the match 8–6 (+5−3=6) .\n\nIn November 2012, he won the Cap d'Agde rapid tournament which bears his name (Anatoly Karpov Trophy) by beating Vassily Ivanchuk (ranked 9th in the October 2012 FIDE world rankings) in the final.\n\nSince 2005, he has been a member of the Public Chamber of Russia. He has recently involved himself in several humanitarian causes, such as advocating the use of iodised salt. On December 17, 2012, Karpov supported the law in the Russian Parliament banning adoption of Russian orphans by citizens of the US.\n\nKarpov expressed support of the annexation of Crimea by the Russian Federation, and accused Europe of trying to demonise Putin.\n\n(Rapid, blitz and blindfold games not included; listed as +wins −losses =draws as of May 2, 2014.)<br>\nIn March 2010 Karpov announced that he would be a candidate for the presidency of FIDE. The election took place in September 2010 at the 39th Chess Olympiad. In May a fund-raising event took place in New York with the participation of his former rival Garry Kasparov and of Magnus Carlsen, both of whom supported his bid and campaigned for him. Also Nigel Short announced he supported Karpov's candidacy. However, on September 29, 2010, Kirsan Ilyumzhinov was reelected as President of FIDE, winning the election by 95 votes to 55.\n\nKarpov's \"boa constrictor\" playing style is solidly positional, taking no risks but reacting mercilessly to any tiny errors made by his opponents. As a result, he is often compared to his idol, the famous José Raúl Capablanca, the third World Champion. Karpov himself describes his style as follows:Let us say the game may be continued in two ways: one of them is a beautiful tactical blow that gives rise to variations that don't yield to precise calculations; the other is clear positional pressure that leads to an endgame with microscopic chances of victory... I would choose [the latter] without thinking twice. If the opponent offers keen play I don't object; but in such cases I get less satisfaction, even if I win, than from a game conducted according to all the rules of strategy with its ruthless logic.\n\n\nKarpov's extensive stamp collection of Belgium philately and Belgian Congo stamps and postal history covering mail from 1742 through 1980 was sold by David Feldman's auction company between December 2011 and 2012. He is also known to have a large chess stamp and chess book collections. His private chess library consists of over 9000 books.\n\n\nKarpov has authored or co-authored several books, most of which have been translated into English.\n\n\n\n \n", "id": "1020", "title": "Anatoly Karpov"},{"url": "https://en.wikipedia.org/wiki?curid=1021", "text": "Aspect ratio\n\nThe aspect ratio of a geometric shape is the ratio of its sizes in different dimensions. For example, the aspect ratio of a rectangle is the ratio of its longer side to its shorter sidethe ratio of width to height, when the rectangle is oriented as a \"landscape\".\n\nThe aspect ratio is expressed as two numbers separated by a colon (x:y). The values x and y do not represent actual widths and heights but, rather, the relationship between width and height. As an example, 8:5, 16:10 and 1.6:1 are three ways of representing the same aspect ratio.\n\nIn objects of more than two dimensions, such as hyperrectangles, the aspect ratio can still be defined as the ratio of the longest side to the shortest side.\n\nThe term is most commonly used with reference to:\n\nFor a rectangle, the aspect ratio denotes the ratio of the width to the height of the rectangle. A square has the smallest possible aspect ratio of 1:1.\n\nExamples:\n\nFor an ellipse, the aspect ratio denotes the ratio of the major axis to the minor axis. An ellipse with an aspect ratio of 1:1 is a circle.\n\nIn geometry, there are several alternative definitions to aspect ratios of general compact sets in a d-dimensional space:\n\n\nIf the dimension d is fixed, then all reasonable definitions of aspect ratio are equivalent to within constant factors.\n\nAspect ratios are mathematically expressed as \"x\":\"y\" (pronounced \"x-to-y\").\n\nCinematographic aspect ratios are usually denoted as a (rounded) decimal multiple of width vs unit height, while photographic and videographic aspect ratios are usually defined and denoted by whole number ratios of width to height. In digital images there is a subtle distinction between the \"Display\" Aspect Ratio (the image as displayed) and the \"Storage\" Aspect Ratio (the ratio of pixel dimensions); see Distinctions.\n\n", "id": "1021", "title": "Aspect ratio"},{"url": "https://en.wikipedia.org/wiki?curid=1022", "text": "Auto racing\n\nAuto racing (also known as car racing, motor racing or automobile racing) is a sport involving the racing of automobiles for competition.\n\nAlmost as soon as automobiles had been invented, races of various sorts were organised, with the first recorded as early as 1867. Many of the earliest events were effectively reliability trials, aimed at proving these new machines were a practical mode of transport, but soon became an important way for competing makers to demonstrate their machines. By the 1930s specialist racing cars had developed.\nThere are now numerous different categories, each with different rules and regulations.\n\nThe first prearranged match race of two self-powered road vehicles over a prescribed route occurred at 4:30 A.M. on August 30, 1867, between Ashton-under-Lyne and Old Trafford, a distance of eight miles. It was won by the carriage of Isaac Watt Boulton.\n\nInternal combustion auto racing events began soon after the construction of the first successful gasoline-fueled automobiles. The first organized contest was on April 28, 1887, by the chief editor of Paris publication \"Le Vélocipède\", Monsieur Fossier. It ran from Neuilly Bridge to the Bois de Boulogne.\n\nOn July 22, 1894, the Parisian magazine \"Le Petit Journal\" organized what is considered to be the world's first motoring competition, from Paris to Rouen. One hundred and two competitors paid a 10-franc entrance fee.\n\nThe first American automobile race is generally held to be the Thanksgiving Day \"Chicago Times-Herald\" race of November 28, 1895. Press coverage of the event first aroused significant American interest in the automobile.\n\nWith auto construction and racing dominated by France, the French automobile club ACF staged a number of major international races, usually from or to Paris, connecting with another major city, in France or elsewhere in Europe.\nBrooklands, in Surrey, was the first purpose-built motor racing venue, opening in June 1907. It featured a concrete track with high-speed banked corners.\n\nOne of the oldest existing purpose-built automobile racing circuits in the United States, still in use, is the 2.5-mile (4.02 km)-long Indianapolis Motor Speedway in Speedway, Indiana. It is the largest capacity sports venue of any variety worldwide, with a top capacity of some 257,000+ seated spectators.\n\nNASCAR was founded by Bill France, Sr. on February 21, 1948, with the help of several other drivers of the time. The first NASCAR \"Strictly Stock\" race ever was held on June 19, 1949, at Daytona Beach, Florida.\n\nFrom 1962, sports cars temporarily took a back seat to GT cars, with the FIA replacing the World Championship for Sports Cars with the International Championship for GT Manufacturers.\n\nFrom 1972 through 2003, NASCAR's premier series was called the Winston Cup Series, sponsored by R. J. Reynolds Tobacco Company cigarette brand Winston. The changes that resulted from RJR's involvement, as well as the reduction of the schedule from 48 to 31 races a year, established 1972 as the beginning of NASCAR's \"modern era\".\n\nThe IMSA GT Series evolved into the American Le Mans Series, which ran its first season in 1999. The European races eventually became the closely related Le Mans Series, both of which mix prototypes and GTs.\n\nThe two most popular varieties of open wheel racing are Formula One and the IndyCar Series.\n\nFormula One is a European-based series that runs only street and road courses. These cars are very technologically advanced, and are very fast through turns. These cars can go 375 kph (233 mph). Some of the famous races they run are the Monaco Grand Prix, the Italian Grand Prix, and the British Grand Prix. The season ends with the crowning of the World Championship for drivers and constructors.\n\nIn single-seater (open-wheel), the wheels are not covered, and the cars often have aerofoil wings front and rear to produce downforce and enhance adhesion to the track. In Europe and Asia, open-wheeled racing is commonly referred to as \"Formula\", with appropriate hierarchical suffixes. In North America, the \"Formula\" terminology is not followed (with the exception of F1). The sport is usually arranged to follow an international format (such as F1), a regional format (such as the Formula 3 Euro Series), and/or a domestic, or country-specific, format (such as the German Formula 3 championship, or the British Formula Ford).\n\nIn the Americas, the most popular series is the National Championship, more commonly known as the IndyCar Series and previously known as CART). The cars have traditionally been similar though less technologically sophisticated than F1 cars, with more restrictions on technology aimed at controlling costs. While these cars are not as technologically advanced, they are faster, being able to average a lap at 388 kph (241 mph). The series' biggest race is the Indianapolis 500, which is commonly referred to as \"The Greatest Spectacle in Racing\" due to being the longest continuously run race and having the largest crowd for a single-day sporting event (350,000+).\n\nThe other major international single-seater racing series is GP2 (formerly known as Formula 3000 and Formula Two). Regional series include Formula Nippon and Formula V6 Asia (specifically in Asia), Formula Renault 3.5 (also known as the World Series by Renault, succession series of World Series by Nissan), Formula Three, Formula Palmer Audi and Formula Atlantic. In 2009, the FIA Formula Two Championship brought about the revival of the F2 series. Domestic, or country-specific, series include Formula Three and Formula Renault, with the leading introductory series being Formula Ford.\n\nSingle-seater racing is not limited merely to professional teams and drivers. There exist many amateur racing clubs. In the UK, the major club series are the Monoposto Racing Club, BRSCC F3 (Formerly ClubF3, formerly ARP F3), Formula Vee and Club Formula Ford. Each series caters for a section of the market, with some primarily providing low-cost racing, while others aim for an authentic experience using the same regulations as the professional series (BRSCC F3).\n\nThere are other categories of single-seater racing, including kart racing, which employs a small, low-cost machine on small tracks. Many of the current top drivers began their careers in karts. Formula Ford represents the most popular first open-wheel category for up-and-coming drivers stepping up from karts. The series is still the preferred option, as it has introduced an aero package and slicks, allowing the junior drivers to gain experience in a race car with dynamics closer F1. The Star Mazda Series is another entry-level series.\n\nStudents at colleges and universities can also take part in single-seater racing through the Formula SAE competition, which involves designing and building a single-seater car in a multidisciplinary team and racing it at the competition. This also develops other soft skills, such as teamwork, while promoting motorsport and engineering.\n\nThe world's first all-female Formula racing team was created in 2006. The group was an assemblage of drivers from different racing disciplines and formed for an MTV reality pilot, which was shot at Mazda Raceway Laguna Seca.\nIn December 2005, the FIA gave approval to Superleague Formula racing, which debuted in 2008, whereby the racing teams are owned and run by prominent sports clubs such as A.C. Milan and Liverpool F.C.\n\nAfter 25 years away from the sport, former Formula 2 champion Jonathan Palmer reopened the F2 category again; most drivers have graduated from the Formula Palmer Audi series. The category is officially registered as the FIA Formula Two championship. Most rounds have two races and are support races to the FIA World Touring Car Championship.\n\nTouring car racing is a style of road racing that is run with production-derived race cars. It often features full-contact racing due to the small speed differentials and large grids.\n\nThe major touring car championships conducted worldwide are the Supercars Championship (Australia), British Touring Car Championship, Deutsche Tourenwagen Masters (DTM), and the World Touring Car Championship. The European Touring Car Cup is a one-day event open to Super 2000 specification touring cars from Europe's many national championships.\n\nThe Sports Car Club of America's SPEED World Challenge Touring Car and GT championships are dominant in North America. America's historic Trans-Am Series is undergoing a period of transition, but is still the longest-running road racing series in the U.S. The National Auto Sport Association also provides a venue for amateurs to compete in home-built factory-derived vehicles on various local circuits.\n\nIn sports car racing, production-derived versions of sports cars, also known as grand tourers (GTs), and purpose-built sports prototype cars compete within their respective classes on closed circuits. The premier championship series of sports car racing is the FIA World Endurance Championship. The main series for GT car racing is the FIA GT1 World Championship. There is also the FIA GT3 European Championship as well as the less powerful GT4 European Cup. Previously, an intermediate FIA GT2 European Championship existed, but the FIA dropped it to cut costs. Other major GT championships include the Japanese Super GT championship and the International GT Open for GT2 and GT3 cars. There are also national GT championships using mainly GT3 and GT4 cars featuring professional and amateur drivers alike.\nSports prototypes, unlike GT cars, do not rely on road-legal cars as a base. They are closed-wheel and often closed-cockpit purpose-built race cars intended mainly for endurance racing. They have much lower weight and more down force compared to GT cars, making them much faster. They are raced in the 24 hours of Le Mans (held annually since 1923) and in the (European) Le Mans series, Asian Le Mans Series and the WeatherTech SportsCar Championship. These cars are referred to as LMP (Le Mans prototype) cars with LMP1 being run mainly by manufacturers and the slightly less powerful LMP2 cars run by privateer teams. All three Le Mans Series run GT cars in addition to Le Mans Prototypes; these cars have different restrictions than the FIA GT cars.\n\nAnother prototype and GT racing championship exists in the United States; the Grand-Am, which began in 2000, sanctions its own endurance series, the Rolex Sports Car Series, which consists of slower and lower-cost race cars compared to LMP and FIA GT cars. The Rolex Sports Car Series and American Le Mans Series announced a merger between the two series forming the WeatherTech SportsCar Championship starting in 2014.\n\nThese races are often conducted over long distances, at least , and cars are driven by teams of two or more drivers, switching every few hours. Due to the performance difference between production-based sports cars and purpose-built sports prototypes, one race usually involves several racing classes, each fighting for their own championship.\n\nFamous sports car races include the 24 Hours of Le Mans, the Rolex 24 at Daytona, 24 Hours of Spa-Franchorchamps, the 12 Hours of Sebring, the 6 Hours of Watkins Glen, and the Petit Le Mans at Road Atlanta. There is also the 24 Hours of the Nürburgring on the infamous Nordschleife track and the Dubai 24 Hour, which is aimed at GT3 and below cars with a mixture of professional and pro-am drivers.\n\nProduction-car racing, otherwise known as \"showroom stock\" in the US, is an economical and rules-restricted version of touring-car racing, mainly used to restrict costs. Numerous production racing categories are based on particular makes of cars.\n\nMost series follow the Group N regulation with a few exceptions. There are several different series that are run all over the world, most notably, Japan's Super Taikyu and IMSA's Firehawk Series, which ran in the 1980s and 1990s all over the United States.\n\nOne-make, or single marque, championships often employ production-based cars from a single manufacturer or even a single model from a manufacturer's range. There are numerous notable one-make formulae from various countries and regions, some of which – such as the Porsche Supercup and, previously, IROC – have fostered many distinct national championships. Single marque series are often found at club level, to which the production-based cars, limited modifications, and close parity in performance are very well suited. Some of the better-known single-make series are the Mini 7 Championship (Europe's longest-running one make championship), the Radical European Masters, John Cooper Mini Challenge, Clio Cup, Ginettas, Caterhams, BMWs, and MX5s. There are also single-chassis single seater formulae, such as Formula Renault and Formula BMW, usually as \"feeder\" series for \"senior\" race formula (in the fashion of farm teams).\n\nIn North America, stock car racing is the most popular form of auto racing. Primarily raced on oval tracks, stock cars vaguely resemble production cars, but are in fact purpose-built racing machines that are built to tight specifications and also called Silhouette racing cars.\n\nThe largest stock car racing governing body is NASCAR (National Association for Stock Car Auto Racing). NASCAR's premier series is the Monster Energy Cup Series, its most famous races being the Daytona 500, the Southern 500, the Coca-Cola 600, and the Brickyard 400. NASCAR also runs several feeder series, including the Xfinity Series and Camping World Truck Series (a pickup truck racing series). The series conduct races across the entire continental United States. The NASCAR Pinty's Series conducts races across Canada and the NASCAR PEAK Mexico Series conducts races across Mexico.\n\nNASCAR also governs several smaller regional series, such as the Whelen Modified Tour. Modified cars are best described as open-wheel cars. Modified cars have no parts related to the stock vehicle for which they are named after. A number of modified cars display a \"manufacturer's\" logo and \"vehicle name\", yet use components produced by another automobile manufacturer.\n\nThere are also other stock car governing bodies, most notably the Automobile Racing Club of America (ARCA).\n\nIn the UK, British Stock car racing is also referred to as \"Short Circuit Racing\". This takes place on shale or tarmac tracks – usually around 1/4 mile long. The governing bodies for the sport are the Oval Racing Council (ORC) and BriSCA. Both bodies are made up of individual stadium promoters. There are around 35 tracks in the UK and upwards of 7000 active drivers. The sport is split into three basic divisions – distinguished by the rules regarding car contact during racing. The most famous championship is the BriSCA F1 Stock Cars. Full-contact formulas include Bangers, Bombers and Rookie Bangers – and racing features Demolitions Derbies, Figure of Eight racing and Oval Racing.\n\nSemi Contact Formulas include BriSCA F1, F2 and Superstox – where bumpers are used tactically.\n\nNon-contact formulas include National Hot Rods, Stock Rods and Lightning Rods.\n\nUK Stock car racing started in the 1950s and grew rapidly through the 1960s and 1970s.\n\nRallying at international and most national championship levels involves two classes of homologated road-legal production-based cars; Group N production cars and more modified Group A cars. Cars compete on closed public roads or off-road areas on a point-to-point format where participants and their co-drivers \"rally\" to a set of points, leaving in regular intervals from start points. A rally is typically conducted over a number of \"special stages\" on any terrain, which entrants are often allowed to scout beforehand at reduced speeds compiling detailed shorthand descriptions of the track or road as they go. These detailed descriptions are known as pace notes. During the actual rally, the co-driver reads the pace notes aloud (using an in-helmet intercom system) to the driver, enabling them to complete each stage as quickly as possible. Competition is based on lowest total elapsed time over the course of an event's special stages, including penalties.\n\nThe top series is the World Rally Championship (WRC), first contested in 1973, but there are also regional championships, and many countries have their own national championships. Some famous rallies include the Monte Carlo Rally, Rally Argentina, Rally Finland and Rally GB. Another famous event (actually best described as a rally raid) is the Paris-Dakar Rally, conceived in 1978. There are also many smaller, club level, categories of rallies, which are popular with amateurs, making up the \"grass roots\" of motor sports. Cars at this level may not comply fully with the requirements of group A or group N homologation.\nOther major rally events include the British Rally Championship, Intercontinental Rally Challenge, African Rally Championship, Asia-Pacific Rally Championship and endurance rally events like the Dakar Rally.\nThe Targa Tasmania, held on the Australian island state of Tasmania and run annually since 1992, takes its name from the Targa Florio, a former motoring event held on the island of Sicily. The competition concept is drawn directly from the best features of the Mille Miglia, the Coupe des Alpes and the Tour de Corse. Similarly named events around the world include the Targa Newfoundland based in Canada, Targa West based in Western Australia, Targa New Zealand and other smaller events.\n\nIn drag racing, the objective is to complete a given straight-line distance, from a standing start, ahead of a vehicle in a parallel lane. This distance is traditionally ¼ mile (400 m), though ⅛ mile (200 m) has become popular since the 1990s. The vehicles may or may not be given the signal to start at the same time, depending on the class of racing. Vehicles range from the everyday car to the purpose-built dragster. Speeds and elapsed time differ from class to class. Average street cars cover the ¼ mile in 12 to 16 seconds, whereas a top fuel dragster takes 4.5 seconds or less, reaching speeds of up to . Drag racing was organized as a sport by Wally Parks in the early 1950s through the NHRA (National Hot Rod Association). The NHRA was formed to discourage street racing.\n\nWhen launching, a top fuel dragster will accelerate at 3.4 g (33 m/s²), and when braking parachutes are deployed the deceleration is 4 g (39 m/s²), more than the Space Shuttle experiences. A top fuel car can be heard over away and can generate a reading from 1.5 to 3.9 on the Richter scale.\nDrag racing is two cars head-to-head, the winner proceeding to the next round. Professional classes are all first to the finish line wins. Sportsman racing is handicapped (slower car getting a head start) using an index (a lowest e.t. allowed), and cars running under (quicker than) their index \"break out\" and lose. The slowest cars, bracket racers, are also handicapped, but rather than an index, they use a dial-in.\n\nIn off-road racing, various classes of specially modified vehicles, including cars, compete in races through off-road environments. In North America these races often take place in the desert, such as the famous Baja 1000. Another format for off-road racing happens on closed-course short course tracks such as Crandon International Off-Road Raceway. In the 1980s and 1990s, short course was extended to racing inside stadiums in the Mickey Thompson Entertainment Group; this format was revived by Robby Gordon in 2013 with his Speed Energy Formula Off-Road series.\n\nIn Europe, \"offroad\" refers to events such as autocross or rallycross, while desert races and rally-raids such as the Paris-Dakar, Master Rallye or European \"bajas\" are called \"cross-country rallies.\"\n\nThe modern kart was invented by Art Ingels, a fabricator at the legendary Indianapolis-car manufacturer Kurtis-Kraft, in Southern California in 1956. Ingels took a small chainsaw engine and mounted it to a simple tube-frame chassis weighing less than 100 lb. Ingels, and everyone else who drove the kart, were startled at its performance capabilities. The sport soon blossomed in Southern California, and quickly spread around the world. Although often seen as the entry point for serious racers into the sport, kart racing, or karting, can be an economical way for amateurs to try racing and is also a fully fledged international sport in its own right. A large proportion of professional racing drivers began in karts, often from a very young age, such as Michael Schumacher and Fernando Alonso. Several former motorcycle champions have also taken up the sport, notably Wayne Rainey, who was paralysed in a racing accident and now races a hand-controlled kart. As one of the cheapest ways to race, karting is seeing its popularity grow worldwide.\n\nDespite their diminutive size, karting's most powerful class, superkart, can have a power-to-weight ratio of 440 hp/tonne.\n\nAs modern motor racing is centered on modern technology with a lots of corporate sponsors and politics involved, historical racing tends to be the opposite. Because it is based on a particular era it is more hobbyist oriented, reducing corporate sponsorship and politics. Events are regulated to only allow cars of a certain era to participate. The only modern equipment used is related to safety and timing. A historical event can be of a number of different motorsport disciplines.\nNotably some of the most famous events of them all are the Goodwood Festival of Speed and Goodwood Revival in Britain and Monterey Historic in the United States. Championships range from \"grass root\" Austin Seven racing to the FIA Thoroughbred Grand Prix Championship for classic Formula One chassis.\n\nWhile there are several professional teams and drivers in historical racing, this branch of auto sport tends to be contested by wealthy car owners and is thus more amateur and less competitive in its approach.\n\nIn many types of auto races, particularly those held on closed courses, flags are displayed to indicate the general status of the track and to communicate instructions to competitors. While individual series have different rules, and the flags have changed from the first years (e.g., red used to start a race), these are generally accepted.\n\nFor the worst accident in racing history see 1955 Le Mans disaster.\n\nIn auto racing, the racing setup or car setup is the set of adjustments made to the vehicle to optimize its behaviour (performance, handling, reliability, etc.). Adjustments can occur in suspensions, brakes, transmissions, engines, tires, and many others.\n\nAerodynamics and airflow play big roles in the setup of a racecar. Aerodynamic downforce improves the race car’s handling by lowering the center of gravity and distributing the weight of the car equally on each tire. Once this is achieved, fuel consumption decreases and the forces against the car are significantly lowered. Many aerodynamic experiments are conducted in wind tunnels, to simulate real life situations while measuring the various drag forces on the car. These “Rolling roads” produce many wind situations and direct air flow at certain speeds and angles. When a diffuser is installed under the car, the amount of drag force is significantly lowered, and the overall aerodynamics of the vehicle is positively adjusted. Wings and canards channel the airflow in the most efficient way to get the least amount of drag from the car. It is experimentally proven that downforce is gained and the vehicles handling is considerably changed when aerodynamic wings on the front and rear of the vehicle are installed.\n\nSuspension plays a huge part in giving the racecar the ability to be driven optimally. Shocks are mounted vertically or horizontally to prevent the body from rolling in the corners. The suspension is important because it makes the car stable and easier to control and keeps the tires on the road when driving on uneven terrain. It works in three different ways including vertically, longitudinally, and laterally to control movement when racing on various tracks.\n\nTires called R-Compounds are commonly used in motorsports for high amounts of traction. The soft rubber allows them to expand when they are heated up, making more surface area on the pavement, therefore producing the most amount of traction. These types of tires do not have treads on them. Tire pressure is dependent on the temperature of the tire and track when racing. Each time a driver pulls into the pits, the tire pressure and temperature should be tested for optimal performance. When the tires get too hot they will swell or inflate and need to be deflated to the correct pressure. When the tires are not warmed up they will not perform as well.\n\nBrakes on a race car are imperative in slowing and stopping the car at precise times and wear quickly depending on the road or track on which the car is being raced, how many laps are being run, track conditions due to weather, and how many caution runs require more braking. There are three variables to consider in racing: brake pedal displacement, brake pedal force, and vehicle deceleration. Various combinations of these variables work together to determine the stiffness, sensitivity, and pedal force of the brakes. When using the brakes effectively, the driver must go through a buildup phase and end with a modulating phase. These phases include attaining maximum deceleration and modulating the brake pressure. Brake performance is measured in bite and consistency. Bite happens when the driver first applies the brakes and they have not warmed up to the correct temperature to operate efficiently. Consistency is measured in how consistent the friction is during the entire time of braking. These two measurements determine the wear of the brakes.\n\nThe race car’s engine needs a considerable amount of air to produce maximum power. The air intake manifold sucks the air from scoops on the hood and front bumper and feeds it into the engine. Many engine modifications to increase horsepower and efficiency are commonly used in many racing sanctioning bodies. Engines are tuned on a machine called a dynamometer that is commonly known in the racing world as a DYNO. The car is driven onto the DYNO and many gauges and sensors are hooked up to the car that are controlled on an online program to test force, torque, or power. Through the testing, the car's engine maps can be changed to get the most amount of horsepower and ultimately speed out of the vehicle.\n\nRacing drivers at the highest levels are usually paid by the team, or by sponsors, and can command very substantial salaries.\n\nContrary to what may be popularly assumed, racing drivers as a group do not have unusually good reflexes. During countless physiological (and psychological) evaluations of professional racing drivers, the two characteristics that stand out are racers' near-obsessive need to control their surroundings (the psychological aspect), and an unusual ability to process fast-moving information (physiological). In this, researchers have noted a strong correlation between racers' psychological profiles and those of fighter pilots. In tests comparing racers to members of the general public, the greater the complexity of the information processing matrix, the greater the speed gap between racers and the public. Due partly to the performance capabilities of modern racing cars, racing drivers require a high level of fitness, focus and the ability to concentrate at high levels for long periods in an inherently difficult environment. Racing drivers mainly complain about pains in the lumbar, shoulder and neck regions.\n\nIn particular, racing cars such as formula cars and sports prototypes that generate a substantial amount of downforce are able to corner at speeds that impose extremely large g-forces on drivers. Formula 1 drivers routinely experience g-loadings in excess of 4.5 g.\n\n\n", "id": "1022", "title": "Auto racing"}]}